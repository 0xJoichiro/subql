(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(e){function n(n){for(var o,i,s=n[0],l=n[1],u=n[2],d=0,h=[];d<s.length;d++)i=s[d],Object.prototype.hasOwnProperty.call(r,i)&&r[i]&&h.push(r[i][0]),r[i]=0;for(o in l)Object.prototype.hasOwnProperty.call(l,o)&&(e[o]=l[o]);for(c&&c(n);h.length;)h.shift()();return a.push.apply(a,u||[]),t()}function t(){for(var e,n=0;n<a.length;n++){for(var t=a[n],o=!0,s=1;s<t.length;s++){var l=t[s];0!==r[l]&&(o=!1)}o&&(a.splice(n--,1),e=i(i.s=t[0]))}return e}var o={},r={3:0},a=[];function i(n){if(o[n])return o[n].exports;var t=o[n]={i:n,l:!1,exports:{}};return e[n].call(t.exports,t,t.exports,i),t.l=!0,t.exports}i.e=function(e){var n=[],t=r[e];if(0!==t)if(t)n.push(t[2]);else{var o=new Promise((function(n,o){t=r[e]=[n,o]}));n.push(t[2]=o);var a,s=document.createElement("script");s.charset="utf-8",s.timeout=120,i.nc&&s.setAttribute("nonce",i.nc),s.src=function(e){return i.p+"assets/js/"+({1:"vendors~layout-Blog~layout-Layout~layout-NotFound~layout-Slide",2:"vendors~layout-Blog~layout-Layout~layout-NotFound",4:"layout-Blog",5:"layout-Layout",6:"layout-NotFound",7:"layout-Slide",8:"page--1397d61e",9:"page--14d51344",10:"page--188a7204",11:"page--2a03c37e",12:"page--3bb71ffe",13:"page--47639a6e",14:"page--4806233e",15:"page--560420fe",16:"page--5dda9d1e",17:"page--8fbc73c4",18:"page--e894ac04",19:"page-AmbassadorProgram",20:"page-BrandingMaterials",21:"page-CommandLineFlags",22:"page-ConnecttoyourNewProject",23:"page-Connecttoyournewproject",24:"page-ContributingToSubQuery",25:"page-CreatingaSubQueryProject",26:"page-DeployaNewVersionofyourSubQueryProject",27:"page-DeployanewversionofyourSubQueryproject",28:"page-FrequentlyAskedQuestions",29:"page-GraphQLSchema",30:"page-GraphQL方案",31:"page-HelloWorld(SubQueryhosted)",32:"page-HelloWorld(localhost+Docker)",33:"page-HelloWorldExplained",34:"page-HowdoesaSubQuerydictionarywork",35:"page-Howtochangetheblockchainfetchingbatchsize",36:"page-HowtodebugaSubQueryproject",37:"page-Howtorunanindexernode",38:"page-Howtostartatadifferentblockheight",39:"page-InstallingSubQuery",40:"page-LearnmoreaboutGraphQL",41:"page-ManifestFile",42:"page-Mapping",43:"page-PublishyourSubQueryProject",44:"page-PublishyourSubQueryproject",45:"page-QueryyourProjectinSubQueryExplorer",46:"page-QuickStartGuide",47:"page-RunningSubQueryLocally",48:"page-SocialMediaLinks",49:"page-Terminology",50:"page-TheSandbox",51:"page-Tutorials",52:"page-TutorialsExamples",53:"page-Амбассадорскаяпрограмма",54:"page-СозданиеSubQueryпроекта",55:"page-Сопоставление",56:"page-СхемаGraphQL",57:"page-Частозадаваемыевопросы",58:"vendors~layout-Layout",59:"vendors~photo-swipe"}[e]||e)+"."+{1:"9352c3ab",2:"14c09c19",4:"3563f886",5:"f3e9cb51",6:"1d8fa5a1",7:"ba37b1c1",8:"7830a212",9:"78b27baf",10:"63a93a38",11:"c9233d2f",12:"fd469dc6",13:"5b83f810",14:"6e5d0422",15:"d47a4579",16:"96802880",17:"9b4851d0",18:"485b2823",19:"13b265a4",20:"6f8fa41f",21:"a6e55dbf",22:"95988254",23:"5d323d28",24:"3bfaf208",25:"5826dfad",26:"b8bdcbd9",27:"7e62f652",28:"5d649742",29:"81a5fc82",30:"48a349ff",31:"160eb727",32:"2038caec",33:"1410b096",34:"de9c5fcc",35:"6e72cfa7",36:"3563b98e",37:"74bbc149",38:"33303e40",39:"e2552f2d",40:"7281e99a",41:"dbd7f03b",42:"a1e209b8",43:"feeb209e",44:"f12c2f7c",45:"a3e65ba3",46:"0fa6a12c",47:"619fd947",48:"0a628575",49:"87f43072",50:"c54e9f28",51:"3c10e008",52:"0ae9231e",53:"a03093dd",54:"d8c9da88",55:"88970ab6",56:"4b65a27b",57:"3c81606e",58:"84ed3504",59:"f3e95bdf",60:"007c51f1"}[e]+".js"}(e);var l=new Error;a=function(n){s.onerror=s.onload=null,clearTimeout(u);var t=r[e];if(0!==t){if(t){var o=n&&("load"===n.type?"missing":n.type),a=n&&n.target&&n.target.src;l.message="Loading chunk "+e+" failed.\n("+o+": "+a+")",l.name="ChunkLoadError",l.type=o,l.request=a,t[1](l)}r[e]=void 0}};var u=setTimeout((function(){a({type:"timeout",target:s})}),12e4);s.onerror=s.onload=a,document.head.appendChild(s)}return Promise.all(n)},i.m=e,i.c=o,i.d=function(e,n,t){i.o(e,n)||Object.defineProperty(e,n,{enumerable:!0,get:t})},i.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},i.t=function(e,n){if(1&n&&(e=i(e)),8&n)return e;if(4&n&&"object"==typeof e&&e&&e.__esModule)return e;var t=Object.create(null);if(i.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:e}),2&n&&"string"!=typeof e)for(var o in e)i.d(t,o,function(n){return e[n]}.bind(null,o));return t},i.n=function(e){var n=e&&e.__esModule?function(){return e.default}:function(){return e};return i.d(n,"a",n),n},i.o=function(e,n){return Object.prototype.hasOwnProperty.call(e,n)},i.p="/",i.oe=function(e){throw console.error(e),e};var s=window.webpackJsonp=window.webpackJsonp||[],l=s.push.bind(s);s.push=n,s=s.slice();for(var u=0;u<s.length;u++)n(s[u]);var c=l;a.push([63,0]),t()}([function(e,n,t){"use strict";
/*!
 * Vue.js v2.6.14
 * (c) 2014-2021 Evan You
 * Released under the MIT License.
 */var o=Object.freeze({});function r(e){return null==e}function a(e){return null!=e}function i(e){return!0===e}function s(e){return"string"==typeof e||"number"==typeof e||"symbol"==typeof e||"boolean"==typeof e}function l(e){return null!==e&&"object"==typeof e}var u=Object.prototype.toString;function c(e){return"[object Object]"===u.call(e)}function d(e){return"[object RegExp]"===u.call(e)}function h(e){var n=parseFloat(String(e));return n>=0&&Math.floor(n)===n&&isFinite(e)}function p(e){return a(e)&&"function"==typeof e.then&&"function"==typeof e.catch}function y(e){return null==e?"":Array.isArray(e)||c(e)&&e.toString===u?JSON.stringify(e,null,2):String(e)}function m(e){var n=parseFloat(e);return isNaN(n)?e:n}function g(e,n){for(var t=Object.create(null),o=e.split(","),r=0;r<o.length;r++)t[o[r]]=!0;return n?function(e){return t[e.toLowerCase()]}:function(e){return t[e]}}g("slot,component",!0);var b=g("key,ref,slot,slot-scope,is");function f(e,n){if(e.length){var t=e.indexOf(n);if(t>-1)return e.splice(t,1)}}var w=Object.prototype.hasOwnProperty;function v(e,n){return w.call(e,n)}function k(e){var n=Object.create(null);return function(t){return n[t]||(n[t]=e(t))}}var q=/-(\w)/g,x=k((function(e){return e.replace(q,(function(e,n){return n?n.toUpperCase():""}))})),j=k((function(e){return e.charAt(0).toUpperCase()+e.slice(1)})),S=/\B([A-Z])/g,T=k((function(e){return e.replace(S,"-$1").toLowerCase()}));var Q=Function.prototype.bind?function(e,n){return e.bind(n)}:function(e,n){function t(t){var o=arguments.length;return o?o>1?e.apply(n,arguments):e.call(n,t):e.call(n)}return t._length=e.length,t};function I(e,n){n=n||0;for(var t=e.length-n,o=new Array(t);t--;)o[t]=e[t+n];return o}function P(e,n){for(var t in n)e[t]=n[t];return e}function z(e){for(var n={},t=0;t<e.length;t++)e[t]&&P(n,e[t]);return n}function C(e,n,t){}var _=function(e,n,t){return!1},A=function(e){return e};function E(e,n){if(e===n)return!0;var t=l(e),o=l(n);if(!t||!o)return!t&&!o&&String(e)===String(n);try{var r=Array.isArray(e),a=Array.isArray(n);if(r&&a)return e.length===n.length&&e.every((function(e,t){return E(e,n[t])}));if(e instanceof Date&&n instanceof Date)return e.getTime()===n.getTime();if(r||a)return!1;var i=Object.keys(e),s=Object.keys(n);return i.length===s.length&&i.every((function(t){return E(e[t],n[t])}))}catch(e){return!1}}function L(e,n){for(var t=0;t<e.length;t++)if(E(e[t],n))return t;return-1}function H(e){var n=!1;return function(){n||(n=!0,e.apply(this,arguments))}}var O=["component","directive","filter"],D=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch"],G={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:_,isReservedAttr:_,isUnknownElement:_,getTagNamespace:C,parsePlatformTagName:A,mustUseProp:_,async:!0,_lifecycleHooks:D},N=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function R(e,n,t,o){Object.defineProperty(e,n,{value:t,enumerable:!!o,writable:!0,configurable:!0})}var M=new RegExp("[^"+N.source+".$_\\d]");var W,B="__proto__"in{},F="undefined"!=typeof window,U="undefined"!=typeof WXEnvironment&&!!WXEnvironment.platform,Y=U&&WXEnvironment.platform.toLowerCase(),V=F&&window.navigator.userAgent.toLowerCase(),J=V&&/msie|trident/.test(V),$=V&&V.indexOf("msie 9.0")>0,K=V&&V.indexOf("edge/")>0,Z=(V&&V.indexOf("android"),V&&/iphone|ipad|ipod|ios/.test(V)||"ios"===Y),X=(V&&/chrome\/\d+/.test(V),V&&/phantomjs/.test(V),V&&V.match(/firefox\/(\d+)/)),ee={}.watch,ne=!1;if(F)try{var te={};Object.defineProperty(te,"passive",{get:function(){ne=!0}}),window.addEventListener("test-passive",null,te)}catch(e){}var oe=function(){return void 0===W&&(W=!F&&!U&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),W},re=F&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function ae(e){return"function"==typeof e&&/native code/.test(e.toString())}var ie,se="undefined"!=typeof Symbol&&ae(Symbol)&&"undefined"!=typeof Reflect&&ae(Reflect.ownKeys);ie="undefined"!=typeof Set&&ae(Set)?Set:function(){function e(){this.set=Object.create(null)}return e.prototype.has=function(e){return!0===this.set[e]},e.prototype.add=function(e){this.set[e]=!0},e.prototype.clear=function(){this.set=Object.create(null)},e}();var le=C,ue=0,ce=function(){this.id=ue++,this.subs=[]};ce.prototype.addSub=function(e){this.subs.push(e)},ce.prototype.removeSub=function(e){f(this.subs,e)},ce.prototype.depend=function(){ce.target&&ce.target.addDep(this)},ce.prototype.notify=function(){var e=this.subs.slice();for(var n=0,t=e.length;n<t;n++)e[n].update()},ce.target=null;var de=[];function he(e){de.push(e),ce.target=e}function pe(){de.pop(),ce.target=de[de.length-1]}var ye=function(e,n,t,o,r,a,i,s){this.tag=e,this.data=n,this.children=t,this.text=o,this.elm=r,this.ns=void 0,this.context=a,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=n&&n.key,this.componentOptions=i,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=s,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1},me={child:{configurable:!0}};me.child.get=function(){return this.componentInstance},Object.defineProperties(ye.prototype,me);var ge=function(e){void 0===e&&(e="");var n=new ye;return n.text=e,n.isComment=!0,n};function be(e){return new ye(void 0,void 0,void 0,String(e))}function fe(e){var n=new ye(e.tag,e.data,e.children&&e.children.slice(),e.text,e.elm,e.context,e.componentOptions,e.asyncFactory);return n.ns=e.ns,n.isStatic=e.isStatic,n.key=e.key,n.isComment=e.isComment,n.fnContext=e.fnContext,n.fnOptions=e.fnOptions,n.fnScopeId=e.fnScopeId,n.asyncMeta=e.asyncMeta,n.isCloned=!0,n}var we=Array.prototype,ve=Object.create(we);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(e){var n=we[e];R(ve,e,(function(){for(var t=[],o=arguments.length;o--;)t[o]=arguments[o];var r,a=n.apply(this,t),i=this.__ob__;switch(e){case"push":case"unshift":r=t;break;case"splice":r=t.slice(2)}return r&&i.observeArray(r),i.dep.notify(),a}))}));var ke=Object.getOwnPropertyNames(ve),qe=!0;function xe(e){qe=e}var je=function(e){this.value=e,this.dep=new ce,this.vmCount=0,R(e,"__ob__",this),Array.isArray(e)?(B?function(e,n){e.__proto__=n}(e,ve):function(e,n,t){for(var o=0,r=t.length;o<r;o++){var a=t[o];R(e,a,n[a])}}(e,ve,ke),this.observeArray(e)):this.walk(e)};function Se(e,n){var t;if(l(e)&&!(e instanceof ye))return v(e,"__ob__")&&e.__ob__ instanceof je?t=e.__ob__:qe&&!oe()&&(Array.isArray(e)||c(e))&&Object.isExtensible(e)&&!e._isVue&&(t=new je(e)),n&&t&&t.vmCount++,t}function Te(e,n,t,o,r){var a=new ce,i=Object.getOwnPropertyDescriptor(e,n);if(!i||!1!==i.configurable){var s=i&&i.get,l=i&&i.set;s&&!l||2!==arguments.length||(t=e[n]);var u=!r&&Se(t);Object.defineProperty(e,n,{enumerable:!0,configurable:!0,get:function(){var n=s?s.call(e):t;return ce.target&&(a.depend(),u&&(u.dep.depend(),Array.isArray(n)&&Pe(n))),n},set:function(n){var o=s?s.call(e):t;n===o||n!=n&&o!=o||s&&!l||(l?l.call(e,n):t=n,u=!r&&Se(n),a.notify())}})}}function Qe(e,n,t){if(Array.isArray(e)&&h(n))return e.length=Math.max(e.length,n),e.splice(n,1,t),t;if(n in e&&!(n in Object.prototype))return e[n]=t,t;var o=e.__ob__;return e._isVue||o&&o.vmCount?t:o?(Te(o.value,n,t),o.dep.notify(),t):(e[n]=t,t)}function Ie(e,n){if(Array.isArray(e)&&h(n))e.splice(n,1);else{var t=e.__ob__;e._isVue||t&&t.vmCount||v(e,n)&&(delete e[n],t&&t.dep.notify())}}function Pe(e){for(var n=void 0,t=0,o=e.length;t<o;t++)(n=e[t])&&n.__ob__&&n.__ob__.dep.depend(),Array.isArray(n)&&Pe(n)}je.prototype.walk=function(e){for(var n=Object.keys(e),t=0;t<n.length;t++)Te(e,n[t])},je.prototype.observeArray=function(e){for(var n=0,t=e.length;n<t;n++)Se(e[n])};var ze=G.optionMergeStrategies;function Ce(e,n){if(!n)return e;for(var t,o,r,a=se?Reflect.ownKeys(n):Object.keys(n),i=0;i<a.length;i++)"__ob__"!==(t=a[i])&&(o=e[t],r=n[t],v(e,t)?o!==r&&c(o)&&c(r)&&Ce(o,r):Qe(e,t,r));return e}function _e(e,n,t){return t?function(){var o="function"==typeof n?n.call(t,t):n,r="function"==typeof e?e.call(t,t):e;return o?Ce(o,r):r}:n?e?function(){return Ce("function"==typeof n?n.call(this,this):n,"function"==typeof e?e.call(this,this):e)}:n:e}function Ae(e,n){var t=n?e?e.concat(n):Array.isArray(n)?n:[n]:e;return t?function(e){for(var n=[],t=0;t<e.length;t++)-1===n.indexOf(e[t])&&n.push(e[t]);return n}(t):t}function Ee(e,n,t,o){var r=Object.create(e||null);return n?P(r,n):r}ze.data=function(e,n,t){return t?_e(e,n,t):n&&"function"!=typeof n?e:_e(e,n)},D.forEach((function(e){ze[e]=Ae})),O.forEach((function(e){ze[e+"s"]=Ee})),ze.watch=function(e,n,t,o){if(e===ee&&(e=void 0),n===ee&&(n=void 0),!n)return Object.create(e||null);if(!e)return n;var r={};for(var a in P(r,e),n){var i=r[a],s=n[a];i&&!Array.isArray(i)&&(i=[i]),r[a]=i?i.concat(s):Array.isArray(s)?s:[s]}return r},ze.props=ze.methods=ze.inject=ze.computed=function(e,n,t,o){if(!e)return n;var r=Object.create(null);return P(r,e),n&&P(r,n),r},ze.provide=_e;var Le=function(e,n){return void 0===n?e:n};function He(e,n,t){if("function"==typeof n&&(n=n.options),function(e,n){var t=e.props;if(t){var o,r,a={};if(Array.isArray(t))for(o=t.length;o--;)"string"==typeof(r=t[o])&&(a[x(r)]={type:null});else if(c(t))for(var i in t)r=t[i],a[x(i)]=c(r)?r:{type:r};else 0;e.props=a}}(n),function(e,n){var t=e.inject;if(t){var o=e.inject={};if(Array.isArray(t))for(var r=0;r<t.length;r++)o[t[r]]={from:t[r]};else if(c(t))for(var a in t){var i=t[a];o[a]=c(i)?P({from:a},i):{from:i}}else 0}}(n),function(e){var n=e.directives;if(n)for(var t in n){var o=n[t];"function"==typeof o&&(n[t]={bind:o,update:o})}}(n),!n._base&&(n.extends&&(e=He(e,n.extends,t)),n.mixins))for(var o=0,r=n.mixins.length;o<r;o++)e=He(e,n.mixins[o],t);var a,i={};for(a in e)s(a);for(a in n)v(e,a)||s(a);function s(o){var r=ze[o]||Le;i[o]=r(e[o],n[o],t,o)}return i}function Oe(e,n,t,o){if("string"==typeof t){var r=e[n];if(v(r,t))return r[t];var a=x(t);if(v(r,a))return r[a];var i=j(a);return v(r,i)?r[i]:r[t]||r[a]||r[i]}}function De(e,n,t,o){var r=n[e],a=!v(t,e),i=t[e],s=Me(Boolean,r.type);if(s>-1)if(a&&!v(r,"default"))i=!1;else if(""===i||i===T(e)){var l=Me(String,r.type);(l<0||s<l)&&(i=!0)}if(void 0===i){i=function(e,n,t){if(!v(n,"default"))return;var o=n.default;0;if(e&&e.$options.propsData&&void 0===e.$options.propsData[t]&&void 0!==e._props[t])return e._props[t];return"function"==typeof o&&"Function"!==Ne(n.type)?o.call(e):o}(o,r,e);var u=qe;xe(!0),Se(i),xe(u)}return i}var Ge=/^\s*function (\w+)/;function Ne(e){var n=e&&e.toString().match(Ge);return n?n[1]:""}function Re(e,n){return Ne(e)===Ne(n)}function Me(e,n){if(!Array.isArray(n))return Re(n,e)?0:-1;for(var t=0,o=n.length;t<o;t++)if(Re(n[t],e))return t;return-1}function We(e,n,t){he();try{if(n)for(var o=n;o=o.$parent;){var r=o.$options.errorCaptured;if(r)for(var a=0;a<r.length;a++)try{if(!1===r[a].call(o,e,n,t))return}catch(e){Fe(e,o,"errorCaptured hook")}}Fe(e,n,t)}finally{pe()}}function Be(e,n,t,o,r){var a;try{(a=t?e.apply(n,t):e.call(n))&&!a._isVue&&p(a)&&!a._handled&&(a.catch((function(e){return We(e,o,r+" (Promise/async)")})),a._handled=!0)}catch(e){We(e,o,r)}return a}function Fe(e,n,t){if(G.errorHandler)try{return G.errorHandler.call(null,e,n,t)}catch(n){n!==e&&Ue(n,null,"config.errorHandler")}Ue(e,n,t)}function Ue(e,n,t){if(!F&&!U||"undefined"==typeof console)throw e;console.error(e)}var Ye,Ve=!1,Je=[],$e=!1;function Ke(){$e=!1;var e=Je.slice(0);Je.length=0;for(var n=0;n<e.length;n++)e[n]()}if("undefined"!=typeof Promise&&ae(Promise)){var Ze=Promise.resolve();Ye=function(){Ze.then(Ke),Z&&setTimeout(C)},Ve=!0}else if(J||"undefined"==typeof MutationObserver||!ae(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())Ye="undefined"!=typeof setImmediate&&ae(setImmediate)?function(){setImmediate(Ke)}:function(){setTimeout(Ke,0)};else{var Xe=1,en=new MutationObserver(Ke),nn=document.createTextNode(String(Xe));en.observe(nn,{characterData:!0}),Ye=function(){Xe=(Xe+1)%2,nn.data=String(Xe)},Ve=!0}function tn(e,n){var t;if(Je.push((function(){if(e)try{e.call(n)}catch(e){We(e,n,"nextTick")}else t&&t(n)})),$e||($e=!0,Ye()),!e&&"undefined"!=typeof Promise)return new Promise((function(e){t=e}))}var on=new ie;function rn(e){!function e(n,t){var o,r,a=Array.isArray(n);if(!a&&!l(n)||Object.isFrozen(n)||n instanceof ye)return;if(n.__ob__){var i=n.__ob__.dep.id;if(t.has(i))return;t.add(i)}if(a)for(o=n.length;o--;)e(n[o],t);else for(r=Object.keys(n),o=r.length;o--;)e(n[r[o]],t)}(e,on),on.clear()}var an=k((function(e){var n="&"===e.charAt(0),t="~"===(e=n?e.slice(1):e).charAt(0),o="!"===(e=t?e.slice(1):e).charAt(0);return{name:e=o?e.slice(1):e,once:t,capture:o,passive:n}}));function sn(e,n){function t(){var e=arguments,o=t.fns;if(!Array.isArray(o))return Be(o,null,arguments,n,"v-on handler");for(var r=o.slice(),a=0;a<r.length;a++)Be(r[a],null,e,n,"v-on handler")}return t.fns=e,t}function ln(e,n,t,o,a,s){var l,u,c,d;for(l in e)u=e[l],c=n[l],d=an(l),r(u)||(r(c)?(r(u.fns)&&(u=e[l]=sn(u,s)),i(d.once)&&(u=e[l]=a(d.name,u,d.capture)),t(d.name,u,d.capture,d.passive,d.params)):u!==c&&(c.fns=u,e[l]=c));for(l in n)r(e[l])&&o((d=an(l)).name,n[l],d.capture)}function un(e,n,t){var o;e instanceof ye&&(e=e.data.hook||(e.data.hook={}));var s=e[n];function l(){t.apply(this,arguments),f(o.fns,l)}r(s)?o=sn([l]):a(s.fns)&&i(s.merged)?(o=s).fns.push(l):o=sn([s,l]),o.merged=!0,e[n]=o}function cn(e,n,t,o,r){if(a(n)){if(v(n,t))return e[t]=n[t],r||delete n[t],!0;if(v(n,o))return e[t]=n[o],r||delete n[o],!0}return!1}function dn(e){return s(e)?[be(e)]:Array.isArray(e)?function e(n,t){var o,l,u,c,d=[];for(o=0;o<n.length;o++)r(l=n[o])||"boolean"==typeof l||(u=d.length-1,c=d[u],Array.isArray(l)?l.length>0&&(hn((l=e(l,(t||"")+"_"+o))[0])&&hn(c)&&(d[u]=be(c.text+l[0].text),l.shift()),d.push.apply(d,l)):s(l)?hn(c)?d[u]=be(c.text+l):""!==l&&d.push(be(l)):hn(l)&&hn(c)?d[u]=be(c.text+l.text):(i(n._isVList)&&a(l.tag)&&r(l.key)&&a(t)&&(l.key="__vlist"+t+"_"+o+"__"),d.push(l)));return d}(e):void 0}function hn(e){return a(e)&&a(e.text)&&!1===e.isComment}function pn(e,n){if(e){for(var t=Object.create(null),o=se?Reflect.ownKeys(e):Object.keys(e),r=0;r<o.length;r++){var a=o[r];if("__ob__"!==a){for(var i=e[a].from,s=n;s;){if(s._provided&&v(s._provided,i)){t[a]=s._provided[i];break}s=s.$parent}if(!s)if("default"in e[a]){var l=e[a].default;t[a]="function"==typeof l?l.call(n):l}else 0}}return t}}function yn(e,n){if(!e||!e.length)return{};for(var t={},o=0,r=e.length;o<r;o++){var a=e[o],i=a.data;if(i&&i.attrs&&i.attrs.slot&&delete i.attrs.slot,a.context!==n&&a.fnContext!==n||!i||null==i.slot)(t.default||(t.default=[])).push(a);else{var s=i.slot,l=t[s]||(t[s]=[]);"template"===a.tag?l.push.apply(l,a.children||[]):l.push(a)}}for(var u in t)t[u].every(mn)&&delete t[u];return t}function mn(e){return e.isComment&&!e.asyncFactory||" "===e.text}function gn(e){return e.isComment&&e.asyncFactory}function bn(e,n,t){var r,a=Object.keys(n).length>0,i=e?!!e.$stable:!a,s=e&&e.$key;if(e){if(e._normalized)return e._normalized;if(i&&t&&t!==o&&s===t.$key&&!a&&!t.$hasNormal)return t;for(var l in r={},e)e[l]&&"$"!==l[0]&&(r[l]=fn(n,l,e[l]))}else r={};for(var u in n)u in r||(r[u]=wn(n,u));return e&&Object.isExtensible(e)&&(e._normalized=r),R(r,"$stable",i),R(r,"$key",s),R(r,"$hasNormal",a),r}function fn(e,n,t){var o=function(){var e=arguments.length?t.apply(null,arguments):t({}),n=(e=e&&"object"==typeof e&&!Array.isArray(e)?[e]:dn(e))&&e[0];return e&&(!n||1===e.length&&n.isComment&&!gn(n))?void 0:e};return t.proxy&&Object.defineProperty(e,n,{get:o,enumerable:!0,configurable:!0}),o}function wn(e,n){return function(){return e[n]}}function vn(e,n){var t,o,r,i,s;if(Array.isArray(e)||"string"==typeof e)for(t=new Array(e.length),o=0,r=e.length;o<r;o++)t[o]=n(e[o],o);else if("number"==typeof e)for(t=new Array(e),o=0;o<e;o++)t[o]=n(o+1,o);else if(l(e))if(se&&e[Symbol.iterator]){t=[];for(var u=e[Symbol.iterator](),c=u.next();!c.done;)t.push(n(c.value,t.length)),c=u.next()}else for(i=Object.keys(e),t=new Array(i.length),o=0,r=i.length;o<r;o++)s=i[o],t[o]=n(e[s],s,o);return a(t)||(t=[]),t._isVList=!0,t}function kn(e,n,t,o){var r,a=this.$scopedSlots[e];a?(t=t||{},o&&(t=P(P({},o),t)),r=a(t)||("function"==typeof n?n():n)):r=this.$slots[e]||("function"==typeof n?n():n);var i=t&&t.slot;return i?this.$createElement("template",{slot:i},r):r}function qn(e){return Oe(this.$options,"filters",e)||A}function xn(e,n){return Array.isArray(e)?-1===e.indexOf(n):e!==n}function jn(e,n,t,o,r){var a=G.keyCodes[n]||t;return r&&o&&!G.keyCodes[n]?xn(r,o):a?xn(a,e):o?T(o)!==n:void 0===e}function Sn(e,n,t,o,r){if(t)if(l(t)){var a;Array.isArray(t)&&(t=z(t));var i=function(i){if("class"===i||"style"===i||b(i))a=e;else{var s=e.attrs&&e.attrs.type;a=o||G.mustUseProp(n,s,i)?e.domProps||(e.domProps={}):e.attrs||(e.attrs={})}var l=x(i),u=T(i);l in a||u in a||(a[i]=t[i],r&&((e.on||(e.on={}))["update:"+i]=function(e){t[i]=e}))};for(var s in t)i(s)}else;return e}function Tn(e,n){var t=this._staticTrees||(this._staticTrees=[]),o=t[e];return o&&!n||In(o=t[e]=this.$options.staticRenderFns[e].call(this._renderProxy,null,this),"__static__"+e,!1),o}function Qn(e,n,t){return In(e,"__once__"+n+(t?"_"+t:""),!0),e}function In(e,n,t){if(Array.isArray(e))for(var o=0;o<e.length;o++)e[o]&&"string"!=typeof e[o]&&Pn(e[o],n+"_"+o,t);else Pn(e,n,t)}function Pn(e,n,t){e.isStatic=!0,e.key=n,e.isOnce=t}function zn(e,n){if(n)if(c(n)){var t=e.on=e.on?P({},e.on):{};for(var o in n){var r=t[o],a=n[o];t[o]=r?[].concat(r,a):a}}else;return e}function Cn(e,n,t,o){n=n||{$stable:!t};for(var r=0;r<e.length;r++){var a=e[r];Array.isArray(a)?Cn(a,n,t):a&&(a.proxy&&(a.fn.proxy=!0),n[a.key]=a.fn)}return o&&(n.$key=o),n}function _n(e,n){for(var t=0;t<n.length;t+=2){var o=n[t];"string"==typeof o&&o&&(e[n[t]]=n[t+1])}return e}function An(e,n){return"string"==typeof e?n+e:e}function En(e){e._o=Qn,e._n=m,e._s=y,e._l=vn,e._t=kn,e._q=E,e._i=L,e._m=Tn,e._f=qn,e._k=jn,e._b=Sn,e._v=be,e._e=ge,e._u=Cn,e._g=zn,e._d=_n,e._p=An}function Ln(e,n,t,r,a){var s,l=this,u=a.options;v(r,"_uid")?(s=Object.create(r))._original=r:(s=r,r=r._original);var c=i(u._compiled),d=!c;this.data=e,this.props=n,this.children=t,this.parent=r,this.listeners=e.on||o,this.injections=pn(u.inject,r),this.slots=function(){return l.$slots||bn(e.scopedSlots,l.$slots=yn(t,r)),l.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return bn(e.scopedSlots,this.slots())}}),c&&(this.$options=u,this.$slots=this.slots(),this.$scopedSlots=bn(e.scopedSlots,this.$slots)),u._scopeId?this._c=function(e,n,t,o){var a=Mn(s,e,n,t,o,d);return a&&!Array.isArray(a)&&(a.fnScopeId=u._scopeId,a.fnContext=r),a}:this._c=function(e,n,t,o){return Mn(s,e,n,t,o,d)}}function Hn(e,n,t,o,r){var a=fe(e);return a.fnContext=t,a.fnOptions=o,n.slot&&((a.data||(a.data={})).slot=n.slot),a}function On(e,n){for(var t in n)e[x(t)]=n[t]}En(Ln.prototype);var Dn={init:function(e,n){if(e.componentInstance&&!e.componentInstance._isDestroyed&&e.data.keepAlive){var t=e;Dn.prepatch(t,t)}else{(e.componentInstance=function(e,n){var t={_isComponent:!0,_parentVnode:e,parent:n},o=e.data.inlineTemplate;a(o)&&(t.render=o.render,t.staticRenderFns=o.staticRenderFns);return new e.componentOptions.Ctor(t)}(e,Kn)).$mount(n?e.elm:void 0,n)}},prepatch:function(e,n){var t=n.componentOptions;!function(e,n,t,r,a){0;var i=r.data.scopedSlots,s=e.$scopedSlots,l=!!(i&&!i.$stable||s!==o&&!s.$stable||i&&e.$scopedSlots.$key!==i.$key||!i&&e.$scopedSlots.$key),u=!!(a||e.$options._renderChildren||l);e.$options._parentVnode=r,e.$vnode=r,e._vnode&&(e._vnode.parent=r);if(e.$options._renderChildren=a,e.$attrs=r.data.attrs||o,e.$listeners=t||o,n&&e.$options.props){xe(!1);for(var c=e._props,d=e.$options._propKeys||[],h=0;h<d.length;h++){var p=d[h],y=e.$options.props;c[p]=De(p,y,n,e)}xe(!0),e.$options.propsData=n}t=t||o;var m=e.$options._parentListeners;e.$options._parentListeners=t,$n(e,t,m),u&&(e.$slots=yn(a,r.context),e.$forceUpdate());0}(n.componentInstance=e.componentInstance,t.propsData,t.listeners,n,t.children)},insert:function(e){var n,t=e.context,o=e.componentInstance;o._isMounted||(o._isMounted=!0,nt(o,"mounted")),e.data.keepAlive&&(t._isMounted?((n=o)._inactive=!1,ot.push(n)):et(o,!0))},destroy:function(e){var n=e.componentInstance;n._isDestroyed||(e.data.keepAlive?function e(n,t){if(t&&(n._directInactive=!0,Xn(n)))return;if(!n._inactive){n._inactive=!0;for(var o=0;o<n.$children.length;o++)e(n.$children[o]);nt(n,"deactivated")}}(n,!0):n.$destroy())}},Gn=Object.keys(Dn);function Nn(e,n,t,s,u){if(!r(e)){var c=t.$options._base;if(l(e)&&(e=c.extend(e)),"function"==typeof e){var d;if(r(e.cid)&&void 0===(e=function(e,n){if(i(e.error)&&a(e.errorComp))return e.errorComp;if(a(e.resolved))return e.resolved;var t=Bn;t&&a(e.owners)&&-1===e.owners.indexOf(t)&&e.owners.push(t);if(i(e.loading)&&a(e.loadingComp))return e.loadingComp;if(t&&!a(e.owners)){var o=e.owners=[t],s=!0,u=null,c=null;t.$on("hook:destroyed",(function(){return f(o,t)}));var d=function(e){for(var n=0,t=o.length;n<t;n++)o[n].$forceUpdate();e&&(o.length=0,null!==u&&(clearTimeout(u),u=null),null!==c&&(clearTimeout(c),c=null))},h=H((function(t){e.resolved=Fn(t,n),s?o.length=0:d(!0)})),y=H((function(n){a(e.errorComp)&&(e.error=!0,d(!0))})),m=e(h,y);return l(m)&&(p(m)?r(e.resolved)&&m.then(h,y):p(m.component)&&(m.component.then(h,y),a(m.error)&&(e.errorComp=Fn(m.error,n)),a(m.loading)&&(e.loadingComp=Fn(m.loading,n),0===m.delay?e.loading=!0:u=setTimeout((function(){u=null,r(e.resolved)&&r(e.error)&&(e.loading=!0,d(!1))}),m.delay||200)),a(m.timeout)&&(c=setTimeout((function(){c=null,r(e.resolved)&&y(null)}),m.timeout)))),s=!1,e.loading?e.loadingComp:e.resolved}}(d=e,c)))return function(e,n,t,o,r){var a=ge();return a.asyncFactory=e,a.asyncMeta={data:n,context:t,children:o,tag:r},a}(d,n,t,s,u);n=n||{},xt(e),a(n.model)&&function(e,n){var t=e.model&&e.model.prop||"value",o=e.model&&e.model.event||"input";(n.attrs||(n.attrs={}))[t]=n.model.value;var r=n.on||(n.on={}),i=r[o],s=n.model.callback;a(i)?(Array.isArray(i)?-1===i.indexOf(s):i!==s)&&(r[o]=[s].concat(i)):r[o]=s}(e.options,n);var h=function(e,n,t){var o=n.options.props;if(!r(o)){var i={},s=e.attrs,l=e.props;if(a(s)||a(l))for(var u in o){var c=T(u);cn(i,l,u,c,!0)||cn(i,s,u,c,!1)}return i}}(n,e);if(i(e.options.functional))return function(e,n,t,r,i){var s=e.options,l={},u=s.props;if(a(u))for(var c in u)l[c]=De(c,u,n||o);else a(t.attrs)&&On(l,t.attrs),a(t.props)&&On(l,t.props);var d=new Ln(t,l,i,r,e),h=s.render.call(null,d._c,d);if(h instanceof ye)return Hn(h,t,d.parent,s,d);if(Array.isArray(h)){for(var p=dn(h)||[],y=new Array(p.length),m=0;m<p.length;m++)y[m]=Hn(p[m],t,d.parent,s,d);return y}}(e,h,n,t,s);var y=n.on;if(n.on=n.nativeOn,i(e.options.abstract)){var m=n.slot;n={},m&&(n.slot=m)}!function(e){for(var n=e.hook||(e.hook={}),t=0;t<Gn.length;t++){var o=Gn[t],r=n[o],a=Dn[o];r===a||r&&r._merged||(n[o]=r?Rn(a,r):a)}}(n);var g=e.options.name||u;return new ye("vue-component-"+e.cid+(g?"-"+g:""),n,void 0,void 0,void 0,t,{Ctor:e,propsData:h,listeners:y,tag:u,children:s},d)}}}function Rn(e,n){var t=function(t,o){e(t,o),n(t,o)};return t._merged=!0,t}function Mn(e,n,t,o,u,c){return(Array.isArray(t)||s(t))&&(u=o,o=t,t=void 0),i(c)&&(u=2),function(e,n,t,o,s){if(a(t)&&a(t.__ob__))return ge();a(t)&&a(t.is)&&(n=t.is);if(!n)return ge();0;Array.isArray(o)&&"function"==typeof o[0]&&((t=t||{}).scopedSlots={default:o[0]},o.length=0);2===s?o=dn(o):1===s&&(o=function(e){for(var n=0;n<e.length;n++)if(Array.isArray(e[n]))return Array.prototype.concat.apply([],e);return e}(o));var u,c;if("string"==typeof n){var d;c=e.$vnode&&e.$vnode.ns||G.getTagNamespace(n),u=G.isReservedTag(n)?new ye(G.parsePlatformTagName(n),t,o,void 0,void 0,e):t&&t.pre||!a(d=Oe(e.$options,"components",n))?new ye(n,t,o,void 0,void 0,e):Nn(d,t,e,o,n)}else u=Nn(n,t,e,o);return Array.isArray(u)?u:a(u)?(a(c)&&function e(n,t,o){n.ns=t,"foreignObject"===n.tag&&(t=void 0,o=!0);if(a(n.children))for(var s=0,l=n.children.length;s<l;s++){var u=n.children[s];a(u.tag)&&(r(u.ns)||i(o)&&"svg"!==u.tag)&&e(u,t,o)}}(u,c),a(t)&&function(e){l(e.style)&&rn(e.style);l(e.class)&&rn(e.class)}(t),u):ge()}(e,n,t,o,u)}var Wn,Bn=null;function Fn(e,n){return(e.__esModule||se&&"Module"===e[Symbol.toStringTag])&&(e=e.default),l(e)?n.extend(e):e}function Un(e){if(Array.isArray(e))for(var n=0;n<e.length;n++){var t=e[n];if(a(t)&&(a(t.componentOptions)||gn(t)))return t}}function Yn(e,n){Wn.$on(e,n)}function Vn(e,n){Wn.$off(e,n)}function Jn(e,n){var t=Wn;return function o(){var r=n.apply(null,arguments);null!==r&&t.$off(e,o)}}function $n(e,n,t){Wn=e,ln(n,t||{},Yn,Vn,Jn,e),Wn=void 0}var Kn=null;function Zn(e){var n=Kn;return Kn=e,function(){Kn=n}}function Xn(e){for(;e&&(e=e.$parent);)if(e._inactive)return!0;return!1}function et(e,n){if(n){if(e._directInactive=!1,Xn(e))return}else if(e._directInactive)return;if(e._inactive||null===e._inactive){e._inactive=!1;for(var t=0;t<e.$children.length;t++)et(e.$children[t]);nt(e,"activated")}}function nt(e,n){he();var t=e.$options[n],o=n+" hook";if(t)for(var r=0,a=t.length;r<a;r++)Be(t[r],e,null,e,o);e._hasHookEvent&&e.$emit("hook:"+n),pe()}var tt=[],ot=[],rt={},at=!1,it=!1,st=0;var lt=0,ut=Date.now;if(F&&!J){var ct=window.performance;ct&&"function"==typeof ct.now&&ut()>document.createEvent("Event").timeStamp&&(ut=function(){return ct.now()})}function dt(){var e,n;for(lt=ut(),it=!0,tt.sort((function(e,n){return e.id-n.id})),st=0;st<tt.length;st++)(e=tt[st]).before&&e.before(),n=e.id,rt[n]=null,e.run();var t=ot.slice(),o=tt.slice();st=tt.length=ot.length=0,rt={},at=it=!1,function(e){for(var n=0;n<e.length;n++)e[n]._inactive=!0,et(e[n],!0)}(t),function(e){var n=e.length;for(;n--;){var t=e[n],o=t.vm;o._watcher===t&&o._isMounted&&!o._isDestroyed&&nt(o,"updated")}}(o),re&&G.devtools&&re.emit("flush")}var ht=0,pt=function(e,n,t,o,r){this.vm=e,r&&(e._watcher=this),e._watchers.push(this),o?(this.deep=!!o.deep,this.user=!!o.user,this.lazy=!!o.lazy,this.sync=!!o.sync,this.before=o.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++ht,this.active=!0,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new ie,this.newDepIds=new ie,this.expression="","function"==typeof n?this.getter=n:(this.getter=function(e){if(!M.test(e)){var n=e.split(".");return function(e){for(var t=0;t<n.length;t++){if(!e)return;e=e[n[t]]}return e}}}(n),this.getter||(this.getter=C)),this.value=this.lazy?void 0:this.get()};pt.prototype.get=function(){var e;he(this);var n=this.vm;try{e=this.getter.call(n,n)}catch(e){if(!this.user)throw e;We(e,n,'getter for watcher "'+this.expression+'"')}finally{this.deep&&rn(e),pe(),this.cleanupDeps()}return e},pt.prototype.addDep=function(e){var n=e.id;this.newDepIds.has(n)||(this.newDepIds.add(n),this.newDeps.push(e),this.depIds.has(n)||e.addSub(this))},pt.prototype.cleanupDeps=function(){for(var e=this.deps.length;e--;){var n=this.deps[e];this.newDepIds.has(n.id)||n.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},pt.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():function(e){var n=e.id;if(null==rt[n]){if(rt[n]=!0,it){for(var t=tt.length-1;t>st&&tt[t].id>e.id;)t--;tt.splice(t+1,0,e)}else tt.push(e);at||(at=!0,tn(dt))}}(this)},pt.prototype.run=function(){if(this.active){var e=this.get();if(e!==this.value||l(e)||this.deep){var n=this.value;if(this.value=e,this.user){var t='callback for watcher "'+this.expression+'"';Be(this.cb,this.vm,[e,n],this.vm,t)}else this.cb.call(this.vm,e,n)}}},pt.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},pt.prototype.depend=function(){for(var e=this.deps.length;e--;)this.deps[e].depend()},pt.prototype.teardown=function(){if(this.active){this.vm._isBeingDestroyed||f(this.vm._watchers,this);for(var e=this.deps.length;e--;)this.deps[e].removeSub(this);this.active=!1}};var yt={enumerable:!0,configurable:!0,get:C,set:C};function mt(e,n,t){yt.get=function(){return this[n][t]},yt.set=function(e){this[n][t]=e},Object.defineProperty(e,t,yt)}function gt(e){e._watchers=[];var n=e.$options;n.props&&function(e,n){var t=e.$options.propsData||{},o=e._props={},r=e.$options._propKeys=[];e.$parent&&xe(!1);var a=function(a){r.push(a);var i=De(a,n,t,e);Te(o,a,i),a in e||mt(e,"_props",a)};for(var i in n)a(i);xe(!0)}(e,n.props),n.methods&&function(e,n){e.$options.props;for(var t in n)e[t]="function"!=typeof n[t]?C:Q(n[t],e)}(e,n.methods),n.data?function(e){var n=e.$options.data;c(n=e._data="function"==typeof n?function(e,n){he();try{return e.call(n,n)}catch(e){return We(e,n,"data()"),{}}finally{pe()}}(n,e):n||{})||(n={});var t=Object.keys(n),o=e.$options.props,r=(e.$options.methods,t.length);for(;r--;){var a=t[r];0,o&&v(o,a)||(i=void 0,36!==(i=(a+"").charCodeAt(0))&&95!==i&&mt(e,"_data",a))}var i;Se(n,!0)}(e):Se(e._data={},!0),n.computed&&function(e,n){var t=e._computedWatchers=Object.create(null),o=oe();for(var r in n){var a=n[r],i="function"==typeof a?a:a.get;0,o||(t[r]=new pt(e,i||C,C,bt)),r in e||ft(e,r,a)}}(e,n.computed),n.watch&&n.watch!==ee&&function(e,n){for(var t in n){var o=n[t];if(Array.isArray(o))for(var r=0;r<o.length;r++)kt(e,t,o[r]);else kt(e,t,o)}}(e,n.watch)}var bt={lazy:!0};function ft(e,n,t){var o=!oe();"function"==typeof t?(yt.get=o?wt(n):vt(t),yt.set=C):(yt.get=t.get?o&&!1!==t.cache?wt(n):vt(t.get):C,yt.set=t.set||C),Object.defineProperty(e,n,yt)}function wt(e){return function(){var n=this._computedWatchers&&this._computedWatchers[e];if(n)return n.dirty&&n.evaluate(),ce.target&&n.depend(),n.value}}function vt(e){return function(){return e.call(this,this)}}function kt(e,n,t,o){return c(t)&&(o=t,t=t.handler),"string"==typeof t&&(t=e[t]),e.$watch(n,t,o)}var qt=0;function xt(e){var n=e.options;if(e.super){var t=xt(e.super);if(t!==e.superOptions){e.superOptions=t;var o=function(e){var n,t=e.options,o=e.sealedOptions;for(var r in t)t[r]!==o[r]&&(n||(n={}),n[r]=t[r]);return n}(e);o&&P(e.extendOptions,o),(n=e.options=He(t,e.extendOptions)).name&&(n.components[n.name]=e)}}return n}function jt(e){this._init(e)}function St(e){e.cid=0;var n=1;e.extend=function(e){e=e||{};var t=this,o=t.cid,r=e._Ctor||(e._Ctor={});if(r[o])return r[o];var a=e.name||t.options.name;var i=function(e){this._init(e)};return(i.prototype=Object.create(t.prototype)).constructor=i,i.cid=n++,i.options=He(t.options,e),i.super=t,i.options.props&&function(e){var n=e.options.props;for(var t in n)mt(e.prototype,"_props",t)}(i),i.options.computed&&function(e){var n=e.options.computed;for(var t in n)ft(e.prototype,t,n[t])}(i),i.extend=t.extend,i.mixin=t.mixin,i.use=t.use,O.forEach((function(e){i[e]=t[e]})),a&&(i.options.components[a]=i),i.superOptions=t.options,i.extendOptions=e,i.sealedOptions=P({},i.options),r[o]=i,i}}function Tt(e){return e&&(e.Ctor.options.name||e.tag)}function Qt(e,n){return Array.isArray(e)?e.indexOf(n)>-1:"string"==typeof e?e.split(",").indexOf(n)>-1:!!d(e)&&e.test(n)}function It(e,n){var t=e.cache,o=e.keys,r=e._vnode;for(var a in t){var i=t[a];if(i){var s=i.name;s&&!n(s)&&Pt(t,a,o,r)}}}function Pt(e,n,t,o){var r=e[n];!r||o&&r.tag===o.tag||r.componentInstance.$destroy(),e[n]=null,f(t,n)}!function(e){e.prototype._init=function(e){var n=this;n._uid=qt++,n._isVue=!0,e&&e._isComponent?function(e,n){var t=e.$options=Object.create(e.constructor.options),o=n._parentVnode;t.parent=n.parent,t._parentVnode=o;var r=o.componentOptions;t.propsData=r.propsData,t._parentListeners=r.listeners,t._renderChildren=r.children,t._componentTag=r.tag,n.render&&(t.render=n.render,t.staticRenderFns=n.staticRenderFns)}(n,e):n.$options=He(xt(n.constructor),e||{},n),n._renderProxy=n,n._self=n,function(e){var n=e.$options,t=n.parent;if(t&&!n.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(e)}e.$parent=t,e.$root=t?t.$root:e,e.$children=[],e.$refs={},e._watcher=null,e._inactive=null,e._directInactive=!1,e._isMounted=!1,e._isDestroyed=!1,e._isBeingDestroyed=!1}(n),function(e){e._events=Object.create(null),e._hasHookEvent=!1;var n=e.$options._parentListeners;n&&$n(e,n)}(n),function(e){e._vnode=null,e._staticTrees=null;var n=e.$options,t=e.$vnode=n._parentVnode,r=t&&t.context;e.$slots=yn(n._renderChildren,r),e.$scopedSlots=o,e._c=function(n,t,o,r){return Mn(e,n,t,o,r,!1)},e.$createElement=function(n,t,o,r){return Mn(e,n,t,o,r,!0)};var a=t&&t.data;Te(e,"$attrs",a&&a.attrs||o,null,!0),Te(e,"$listeners",n._parentListeners||o,null,!0)}(n),nt(n,"beforeCreate"),function(e){var n=pn(e.$options.inject,e);n&&(xe(!1),Object.keys(n).forEach((function(t){Te(e,t,n[t])})),xe(!0))}(n),gt(n),function(e){var n=e.$options.provide;n&&(e._provided="function"==typeof n?n.call(e):n)}(n),nt(n,"created"),n.$options.el&&n.$mount(n.$options.el)}}(jt),function(e){var n={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(e.prototype,"$data",n),Object.defineProperty(e.prototype,"$props",t),e.prototype.$set=Qe,e.prototype.$delete=Ie,e.prototype.$watch=function(e,n,t){if(c(n))return kt(this,e,n,t);(t=t||{}).user=!0;var o=new pt(this,e,n,t);if(t.immediate){var r='callback for immediate watcher "'+o.expression+'"';he(),Be(n,this,[o.value],this,r),pe()}return function(){o.teardown()}}}(jt),function(e){var n=/^hook:/;e.prototype.$on=function(e,t){var o=this;if(Array.isArray(e))for(var r=0,a=e.length;r<a;r++)o.$on(e[r],t);else(o._events[e]||(o._events[e]=[])).push(t),n.test(e)&&(o._hasHookEvent=!0);return o},e.prototype.$once=function(e,n){var t=this;function o(){t.$off(e,o),n.apply(t,arguments)}return o.fn=n,t.$on(e,o),t},e.prototype.$off=function(e,n){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(Array.isArray(e)){for(var o=0,r=e.length;o<r;o++)t.$off(e[o],n);return t}var a,i=t._events[e];if(!i)return t;if(!n)return t._events[e]=null,t;for(var s=i.length;s--;)if((a=i[s])===n||a.fn===n){i.splice(s,1);break}return t},e.prototype.$emit=function(e){var n=this,t=n._events[e];if(t){t=t.length>1?I(t):t;for(var o=I(arguments,1),r='event handler for "'+e+'"',a=0,i=t.length;a<i;a++)Be(t[a],n,o,n,r)}return n}}(jt),function(e){e.prototype._update=function(e,n){var t=this,o=t.$el,r=t._vnode,a=Zn(t);t._vnode=e,t.$el=r?t.__patch__(r,e):t.__patch__(t.$el,e,n,!1),a(),o&&(o.__vue__=null),t.$el&&(t.$el.__vue__=t),t.$vnode&&t.$parent&&t.$vnode===t.$parent._vnode&&(t.$parent.$el=t.$el)},e.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},e.prototype.$destroy=function(){var e=this;if(!e._isBeingDestroyed){nt(e,"beforeDestroy"),e._isBeingDestroyed=!0;var n=e.$parent;!n||n._isBeingDestroyed||e.$options.abstract||f(n.$children,e),e._watcher&&e._watcher.teardown();for(var t=e._watchers.length;t--;)e._watchers[t].teardown();e._data.__ob__&&e._data.__ob__.vmCount--,e._isDestroyed=!0,e.__patch__(e._vnode,null),nt(e,"destroyed"),e.$off(),e.$el&&(e.$el.__vue__=null),e.$vnode&&(e.$vnode.parent=null)}}}(jt),function(e){En(e.prototype),e.prototype.$nextTick=function(e){return tn(e,this)},e.prototype._render=function(){var e,n=this,t=n.$options,o=t.render,r=t._parentVnode;r&&(n.$scopedSlots=bn(r.data.scopedSlots,n.$slots,n.$scopedSlots)),n.$vnode=r;try{Bn=n,e=o.call(n._renderProxy,n.$createElement)}catch(t){We(t,n,"render"),e=n._vnode}finally{Bn=null}return Array.isArray(e)&&1===e.length&&(e=e[0]),e instanceof ye||(e=ge()),e.parent=r,e}}(jt);var zt=[String,RegExp,Array],Ct={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:zt,exclude:zt,max:[String,Number]},methods:{cacheVNode:function(){var e=this.cache,n=this.keys,t=this.vnodeToCache,o=this.keyToCache;if(t){var r=t.tag,a=t.componentInstance,i=t.componentOptions;e[o]={name:Tt(i),tag:r,componentInstance:a},n.push(o),this.max&&n.length>parseInt(this.max)&&Pt(e,n[0],n,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var e in this.cache)Pt(this.cache,e,this.keys)},mounted:function(){var e=this;this.cacheVNode(),this.$watch("include",(function(n){It(e,(function(e){return Qt(n,e)}))})),this.$watch("exclude",(function(n){It(e,(function(e){return!Qt(n,e)}))}))},updated:function(){this.cacheVNode()},render:function(){var e=this.$slots.default,n=Un(e),t=n&&n.componentOptions;if(t){var o=Tt(t),r=this.include,a=this.exclude;if(r&&(!o||!Qt(r,o))||a&&o&&Qt(a,o))return n;var i=this.cache,s=this.keys,l=null==n.key?t.Ctor.cid+(t.tag?"::"+t.tag:""):n.key;i[l]?(n.componentInstance=i[l].componentInstance,f(s,l),s.push(l)):(this.vnodeToCache=n,this.keyToCache=l),n.data.keepAlive=!0}return n||e&&e[0]}}};!function(e){var n={get:function(){return G}};Object.defineProperty(e,"config",n),e.util={warn:le,extend:P,mergeOptions:He,defineReactive:Te},e.set=Qe,e.delete=Ie,e.nextTick=tn,e.observable=function(e){return Se(e),e},e.options=Object.create(null),O.forEach((function(n){e.options[n+"s"]=Object.create(null)})),e.options._base=e,P(e.options.components,Ct),function(e){e.use=function(e){var n=this._installedPlugins||(this._installedPlugins=[]);if(n.indexOf(e)>-1)return this;var t=I(arguments,1);return t.unshift(this),"function"==typeof e.install?e.install.apply(e,t):"function"==typeof e&&e.apply(null,t),n.push(e),this}}(e),function(e){e.mixin=function(e){return this.options=He(this.options,e),this}}(e),St(e),function(e){O.forEach((function(n){e[n]=function(e,t){return t?("component"===n&&c(t)&&(t.name=t.name||e,t=this.options._base.extend(t)),"directive"===n&&"function"==typeof t&&(t={bind:t,update:t}),this.options[n+"s"][e]=t,t):this.options[n+"s"][e]}}))}(e)}(jt),Object.defineProperty(jt.prototype,"$isServer",{get:oe}),Object.defineProperty(jt.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(jt,"FunctionalRenderContext",{value:Ln}),jt.version="2.6.14";var _t=g("style,class"),At=g("input,textarea,option,select,progress"),Et=g("contenteditable,draggable,spellcheck"),Lt=g("events,caret,typing,plaintext-only"),Ht=g("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),Ot="http://www.w3.org/1999/xlink",Dt=function(e){return":"===e.charAt(5)&&"xlink"===e.slice(0,5)},Gt=function(e){return Dt(e)?e.slice(6,e.length):""},Nt=function(e){return null==e||!1===e};function Rt(e){for(var n=e.data,t=e,o=e;a(o.componentInstance);)(o=o.componentInstance._vnode)&&o.data&&(n=Mt(o.data,n));for(;a(t=t.parent);)t&&t.data&&(n=Mt(n,t.data));return function(e,n){if(a(e)||a(n))return Wt(e,Bt(n));return""}(n.staticClass,n.class)}function Mt(e,n){return{staticClass:Wt(e.staticClass,n.staticClass),class:a(e.class)?[e.class,n.class]:n.class}}function Wt(e,n){return e?n?e+" "+n:e:n||""}function Bt(e){return Array.isArray(e)?function(e){for(var n,t="",o=0,r=e.length;o<r;o++)a(n=Bt(e[o]))&&""!==n&&(t&&(t+=" "),t+=n);return t}(e):l(e)?function(e){var n="";for(var t in e)e[t]&&(n&&(n+=" "),n+=t);return n}(e):"string"==typeof e?e:""}var Ft={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},Ut=g("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),Yt=g("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),Vt=function(e){return Ut(e)||Yt(e)};var Jt=Object.create(null);var $t=g("text,number,password,search,email,tel,url");var Kt=Object.freeze({createElement:function(e,n){var t=document.createElement(e);return"select"!==e||n.data&&n.data.attrs&&void 0!==n.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(e,n){return document.createElementNS(Ft[e],n)},createTextNode:function(e){return document.createTextNode(e)},createComment:function(e){return document.createComment(e)},insertBefore:function(e,n,t){e.insertBefore(n,t)},removeChild:function(e,n){e.removeChild(n)},appendChild:function(e,n){e.appendChild(n)},parentNode:function(e){return e.parentNode},nextSibling:function(e){return e.nextSibling},tagName:function(e){return e.tagName},setTextContent:function(e,n){e.textContent=n},setStyleScope:function(e,n){e.setAttribute(n,"")}}),Zt={create:function(e,n){Xt(n)},update:function(e,n){e.data.ref!==n.data.ref&&(Xt(e,!0),Xt(n))},destroy:function(e){Xt(e,!0)}};function Xt(e,n){var t=e.data.ref;if(a(t)){var o=e.context,r=e.componentInstance||e.elm,i=o.$refs;n?Array.isArray(i[t])?f(i[t],r):i[t]===r&&(i[t]=void 0):e.data.refInFor?Array.isArray(i[t])?i[t].indexOf(r)<0&&i[t].push(r):i[t]=[r]:i[t]=r}}var eo=new ye("",{},[]),no=["create","activate","update","remove","destroy"];function to(e,n){return e.key===n.key&&e.asyncFactory===n.asyncFactory&&(e.tag===n.tag&&e.isComment===n.isComment&&a(e.data)===a(n.data)&&function(e,n){if("input"!==e.tag)return!0;var t,o=a(t=e.data)&&a(t=t.attrs)&&t.type,r=a(t=n.data)&&a(t=t.attrs)&&t.type;return o===r||$t(o)&&$t(r)}(e,n)||i(e.isAsyncPlaceholder)&&r(n.asyncFactory.error))}function oo(e,n,t){var o,r,i={};for(o=n;o<=t;++o)a(r=e[o].key)&&(i[r]=o);return i}var ro={create:ao,update:ao,destroy:function(e){ao(e,eo)}};function ao(e,n){(e.data.directives||n.data.directives)&&function(e,n){var t,o,r,a=e===eo,i=n===eo,s=so(e.data.directives,e.context),l=so(n.data.directives,n.context),u=[],c=[];for(t in l)o=s[t],r=l[t],o?(r.oldValue=o.value,r.oldArg=o.arg,uo(r,"update",n,e),r.def&&r.def.componentUpdated&&c.push(r)):(uo(r,"bind",n,e),r.def&&r.def.inserted&&u.push(r));if(u.length){var d=function(){for(var t=0;t<u.length;t++)uo(u[t],"inserted",n,e)};a?un(n,"insert",d):d()}c.length&&un(n,"postpatch",(function(){for(var t=0;t<c.length;t++)uo(c[t],"componentUpdated",n,e)}));if(!a)for(t in s)l[t]||uo(s[t],"unbind",e,e,i)}(e,n)}var io=Object.create(null);function so(e,n){var t,o,r=Object.create(null);if(!e)return r;for(t=0;t<e.length;t++)(o=e[t]).modifiers||(o.modifiers=io),r[lo(o)]=o,o.def=Oe(n.$options,"directives",o.name);return r}function lo(e){return e.rawName||e.name+"."+Object.keys(e.modifiers||{}).join(".")}function uo(e,n,t,o,r){var a=e.def&&e.def[n];if(a)try{a(t.elm,e,t,o,r)}catch(o){We(o,t.context,"directive "+e.name+" "+n+" hook")}}var co=[Zt,ro];function ho(e,n){var t=n.componentOptions;if(!(a(t)&&!1===t.Ctor.options.inheritAttrs||r(e.data.attrs)&&r(n.data.attrs))){var o,i,s=n.elm,l=e.data.attrs||{},u=n.data.attrs||{};for(o in a(u.__ob__)&&(u=n.data.attrs=P({},u)),u)i=u[o],l[o]!==i&&po(s,o,i,n.data.pre);for(o in(J||K)&&u.value!==l.value&&po(s,"value",u.value),l)r(u[o])&&(Dt(o)?s.removeAttributeNS(Ot,Gt(o)):Et(o)||s.removeAttribute(o))}}function po(e,n,t,o){o||e.tagName.indexOf("-")>-1?yo(e,n,t):Ht(n)?Nt(t)?e.removeAttribute(n):(t="allowfullscreen"===n&&"EMBED"===e.tagName?"true":n,e.setAttribute(n,t)):Et(n)?e.setAttribute(n,function(e,n){return Nt(n)||"false"===n?"false":"contenteditable"===e&&Lt(n)?n:"true"}(n,t)):Dt(n)?Nt(t)?e.removeAttributeNS(Ot,Gt(n)):e.setAttributeNS(Ot,n,t):yo(e,n,t)}function yo(e,n,t){if(Nt(t))e.removeAttribute(n);else{if(J&&!$&&"TEXTAREA"===e.tagName&&"placeholder"===n&&""!==t&&!e.__ieph){var o=function(n){n.stopImmediatePropagation(),e.removeEventListener("input",o)};e.addEventListener("input",o),e.__ieph=!0}e.setAttribute(n,t)}}var mo={create:ho,update:ho};function go(e,n){var t=n.elm,o=n.data,i=e.data;if(!(r(o.staticClass)&&r(o.class)&&(r(i)||r(i.staticClass)&&r(i.class)))){var s=Rt(n),l=t._transitionClasses;a(l)&&(s=Wt(s,Bt(l))),s!==t._prevClass&&(t.setAttribute("class",s),t._prevClass=s)}}var bo,fo={create:go,update:go};function wo(e,n,t){var o=bo;return function r(){var a=n.apply(null,arguments);null!==a&&qo(e,r,t,o)}}var vo=Ve&&!(X&&Number(X[1])<=53);function ko(e,n,t,o){if(vo){var r=lt,a=n;n=a._wrapper=function(e){if(e.target===e.currentTarget||e.timeStamp>=r||e.timeStamp<=0||e.target.ownerDocument!==document)return a.apply(this,arguments)}}bo.addEventListener(e,n,ne?{capture:t,passive:o}:t)}function qo(e,n,t,o){(o||bo).removeEventListener(e,n._wrapper||n,t)}function xo(e,n){if(!r(e.data.on)||!r(n.data.on)){var t=n.data.on||{},o=e.data.on||{};bo=n.elm,function(e){if(a(e.__r)){var n=J?"change":"input";e[n]=[].concat(e.__r,e[n]||[]),delete e.__r}a(e.__c)&&(e.change=[].concat(e.__c,e.change||[]),delete e.__c)}(t),ln(t,o,ko,qo,wo,n.context),bo=void 0}}var jo,So={create:xo,update:xo};function To(e,n){if(!r(e.data.domProps)||!r(n.data.domProps)){var t,o,i=n.elm,s=e.data.domProps||{},l=n.data.domProps||{};for(t in a(l.__ob__)&&(l=n.data.domProps=P({},l)),s)t in l||(i[t]="");for(t in l){if(o=l[t],"textContent"===t||"innerHTML"===t){if(n.children&&(n.children.length=0),o===s[t])continue;1===i.childNodes.length&&i.removeChild(i.childNodes[0])}if("value"===t&&"PROGRESS"!==i.tagName){i._value=o;var u=r(o)?"":String(o);Qo(i,u)&&(i.value=u)}else if("innerHTML"===t&&Yt(i.tagName)&&r(i.innerHTML)){(jo=jo||document.createElement("div")).innerHTML="<svg>"+o+"</svg>";for(var c=jo.firstChild;i.firstChild;)i.removeChild(i.firstChild);for(;c.firstChild;)i.appendChild(c.firstChild)}else if(o!==s[t])try{i[t]=o}catch(e){}}}}function Qo(e,n){return!e.composing&&("OPTION"===e.tagName||function(e,n){var t=!0;try{t=document.activeElement!==e}catch(e){}return t&&e.value!==n}(e,n)||function(e,n){var t=e.value,o=e._vModifiers;if(a(o)){if(o.number)return m(t)!==m(n);if(o.trim)return t.trim()!==n.trim()}return t!==n}(e,n))}var Io={create:To,update:To},Po=k((function(e){var n={},t=/:(.+)/;return e.split(/;(?![^(]*\))/g).forEach((function(e){if(e){var o=e.split(t);o.length>1&&(n[o[0].trim()]=o[1].trim())}})),n}));function zo(e){var n=Co(e.style);return e.staticStyle?P(e.staticStyle,n):n}function Co(e){return Array.isArray(e)?z(e):"string"==typeof e?Po(e):e}var _o,Ao=/^--/,Eo=/\s*!important$/,Lo=function(e,n,t){if(Ao.test(n))e.style.setProperty(n,t);else if(Eo.test(t))e.style.setProperty(T(n),t.replace(Eo,""),"important");else{var o=Oo(n);if(Array.isArray(t))for(var r=0,a=t.length;r<a;r++)e.style[o]=t[r];else e.style[o]=t}},Ho=["Webkit","Moz","ms"],Oo=k((function(e){if(_o=_o||document.createElement("div").style,"filter"!==(e=x(e))&&e in _o)return e;for(var n=e.charAt(0).toUpperCase()+e.slice(1),t=0;t<Ho.length;t++){var o=Ho[t]+n;if(o in _o)return o}}));function Do(e,n){var t=n.data,o=e.data;if(!(r(t.staticStyle)&&r(t.style)&&r(o.staticStyle)&&r(o.style))){var i,s,l=n.elm,u=o.staticStyle,c=o.normalizedStyle||o.style||{},d=u||c,h=Co(n.data.style)||{};n.data.normalizedStyle=a(h.__ob__)?P({},h):h;var p=function(e,n){var t,o={};if(n)for(var r=e;r.componentInstance;)(r=r.componentInstance._vnode)&&r.data&&(t=zo(r.data))&&P(o,t);(t=zo(e.data))&&P(o,t);for(var a=e;a=a.parent;)a.data&&(t=zo(a.data))&&P(o,t);return o}(n,!0);for(s in d)r(p[s])&&Lo(l,s,"");for(s in p)(i=p[s])!==d[s]&&Lo(l,s,null==i?"":i)}}var Go={create:Do,update:Do},No=/\s+/;function Ro(e,n){if(n&&(n=n.trim()))if(e.classList)n.indexOf(" ")>-1?n.split(No).forEach((function(n){return e.classList.add(n)})):e.classList.add(n);else{var t=" "+(e.getAttribute("class")||"")+" ";t.indexOf(" "+n+" ")<0&&e.setAttribute("class",(t+n).trim())}}function Mo(e,n){if(n&&(n=n.trim()))if(e.classList)n.indexOf(" ")>-1?n.split(No).forEach((function(n){return e.classList.remove(n)})):e.classList.remove(n),e.classList.length||e.removeAttribute("class");else{for(var t=" "+(e.getAttribute("class")||"")+" ",o=" "+n+" ";t.indexOf(o)>=0;)t=t.replace(o," ");(t=t.trim())?e.setAttribute("class",t):e.removeAttribute("class")}}function Wo(e){if(e){if("object"==typeof e){var n={};return!1!==e.css&&P(n,Bo(e.name||"v")),P(n,e),n}return"string"==typeof e?Bo(e):void 0}}var Bo=k((function(e){return{enterClass:e+"-enter",enterToClass:e+"-enter-to",enterActiveClass:e+"-enter-active",leaveClass:e+"-leave",leaveToClass:e+"-leave-to",leaveActiveClass:e+"-leave-active"}})),Fo=F&&!$,Uo="transition",Yo="transitionend",Vo="animation",Jo="animationend";Fo&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(Uo="WebkitTransition",Yo="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(Vo="WebkitAnimation",Jo="webkitAnimationEnd"));var $o=F?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(e){return e()};function Ko(e){$o((function(){$o(e)}))}function Zo(e,n){var t=e._transitionClasses||(e._transitionClasses=[]);t.indexOf(n)<0&&(t.push(n),Ro(e,n))}function Xo(e,n){e._transitionClasses&&f(e._transitionClasses,n),Mo(e,n)}function er(e,n,t){var o=tr(e,n),r=o.type,a=o.timeout,i=o.propCount;if(!r)return t();var s="transition"===r?Yo:Jo,l=0,u=function(){e.removeEventListener(s,c),t()},c=function(n){n.target===e&&++l>=i&&u()};setTimeout((function(){l<i&&u()}),a+1),e.addEventListener(s,c)}var nr=/\b(transform|all)(,|$)/;function tr(e,n){var t,o=window.getComputedStyle(e),r=(o[Uo+"Delay"]||"").split(", "),a=(o[Uo+"Duration"]||"").split(", "),i=or(r,a),s=(o[Vo+"Delay"]||"").split(", "),l=(o[Vo+"Duration"]||"").split(", "),u=or(s,l),c=0,d=0;return"transition"===n?i>0&&(t="transition",c=i,d=a.length):"animation"===n?u>0&&(t="animation",c=u,d=l.length):d=(t=(c=Math.max(i,u))>0?i>u?"transition":"animation":null)?"transition"===t?a.length:l.length:0,{type:t,timeout:c,propCount:d,hasTransform:"transition"===t&&nr.test(o[Uo+"Property"])}}function or(e,n){for(;e.length<n.length;)e=e.concat(e);return Math.max.apply(null,n.map((function(n,t){return rr(n)+rr(e[t])})))}function rr(e){return 1e3*Number(e.slice(0,-1).replace(",","."))}function ar(e,n){var t=e.elm;a(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var o=Wo(e.data.transition);if(!r(o)&&!a(t._enterCb)&&1===t.nodeType){for(var i=o.css,s=o.type,u=o.enterClass,c=o.enterToClass,d=o.enterActiveClass,h=o.appearClass,p=o.appearToClass,y=o.appearActiveClass,g=o.beforeEnter,b=o.enter,f=o.afterEnter,w=o.enterCancelled,v=o.beforeAppear,k=o.appear,q=o.afterAppear,x=o.appearCancelled,j=o.duration,S=Kn,T=Kn.$vnode;T&&T.parent;)S=T.context,T=T.parent;var Q=!S._isMounted||!e.isRootInsert;if(!Q||k||""===k){var I=Q&&h?h:u,P=Q&&y?y:d,z=Q&&p?p:c,C=Q&&v||g,_=Q&&"function"==typeof k?k:b,A=Q&&q||f,E=Q&&x||w,L=m(l(j)?j.enter:j);0;var O=!1!==i&&!$,D=lr(_),G=t._enterCb=H((function(){O&&(Xo(t,z),Xo(t,P)),G.cancelled?(O&&Xo(t,I),E&&E(t)):A&&A(t),t._enterCb=null}));e.data.show||un(e,"insert",(function(){var n=t.parentNode,o=n&&n._pending&&n._pending[e.key];o&&o.tag===e.tag&&o.elm._leaveCb&&o.elm._leaveCb(),_&&_(t,G)})),C&&C(t),O&&(Zo(t,I),Zo(t,P),Ko((function(){Xo(t,I),G.cancelled||(Zo(t,z),D||(sr(L)?setTimeout(G,L):er(t,s,G)))}))),e.data.show&&(n&&n(),_&&_(t,G)),O||D||G()}}}function ir(e,n){var t=e.elm;a(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var o=Wo(e.data.transition);if(r(o)||1!==t.nodeType)return n();if(!a(t._leaveCb)){var i=o.css,s=o.type,u=o.leaveClass,c=o.leaveToClass,d=o.leaveActiveClass,h=o.beforeLeave,p=o.leave,y=o.afterLeave,g=o.leaveCancelled,b=o.delayLeave,f=o.duration,w=!1!==i&&!$,v=lr(p),k=m(l(f)?f.leave:f);0;var q=t._leaveCb=H((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[e.key]=null),w&&(Xo(t,c),Xo(t,d)),q.cancelled?(w&&Xo(t,u),g&&g(t)):(n(),y&&y(t)),t._leaveCb=null}));b?b(x):x()}function x(){q.cancelled||(!e.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[e.key]=e),h&&h(t),w&&(Zo(t,u),Zo(t,d),Ko((function(){Xo(t,u),q.cancelled||(Zo(t,c),v||(sr(k)?setTimeout(q,k):er(t,s,q)))}))),p&&p(t,q),w||v||q())}}function sr(e){return"number"==typeof e&&!isNaN(e)}function lr(e){if(r(e))return!1;var n=e.fns;return a(n)?lr(Array.isArray(n)?n[0]:n):(e._length||e.length)>1}function ur(e,n){!0!==n.data.show&&ar(n)}var cr=function(e){var n,t,o={},l=e.modules,u=e.nodeOps;for(n=0;n<no.length;++n)for(o[no[n]]=[],t=0;t<l.length;++t)a(l[t][no[n]])&&o[no[n]].push(l[t][no[n]]);function c(e){var n=u.parentNode(e);a(n)&&u.removeChild(n,e)}function d(e,n,t,r,s,l,c){if(a(e.elm)&&a(l)&&(e=l[c]=fe(e)),e.isRootInsert=!s,!function(e,n,t,r){var s=e.data;if(a(s)){var l=a(e.componentInstance)&&s.keepAlive;if(a(s=s.hook)&&a(s=s.init)&&s(e,!1),a(e.componentInstance))return h(e,n),p(t,e.elm,r),i(l)&&function(e,n,t,r){var i,s=e;for(;s.componentInstance;)if(s=s.componentInstance._vnode,a(i=s.data)&&a(i=i.transition)){for(i=0;i<o.activate.length;++i)o.activate[i](eo,s);n.push(s);break}p(t,e.elm,r)}(e,n,t,r),!0}}(e,n,t,r)){var d=e.data,m=e.children,g=e.tag;a(g)?(e.elm=e.ns?u.createElementNS(e.ns,g):u.createElement(g,e),f(e),y(e,m,n),a(d)&&b(e,n),p(t,e.elm,r)):i(e.isComment)?(e.elm=u.createComment(e.text),p(t,e.elm,r)):(e.elm=u.createTextNode(e.text),p(t,e.elm,r))}}function h(e,n){a(e.data.pendingInsert)&&(n.push.apply(n,e.data.pendingInsert),e.data.pendingInsert=null),e.elm=e.componentInstance.$el,m(e)?(b(e,n),f(e)):(Xt(e),n.push(e))}function p(e,n,t){a(e)&&(a(t)?u.parentNode(t)===e&&u.insertBefore(e,n,t):u.appendChild(e,n))}function y(e,n,t){if(Array.isArray(n)){0;for(var o=0;o<n.length;++o)d(n[o],t,e.elm,null,!0,n,o)}else s(e.text)&&u.appendChild(e.elm,u.createTextNode(String(e.text)))}function m(e){for(;e.componentInstance;)e=e.componentInstance._vnode;return a(e.tag)}function b(e,t){for(var r=0;r<o.create.length;++r)o.create[r](eo,e);a(n=e.data.hook)&&(a(n.create)&&n.create(eo,e),a(n.insert)&&t.push(e))}function f(e){var n;if(a(n=e.fnScopeId))u.setStyleScope(e.elm,n);else for(var t=e;t;)a(n=t.context)&&a(n=n.$options._scopeId)&&u.setStyleScope(e.elm,n),t=t.parent;a(n=Kn)&&n!==e.context&&n!==e.fnContext&&a(n=n.$options._scopeId)&&u.setStyleScope(e.elm,n)}function w(e,n,t,o,r,a){for(;o<=r;++o)d(t[o],a,e,n,!1,t,o)}function v(e){var n,t,r=e.data;if(a(r))for(a(n=r.hook)&&a(n=n.destroy)&&n(e),n=0;n<o.destroy.length;++n)o.destroy[n](e);if(a(n=e.children))for(t=0;t<e.children.length;++t)v(e.children[t])}function k(e,n,t){for(;n<=t;++n){var o=e[n];a(o)&&(a(o.tag)?(q(o),v(o)):c(o.elm))}}function q(e,n){if(a(n)||a(e.data)){var t,r=o.remove.length+1;for(a(n)?n.listeners+=r:n=function(e,n){function t(){0==--t.listeners&&c(e)}return t.listeners=n,t}(e.elm,r),a(t=e.componentInstance)&&a(t=t._vnode)&&a(t.data)&&q(t,n),t=0;t<o.remove.length;++t)o.remove[t](e,n);a(t=e.data.hook)&&a(t=t.remove)?t(e,n):n()}else c(e.elm)}function x(e,n,t,o){for(var r=t;r<o;r++){var i=n[r];if(a(i)&&to(e,i))return r}}function j(e,n,t,s,l,c){if(e!==n){a(n.elm)&&a(s)&&(n=s[l]=fe(n));var h=n.elm=e.elm;if(i(e.isAsyncPlaceholder))a(n.asyncFactory.resolved)?Q(e.elm,n,t):n.isAsyncPlaceholder=!0;else if(i(n.isStatic)&&i(e.isStatic)&&n.key===e.key&&(i(n.isCloned)||i(n.isOnce)))n.componentInstance=e.componentInstance;else{var p,y=n.data;a(y)&&a(p=y.hook)&&a(p=p.prepatch)&&p(e,n);var g=e.children,b=n.children;if(a(y)&&m(n)){for(p=0;p<o.update.length;++p)o.update[p](e,n);a(p=y.hook)&&a(p=p.update)&&p(e,n)}r(n.text)?a(g)&&a(b)?g!==b&&function(e,n,t,o,i){var s,l,c,h=0,p=0,y=n.length-1,m=n[0],g=n[y],b=t.length-1,f=t[0],v=t[b],q=!i;for(0;h<=y&&p<=b;)r(m)?m=n[++h]:r(g)?g=n[--y]:to(m,f)?(j(m,f,o,t,p),m=n[++h],f=t[++p]):to(g,v)?(j(g,v,o,t,b),g=n[--y],v=t[--b]):to(m,v)?(j(m,v,o,t,b),q&&u.insertBefore(e,m.elm,u.nextSibling(g.elm)),m=n[++h],v=t[--b]):to(g,f)?(j(g,f,o,t,p),q&&u.insertBefore(e,g.elm,m.elm),g=n[--y],f=t[++p]):(r(s)&&(s=oo(n,h,y)),r(l=a(f.key)?s[f.key]:x(f,n,h,y))?d(f,o,e,m.elm,!1,t,p):to(c=n[l],f)?(j(c,f,o,t,p),n[l]=void 0,q&&u.insertBefore(e,c.elm,m.elm)):d(f,o,e,m.elm,!1,t,p),f=t[++p]);h>y?w(e,r(t[b+1])?null:t[b+1].elm,t,p,b,o):p>b&&k(n,h,y)}(h,g,b,t,c):a(b)?(a(e.text)&&u.setTextContent(h,""),w(h,null,b,0,b.length-1,t)):a(g)?k(g,0,g.length-1):a(e.text)&&u.setTextContent(h,""):e.text!==n.text&&u.setTextContent(h,n.text),a(y)&&a(p=y.hook)&&a(p=p.postpatch)&&p(e,n)}}}function S(e,n,t){if(i(t)&&a(e.parent))e.parent.data.pendingInsert=n;else for(var o=0;o<n.length;++o)n[o].data.hook.insert(n[o])}var T=g("attrs,class,staticClass,staticStyle,key");function Q(e,n,t,o){var r,s=n.tag,l=n.data,u=n.children;if(o=o||l&&l.pre,n.elm=e,i(n.isComment)&&a(n.asyncFactory))return n.isAsyncPlaceholder=!0,!0;if(a(l)&&(a(r=l.hook)&&a(r=r.init)&&r(n,!0),a(r=n.componentInstance)))return h(n,t),!0;if(a(s)){if(a(u))if(e.hasChildNodes())if(a(r=l)&&a(r=r.domProps)&&a(r=r.innerHTML)){if(r!==e.innerHTML)return!1}else{for(var c=!0,d=e.firstChild,p=0;p<u.length;p++){if(!d||!Q(d,u[p],t,o)){c=!1;break}d=d.nextSibling}if(!c||d)return!1}else y(n,u,t);if(a(l)){var m=!1;for(var g in l)if(!T(g)){m=!0,b(n,t);break}!m&&l.class&&rn(l.class)}}else e.data!==n.text&&(e.data=n.text);return!0}return function(e,n,t,s){if(!r(n)){var l,c=!1,h=[];if(r(e))c=!0,d(n,h);else{var p=a(e.nodeType);if(!p&&to(e,n))j(e,n,h,null,null,s);else{if(p){if(1===e.nodeType&&e.hasAttribute("data-server-rendered")&&(e.removeAttribute("data-server-rendered"),t=!0),i(t)&&Q(e,n,h))return S(n,h,!0),e;l=e,e=new ye(u.tagName(l).toLowerCase(),{},[],void 0,l)}var y=e.elm,g=u.parentNode(y);if(d(n,h,y._leaveCb?null:g,u.nextSibling(y)),a(n.parent))for(var b=n.parent,f=m(n);b;){for(var w=0;w<o.destroy.length;++w)o.destroy[w](b);if(b.elm=n.elm,f){for(var q=0;q<o.create.length;++q)o.create[q](eo,b);var x=b.data.hook.insert;if(x.merged)for(var T=1;T<x.fns.length;T++)x.fns[T]()}else Xt(b);b=b.parent}a(g)?k([e],0,0):a(e.tag)&&v(e)}}return S(n,h,c),n.elm}a(e)&&v(e)}}({nodeOps:Kt,modules:[mo,fo,So,Io,Go,F?{create:ur,activate:ur,remove:function(e,n){!0!==e.data.show?ir(e,n):n()}}:{}].concat(co)});$&&document.addEventListener("selectionchange",(function(){var e=document.activeElement;e&&e.vmodel&&fr(e,"input")}));var dr={inserted:function(e,n,t,o){"select"===t.tag?(o.elm&&!o.elm._vOptions?un(t,"postpatch",(function(){dr.componentUpdated(e,n,t)})):hr(e,n,t.context),e._vOptions=[].map.call(e.options,mr)):("textarea"===t.tag||$t(e.type))&&(e._vModifiers=n.modifiers,n.modifiers.lazy||(e.addEventListener("compositionstart",gr),e.addEventListener("compositionend",br),e.addEventListener("change",br),$&&(e.vmodel=!0)))},componentUpdated:function(e,n,t){if("select"===t.tag){hr(e,n,t.context);var o=e._vOptions,r=e._vOptions=[].map.call(e.options,mr);if(r.some((function(e,n){return!E(e,o[n])})))(e.multiple?n.value.some((function(e){return yr(e,r)})):n.value!==n.oldValue&&yr(n.value,r))&&fr(e,"change")}}};function hr(e,n,t){pr(e,n,t),(J||K)&&setTimeout((function(){pr(e,n,t)}),0)}function pr(e,n,t){var o=n.value,r=e.multiple;if(!r||Array.isArray(o)){for(var a,i,s=0,l=e.options.length;s<l;s++)if(i=e.options[s],r)a=L(o,mr(i))>-1,i.selected!==a&&(i.selected=a);else if(E(mr(i),o))return void(e.selectedIndex!==s&&(e.selectedIndex=s));r||(e.selectedIndex=-1)}}function yr(e,n){return n.every((function(n){return!E(n,e)}))}function mr(e){return"_value"in e?e._value:e.value}function gr(e){e.target.composing=!0}function br(e){e.target.composing&&(e.target.composing=!1,fr(e.target,"input"))}function fr(e,n){var t=document.createEvent("HTMLEvents");t.initEvent(n,!0,!0),e.dispatchEvent(t)}function wr(e){return!e.componentInstance||e.data&&e.data.transition?e:wr(e.componentInstance._vnode)}var vr={model:dr,show:{bind:function(e,n,t){var o=n.value,r=(t=wr(t)).data&&t.data.transition,a=e.__vOriginalDisplay="none"===e.style.display?"":e.style.display;o&&r?(t.data.show=!0,ar(t,(function(){e.style.display=a}))):e.style.display=o?a:"none"},update:function(e,n,t){var o=n.value;!o!=!n.oldValue&&((t=wr(t)).data&&t.data.transition?(t.data.show=!0,o?ar(t,(function(){e.style.display=e.__vOriginalDisplay})):ir(t,(function(){e.style.display="none"}))):e.style.display=o?e.__vOriginalDisplay:"none")},unbind:function(e,n,t,o,r){r||(e.style.display=e.__vOriginalDisplay)}}},kr={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function qr(e){var n=e&&e.componentOptions;return n&&n.Ctor.options.abstract?qr(Un(n.children)):e}function xr(e){var n={},t=e.$options;for(var o in t.propsData)n[o]=e[o];var r=t._parentListeners;for(var a in r)n[x(a)]=r[a];return n}function jr(e,n){if(/\d-keep-alive$/.test(n.tag))return e("keep-alive",{props:n.componentOptions.propsData})}var Sr=function(e){return e.tag||gn(e)},Tr=function(e){return"show"===e.name},Qr={name:"transition",props:kr,abstract:!0,render:function(e){var n=this,t=this.$slots.default;if(t&&(t=t.filter(Sr)).length){0;var o=this.mode;0;var r=t[0];if(function(e){for(;e=e.parent;)if(e.data.transition)return!0}(this.$vnode))return r;var a=qr(r);if(!a)return r;if(this._leaving)return jr(e,r);var i="__transition-"+this._uid+"-";a.key=null==a.key?a.isComment?i+"comment":i+a.tag:s(a.key)?0===String(a.key).indexOf(i)?a.key:i+a.key:a.key;var l=(a.data||(a.data={})).transition=xr(this),u=this._vnode,c=qr(u);if(a.data.directives&&a.data.directives.some(Tr)&&(a.data.show=!0),c&&c.data&&!function(e,n){return n.key===e.key&&n.tag===e.tag}(a,c)&&!gn(c)&&(!c.componentInstance||!c.componentInstance._vnode.isComment)){var d=c.data.transition=P({},l);if("out-in"===o)return this._leaving=!0,un(d,"afterLeave",(function(){n._leaving=!1,n.$forceUpdate()})),jr(e,r);if("in-out"===o){if(gn(a))return u;var h,p=function(){h()};un(l,"afterEnter",p),un(l,"enterCancelled",p),un(d,"delayLeave",(function(e){h=e}))}}return r}}},Ir=P({tag:String,moveClass:String},kr);function Pr(e){e.elm._moveCb&&e.elm._moveCb(),e.elm._enterCb&&e.elm._enterCb()}function zr(e){e.data.newPos=e.elm.getBoundingClientRect()}function Cr(e){var n=e.data.pos,t=e.data.newPos,o=n.left-t.left,r=n.top-t.top;if(o||r){e.data.moved=!0;var a=e.elm.style;a.transform=a.WebkitTransform="translate("+o+"px,"+r+"px)",a.transitionDuration="0s"}}delete Ir.mode;var _r={Transition:Qr,TransitionGroup:{props:Ir,beforeMount:function(){var e=this,n=this._update;this._update=function(t,o){var r=Zn(e);e.__patch__(e._vnode,e.kept,!1,!0),e._vnode=e.kept,r(),n.call(e,t,o)}},render:function(e){for(var n=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),o=this.prevChildren=this.children,r=this.$slots.default||[],a=this.children=[],i=xr(this),s=0;s<r.length;s++){var l=r[s];if(l.tag)if(null!=l.key&&0!==String(l.key).indexOf("__vlist"))a.push(l),t[l.key]=l,(l.data||(l.data={})).transition=i;else;}if(o){for(var u=[],c=[],d=0;d<o.length;d++){var h=o[d];h.data.transition=i,h.data.pos=h.elm.getBoundingClientRect(),t[h.key]?u.push(h):c.push(h)}this.kept=e(n,null,u),this.removed=c}return e(n,null,a)},updated:function(){var e=this.prevChildren,n=this.moveClass||(this.name||"v")+"-move";e.length&&this.hasMove(e[0].elm,n)&&(e.forEach(Pr),e.forEach(zr),e.forEach(Cr),this._reflow=document.body.offsetHeight,e.forEach((function(e){if(e.data.moved){var t=e.elm,o=t.style;Zo(t,n),o.transform=o.WebkitTransform=o.transitionDuration="",t.addEventListener(Yo,t._moveCb=function e(o){o&&o.target!==t||o&&!/transform$/.test(o.propertyName)||(t.removeEventListener(Yo,e),t._moveCb=null,Xo(t,n))})}})))},methods:{hasMove:function(e,n){if(!Fo)return!1;if(this._hasMove)return this._hasMove;var t=e.cloneNode();e._transitionClasses&&e._transitionClasses.forEach((function(e){Mo(t,e)})),Ro(t,n),t.style.display="none",this.$el.appendChild(t);var o=tr(t);return this.$el.removeChild(t),this._hasMove=o.hasTransform}}}};jt.config.mustUseProp=function(e,n,t){return"value"===t&&At(e)&&"button"!==n||"selected"===t&&"option"===e||"checked"===t&&"input"===e||"muted"===t&&"video"===e},jt.config.isReservedTag=Vt,jt.config.isReservedAttr=_t,jt.config.getTagNamespace=function(e){return Yt(e)?"svg":"math"===e?"math":void 0},jt.config.isUnknownElement=function(e){if(!F)return!0;if(Vt(e))return!1;if(e=e.toLowerCase(),null!=Jt[e])return Jt[e];var n=document.createElement(e);return e.indexOf("-")>-1?Jt[e]=n.constructor===window.HTMLUnknownElement||n.constructor===window.HTMLElement:Jt[e]=/HTMLUnknownElement/.test(n.toString())},P(jt.options.directives,vr),P(jt.options.components,_r),jt.prototype.__patch__=F?cr:C,jt.prototype.$mount=function(e,n){return function(e,n,t){var o;return e.$el=n,e.$options.render||(e.$options.render=ge),nt(e,"beforeMount"),o=function(){e._update(e._render(),t)},new pt(e,o,C,{before:function(){e._isMounted&&!e._isDestroyed&&nt(e,"beforeUpdate")}},!0),t=!1,null==e.$vnode&&(e._isMounted=!0,nt(e,"mounted")),e}(this,e=e&&F?function(e){if("string"==typeof e){var n=document.querySelector(e);return n||document.createElement("div")}return e}(e):void 0,n)},F&&setTimeout((function(){G.devtools&&re&&re.emit("init",jt)}),0),n.a=jt},function(e,n,t){"use strict";function o(e,n,t,o,r,a,i,s){var l,u="function"==typeof e?e.options:e;if(n&&(u.render=n,u.staticRenderFns=t,u._compiled=!0),o&&(u.functional=!0),a&&(u._scopeId="data-v-"+a),i?(l=function(e){(e=e||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(e=__VUE_SSR_CONTEXT__),r&&r.call(this,e),e&&e._registeredComponents&&e._registeredComponents.add(i)},u._ssrRegister=l):r&&(l=s?function(){r.call(this,(u.functional?this.parent:this).$root.$options.shadowRoot)}:r),l)if(u.functional){u._injectStyles=l;var c=u.render;u.render=function(e,n){return l.call(n),c(e,n)}}else{var d=u.beforeCreate;u.beforeCreate=d?[].concat(d,l):[l]}return{exports:e,options:u}}t.d(n,"a",(function(){return o}))},function(e,n,t){var o=t(28),r="object"==typeof self&&self&&self.Object===Object&&self,a=o||r||Function("return this")();e.exports=a},function(e,n){var t=Array.isArray;e.exports=t},function(e,n,t){var o=t(82),r=t(85);e.exports=function(e,n){var t=r(e,n);return o(t)?t:void 0}},function(e,n){e.exports=function(e){return null!=e&&"object"==typeof e}},function(e,n,t){var o=t(2).Symbol;e.exports=o},function(e,n,t){var o=t(6),r=t(67),a=t(68),i=o?o.toStringTag:void 0;e.exports=function(e){return null==e?void 0===e?"[object Undefined]":"[object Null]":i&&i in Object(e)?r(e):a(e)}},function(e,n,t){
/*!
* screenfull
* v5.1.0 - 2020-12-24
* (c) Sindre Sorhus; MIT License
*/
!function(){"use strict";var n="undefined"!=typeof window&&void 0!==window.document?window.document:{},t=e.exports,o=function(){for(var e,t=[["requestFullscreen","exitFullscreen","fullscreenElement","fullscreenEnabled","fullscreenchange","fullscreenerror"],["webkitRequestFullscreen","webkitExitFullscreen","webkitFullscreenElement","webkitFullscreenEnabled","webkitfullscreenchange","webkitfullscreenerror"],["webkitRequestFullScreen","webkitCancelFullScreen","webkitCurrentFullScreenElement","webkitCancelFullScreen","webkitfullscreenchange","webkitfullscreenerror"],["mozRequestFullScreen","mozCancelFullScreen","mozFullScreenElement","mozFullScreenEnabled","mozfullscreenchange","mozfullscreenerror"],["msRequestFullscreen","msExitFullscreen","msFullscreenElement","msFullscreenEnabled","MSFullscreenChange","MSFullscreenError"]],o=0,r=t.length,a={};o<r;o++)if((e=t[o])&&e[1]in n){for(o=0;o<e.length;o++)a[t[0][o]]=e[o];return a}return!1}(),r={change:o.fullscreenchange,error:o.fullscreenerror},a={request:function(e,t){return new Promise(function(r,a){var i=function(){this.off("change",i),r()}.bind(this);this.on("change",i);var s=(e=e||n.documentElement)[o.requestFullscreen](t);s instanceof Promise&&s.then(i).catch(a)}.bind(this))},exit:function(){return new Promise(function(e,t){if(this.isFullscreen){var r=function(){this.off("change",r),e()}.bind(this);this.on("change",r);var a=n[o.exitFullscreen]();a instanceof Promise&&a.then(r).catch(t)}else e()}.bind(this))},toggle:function(e,n){return this.isFullscreen?this.exit():this.request(e,n)},onchange:function(e){this.on("change",e)},onerror:function(e){this.on("error",e)},on:function(e,t){var o=r[e];o&&n.addEventListener(o,t,!1)},off:function(e,t){var o=r[e];o&&n.removeEventListener(o,t,!1)},raw:o};o?(Object.defineProperties(a,{isFullscreen:{get:function(){return Boolean(n[o.fullscreenElement])}},element:{enumerable:!0,get:function(){return n[o.fullscreenElement]}},isEnabled:{enumerable:!0,get:function(){return Boolean(n[o.fullscreenEnabled])}}}),t?e.exports=a:window.screenfull=a):t?e.exports={isEnabled:!1}:window.screenfull={isEnabled:!1}}()},function(e,n,t){var o=t(72),r=t(73),a=t(74),i=t(75),s=t(76);function l(e){var n=-1,t=null==e?0:e.length;for(this.clear();++n<t;){var o=e[n];this.set(o[0],o[1])}}l.prototype.clear=o,l.prototype.delete=r,l.prototype.get=a,l.prototype.has=i,l.prototype.set=s,e.exports=l},function(e,n,t){var o=t(30);e.exports=function(e,n){for(var t=e.length;t--;)if(o(e[t][0],n))return t;return-1}},function(e,n,t){var o=t(4)(Object,"create");e.exports=o},function(e,n,t){var o=t(94);e.exports=function(e,n){var t=e.__data__;return o(n)?t["string"==typeof n?"string":"hash"]:t.map}},function(e,n,t){var o=t(24);e.exports=function(e){if("string"==typeof e||o(e))return e;var n=e+"";return"0"==n&&1/e==-1/0?"-0":n}},function(e,n){var t=/^\s+|\s+$/g,o=/^[-+]0x[0-9a-f]+$/i,r=/^0b[01]+$/i,a=/^0o[0-7]+$/i,i=parseInt,s="object"==typeof global&&global&&global.Object===Object&&global,l="object"==typeof self&&self&&self.Object===Object&&self,u=s||l||Function("return this")(),c=Object.prototype.toString,d=Math.max,h=Math.min,p=function(){return u.Date.now()};function y(e){var n=typeof e;return!!e&&("object"==n||"function"==n)}function m(e){if("number"==typeof e)return e;if(function(e){return"symbol"==typeof e||function(e){return!!e&&"object"==typeof e}(e)&&"[object Symbol]"==c.call(e)}(e))return NaN;if(y(e)){var n="function"==typeof e.valueOf?e.valueOf():e;e=y(n)?n+"":n}if("string"!=typeof e)return 0===e?e:+e;e=e.replace(t,"");var s=r.test(e);return s||a.test(e)?i(e.slice(2),s?2:8):o.test(e)?NaN:+e}e.exports=function(e,n,t){var o,r,a,i,s,l,u=0,c=!1,g=!1,b=!0;if("function"!=typeof e)throw new TypeError("Expected a function");function f(n){var t=o,a=r;return o=r=void 0,u=n,i=e.apply(a,t)}function w(e){return u=e,s=setTimeout(k,n),c?f(e):i}function v(e){var t=e-l;return void 0===l||t>=n||t<0||g&&e-u>=a}function k(){var e=p();if(v(e))return q(e);s=setTimeout(k,function(e){var t=n-(e-l);return g?h(t,a-(e-u)):t}(e))}function q(e){return s=void 0,b&&o?f(e):(o=r=void 0,i)}function x(){var e=p(),t=v(e);if(o=arguments,r=this,l=e,t){if(void 0===s)return w(l);if(g)return s=setTimeout(k,n),f(l)}return void 0===s&&(s=setTimeout(k,n)),i}return n=m(n)||0,y(t)&&(c=!!t.leading,a=(g="maxWait"in t)?d(m(t.maxWait)||0,n):a,b="trailing"in t?!!t.trailing:b),x.cancel=function(){void 0!==s&&clearTimeout(s),u=0,o=l=r=s=void 0},x.flush=function(){return void 0===s?i:q(p())},x}},function(e,n,t){var o,r;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(r="function"==typeof(o=function(){var e,n,t={version:"0.2.0"},o=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function r(e,n,t){return e<n?n:e>t?t:e}function a(e){return 100*(-1+e)}t.configure=function(e){var n,t;for(n in e)void 0!==(t=e[n])&&e.hasOwnProperty(n)&&(o[n]=t);return this},t.status=null,t.set=function(e){var n=t.isStarted();e=r(e,o.minimum,1),t.status=1===e?null:e;var l=t.render(!n),u=l.querySelector(o.barSelector),c=o.speed,d=o.easing;return l.offsetWidth,i((function(n){""===o.positionUsing&&(o.positionUsing=t.getPositioningCSS()),s(u,function(e,n,t){var r;return(r="translate3d"===o.positionUsing?{transform:"translate3d("+a(e)+"%,0,0)"}:"translate"===o.positionUsing?{transform:"translate("+a(e)+"%,0)"}:{"margin-left":a(e)+"%"}).transition="all "+n+"ms "+t,r}(e,c,d)),1===e?(s(l,{transition:"none",opacity:1}),l.offsetWidth,setTimeout((function(){s(l,{transition:"all "+c+"ms linear",opacity:0}),setTimeout((function(){t.remove(),n()}),c)}),c)):setTimeout(n,c)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var e=function(){setTimeout((function(){t.status&&(t.trickle(),e())}),o.trickleSpeed)};return o.trickle&&e(),this},t.done=function(e){return e||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(e){var n=t.status;return n?("number"!=typeof e&&(e=(1-n)*r(Math.random()*n,.1,.95)),n=r(n+e,0,.994),t.set(n)):t.start()},t.trickle=function(){return t.inc(Math.random()*o.trickleRate)},e=0,n=0,t.promise=function(o){return o&&"resolved"!==o.state()?(0===n&&t.start(),e++,n++,o.always((function(){0==--n?(e=0,t.done()):t.set((e-n)/e)})),this):this},t.render=function(e){if(t.isRendered())return document.getElementById("nprogress");u(document.documentElement,"nprogress-busy");var n=document.createElement("div");n.id="nprogress",n.innerHTML=o.template;var r,i=n.querySelector(o.barSelector),l=e?"-100":a(t.status||0),c=document.querySelector(o.parent);return s(i,{transition:"all 0 linear",transform:"translate3d("+l+"%,0,0)"}),o.showSpinner||(r=n.querySelector(o.spinnerSelector))&&h(r),c!=document.body&&u(c,"nprogress-custom-parent"),c.appendChild(n),n},t.remove=function(){c(document.documentElement,"nprogress-busy"),c(document.querySelector(o.parent),"nprogress-custom-parent");var e=document.getElementById("nprogress");e&&h(e)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var e=document.body.style,n="WebkitTransform"in e?"Webkit":"MozTransform"in e?"Moz":"msTransform"in e?"ms":"OTransform"in e?"O":"";return n+"Perspective"in e?"translate3d":n+"Transform"in e?"translate":"margin"};var i=function(){var e=[];function n(){var t=e.shift();t&&t(n)}return function(t){e.push(t),1==e.length&&n()}}(),s=function(){var e=["Webkit","O","Moz","ms"],n={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(e,n){return n.toUpperCase()})),n[t]||(n[t]=function(n){var t=document.body.style;if(n in t)return n;for(var o,r=e.length,a=n.charAt(0).toUpperCase()+n.slice(1);r--;)if((o=e[r]+a)in t)return o;return n}(t))}function o(e,n,o){n=t(n),e.style[n]=o}return function(e,n){var t,r,a=arguments;if(2==a.length)for(t in n)void 0!==(r=n[t])&&n.hasOwnProperty(t)&&o(e,t,r);else o(e,a[1],a[2])}}();function l(e,n){return("string"==typeof e?e:d(e)).indexOf(" "+n+" ")>=0}function u(e,n){var t=d(e),o=t+n;l(t,n)||(e.className=o.substring(1))}function c(e,n){var t,o=d(e);l(e,n)&&(t=o.replace(" "+n+" "," "),e.className=t.substring(1,t.length-1))}function d(e){return(" "+(e.className||"")+" ").replace(/\s+/gi," ")}function h(e){e&&e.parentNode&&e.parentNode.removeChild(e)}return t})?o.call(n,t,n,e):o)||(e.exports=r)},function(e,n,t){"use strict";n.a={render:()=>null}},function(e,n,t){var o=t(66),r=t(5),a=Object.prototype,i=a.hasOwnProperty,s=a.propertyIsEnumerable,l=o(function(){return arguments}())?o:function(e){return r(e)&&i.call(e,"callee")&&!s.call(e,"callee")};e.exports=l},function(e,n,t){var o=t(4)(t(2),"Map");e.exports=o},function(e,n){e.exports=function(e){var n=typeof e;return null!=e&&("object"==n||"function"==n)}},function(e,n,t){var o=t(86),r=t(93),a=t(95),i=t(96),s=t(97);function l(e){var n=-1,t=null==e?0:e.length;for(this.clear();++n<t;){var o=e[n];this.set(o[0],o[1])}}l.prototype.clear=o,l.prototype.delete=r,l.prototype.get=a,l.prototype.has=i,l.prototype.set=s,e.exports=l},function(e,n){e.exports=function(e){var n=-1,t=Array(e.size);return e.forEach((function(e){t[++n]=e})),t}},function(e,n){e.exports=function(e){return"number"==typeof e&&e>-1&&e%1==0&&e<=9007199254740991}},function(e,n,t){var o=t(3),r=t(24),a=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,i=/^\w*$/;e.exports=function(e,n){if(o(e))return!1;var t=typeof e;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=e&&!r(e))||(i.test(e)||!a.test(e)||null!=n&&e in Object(n))}},function(e,n,t){var o=t(7),r=t(5);e.exports=function(e){return"symbol"==typeof e||r(e)&&"[object Symbol]"==o(e)}},function(e,n){e.exports=function(e){return e}},function(e,n){e.exports=function(e){return e.webpackPolyfill||(e.deprecate=function(){},e.paths=[],e.children||(e.children=[]),Object.defineProperty(e,"loaded",{enumerable:!0,get:function(){return e.l}}),Object.defineProperty(e,"id",{enumerable:!0,get:function(){return e.i}}),e.webpackPolyfill=1),e}},function(e,n){e.exports=function(e,n){for(var t=-1,o=n.length,r=e.length;++t<o;)e[r+t]=n[t];return e}},function(e,n){var t="object"==typeof global&&global&&global.Object===Object&&global;e.exports=t},function(e,n,t){var o=t(9),r=t(77),a=t(78),i=t(79),s=t(80),l=t(81);function u(e){var n=this.__data__=new o(e);this.size=n.size}u.prototype.clear=r,u.prototype.delete=a,u.prototype.get=i,u.prototype.has=s,u.prototype.set=l,e.exports=u},function(e,n){e.exports=function(e,n){return e===n||e!=e&&n!=n}},function(e,n,t){var o=t(7),r=t(19);e.exports=function(e){if(!r(e))return!1;var n=o(e);return"[object Function]"==n||"[object GeneratorFunction]"==n||"[object AsyncFunction]"==n||"[object Proxy]"==n}},function(e,n){var t=Function.prototype.toString;e.exports=function(e){if(null!=e){try{return t.call(e)}catch(e){}try{return e+""}catch(e){}}return""}},function(e,n,t){var o=t(98),r=t(5);e.exports=function e(n,t,a,i,s){return n===t||(null==n||null==t||!r(n)&&!r(t)?n!=n&&t!=t:o(n,t,a,i,e,s))}},function(e,n,t){var o=t(35),r=t(101),a=t(36);e.exports=function(e,n,t,i,s,l){var u=1&t,c=e.length,d=n.length;if(c!=d&&!(u&&d>c))return!1;var h=l.get(e),p=l.get(n);if(h&&p)return h==n&&p==e;var y=-1,m=!0,g=2&t?new o:void 0;for(l.set(e,n),l.set(n,e);++y<c;){var b=e[y],f=n[y];if(i)var w=u?i(f,b,y,n,e,l):i(b,f,y,e,n,l);if(void 0!==w){if(w)continue;m=!1;break}if(g){if(!r(n,(function(e,n){if(!a(g,n)&&(b===e||s(b,e,t,i,l)))return g.push(n)}))){m=!1;break}}else if(b!==f&&!s(b,f,t,i,l)){m=!1;break}}return l.delete(e),l.delete(n),m}},function(e,n,t){var o=t(20),r=t(99),a=t(100);function i(e){var n=-1,t=null==e?0:e.length;for(this.__data__=new o;++n<t;)this.add(e[n])}i.prototype.add=i.prototype.push=r,i.prototype.has=a,e.exports=i},function(e,n){e.exports=function(e,n){return e.has(n)}},function(e,n,t){var o=t(111),r=t(117),a=t(41);e.exports=function(e){return a(e)?o(e):r(e)}},function(e,n,t){(function(e){var o=t(2),r=t(113),a=n&&!n.nodeType&&n,i=a&&"object"==typeof e&&e&&!e.nodeType&&e,s=i&&i.exports===a?o.Buffer:void 0,l=(s?s.isBuffer:void 0)||r;e.exports=l}).call(this,t(26)(e))},function(e,n){var t=/^(?:0|[1-9]\d*)$/;e.exports=function(e,n){var o=typeof e;return!!(n=null==n?9007199254740991:n)&&("number"==o||"symbol"!=o&&t.test(e))&&e>-1&&e%1==0&&e<n}},function(e,n,t){var o=t(114),r=t(115),a=t(116),i=a&&a.isTypedArray,s=i?r(i):o;e.exports=s},function(e,n,t){var o=t(31),r=t(22);e.exports=function(e){return null!=e&&r(e.length)&&!o(e)}},function(e,n,t){var o=t(4)(t(2),"Set");e.exports=o},function(e,n,t){var o=t(19);e.exports=function(e){return e==e&&!o(e)}},function(e,n){e.exports=function(e,n){return function(t){return null!=t&&(t[e]===n&&(void 0!==n||e in Object(t)))}}},function(e,n,t){var o=t(46),r=t(13);e.exports=function(e,n){for(var t=0,a=(n=o(n,e)).length;null!=e&&t<a;)e=e[r(n[t++])];return t&&t==a?e:void 0}},function(e,n,t){var o=t(3),r=t(23),a=t(128),i=t(131);e.exports=function(e,n){return o(e)?e:r(e,n)?[e]:a(i(e))}},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){var o=t(64),r=t(69),a=t(140),i=t(148),s=t(157),l=t(158),u=a((function(e){var n=l(e);return s(n)&&(n=void 0),i(o(e,1,s,!0),r(n,2))}));e.exports=u},function(e,n,t){n.formatArgs=function(n){if(n[0]=(this.useColors?"%c":"")+this.namespace+(this.useColors?" %c":" ")+n[0]+(this.useColors?"%c ":" ")+"+"+e.exports.humanize(this.diff),!this.useColors)return;const t="color: "+this.color;n.splice(1,0,t,"color: inherit");let o=0,r=0;n[0].replace(/%[a-zA-Z%]/g,e=>{"%%"!==e&&(o++,"%c"===e&&(r=o))}),n.splice(r,0,t)},n.save=function(e){try{e?n.storage.setItem("debug",e):n.storage.removeItem("debug")}catch(e){}},n.load=function(){let e;try{e=n.storage.getItem("debug")}catch(e){}!e&&"undefined"!=typeof process&&"env"in process&&(e=process.env.DEBUG);return e},n.useColors=function(){if("undefined"!=typeof window&&window.process&&("renderer"===window.process.type||window.process.__nwjs))return!0;if("undefined"!=typeof navigator&&navigator.userAgent&&navigator.userAgent.toLowerCase().match(/(edge|trident)\/(\d+)/))return!1;return"undefined"!=typeof document&&document.documentElement&&document.documentElement.style&&document.documentElement.style.WebkitAppearance||"undefined"!=typeof window&&window.console&&(window.console.firebug||window.console.exception&&window.console.table)||"undefined"!=typeof navigator&&navigator.userAgent&&navigator.userAgent.toLowerCase().match(/firefox\/(\d+)/)&&parseInt(RegExp.$1,10)>=31||"undefined"!=typeof navigator&&navigator.userAgent&&navigator.userAgent.toLowerCase().match(/applewebkit\/(\d+)/)},n.storage=function(){try{return localStorage}catch(e){}}(),n.destroy=(()=>{let e=!1;return()=>{e||(e=!0,console.warn("Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`."))}})(),n.colors=["#0000CC","#0000FF","#0033CC","#0033FF","#0066CC","#0066FF","#0099CC","#0099FF","#00CC00","#00CC33","#00CC66","#00CC99","#00CCCC","#00CCFF","#3300CC","#3300FF","#3333CC","#3333FF","#3366CC","#3366FF","#3399CC","#3399FF","#33CC00","#33CC33","#33CC66","#33CC99","#33CCCC","#33CCFF","#6600CC","#6600FF","#6633CC","#6633FF","#66CC00","#66CC33","#9900CC","#9900FF","#9933CC","#9933FF","#99CC00","#99CC33","#CC0000","#CC0033","#CC0066","#CC0099","#CC00CC","#CC00FF","#CC3300","#CC3333","#CC3366","#CC3399","#CC33CC","#CC33FF","#CC6600","#CC6633","#CC9900","#CC9933","#CCCC00","#CCCC33","#FF0000","#FF0033","#FF0066","#FF0099","#FF00CC","#FF00FF","#FF3300","#FF3333","#FF3366","#FF3399","#FF33CC","#FF33FF","#FF6600","#FF6633","#FF9900","#FF9933","#FFCC00","#FFCC33"],n.log=console.debug||console.log||(()=>{}),e.exports=t(173)(n);const{formatters:o}=e.exports;o.j=function(e){try{return JSON.stringify(e)}catch(e){return"[UnexpectedJSONParseError]: "+e.message}}},function(e,n,t){},function(e,n,t){e.exports=t(180)},function(e,n,t){var o=t(27),r=t(65);e.exports=function e(n,t,a,i,s){var l=-1,u=n.length;for(a||(a=r),s||(s=[]);++l<u;){var c=n[l];t>0&&a(c)?t>1?e(c,t-1,a,i,s):o(s,c):i||(s[s.length]=c)}return s}},function(e,n,t){var o=t(6),r=t(17),a=t(3),i=o?o.isConcatSpreadable:void 0;e.exports=function(e){return a(e)||r(e)||!!(i&&e&&e[i])}},function(e,n,t){var o=t(7),r=t(5);e.exports=function(e){return r(e)&&"[object Arguments]"==o(e)}},function(e,n,t){var o=t(6),r=Object.prototype,a=r.hasOwnProperty,i=r.toString,s=o?o.toStringTag:void 0;e.exports=function(e){var n=a.call(e,s),t=e[s];try{e[s]=void 0;var o=!0}catch(e){}var r=i.call(e);return o&&(n?e[s]=t:delete e[s]),r}},function(e,n){var t=Object.prototype.toString;e.exports=function(e){return t.call(e)}},function(e,n,t){var o=t(70),r=t(126),a=t(25),i=t(3),s=t(137);e.exports=function(e){return"function"==typeof e?e:null==e?a:"object"==typeof e?i(e)?r(e[0],e[1]):o(e):s(e)}},function(e,n,t){var o=t(71),r=t(125),a=t(44);e.exports=function(e){var n=r(e);return 1==n.length&&n[0][2]?a(n[0][0],n[0][1]):function(t){return t===e||o(t,e,n)}}},function(e,n,t){var o=t(29),r=t(33);e.exports=function(e,n,t,a){var i=t.length,s=i,l=!a;if(null==e)return!s;for(e=Object(e);i--;){var u=t[i];if(l&&u[2]?u[1]!==e[u[0]]:!(u[0]in e))return!1}for(;++i<s;){var c=(u=t[i])[0],d=e[c],h=u[1];if(l&&u[2]){if(void 0===d&&!(c in e))return!1}else{var p=new o;if(a)var y=a(d,h,c,e,n,p);if(!(void 0===y?r(h,d,3,a,p):y))return!1}}return!0}},function(e,n){e.exports=function(){this.__data__=[],this.size=0}},function(e,n,t){var o=t(10),r=Array.prototype.splice;e.exports=function(e){var n=this.__data__,t=o(n,e);return!(t<0)&&(t==n.length-1?n.pop():r.call(n,t,1),--this.size,!0)}},function(e,n,t){var o=t(10);e.exports=function(e){var n=this.__data__,t=o(n,e);return t<0?void 0:n[t][1]}},function(e,n,t){var o=t(10);e.exports=function(e){return o(this.__data__,e)>-1}},function(e,n,t){var o=t(10);e.exports=function(e,n){var t=this.__data__,r=o(t,e);return r<0?(++this.size,t.push([e,n])):t[r][1]=n,this}},function(e,n,t){var o=t(9);e.exports=function(){this.__data__=new o,this.size=0}},function(e,n){e.exports=function(e){var n=this.__data__,t=n.delete(e);return this.size=n.size,t}},function(e,n){e.exports=function(e){return this.__data__.get(e)}},function(e,n){e.exports=function(e){return this.__data__.has(e)}},function(e,n,t){var o=t(9),r=t(18),a=t(20);e.exports=function(e,n){var t=this.__data__;if(t instanceof o){var i=t.__data__;if(!r||i.length<199)return i.push([e,n]),this.size=++t.size,this;t=this.__data__=new a(i)}return t.set(e,n),this.size=t.size,this}},function(e,n,t){var o=t(31),r=t(83),a=t(19),i=t(32),s=/^\[object .+?Constructor\]$/,l=Function.prototype,u=Object.prototype,c=l.toString,d=u.hasOwnProperty,h=RegExp("^"+c.call(d).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");e.exports=function(e){return!(!a(e)||r(e))&&(o(e)?h:s).test(i(e))}},function(e,n,t){var o,r=t(84),a=(o=/[^.]+$/.exec(r&&r.keys&&r.keys.IE_PROTO||""))?"Symbol(src)_1."+o:"";e.exports=function(e){return!!a&&a in e}},function(e,n,t){var o=t(2)["__core-js_shared__"];e.exports=o},function(e,n){e.exports=function(e,n){return null==e?void 0:e[n]}},function(e,n,t){var o=t(87),r=t(9),a=t(18);e.exports=function(){this.size=0,this.__data__={hash:new o,map:new(a||r),string:new o}}},function(e,n,t){var o=t(88),r=t(89),a=t(90),i=t(91),s=t(92);function l(e){var n=-1,t=null==e?0:e.length;for(this.clear();++n<t;){var o=e[n];this.set(o[0],o[1])}}l.prototype.clear=o,l.prototype.delete=r,l.prototype.get=a,l.prototype.has=i,l.prototype.set=s,e.exports=l},function(e,n,t){var o=t(11);e.exports=function(){this.__data__=o?o(null):{},this.size=0}},function(e,n){e.exports=function(e){var n=this.has(e)&&delete this.__data__[e];return this.size-=n?1:0,n}},function(e,n,t){var o=t(11),r=Object.prototype.hasOwnProperty;e.exports=function(e){var n=this.__data__;if(o){var t=n[e];return"__lodash_hash_undefined__"===t?void 0:t}return r.call(n,e)?n[e]:void 0}},function(e,n,t){var o=t(11),r=Object.prototype.hasOwnProperty;e.exports=function(e){var n=this.__data__;return o?void 0!==n[e]:r.call(n,e)}},function(e,n,t){var o=t(11);e.exports=function(e,n){var t=this.__data__;return this.size+=this.has(e)?0:1,t[e]=o&&void 0===n?"__lodash_hash_undefined__":n,this}},function(e,n,t){var o=t(12);e.exports=function(e){var n=o(this,e).delete(e);return this.size-=n?1:0,n}},function(e,n){e.exports=function(e){var n=typeof e;return"string"==n||"number"==n||"symbol"==n||"boolean"==n?"__proto__"!==e:null===e}},function(e,n,t){var o=t(12);e.exports=function(e){return o(this,e).get(e)}},function(e,n,t){var o=t(12);e.exports=function(e){return o(this,e).has(e)}},function(e,n,t){var o=t(12);e.exports=function(e,n){var t=o(this,e),r=t.size;return t.set(e,n),this.size+=t.size==r?0:1,this}},function(e,n,t){var o=t(29),r=t(34),a=t(102),i=t(105),s=t(121),l=t(3),u=t(38),c=t(40),d="[object Object]",h=Object.prototype.hasOwnProperty;e.exports=function(e,n,t,p,y,m){var g=l(e),b=l(n),f=g?"[object Array]":s(e),w=b?"[object Array]":s(n),v=(f="[object Arguments]"==f?d:f)==d,k=(w="[object Arguments]"==w?d:w)==d,q=f==w;if(q&&u(e)){if(!u(n))return!1;g=!0,v=!1}if(q&&!v)return m||(m=new o),g||c(e)?r(e,n,t,p,y,m):a(e,n,f,t,p,y,m);if(!(1&t)){var x=v&&h.call(e,"__wrapped__"),j=k&&h.call(n,"__wrapped__");if(x||j){var S=x?e.value():e,T=j?n.value():n;return m||(m=new o),y(S,T,t,p,m)}}return!!q&&(m||(m=new o),i(e,n,t,p,y,m))}},function(e,n){e.exports=function(e){return this.__data__.set(e,"__lodash_hash_undefined__"),this}},function(e,n){e.exports=function(e){return this.__data__.has(e)}},function(e,n){e.exports=function(e,n){for(var t=-1,o=null==e?0:e.length;++t<o;)if(n(e[t],t,e))return!0;return!1}},function(e,n,t){var o=t(6),r=t(103),a=t(30),i=t(34),s=t(104),l=t(21),u=o?o.prototype:void 0,c=u?u.valueOf:void 0;e.exports=function(e,n,t,o,u,d,h){switch(t){case"[object DataView]":if(e.byteLength!=n.byteLength||e.byteOffset!=n.byteOffset)return!1;e=e.buffer,n=n.buffer;case"[object ArrayBuffer]":return!(e.byteLength!=n.byteLength||!d(new r(e),new r(n)));case"[object Boolean]":case"[object Date]":case"[object Number]":return a(+e,+n);case"[object Error]":return e.name==n.name&&e.message==n.message;case"[object RegExp]":case"[object String]":return e==n+"";case"[object Map]":var p=s;case"[object Set]":var y=1&o;if(p||(p=l),e.size!=n.size&&!y)return!1;var m=h.get(e);if(m)return m==n;o|=2,h.set(e,n);var g=i(p(e),p(n),o,u,d,h);return h.delete(e),g;case"[object Symbol]":if(c)return c.call(e)==c.call(n)}return!1}},function(e,n,t){var o=t(2).Uint8Array;e.exports=o},function(e,n){e.exports=function(e){var n=-1,t=Array(e.size);return e.forEach((function(e,o){t[++n]=[o,e]})),t}},function(e,n,t){var o=t(106),r=Object.prototype.hasOwnProperty;e.exports=function(e,n,t,a,i,s){var l=1&t,u=o(e),c=u.length;if(c!=o(n).length&&!l)return!1;for(var d=c;d--;){var h=u[d];if(!(l?h in n:r.call(n,h)))return!1}var p=s.get(e),y=s.get(n);if(p&&y)return p==n&&y==e;var m=!0;s.set(e,n),s.set(n,e);for(var g=l;++d<c;){var b=e[h=u[d]],f=n[h];if(a)var w=l?a(f,b,h,n,e,s):a(b,f,h,e,n,s);if(!(void 0===w?b===f||i(b,f,t,a,s):w)){m=!1;break}g||(g="constructor"==h)}if(m&&!g){var v=e.constructor,k=n.constructor;v==k||!("constructor"in e)||!("constructor"in n)||"function"==typeof v&&v instanceof v&&"function"==typeof k&&k instanceof k||(m=!1)}return s.delete(e),s.delete(n),m}},function(e,n,t){var o=t(107),r=t(108),a=t(37);e.exports=function(e){return o(e,a,r)}},function(e,n,t){var o=t(27),r=t(3);e.exports=function(e,n,t){var a=n(e);return r(e)?a:o(a,t(e))}},function(e,n,t){var o=t(109),r=t(110),a=Object.prototype.propertyIsEnumerable,i=Object.getOwnPropertySymbols,s=i?function(e){return null==e?[]:(e=Object(e),o(i(e),(function(n){return a.call(e,n)})))}:r;e.exports=s},function(e,n){e.exports=function(e,n){for(var t=-1,o=null==e?0:e.length,r=0,a=[];++t<o;){var i=e[t];n(i,t,e)&&(a[r++]=i)}return a}},function(e,n){e.exports=function(){return[]}},function(e,n,t){var o=t(112),r=t(17),a=t(3),i=t(38),s=t(39),l=t(40),u=Object.prototype.hasOwnProperty;e.exports=function(e,n){var t=a(e),c=!t&&r(e),d=!t&&!c&&i(e),h=!t&&!c&&!d&&l(e),p=t||c||d||h,y=p?o(e.length,String):[],m=y.length;for(var g in e)!n&&!u.call(e,g)||p&&("length"==g||d&&("offset"==g||"parent"==g)||h&&("buffer"==g||"byteLength"==g||"byteOffset"==g)||s(g,m))||y.push(g);return y}},function(e,n){e.exports=function(e,n){for(var t=-1,o=Array(e);++t<e;)o[t]=n(t);return o}},function(e,n){e.exports=function(){return!1}},function(e,n,t){var o=t(7),r=t(22),a=t(5),i={};i["[object Float32Array]"]=i["[object Float64Array]"]=i["[object Int8Array]"]=i["[object Int16Array]"]=i["[object Int32Array]"]=i["[object Uint8Array]"]=i["[object Uint8ClampedArray]"]=i["[object Uint16Array]"]=i["[object Uint32Array]"]=!0,i["[object Arguments]"]=i["[object Array]"]=i["[object ArrayBuffer]"]=i["[object Boolean]"]=i["[object DataView]"]=i["[object Date]"]=i["[object Error]"]=i["[object Function]"]=i["[object Map]"]=i["[object Number]"]=i["[object Object]"]=i["[object RegExp]"]=i["[object Set]"]=i["[object String]"]=i["[object WeakMap]"]=!1,e.exports=function(e){return a(e)&&r(e.length)&&!!i[o(e)]}},function(e,n){e.exports=function(e){return function(n){return e(n)}}},function(e,n,t){(function(e){var o=t(28),r=n&&!n.nodeType&&n,a=r&&"object"==typeof e&&e&&!e.nodeType&&e,i=a&&a.exports===r&&o.process,s=function(){try{var e=a&&a.require&&a.require("util").types;return e||i&&i.binding&&i.binding("util")}catch(e){}}();e.exports=s}).call(this,t(26)(e))},function(e,n,t){var o=t(118),r=t(119),a=Object.prototype.hasOwnProperty;e.exports=function(e){if(!o(e))return r(e);var n=[];for(var t in Object(e))a.call(e,t)&&"constructor"!=t&&n.push(t);return n}},function(e,n){var t=Object.prototype;e.exports=function(e){var n=e&&e.constructor;return e===("function"==typeof n&&n.prototype||t)}},function(e,n,t){var o=t(120)(Object.keys,Object);e.exports=o},function(e,n){e.exports=function(e,n){return function(t){return e(n(t))}}},function(e,n,t){var o=t(122),r=t(18),a=t(123),i=t(42),s=t(124),l=t(7),u=t(32),c=u(o),d=u(r),h=u(a),p=u(i),y=u(s),m=l;(o&&"[object DataView]"!=m(new o(new ArrayBuffer(1)))||r&&"[object Map]"!=m(new r)||a&&"[object Promise]"!=m(a.resolve())||i&&"[object Set]"!=m(new i)||s&&"[object WeakMap]"!=m(new s))&&(m=function(e){var n=l(e),t="[object Object]"==n?e.constructor:void 0,o=t?u(t):"";if(o)switch(o){case c:return"[object DataView]";case d:return"[object Map]";case h:return"[object Promise]";case p:return"[object Set]";case y:return"[object WeakMap]"}return n}),e.exports=m},function(e,n,t){var o=t(4)(t(2),"DataView");e.exports=o},function(e,n,t){var o=t(4)(t(2),"Promise");e.exports=o},function(e,n,t){var o=t(4)(t(2),"WeakMap");e.exports=o},function(e,n,t){var o=t(43),r=t(37);e.exports=function(e){for(var n=r(e),t=n.length;t--;){var a=n[t],i=e[a];n[t]=[a,i,o(i)]}return n}},function(e,n,t){var o=t(33),r=t(127),a=t(134),i=t(23),s=t(43),l=t(44),u=t(13);e.exports=function(e,n){return i(e)&&s(n)?l(u(e),n):function(t){var i=r(t,e);return void 0===i&&i===n?a(t,e):o(n,i,3)}}},function(e,n,t){var o=t(45);e.exports=function(e,n,t){var r=null==e?void 0:o(e,n);return void 0===r?t:r}},function(e,n,t){var o=t(129),r=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,a=/\\(\\)?/g,i=o((function(e){var n=[];return 46===e.charCodeAt(0)&&n.push(""),e.replace(r,(function(e,t,o,r){n.push(o?r.replace(a,"$1"):t||e)})),n}));e.exports=i},function(e,n,t){var o=t(130);e.exports=function(e){var n=o(e,(function(e){return 500===t.size&&t.clear(),e})),t=n.cache;return n}},function(e,n,t){var o=t(20);function r(e,n){if("function"!=typeof e||null!=n&&"function"!=typeof n)throw new TypeError("Expected a function");var t=function(){var o=arguments,r=n?n.apply(this,o):o[0],a=t.cache;if(a.has(r))return a.get(r);var i=e.apply(this,o);return t.cache=a.set(r,i)||a,i};return t.cache=new(r.Cache||o),t}r.Cache=o,e.exports=r},function(e,n,t){var o=t(132);e.exports=function(e){return null==e?"":o(e)}},function(e,n,t){var o=t(6),r=t(133),a=t(3),i=t(24),s=o?o.prototype:void 0,l=s?s.toString:void 0;e.exports=function e(n){if("string"==typeof n)return n;if(a(n))return r(n,e)+"";if(i(n))return l?l.call(n):"";var t=n+"";return"0"==t&&1/n==-1/0?"-0":t}},function(e,n){e.exports=function(e,n){for(var t=-1,o=null==e?0:e.length,r=Array(o);++t<o;)r[t]=n(e[t],t,e);return r}},function(e,n,t){var o=t(135),r=t(136);e.exports=function(e,n){return null!=e&&r(e,n,o)}},function(e,n){e.exports=function(e,n){return null!=e&&n in Object(e)}},function(e,n,t){var o=t(46),r=t(17),a=t(3),i=t(39),s=t(22),l=t(13);e.exports=function(e,n,t){for(var u=-1,c=(n=o(n,e)).length,d=!1;++u<c;){var h=l(n[u]);if(!(d=null!=e&&t(e,h)))break;e=e[h]}return d||++u!=c?d:!!(c=null==e?0:e.length)&&s(c)&&i(h,c)&&(a(e)||r(e))}},function(e,n,t){var o=t(138),r=t(139),a=t(23),i=t(13);e.exports=function(e){return a(e)?o(i(e)):r(e)}},function(e,n){e.exports=function(e){return function(n){return null==n?void 0:n[e]}}},function(e,n,t){var o=t(45);e.exports=function(e){return function(n){return o(n,e)}}},function(e,n,t){var o=t(25),r=t(141),a=t(143);e.exports=function(e,n){return a(r(e,n,o),e+"")}},function(e,n,t){var o=t(142),r=Math.max;e.exports=function(e,n,t){return n=r(void 0===n?e.length-1:n,0),function(){for(var a=arguments,i=-1,s=r(a.length-n,0),l=Array(s);++i<s;)l[i]=a[n+i];i=-1;for(var u=Array(n+1);++i<n;)u[i]=a[i];return u[n]=t(l),o(e,this,u)}}},function(e,n){e.exports=function(e,n,t){switch(t.length){case 0:return e.call(n);case 1:return e.call(n,t[0]);case 2:return e.call(n,t[0],t[1]);case 3:return e.call(n,t[0],t[1],t[2])}return e.apply(n,t)}},function(e,n,t){var o=t(144),r=t(147)(o);e.exports=r},function(e,n,t){var o=t(145),r=t(146),a=t(25),i=r?function(e,n){return r(e,"toString",{configurable:!0,enumerable:!1,value:o(n),writable:!0})}:a;e.exports=i},function(e,n){e.exports=function(e){return function(){return e}}},function(e,n,t){var o=t(4),r=function(){try{var e=o(Object,"defineProperty");return e({},"",{}),e}catch(e){}}();e.exports=r},function(e,n){var t=Date.now;e.exports=function(e){var n=0,o=0;return function(){var r=t(),a=16-(r-o);if(o=r,a>0){if(++n>=800)return arguments[0]}else n=0;return e.apply(void 0,arguments)}}},function(e,n,t){var o=t(35),r=t(149),a=t(154),i=t(36),s=t(155),l=t(21);e.exports=function(e,n,t){var u=-1,c=r,d=e.length,h=!0,p=[],y=p;if(t)h=!1,c=a;else if(d>=200){var m=n?null:s(e);if(m)return l(m);h=!1,c=i,y=new o}else y=n?[]:p;e:for(;++u<d;){var g=e[u],b=n?n(g):g;if(g=t||0!==g?g:0,h&&b==b){for(var f=y.length;f--;)if(y[f]===b)continue e;n&&y.push(b),p.push(g)}else c(y,b,t)||(y!==p&&y.push(b),p.push(g))}return p}},function(e,n,t){var o=t(150);e.exports=function(e,n){return!!(null==e?0:e.length)&&o(e,n,0)>-1}},function(e,n,t){var o=t(151),r=t(152),a=t(153);e.exports=function(e,n,t){return n==n?a(e,n,t):o(e,r,t)}},function(e,n){e.exports=function(e,n,t,o){for(var r=e.length,a=t+(o?1:-1);o?a--:++a<r;)if(n(e[a],a,e))return a;return-1}},function(e,n){e.exports=function(e){return e!=e}},function(e,n){e.exports=function(e,n,t){for(var o=t-1,r=e.length;++o<r;)if(e[o]===n)return o;return-1}},function(e,n){e.exports=function(e,n,t){for(var o=-1,r=null==e?0:e.length;++o<r;)if(t(n,e[o]))return!0;return!1}},function(e,n,t){var o=t(42),r=t(156),a=t(21),i=o&&1/a(new o([,-0]))[1]==1/0?function(e){return new o(e)}:r;e.exports=i},function(e,n){e.exports=function(){}},function(e,n,t){var o=t(41),r=t(5);e.exports=function(e){return r(e)&&o(e)}},function(e,n){e.exports=function(e){var n=null==e?0:e.length;return n?e[n-1]:void 0}},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){"use strict";t(47)},function(e,n,t){"use strict";t(48)},function(e,n,t){"use strict";t(49)},function(e,n,t){"use strict";t(50)},function(e,n,t){"use strict";t(51)},function(e,n,t){"use strict";t(52)},function(e,n,t){"use strict";t(53)},function(e,n,t){"use strict";t(54)},function(e,n,t){"use strict";t(55)},function(e,n,t){"use strict";t(56)},function(e,n,t){},function(e,n,t){e.exports=function(e){function n(e){let t,r,a,i=null;function s(...e){if(!s.enabled)return;const o=s,r=Number(new Date),a=r-(t||r);o.diff=a,o.prev=t,o.curr=r,t=r,e[0]=n.coerce(e[0]),"string"!=typeof e[0]&&e.unshift("%O");let i=0;e[0]=e[0].replace(/%([a-zA-Z%])/g,(t,r)=>{if("%%"===t)return"%";i++;const a=n.formatters[r];if("function"==typeof a){const n=e[i];t=a.call(o,n),e.splice(i,1),i--}return t}),n.formatArgs.call(o,e);(o.log||n.log).apply(o,e)}return s.namespace=e,s.useColors=n.useColors(),s.color=n.selectColor(e),s.extend=o,s.destroy=n.destroy,Object.defineProperty(s,"enabled",{enumerable:!0,configurable:!1,get:()=>null!==i?i:(r!==n.namespaces&&(r=n.namespaces,a=n.enabled(e)),a),set:e=>{i=e}}),"function"==typeof n.init&&n.init(s),s}function o(e,t){const o=n(this.namespace+(void 0===t?":":t)+e);return o.log=this.log,o}function r(e){return e.toString().substring(2,e.toString().length-2).replace(/\.\*\?$/,"*")}return n.debug=n,n.default=n,n.coerce=function(e){if(e instanceof Error)return e.stack||e.message;return e},n.disable=function(){const e=[...n.names.map(r),...n.skips.map(r).map(e=>"-"+e)].join(",");return n.enable(""),e},n.enable=function(e){let t;n.save(e),n.namespaces=e,n.names=[],n.skips=[];const o=("string"==typeof e?e:"").split(/[\s,]+/),r=o.length;for(t=0;t<r;t++)o[t]&&("-"===(e=o[t].replace(/\*/g,".*?"))[0]?n.skips.push(new RegExp("^"+e.substr(1)+"$")):n.names.push(new RegExp("^"+e+"$")))},n.enabled=function(e){if("*"===e[e.length-1])return!0;let t,o;for(t=0,o=n.skips.length;t<o;t++)if(n.skips[t].test(e))return!1;for(t=0,o=n.names.length;t<o;t++)if(n.names[t].test(e))return!0;return!1},n.humanize=t(174),n.destroy=function(){console.warn("Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.")},Object.keys(e).forEach(t=>{n[t]=e[t]}),n.names=[],n.skips=[],n.formatters={},n.selectColor=function(e){let t=0;for(let n=0;n<e.length;n++)t=(t<<5)-t+e.charCodeAt(n),t|=0;return n.colors[Math.abs(t)%n.colors.length]},n.enable(n.load()),n}},function(e,n){var t=1e3,o=6e4,r=60*o,a=24*r;function i(e,n,t){if(!(e<n))return e<1.5*n?Math.floor(e/n)+" "+t:Math.ceil(e/n)+" "+t+"s"}e.exports=function(e,n){n=n||{};var s,l=typeof e;if("string"===l&&e.length>0)return function(e){if((e=String(e)).length>100)return;var n=/^((?:\d+)?\.?\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|years?|yrs?|y)?$/i.exec(e);if(!n)return;var i=parseFloat(n[1]);switch((n[2]||"ms").toLowerCase()){case"years":case"year":case"yrs":case"yr":case"y":return 315576e5*i;case"days":case"day":case"d":return i*a;case"hours":case"hour":case"hrs":case"hr":case"h":return i*r;case"minutes":case"minute":case"mins":case"min":case"m":return i*o;case"seconds":case"second":case"secs":case"sec":case"s":return i*t;case"milliseconds":case"millisecond":case"msecs":case"msec":case"ms":return i;default:return}}(e);if("number"===l&&!1===isNaN(e))return n.long?i(s=e,a,"day")||i(s,r,"hour")||i(s,o,"minute")||i(s,t,"second")||s+" ms":function(e){if(e>=a)return Math.round(e/a)+"d";if(e>=r)return Math.round(e/r)+"h";if(e>=o)return Math.round(e/o)+"m";if(e>=t)return Math.round(e/t)+"s";return e+"ms"}(e);throw new Error("val is not a non-empty string or a valid number. val="+JSON.stringify(e))}},function(e,n,t){},function(e,n,t){},function(e,n,t){"use strict";t(57)},function(e,n,t){"use strict";t(58)},function(e,n,t){"use strict";t(59)},function(e,n,t){"use strict";t.r(n);var o=t(0);
/*!
  * vue-router v3.5.1
  * (c) 2021 Evan You
  * @license MIT
  */function r(e,n){for(var t in n)e[t]=n[t];return e}var a=/[!'()*]/g,i=function(e){return"%"+e.charCodeAt(0).toString(16)},s=/%2C/g,l=function(e){return encodeURIComponent(e).replace(a,i).replace(s,",")};function u(e){try{return decodeURIComponent(e)}catch(e){0}return e}var c=function(e){return null==e||"object"==typeof e?e:String(e)};function d(e){var n={};return(e=e.trim().replace(/^(\?|#|&)/,""))?(e.split("&").forEach((function(e){var t=e.replace(/\+/g," ").split("="),o=u(t.shift()),r=t.length>0?u(t.join("=")):null;void 0===n[o]?n[o]=r:Array.isArray(n[o])?n[o].push(r):n[o]=[n[o],r]})),n):n}function h(e){var n=e?Object.keys(e).map((function(n){var t=e[n];if(void 0===t)return"";if(null===t)return l(n);if(Array.isArray(t)){var o=[];return t.forEach((function(e){void 0!==e&&(null===e?o.push(l(n)):o.push(l(n)+"="+l(e)))})),o.join("&")}return l(n)+"="+l(t)})).filter((function(e){return e.length>0})).join("&"):null;return n?"?"+n:""}var p=/\/?$/;function y(e,n,t,o){var r=o&&o.options.stringifyQuery,a=n.query||{};try{a=m(a)}catch(e){}var i={name:n.name||e&&e.name,meta:e&&e.meta||{},path:n.path||"/",hash:n.hash||"",query:a,params:n.params||{},fullPath:f(n,r),matched:e?b(e):[]};return t&&(i.redirectedFrom=f(t,r)),Object.freeze(i)}function m(e){if(Array.isArray(e))return e.map(m);if(e&&"object"==typeof e){var n={};for(var t in e)n[t]=m(e[t]);return n}return e}var g=y(null,{path:"/"});function b(e){for(var n=[];e;)n.unshift(e),e=e.parent;return n}function f(e,n){var t=e.path,o=e.query;void 0===o&&(o={});var r=e.hash;return void 0===r&&(r=""),(t||"/")+(n||h)(o)+r}function w(e,n,t){return n===g?e===n:!!n&&(e.path&&n.path?e.path.replace(p,"")===n.path.replace(p,"")&&(t||e.hash===n.hash&&v(e.query,n.query)):!(!e.name||!n.name)&&(e.name===n.name&&(t||e.hash===n.hash&&v(e.query,n.query)&&v(e.params,n.params))))}function v(e,n){if(void 0===e&&(e={}),void 0===n&&(n={}),!e||!n)return e===n;var t=Object.keys(e).sort(),o=Object.keys(n).sort();return t.length===o.length&&t.every((function(t,r){var a=e[t];if(o[r]!==t)return!1;var i=n[t];return null==a||null==i?a===i:"object"==typeof a&&"object"==typeof i?v(a,i):String(a)===String(i)}))}function k(e){for(var n=0;n<e.matched.length;n++){var t=e.matched[n];for(var o in t.instances){var r=t.instances[o],a=t.enteredCbs[o];if(r&&a){delete t.enteredCbs[o];for(var i=0;i<a.length;i++)r._isBeingDestroyed||a[i](r)}}}}var q={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(e,n){var t=n.props,o=n.children,a=n.parent,i=n.data;i.routerView=!0;for(var s=a.$createElement,l=t.name,u=a.$route,c=a._routerViewCache||(a._routerViewCache={}),d=0,h=!1;a&&a._routerRoot!==a;){var p=a.$vnode?a.$vnode.data:{};p.routerView&&d++,p.keepAlive&&a._directInactive&&a._inactive&&(h=!0),a=a.$parent}if(i.routerViewDepth=d,h){var y=c[l],m=y&&y.component;return m?(y.configProps&&x(m,i,y.route,y.configProps),s(m,i,o)):s()}var g=u.matched[d],b=g&&g.components[l];if(!g||!b)return c[l]=null,s();c[l]={component:b},i.registerRouteInstance=function(e,n){var t=g.instances[l];(n&&t!==e||!n&&t===e)&&(g.instances[l]=n)},(i.hook||(i.hook={})).prepatch=function(e,n){g.instances[l]=n.componentInstance},i.hook.init=function(e){e.data.keepAlive&&e.componentInstance&&e.componentInstance!==g.instances[l]&&(g.instances[l]=e.componentInstance),k(u)};var f=g.props&&g.props[l];return f&&(r(c[l],{route:u,configProps:f}),x(b,i,u,f)),s(b,i,o)}};function x(e,n,t,o){var a=n.props=function(e,n){switch(typeof n){case"undefined":return;case"object":return n;case"function":return n(e);case"boolean":return n?e.params:void 0;default:0}}(t,o);if(a){a=n.props=r({},a);var i=n.attrs=n.attrs||{};for(var s in a)e.props&&s in e.props||(i[s]=a[s],delete a[s])}}function j(e,n,t){var o=e.charAt(0);if("/"===o)return e;if("?"===o||"#"===o)return n+e;var r=n.split("/");t&&r[r.length-1]||r.pop();for(var a=e.replace(/^\//,"").split("/"),i=0;i<a.length;i++){var s=a[i];".."===s?r.pop():"."!==s&&r.push(s)}return""!==r[0]&&r.unshift(""),r.join("/")}function S(e){return e.replace(/\/\//g,"/")}var T=Array.isArray||function(e){return"[object Array]"==Object.prototype.toString.call(e)},Q=R,I=A,P=function(e,n){return L(A(e,n),n)},z=L,C=N,_=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function A(e,n){for(var t,o=[],r=0,a=0,i="",s=n&&n.delimiter||"/";null!=(t=_.exec(e));){var l=t[0],u=t[1],c=t.index;if(i+=e.slice(a,c),a=c+l.length,u)i+=u[1];else{var d=e[a],h=t[2],p=t[3],y=t[4],m=t[5],g=t[6],b=t[7];i&&(o.push(i),i="");var f=null!=h&&null!=d&&d!==h,w="+"===g||"*"===g,v="?"===g||"*"===g,k=t[2]||s,q=y||m;o.push({name:p||r++,prefix:h||"",delimiter:k,optional:v,repeat:w,partial:f,asterisk:!!b,pattern:q?O(q):b?".*":"[^"+H(k)+"]+?"})}}return a<e.length&&(i+=e.substr(a)),i&&o.push(i),o}function E(e){return encodeURI(e).replace(/[\/?#]/g,(function(e){return"%"+e.charCodeAt(0).toString(16).toUpperCase()}))}function L(e,n){for(var t=new Array(e.length),o=0;o<e.length;o++)"object"==typeof e[o]&&(t[o]=new RegExp("^(?:"+e[o].pattern+")$",G(n)));return function(n,o){for(var r="",a=n||{},i=(o||{}).pretty?E:encodeURIComponent,s=0;s<e.length;s++){var l=e[s];if("string"!=typeof l){var u,c=a[l.name];if(null==c){if(l.optional){l.partial&&(r+=l.prefix);continue}throw new TypeError('Expected "'+l.name+'" to be defined')}if(T(c)){if(!l.repeat)throw new TypeError('Expected "'+l.name+'" to not repeat, but received `'+JSON.stringify(c)+"`");if(0===c.length){if(l.optional)continue;throw new TypeError('Expected "'+l.name+'" to not be empty')}for(var d=0;d<c.length;d++){if(u=i(c[d]),!t[s].test(u))throw new TypeError('Expected all "'+l.name+'" to match "'+l.pattern+'", but received `'+JSON.stringify(u)+"`");r+=(0===d?l.prefix:l.delimiter)+u}}else{if(u=l.asterisk?encodeURI(c).replace(/[?#]/g,(function(e){return"%"+e.charCodeAt(0).toString(16).toUpperCase()})):i(c),!t[s].test(u))throw new TypeError('Expected "'+l.name+'" to match "'+l.pattern+'", but received "'+u+'"');r+=l.prefix+u}}else r+=l}return r}}function H(e){return e.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function O(e){return e.replace(/([=!:$\/()])/g,"\\$1")}function D(e,n){return e.keys=n,e}function G(e){return e&&e.sensitive?"":"i"}function N(e,n,t){T(n)||(t=n||t,n=[]);for(var o=(t=t||{}).strict,r=!1!==t.end,a="",i=0;i<e.length;i++){var s=e[i];if("string"==typeof s)a+=H(s);else{var l=H(s.prefix),u="(?:"+s.pattern+")";n.push(s),s.repeat&&(u+="(?:"+l+u+")*"),a+=u=s.optional?s.partial?l+"("+u+")?":"(?:"+l+"("+u+"))?":l+"("+u+")"}}var c=H(t.delimiter||"/"),d=a.slice(-c.length)===c;return o||(a=(d?a.slice(0,-c.length):a)+"(?:"+c+"(?=$))?"),a+=r?"$":o&&d?"":"(?="+c+"|$)",D(new RegExp("^"+a,G(t)),n)}function R(e,n,t){return T(n)||(t=n||t,n=[]),t=t||{},e instanceof RegExp?function(e,n){var t=e.source.match(/\((?!\?)/g);if(t)for(var o=0;o<t.length;o++)n.push({name:o,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return D(e,n)}(e,n):T(e)?function(e,n,t){for(var o=[],r=0;r<e.length;r++)o.push(R(e[r],n,t).source);return D(new RegExp("(?:"+o.join("|")+")",G(t)),n)}(e,n,t):function(e,n,t){return N(A(e,t),n,t)}(e,n,t)}Q.parse=I,Q.compile=P,Q.tokensToFunction=z,Q.tokensToRegExp=C;var M=Object.create(null);function W(e,n,t){n=n||{};try{var o=M[e]||(M[e]=Q.compile(e));return"string"==typeof n.pathMatch&&(n[0]=n.pathMatch),o(n,{pretty:!0})}catch(e){return""}finally{delete n[0]}}function B(e,n,t,o){var a="string"==typeof e?{path:e}:e;if(a._normalized)return a;if(a.name){var i=(a=r({},e)).params;return i&&"object"==typeof i&&(a.params=r({},i)),a}if(!a.path&&a.params&&n){(a=r({},a))._normalized=!0;var s=r(r({},n.params),a.params);if(n.name)a.name=n.name,a.params=s;else if(n.matched.length){var l=n.matched[n.matched.length-1].path;a.path=W(l,s,n.path)}else 0;return a}var u=function(e){var n="",t="",o=e.indexOf("#");o>=0&&(n=e.slice(o),e=e.slice(0,o));var r=e.indexOf("?");return r>=0&&(t=e.slice(r+1),e=e.slice(0,r)),{path:e,query:t,hash:n}}(a.path||""),h=n&&n.path||"/",p=u.path?j(u.path,h,t||a.append):h,y=function(e,n,t){void 0===n&&(n={});var o,r=t||d;try{o=r(e||"")}catch(e){o={}}for(var a in n){var i=n[a];o[a]=Array.isArray(i)?i.map(c):c(i)}return o}(u.query,a.query,o&&o.options.parseQuery),m=a.hash||u.hash;return m&&"#"!==m.charAt(0)&&(m="#"+m),{_normalized:!0,path:p,query:y,hash:m}}var F,U=function(){},Y={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(e){var n=this,t=this.$router,o=this.$route,a=t.resolve(this.to,o,this.append),i=a.location,s=a.route,l=a.href,u={},c=t.options.linkActiveClass,d=t.options.linkExactActiveClass,h=null==c?"router-link-active":c,m=null==d?"router-link-exact-active":d,g=null==this.activeClass?h:this.activeClass,b=null==this.exactActiveClass?m:this.exactActiveClass,f=s.redirectedFrom?y(null,B(s.redirectedFrom),null,t):s;u[b]=w(o,f,this.exactPath),u[g]=this.exact||this.exactPath?u[b]:function(e,n){return 0===e.path.replace(p,"/").indexOf(n.path.replace(p,"/"))&&(!n.hash||e.hash===n.hash)&&function(e,n){for(var t in n)if(!(t in e))return!1;return!0}(e.query,n.query)}(o,f);var v=u[b]?this.ariaCurrentValue:null,k=function(e){V(e)&&(n.replace?t.replace(i,U):t.push(i,U))},q={click:V};Array.isArray(this.event)?this.event.forEach((function(e){q[e]=k})):q[this.event]=k;var x={class:u},j=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:l,route:s,navigate:k,isActive:u[g],isExactActive:u[b]});if(j){if(1===j.length)return j[0];if(j.length>1||!j.length)return 0===j.length?e():e("span",{},j)}if("a"===this.tag)x.on=q,x.attrs={href:l,"aria-current":v};else{var S=function e(n){var t;if(n)for(var o=0;o<n.length;o++){if("a"===(t=n[o]).tag)return t;if(t.children&&(t=e(t.children)))return t}}(this.$slots.default);if(S){S.isStatic=!1;var T=S.data=r({},S.data);for(var Q in T.on=T.on||{},T.on){var I=T.on[Q];Q in q&&(T.on[Q]=Array.isArray(I)?I:[I])}for(var P in q)P in T.on?T.on[P].push(q[P]):T.on[P]=k;var z=S.data.attrs=r({},S.data.attrs);z.href=l,z["aria-current"]=v}else x.on=q}return e(this.tag,x,this.$slots.default)}};function V(e){if(!(e.metaKey||e.altKey||e.ctrlKey||e.shiftKey||e.defaultPrevented||void 0!==e.button&&0!==e.button)){if(e.currentTarget&&e.currentTarget.getAttribute){var n=e.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(n))return}return e.preventDefault&&e.preventDefault(),!0}}var J="undefined"!=typeof window;function $(e,n,t,o,r){var a=n||[],i=t||Object.create(null),s=o||Object.create(null);e.forEach((function(e){!function e(n,t,o,r,a,i){var s=r.path,l=r.name;0;var u=r.pathToRegexpOptions||{},c=function(e,n,t){t||(e=e.replace(/\/$/,""));if("/"===e[0])return e;if(null==n)return e;return S(n.path+"/"+e)}(s,a,u.strict);"boolean"==typeof r.caseSensitive&&(u.sensitive=r.caseSensitive);var d={path:c,regex:K(c,u),components:r.components||{default:r.component},alias:r.alias?"string"==typeof r.alias?[r.alias]:r.alias:[],instances:{},enteredCbs:{},name:l,parent:a,matchAs:i,redirect:r.redirect,beforeEnter:r.beforeEnter,meta:r.meta||{},props:null==r.props?{}:r.components?r.props:{default:r.props}};r.children&&r.children.forEach((function(r){var a=i?S(i+"/"+r.path):void 0;e(n,t,o,r,d,a)}));t[d.path]||(n.push(d.path),t[d.path]=d);if(void 0!==r.alias)for(var h=Array.isArray(r.alias)?r.alias:[r.alias],p=0;p<h.length;++p){0;var y={path:h[p],children:r.children};e(n,t,o,y,a,d.path||"/")}l&&(o[l]||(o[l]=d))}(a,i,s,e,r)}));for(var l=0,u=a.length;l<u;l++)"*"===a[l]&&(a.push(a.splice(l,1)[0]),u--,l--);return{pathList:a,pathMap:i,nameMap:s}}function K(e,n){return Q(e,[],n)}function Z(e,n){var t=$(e),o=t.pathList,r=t.pathMap,a=t.nameMap;function i(e,t,i){var s=B(e,t,!1,n),u=s.name;if(u){var c=a[u];if(!c)return l(null,s);var d=c.regex.keys.filter((function(e){return!e.optional})).map((function(e){return e.name}));if("object"!=typeof s.params&&(s.params={}),t&&"object"==typeof t.params)for(var h in t.params)!(h in s.params)&&d.indexOf(h)>-1&&(s.params[h]=t.params[h]);return s.path=W(c.path,s.params),l(c,s,i)}if(s.path){s.params={};for(var p=0;p<o.length;p++){var y=o[p],m=r[y];if(X(m.regex,s.path,s.params))return l(m,s,i)}}return l(null,s)}function s(e,t){var o=e.redirect,r="function"==typeof o?o(y(e,t,null,n)):o;if("string"==typeof r&&(r={path:r}),!r||"object"!=typeof r)return l(null,t);var s=r,u=s.name,c=s.path,d=t.query,h=t.hash,p=t.params;if(d=s.hasOwnProperty("query")?s.query:d,h=s.hasOwnProperty("hash")?s.hash:h,p=s.hasOwnProperty("params")?s.params:p,u){a[u];return i({_normalized:!0,name:u,query:d,hash:h,params:p},void 0,t)}if(c){var m=function(e,n){return j(e,n.parent?n.parent.path:"/",!0)}(c,e);return i({_normalized:!0,path:W(m,p),query:d,hash:h},void 0,t)}return l(null,t)}function l(e,t,o){return e&&e.redirect?s(e,o||t):e&&e.matchAs?function(e,n,t){var o=i({_normalized:!0,path:W(t,n.params)});if(o){var r=o.matched,a=r[r.length-1];return n.params=o.params,l(a,n)}return l(null,n)}(0,t,e.matchAs):y(e,t,o,n)}return{match:i,addRoute:function(e,n){var t="object"!=typeof e?a[e]:void 0;$([n||e],o,r,a,t),t&&$(t.alias.map((function(e){return{path:e,children:[n]}})),o,r,a,t)},getRoutes:function(){return o.map((function(e){return r[e]}))},addRoutes:function(e){$(e,o,r,a)}}}function X(e,n,t){var o=n.match(e);if(!o)return!1;if(!t)return!0;for(var r=1,a=o.length;r<a;++r){var i=e.keys[r-1];i&&(t[i.name||"pathMatch"]="string"==typeof o[r]?u(o[r]):o[r])}return!0}var ee=J&&window.performance&&window.performance.now?window.performance:Date;function ne(){return ee.now().toFixed(3)}var te=ne();function oe(){return te}function re(e){return te=e}var ae=Object.create(null);function ie(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var e=window.location.protocol+"//"+window.location.host,n=window.location.href.replace(e,""),t=r({},window.history.state);return t.key=oe(),window.history.replaceState(t,"",n),window.addEventListener("popstate",ue),function(){window.removeEventListener("popstate",ue)}}function se(e,n,t,o){if(e.app){var r=e.options.scrollBehavior;r&&e.app.$nextTick((function(){var a=function(){var e=oe();if(e)return ae[e]}(),i=r.call(e,n,t,o?a:null);i&&("function"==typeof i.then?i.then((function(e){ye(e,a)})).catch((function(e){0})):ye(i,a))}))}}function le(){var e=oe();e&&(ae[e]={x:window.pageXOffset,y:window.pageYOffset})}function ue(e){le(),e.state&&e.state.key&&re(e.state.key)}function ce(e){return he(e.x)||he(e.y)}function de(e){return{x:he(e.x)?e.x:window.pageXOffset,y:he(e.y)?e.y:window.pageYOffset}}function he(e){return"number"==typeof e}var pe=/^#\d/;function ye(e,n){var t,o="object"==typeof e;if(o&&"string"==typeof e.selector){var r=pe.test(e.selector)?document.getElementById(e.selector.slice(1)):document.querySelector(e.selector);if(r){var a=e.offset&&"object"==typeof e.offset?e.offset:{};n=function(e,n){var t=document.documentElement.getBoundingClientRect(),o=e.getBoundingClientRect();return{x:o.left-t.left-n.x,y:o.top-t.top-n.y}}(r,a={x:he((t=a).x)?t.x:0,y:he(t.y)?t.y:0})}else ce(e)&&(n=de(e))}else o&&ce(e)&&(n=de(e));n&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:n.x,top:n.y,behavior:e.behavior}):window.scrollTo(n.x,n.y))}var me,ge=J&&((-1===(me=window.navigator.userAgent).indexOf("Android 2.")&&-1===me.indexOf("Android 4.0")||-1===me.indexOf("Mobile Safari")||-1!==me.indexOf("Chrome")||-1!==me.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function be(e,n){le();var t=window.history;try{if(n){var o=r({},t.state);o.key=oe(),t.replaceState(o,"",e)}else t.pushState({key:re(ne())},"",e)}catch(t){window.location[n?"replace":"assign"](e)}}function fe(e){be(e,!0)}function we(e,n,t){var o=function(r){r>=e.length?t():e[r]?n(e[r],(function(){o(r+1)})):o(r+1)};o(0)}var ve={redirected:2,aborted:4,cancelled:8,duplicated:16};function ke(e,n){return xe(e,n,ve.redirected,'Redirected when going from "'+e.fullPath+'" to "'+function(e){if("string"==typeof e)return e;if("path"in e)return e.path;var n={};return je.forEach((function(t){t in e&&(n[t]=e[t])})),JSON.stringify(n,null,2)}(n)+'" via a navigation guard.')}function qe(e,n){return xe(e,n,ve.cancelled,'Navigation cancelled from "'+e.fullPath+'" to "'+n.fullPath+'" with a new navigation.')}function xe(e,n,t,o){var r=new Error(o);return r._isRouter=!0,r.from=e,r.to=n,r.type=t,r}var je=["params","query","hash"];function Se(e){return Object.prototype.toString.call(e).indexOf("Error")>-1}function Te(e,n){return Se(e)&&e._isRouter&&(null==n||e.type===n)}function Qe(e){return function(n,t,o){var r=!1,a=0,i=null;Ie(e,(function(e,n,t,s){if("function"==typeof e&&void 0===e.cid){r=!0,a++;var l,u=Ce((function(n){var r;((r=n).__esModule||ze&&"Module"===r[Symbol.toStringTag])&&(n=n.default),e.resolved="function"==typeof n?n:F.extend(n),t.components[s]=n,--a<=0&&o()})),c=Ce((function(e){var n="Failed to resolve async component "+s+": "+e;i||(i=Se(e)?e:new Error(n),o(i))}));try{l=e(u,c)}catch(e){c(e)}if(l)if("function"==typeof l.then)l.then(u,c);else{var d=l.component;d&&"function"==typeof d.then&&d.then(u,c)}}})),r||o()}}function Ie(e,n){return Pe(e.map((function(e){return Object.keys(e.components).map((function(t){return n(e.components[t],e.instances[t],e,t)}))})))}function Pe(e){return Array.prototype.concat.apply([],e)}var ze="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function Ce(e){var n=!1;return function(){for(var t=[],o=arguments.length;o--;)t[o]=arguments[o];if(!n)return n=!0,e.apply(this,t)}}var _e=function(e,n){this.router=e,this.base=function(e){if(!e)if(J){var n=document.querySelector("base");e=(e=n&&n.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else e="/";"/"!==e.charAt(0)&&(e="/"+e);return e.replace(/\/$/,"")}(n),this.current=g,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function Ae(e,n,t,o){var r=Ie(e,(function(e,o,r,a){var i=function(e,n){"function"!=typeof e&&(e=F.extend(e));return e.options[n]}(e,n);if(i)return Array.isArray(i)?i.map((function(e){return t(e,o,r,a)})):t(i,o,r,a)}));return Pe(o?r.reverse():r)}function Ee(e,n){if(n)return function(){return e.apply(n,arguments)}}_e.prototype.listen=function(e){this.cb=e},_e.prototype.onReady=function(e,n){this.ready?e():(this.readyCbs.push(e),n&&this.readyErrorCbs.push(n))},_e.prototype.onError=function(e){this.errorCbs.push(e)},_e.prototype.transitionTo=function(e,n,t){var o,r=this;try{o=this.router.match(e,this.current)}catch(e){throw this.errorCbs.forEach((function(n){n(e)})),e}var a=this.current;this.confirmTransition(o,(function(){r.updateRoute(o),n&&n(o),r.ensureURL(),r.router.afterHooks.forEach((function(e){e&&e(o,a)})),r.ready||(r.ready=!0,r.readyCbs.forEach((function(e){e(o)})))}),(function(e){t&&t(e),e&&!r.ready&&(Te(e,ve.redirected)&&a===g||(r.ready=!0,r.readyErrorCbs.forEach((function(n){n(e)}))))}))},_e.prototype.confirmTransition=function(e,n,t){var o=this,r=this.current;this.pending=e;var a,i,s=function(e){!Te(e)&&Se(e)&&(o.errorCbs.length?o.errorCbs.forEach((function(n){n(e)})):console.error(e)),t&&t(e)},l=e.matched.length-1,u=r.matched.length-1;if(w(e,r)&&l===u&&e.matched[l]===r.matched[u])return this.ensureURL(),s(((i=xe(a=r,e,ve.duplicated,'Avoided redundant navigation to current location: "'+a.fullPath+'".')).name="NavigationDuplicated",i));var c=function(e,n){var t,o=Math.max(e.length,n.length);for(t=0;t<o&&e[t]===n[t];t++);return{updated:n.slice(0,t),activated:n.slice(t),deactivated:e.slice(t)}}(this.current.matched,e.matched),d=c.updated,h=c.deactivated,p=c.activated,y=[].concat(function(e){return Ae(e,"beforeRouteLeave",Ee,!0)}(h),this.router.beforeHooks,function(e){return Ae(e,"beforeRouteUpdate",Ee)}(d),p.map((function(e){return e.beforeEnter})),Qe(p)),m=function(n,t){if(o.pending!==e)return s(qe(r,e));try{n(e,r,(function(n){!1===n?(o.ensureURL(!0),s(function(e,n){return xe(e,n,ve.aborted,'Navigation aborted from "'+e.fullPath+'" to "'+n.fullPath+'" via a navigation guard.')}(r,e))):Se(n)?(o.ensureURL(!0),s(n)):"string"==typeof n||"object"==typeof n&&("string"==typeof n.path||"string"==typeof n.name)?(s(ke(r,e)),"object"==typeof n&&n.replace?o.replace(n):o.push(n)):t(n)}))}catch(e){s(e)}};we(y,m,(function(){we(function(e){return Ae(e,"beforeRouteEnter",(function(e,n,t,o){return function(e,n,t){return function(o,r,a){return e(o,r,(function(e){"function"==typeof e&&(n.enteredCbs[t]||(n.enteredCbs[t]=[]),n.enteredCbs[t].push(e)),a(e)}))}}(e,t,o)}))}(p).concat(o.router.resolveHooks),m,(function(){if(o.pending!==e)return s(qe(r,e));o.pending=null,n(e),o.router.app&&o.router.app.$nextTick((function(){k(e)}))}))}))},_e.prototype.updateRoute=function(e){this.current=e,this.cb&&this.cb(e)},_e.prototype.setupListeners=function(){},_e.prototype.teardown=function(){this.listeners.forEach((function(e){e()})),this.listeners=[],this.current=g,this.pending=null};var Le=function(e){function n(n,t){e.call(this,n,t),this._startLocation=He(this.base)}return e&&(n.__proto__=e),n.prototype=Object.create(e&&e.prototype),n.prototype.constructor=n,n.prototype.setupListeners=function(){var e=this;if(!(this.listeners.length>0)){var n=this.router,t=n.options.scrollBehavior,o=ge&&t;o&&this.listeners.push(ie());var r=function(){var t=e.current,r=He(e.base);e.current===g&&r===e._startLocation||e.transitionTo(r,(function(e){o&&se(n,e,t,!0)}))};window.addEventListener("popstate",r),this.listeners.push((function(){window.removeEventListener("popstate",r)}))}},n.prototype.go=function(e){window.history.go(e)},n.prototype.push=function(e,n,t){var o=this,r=this.current;this.transitionTo(e,(function(e){be(S(o.base+e.fullPath)),se(o.router,e,r,!1),n&&n(e)}),t)},n.prototype.replace=function(e,n,t){var o=this,r=this.current;this.transitionTo(e,(function(e){fe(S(o.base+e.fullPath)),se(o.router,e,r,!1),n&&n(e)}),t)},n.prototype.ensureURL=function(e){if(He(this.base)!==this.current.fullPath){var n=S(this.base+this.current.fullPath);e?be(n):fe(n)}},n.prototype.getCurrentLocation=function(){return He(this.base)},n}(_e);function He(e){var n=window.location.pathname;return e&&0===n.toLowerCase().indexOf(e.toLowerCase())&&(n=n.slice(e.length)),(n||"/")+window.location.search+window.location.hash}var Oe=function(e){function n(n,t,o){e.call(this,n,t),o&&function(e){var n=He(e);if(!/^\/#/.test(n))return window.location.replace(S(e+"/#"+n)),!0}(this.base)||De()}return e&&(n.__proto__=e),n.prototype=Object.create(e&&e.prototype),n.prototype.constructor=n,n.prototype.setupListeners=function(){var e=this;if(!(this.listeners.length>0)){var n=this.router.options.scrollBehavior,t=ge&&n;t&&this.listeners.push(ie());var o=function(){var n=e.current;De()&&e.transitionTo(Ge(),(function(o){t&&se(e.router,o,n,!0),ge||Me(o.fullPath)}))},r=ge?"popstate":"hashchange";window.addEventListener(r,o),this.listeners.push((function(){window.removeEventListener(r,o)}))}},n.prototype.push=function(e,n,t){var o=this,r=this.current;this.transitionTo(e,(function(e){Re(e.fullPath),se(o.router,e,r,!1),n&&n(e)}),t)},n.prototype.replace=function(e,n,t){var o=this,r=this.current;this.transitionTo(e,(function(e){Me(e.fullPath),se(o.router,e,r,!1),n&&n(e)}),t)},n.prototype.go=function(e){window.history.go(e)},n.prototype.ensureURL=function(e){var n=this.current.fullPath;Ge()!==n&&(e?Re(n):Me(n))},n.prototype.getCurrentLocation=function(){return Ge()},n}(_e);function De(){var e=Ge();return"/"===e.charAt(0)||(Me("/"+e),!1)}function Ge(){var e=window.location.href,n=e.indexOf("#");return n<0?"":e=e.slice(n+1)}function Ne(e){var n=window.location.href,t=n.indexOf("#");return(t>=0?n.slice(0,t):n)+"#"+e}function Re(e){ge?be(Ne(e)):window.location.hash=e}function Me(e){ge?fe(Ne(e)):window.location.replace(Ne(e))}var We=function(e){function n(n,t){e.call(this,n,t),this.stack=[],this.index=-1}return e&&(n.__proto__=e),n.prototype=Object.create(e&&e.prototype),n.prototype.constructor=n,n.prototype.push=function(e,n,t){var o=this;this.transitionTo(e,(function(e){o.stack=o.stack.slice(0,o.index+1).concat(e),o.index++,n&&n(e)}),t)},n.prototype.replace=function(e,n,t){var o=this;this.transitionTo(e,(function(e){o.stack=o.stack.slice(0,o.index).concat(e),n&&n(e)}),t)},n.prototype.go=function(e){var n=this,t=this.index+e;if(!(t<0||t>=this.stack.length)){var o=this.stack[t];this.confirmTransition(o,(function(){var e=n.current;n.index=t,n.updateRoute(o),n.router.afterHooks.forEach((function(n){n&&n(o,e)}))}),(function(e){Te(e,ve.duplicated)&&(n.index=t)}))}},n.prototype.getCurrentLocation=function(){var e=this.stack[this.stack.length-1];return e?e.fullPath:"/"},n.prototype.ensureURL=function(){},n}(_e),Be=function(e){void 0===e&&(e={}),this.app=null,this.apps=[],this.options=e,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Z(e.routes||[],this);var n=e.mode||"hash";switch(this.fallback="history"===n&&!ge&&!1!==e.fallback,this.fallback&&(n="hash"),J||(n="abstract"),this.mode=n,n){case"history":this.history=new Le(this,e.base);break;case"hash":this.history=new Oe(this,e.base,this.fallback);break;case"abstract":this.history=new We(this,e.base);break;default:0}},Fe={currentRoute:{configurable:!0}};function Ue(e,n){return e.push(n),function(){var t=e.indexOf(n);t>-1&&e.splice(t,1)}}Be.prototype.match=function(e,n,t){return this.matcher.match(e,n,t)},Fe.currentRoute.get=function(){return this.history&&this.history.current},Be.prototype.init=function(e){var n=this;if(this.apps.push(e),e.$once("hook:destroyed",(function(){var t=n.apps.indexOf(e);t>-1&&n.apps.splice(t,1),n.app===e&&(n.app=n.apps[0]||null),n.app||n.history.teardown()})),!this.app){this.app=e;var t=this.history;if(t instanceof Le||t instanceof Oe){var o=function(e){t.setupListeners(),function(e){var o=t.current,r=n.options.scrollBehavior;ge&&r&&"fullPath"in e&&se(n,e,o,!1)}(e)};t.transitionTo(t.getCurrentLocation(),o,o)}t.listen((function(e){n.apps.forEach((function(n){n._route=e}))}))}},Be.prototype.beforeEach=function(e){return Ue(this.beforeHooks,e)},Be.prototype.beforeResolve=function(e){return Ue(this.resolveHooks,e)},Be.prototype.afterEach=function(e){return Ue(this.afterHooks,e)},Be.prototype.onReady=function(e,n){this.history.onReady(e,n)},Be.prototype.onError=function(e){this.history.onError(e)},Be.prototype.push=function(e,n,t){var o=this;if(!n&&!t&&"undefined"!=typeof Promise)return new Promise((function(n,t){o.history.push(e,n,t)}));this.history.push(e,n,t)},Be.prototype.replace=function(e,n,t){var o=this;if(!n&&!t&&"undefined"!=typeof Promise)return new Promise((function(n,t){o.history.replace(e,n,t)}));this.history.replace(e,n,t)},Be.prototype.go=function(e){this.history.go(e)},Be.prototype.back=function(){this.go(-1)},Be.prototype.forward=function(){this.go(1)},Be.prototype.getMatchedComponents=function(e){var n=e?e.matched?e:this.resolve(e).route:this.currentRoute;return n?[].concat.apply([],n.matched.map((function(e){return Object.keys(e.components).map((function(n){return e.components[n]}))}))):[]},Be.prototype.resolve=function(e,n,t){var o=B(e,n=n||this.history.current,t,this),r=this.match(o,n),a=r.redirectedFrom||r.fullPath;return{location:o,route:r,href:function(e,n,t){var o="hash"===t?"#"+n:n;return e?S(e+"/"+o):o}(this.history.base,a,this.mode),normalizedTo:o,resolved:r}},Be.prototype.getRoutes=function(){return this.matcher.getRoutes()},Be.prototype.addRoute=function(e,n){this.matcher.addRoute(e,n),this.history.current!==g&&this.history.transitionTo(this.history.getCurrentLocation())},Be.prototype.addRoutes=function(e){this.matcher.addRoutes(e),this.history.current!==g&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(Be.prototype,Fe),Be.install=function e(n){if(!e.installed||F!==n){e.installed=!0,F=n;var t=function(e){return void 0!==e},o=function(e,n){var o=e.$options._parentVnode;t(o)&&t(o=o.data)&&t(o=o.registerRouteInstance)&&o(e,n)};n.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),n.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,o(this,this)},destroyed:function(){o(this)}}),Object.defineProperty(n.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(n.prototype,"$route",{get:function(){return this._routerRoot._route}}),n.component("RouterView",q),n.component("RouterLink",Y);var r=n.config.optionMergeStrategies;r.beforeRouteEnter=r.beforeRouteLeave=r.beforeRouteUpdate=r.created}},Be.version="3.5.1",Be.isNavigationFailure=Te,Be.NavigationFailureType=ve,Be.START_LOCATION=g,J&&window.Vue&&window.Vue.use(Be);var Ye=Be;var Ve={NotFound:()=>Promise.all([t.e(0),t.e(1),t.e(2),t.e(6)]).then(t.bind(null,481)),Blog:()=>Promise.all([t.e(0),t.e(1),t.e(2),t.e(4)]).then(t.bind(null,480)),Layout:()=>Promise.all([t.e(0),t.e(1),t.e(2),t.e(58),t.e(5)]).then(t.bind(null,479)),Slide:()=>Promise.all([t.e(0),t.e(1),t.e(7)]).then(t.bind(null,482))},Je={"v-47639a6e":()=>t.e(13).then(t.bind(null,483)),"v-86b1f726":()=>t.e(29).then(t.bind(null,484)),"v-94114ee6":()=>t.e(25).then(t.bind(null,485)),"v-5d960c2d":()=>t.e(41).then(t.bind(null,486)),"v-03d2d023":()=>t.e(42).then(t.bind(null,487)),"v-4806233e":()=>t.e(14).then(t.bind(null,488)),"v-64c45226":()=>t.e(29).then(t.bind(null,489)),"v-19f3891b":()=>t.e(25).then(t.bind(null,490)),"v-4f881571":()=>t.e(41).then(t.bind(null,491)),"v-f95dcc66":()=>t.e(42).then(t.bind(null,492)),"v-3d649b57":()=>t.e(28).then(t.bind(null,493)),"v-46088ee7":()=>t.e(39).then(t.bind(null,494)),"v-4f6d6333":()=>t.e(19).then(t.bind(null,495)),"v-25b5132d":()=>t.e(20).then(t.bind(null,496)),"v-220de14d":()=>t.e(24).then(t.bind(null,497)),"v-8fd36766":()=>t.e(48).then(t.bind(null,498)),"v-576a0161":()=>t.e(22).then(t.bind(null,499)),"v-45bb1917":()=>t.e(43).then(t.bind(null,500)),"v-04677efd":()=>t.e(26).then(t.bind(null,501)),"v-03e13271":()=>t.e(40).then(t.bind(null,502)),"v-306d6933":()=>t.e(45).then(t.bind(null,503)),"v-754465ed":()=>t.e(31).then(t.bind(null,504)),"v-756db2b5":()=>t.e(32).then(t.bind(null,505)),"v-e30ce652":()=>t.e(46).then(t.bind(null,506)),"v-76f709af":()=>t.e(33).then(t.bind(null,507)),"v-bc8b07b2":()=>t.e(47).then(t.bind(null,508)),"v-5c0f832f":()=>t.e(50).then(t.bind(null,509)),"v-89f298e6":()=>t.e(51).then(t.bind(null,510)),"v-65f40cc9":()=>t.e(52).then(t.bind(null,511)),"v-4162124d":()=>t.e(49).then(t.bind(null,512)),"v-1397d61e":()=>t.e(8).then(t.bind(null,513)),"v-514b550d":()=>t.e(29).then(t.bind(null,514)),"v-7c3a4841":()=>t.e(25).then(t.bind(null,515)),"v-38986917":()=>t.e(41).then(t.bind(null,516)),"v-06fe97ed":()=>t.e(42).then(t.bind(null,517)),"v-56f85486":()=>t.e(28).then(t.bind(null,518)),"v-2f18e28d":()=>t.e(39).then(t.bind(null,519)),"v-76f64b99":()=>t.e(19).then(t.bind(null,520)),"v-2e6d4e4d":()=>t.e(20).then(t.bind(null,521)),"v-29564a26":()=>t.e(24).then(t.bind(null,522)),"v-fd457426":()=>t.e(48).then(t.bind(null,523)),"v-407a5507":()=>t.e(22).then(t.bind(null,524)),"v-2ecb6cbd":()=>t.e(43).then(t.bind(null,525)),"v-25105aba":()=>t.e(26).then(t.bind(null,526)),"v-0b973857":()=>t.e(40).then(t.bind(null,527)),"v-2d2f1159":()=>t.e(45).then(t.bind(null,528)),"v-ee61d266":()=>t.e(31).then(t.bind(null,529)),"v-2f06345b":()=>t.e(32).then(t.bind(null,530)),"v-19c469bd":()=>t.e(46).then(t.bind(null,531)),"v-6ba4f6d5":()=>t.e(33).then(t.bind(null,532)),"v-ab158e66":()=>t.e(47).then(t.bind(null,533)),"v-58d12b55":()=>t.e(50).then(t.bind(null,534)),"v-76eb85ed":()=>t.e(51).then(t.bind(null,535)),"v-1f8c8e6f":()=>t.e(52).then(t.bind(null,536)),"v-5bbe0a6d":()=>t.e(49).then(t.bind(null,537)),"v-1265970d":()=>t.e(28).then(t.bind(null,538)),"v-560420fe":()=>t.e(15).then(t.bind(null,539)),"v-56f909a6":()=>t.e(29).then(t.bind(null,540)),"v-6a073232":()=>t.e(25).then(t.bind(null,541)),"v-7e31bc3d":()=>t.e(41).then(t.bind(null,542)),"v-eb9283e6":()=>t.e(42).then(t.bind(null,543)),"v-47ab00ba":()=>t.e(28).then(t.bind(null,544)),"v-74b235b3":()=>t.e(39).then(t.bind(null,545)),"v-42d0237f":()=>t.e(19).then(t.bind(null,546)),"v-73371d26":()=>t.e(20).then(t.bind(null,547)),"v-932646e6":()=>t.e(24).then(t.bind(null,548)),"v-4c75478d":()=>t.e(48).then(t.bind(null,549)),"v-f3d8afa6":()=>t.e(22).then(t.bind(null,550)),"v-7464bfe3":()=>t.e(43).then(t.bind(null,551)),"v-331125c9":()=>t.e(26).then(t.bind(null,552)),"v-7981e486":()=>t.e(40).then(t.bind(null,553)),"v-5e3758ff":()=>t.e(45).then(t.bind(null,554)),"v-eabc40a6":()=>t.e(31).then(t.bind(null,555)),"v-79dd94fe":()=>t.e(32).then(t.bind(null,556)),"v-26e5d623":()=>t.e(46).then(t.bind(null,557)),"v-3977c37b":()=>t.e(33).then(t.bind(null,558)),"v-5ee434f3":()=>t.e(47).then(t.bind(null,559)),"v-ec4d1a0a":()=>t.e(50).then(t.bind(null,560)),"v-7c9e504d":()=>t.e(51).then(t.bind(null,561)),"v-98d0e0d6":()=>t.e(52).then(t.bind(null,562)),"v-0765aae6":()=>t.e(49).then(t.bind(null,563)),"v-2680104d":()=>t.e(39).then(t.bind(null,564)),"v-188a7204":()=>t.e(10).then(t.bind(null,565)),"v-1466252d":()=>t.e(29).then(t.bind(null,566)),"v-73c98272":()=>t.e(25).then(t.bind(null,567)),"v-1553fc1d":()=>t.e(41).then(t.bind(null,568)),"v-6bcd2fe6":()=>t.e(42).then(t.bind(null,569)),"v-784c5b83":()=>t.e(28).then(t.bind(null,570)),"v-0bd47593":()=>t.e(39).then(t.bind(null,571)),"v-a8374142":()=>t.e(19).then(t.bind(null,572)),"v-2a342b6d":()=>t.e(20).then(t.bind(null,573)),"v-36e11e8d":()=>t.e(24).then(t.bind(null,574)),"v-662cece6":()=>t.e(48).then(t.bind(null,575)),"v-1d35e80d":()=>t.e(22).then(t.bind(null,576)),"v-0b86ffc3":()=>t.e(43).then(t.bind(null,577)),"v-6b9934ae":()=>t.e(26).then(t.bind(null,578)),"v-a188fcc6":()=>t.e(40).then(t.bind(null,579)),"v-296dfe42":()=>t.e(45).then(t.bind(null,580)),"v-f39834a6":()=>t.e(31).then(t.bind(null,581)),"v-0ca4553e":()=>t.e(32).then(t.bind(null,582)),"v-475b7a03":()=>t.e(46).then(t.bind(null,583)),"v-2fc0fb5b":()=>t.e(33).then(t.bind(null,584)),"v-ec5d765a":()=>t.e(47).then(t.bind(null,585)),"v-16eb1adb":()=>t.e(50).then(t.bind(null,586)),"v-0f11ce4d":()=>t.e(51).then(t.bind(null,587)),"v-2b97a116":()=>t.e(52).then(t.bind(null,588)),"v-444c16e6":()=>t.e(49).then(t.bind(null,589)),"v-027260af":()=>t.e(25).then(t.bind(null,590)),"v-f2a4a7f6":()=>t.e(41).then(t.bind(null,591)),"v-8bf930e6":()=>t.e(42).then(t.bind(null,592)),"v-6d65c06b":()=>t.e(28).then(t.bind(null,593)),"v-7d2e257b":()=>t.e(39).then(t.bind(null,594)),"v-0a98e772":()=>t.e(19).then(t.bind(null,595)),"v-95e01226":()=>t.e(20).then(t.bind(null,596)),"v-1738500d":()=>t.e(24).then(t.bind(null,597)),"v-a57e89e6":()=>t.e(48).then(t.bind(null,598)),"v-e2e0d016":()=>t.e(22).then(t.bind(null,599)),"v-7ce0afab":()=>t.e(43).then(t.bind(null,600)),"v-3b8d1591":()=>t.e(26).then(t.bind(null,601)),"v-bf8e4ef6":()=>t.e(40).then(t.bind(null,602)),"v-d5d38272":()=>t.e(45).then(t.bind(null,603)),"v-02e16a2d":()=>t.e(31).then(t.bind(null,604)),"v-bab9656e":()=>t.e(32).then(t.bind(null,605)),"v-c098962a":()=>t.e(46).then(t.bind(null,606)),"v-2f10357a":()=>t.e(33).then(t.bind(null,607)),"v-6a0310bb":()=>t.e(47).then(t.bind(null,608)),"v-7e8f4e7a":()=>t.e(50).then(t.bind(null,609)),"v-062f2666":()=>t.e(51).then(t.bind(null,610)),"v-d9acb146":()=>t.e(52).then(t.bind(null,611)),"v-07038c0d":()=>t.e(49).then(t.bind(null,612)),"v-14d51344":()=>t.e(9).then(t.bind(null,613)),"v-f004ba66":()=>t.e(29).then(t.bind(null,614)),"v-64b91fd5":()=>t.e(25).then(t.bind(null,615)),"v-6fbdffab":()=>t.e(41).then(t.bind(null,616)),"v-3db0e5ad":()=>t.e(42).then(t.bind(null,617)),"v-0484fad1":()=>t.e(28).then(t.bind(null,618)),"v-663e7921":()=>t.e(39).then(t.bind(null,619)),"v-223c74ad":()=>t.e(19).then(t.bind(null,620)),"v-846f9be6":()=>t.e(20).then(t.bind(null,621)),"v-3f016ca6":()=>t.e(24).then(t.bind(null,622)),"v-7687b4ad":()=>t.e(48).then(t.bind(null,623)),"v-779feb9b":()=>t.e(22).then(t.bind(null,624)),"v-65f10351":()=>t.e(43).then(t.bind(null,625)),"v-249d6937":()=>t.e(26).then(t.bind(null,626)),"v-b022432a":()=>t.e(40).then(t.bind(null,627)),"v-dc503226":()=>t.e(45).then(t.bind(null,628)),"v-166c1b0d":()=>t.e(31).then(t.bind(null,629)),"v-5c3bceef":()=>t.e(32).then(t.bind(null,630)),"v-2afe91d1":()=>t.e(46).then(t.bind(null,631)),"v-45b45b2e":()=>t.e(33).then(t.bind(null,632)),"v-72bdcd61":()=>t.e(47).then(t.bind(null,633)),"v-850bfe2e":()=>t.e(50).then(t.bind(null,634)),"v-8e6581a6":()=>t.e(51).then(t.bind(null,635)),"v-4cc22903":()=>t.e(52).then(t.bind(null,636)),"v-215f842d":()=>t.e(49).then(t.bind(null,637)),"v-ae40a866":()=>t.e(19).then(t.bind(null,638)),"v-a45391be":()=>t.e(20).then(t.bind(null,639)),"v-6d299e43":()=>t.e(24).then(t.bind(null,640)),"v-034044f3":()=>t.e(48).then(t.bind(null,641)),"v-b6710da6":()=>t.e(23).then(t.bind(null,642)),"v-5be2726d":()=>t.e(27).then(t.bind(null,643)),"v-529f2d66":()=>t.e(44).then(t.bind(null,644)),"v-31c257a6":()=>t.e(40).then(t.bind(null,645)),"v-ecedcbe6":()=>t.e(45).then(t.bind(null,646)),"v-562bf2a5":()=>t.e(31).then(t.bind(null,647)),"v-bc9cfe26":()=>t.e(32).then(t.bind(null,648)),"v-867568e6":()=>t.e(46).then(t.bind(null,649)),"v-d4874966":()=>t.e(33).then(t.bind(null,650)),"v-b4ffb0e6":()=>t.e(21).then(t.bind(null,651)),"v-3bb71ffe":()=>t.e(12).then(t.bind(null,652)),"v-1b3677a6":()=>t.e(56).then(t.bind(null,653)),"v-1e91fed2":()=>t.e(54).then(t.bind(null,654)),"v-6a2b59ed":()=>t.e(41).then(t.bind(null,655)),"v-afcff1e6":()=>t.e(55).then(t.bind(null,656)),"v-249ce353":()=>t.e(57).then(t.bind(null,657)),"v-60abd363":()=>t.e(39).then(t.bind(null,658)),"v-4a7311a2":()=>t.e(53).then(t.bind(null,659)),"v-7ce7626d":()=>t.e(20).then(t.bind(null,660)),"v-0258bce6":()=>t.e(24).then(t.bind(null,661)),"v-d647e6e6":()=>t.e(48).then(t.bind(null,662)),"v-720d45dd":()=>t.e(22).then(t.bind(null,663)),"v-605e5d93":()=>t.e(43).then(t.bind(null,664)),"v-1f0ac379":()=>t.e(26).then(t.bind(null,665)),"v-50fd6d6d":()=>t.e(40).then(t.bind(null,666)),"v-0ffdfaaf":()=>t.e(45).then(t.bind(null,667)),"v-38af4ead":()=>t.e(31).then(t.bind(null,668)),"v-953a799e":()=>t.e(32).then(t.bind(null,669)),"v-0133a45a":()=>t.e(46).then(t.bind(null,670)),"v-05c24d2b":()=>t.e(33).then(t.bind(null,671)),"v-0df44aba":()=>t.e(47).then(t.bind(null,672)),"v-3ba014ab":()=>t.e(50).then(t.bind(null,673)),"v-11f6eb4d":()=>t.e(51).then(t.bind(null,674)),"v-b42dc576":()=>t.e(52).then(t.bind(null,675)),"v-48f9c38d":()=>t.e(49).then(t.bind(null,676)),"v-09dfd14d":()=>t.e(47).then(t.bind(null,677)),"v-07cf064d":()=>t.e(50).then(t.bind(null,678)),"v-685a2e6d":()=>t.e(35).then(t.bind(null,679)),"v-295c5866":()=>t.e(38).then(t.bind(null,680)),"v-1bc67126":()=>t.e(36).then(t.bind(null,681)),"v-1f91922d":()=>t.e(34).then(t.bind(null,682)),"v-65affcad":()=>t.e(52).then(t.bind(null,683)),"v-4e5b9057":()=>t.e(37).then(t.bind(null,684)),"v-05bf836b":()=>t.e(49).then(t.bind(null,685)),"v-5dda9d1e":()=>t.e(16).then(t.bind(null,686)),"v-6dcc960d":()=>t.e(29).then(t.bind(null,687)),"v-67670071":()=>t.e(25).then(t.bind(null,688)),"v-237fd8ed":()=>t.e(42).then(t.bind(null,689)),"v-3a2d0547":()=>t.e(41).then(t.bind(null,690)),"v-6e8c87ed":()=>t.e(28).then(t.bind(null,691)),"v-30ad7ebd":()=>t.e(39).then(t.bind(null,692)),"v-0841246e":()=>t.e(19).then(t.bind(null,693)),"v-daa61166":()=>t.e(20).then(t.bind(null,694)),"v-392eb7ed":()=>t.e(24).then(t.bind(null,695)),"v-6191ba26":()=>t.e(48).then(t.bind(null,696)),"v-420ef137":()=>t.e(22).then(t.bind(null,697)),"v-306008ed":()=>t.e(43).then(t.bind(null,698)),"v-21e7225a":()=>t.e(26).then(t.bind(null,699)),"v-7bc99189":()=>t.e(45).then(t.bind(null,700)),"v-ada9f2f2":()=>t.e(40).then(t.bind(null,701)),"v-01b4cdcd":()=>t.e(31).then(t.bind(null,702)),"v-77c86fed":()=>t.e(46).then(t.bind(null,703)),"v-9ea17eea":()=>t.e(32).then(t.bind(null,704)),"v-7943c1f6":()=>t.e(33).then(t.bind(null,705)),"v-47b39cfd":()=>t.e(47).then(t.bind(null,706)),"v-b128a8f6":()=>t.e(50).then(t.bind(null,707)),"v-2ca3ee26":()=>t.e(51).then(t.bind(null,708)),"v-bd94cac2":()=>t.e(52).then(t.bind(null,709)),"v-3b041b6d":()=>t.e(49).then(t.bind(null,710)),"v-e894ac04":()=>t.e(18).then(t.bind(null,711)),"v-9cd12ba6":()=>t.e(29).then(t.bind(null,712)),"v-62e23092":()=>t.e(25).then(t.bind(null,713)),"v-e7c9cde6":()=>t.e(41).then(t.bind(null,714)),"v-674aad0d":()=>t.e(42).then(t.bind(null,715)),"v-6989e673":()=>t.e(28).then(t.bind(null,716)),"v-fac8dafa":()=>t.e(39).then(t.bind(null,717)),"v-8b57cb62":()=>t.e(19).then(t.bind(null,718)),"v-3795786d":()=>t.e(20).then(t.bind(null,719)),"v-1809da8d":()=>t.e(48).then(t.bind(null,720)),"v-fbfd20e6":()=>t.e(24).then(t.bind(null,721)),"v-d805f606":()=>t.e(22).then(t.bind(null,722)),"v-fb63c69a":()=>t.e(43).then(t.bind(null,723)),"v-40fa8299":()=>t.e(26).then(t.bind(null,724)),"v-7636cee6":()=>t.e(40).then(t.bind(null,725)),"v-290cdc62":()=>t.e(45).then(t.bind(null,726)),"v-19ad78ad":()=>t.e(31).then(t.bind(null,727)),"v-33ab2251":()=>t.e(32).then(t.bind(null,728)),"v-3ac4ae1a":()=>t.e(46).then(t.bind(null,729)),"v-7c7a576a":()=>t.e(33).then(t.bind(null,730)),"v-258149c3":()=>t.e(47).then(t.bind(null,731)),"v-171babcb":()=>t.e(50).then(t.bind(null,732)),"v-131f5d4d":()=>t.e(51).then(t.bind(null,733)),"v-24317c65":()=>t.e(52).then(t.bind(null,734)),"v-73d3498d":()=>t.e(49).then(t.bind(null,735)),"v-8fbc73c4":()=>t.e(17).then(t.bind(null,736)),"v-4cb5e50d":()=>t.e(30).then(t.bind(null,737)),"v-8de7f97e":()=>t.e(25).then(t.bind(null,738)),"v-541b37d2":()=>t.e(41).then(t.bind(null,739)),"v-026927ed":()=>t.e(42).then(t.bind(null,740)),"v-39ce30bd":()=>t.e(28).then(t.bind(null,741)),"v-671a44e6":()=>t.e(39).then(t.bind(null,742)),"v-3bc0b2ce":()=>t.e(19).then(t.bind(null,743)),"v-723b4366":()=>t.e(20).then(t.bind(null,744)),"v-0501aa26":()=>t.e(24).then(t.bind(null,745)),"v-d8f0d426":()=>t.e(48).then(t.bind(null,746)),"v-44575ff2":()=>t.e(22).then(t.bind(null,747)),"v-67b53086":()=>t.e(43).then(t.bind(null,748)),"v-ea5c64ba":()=>t.e(26).then(t.bind(null,749)),"v-29ed5952":()=>t.e(40).then(t.bind(null,750)),"v-37f14c59":()=>t.e(45).then(t.bind(null,751)),"v-50bff266":()=>t.e(31).then(t.bind(null,752)),"v-9101a14a":()=>t.e(32).then(t.bind(null,753)),"v-2c2604bd":()=>t.e(46).then(t.bind(null,754)),"v-31d49c56":()=>t.e(33).then(t.bind(null,755)),"v-63936655":()=>t.e(50).then(t.bind(null,756)),"v-5f7fb3cd":()=>t.e(47).then(t.bind(null,757)),"v-58f735ed":()=>t.e(51).then(t.bind(null,758)),"v-cc84cb26":()=>t.e(49).then(t.bind(null,759)),"v-aff4ed22":()=>t.e(52).then(t.bind(null,760)),"v-2a03c37e":()=>t.e(11).then(t.bind(null,761)),"v-045024ad":()=>t.e(29).then(t.bind(null,762))};function $e(e){const n=Object.create(null);return function(t){return n[t]||(n[t]=e(t))}}const Ke=/-(\w)/g,Ze=$e(e=>e.replace(Ke,(e,n)=>n?n.toUpperCase():"")),Xe=/\B([A-Z])/g,en=$e(e=>e.replace(Xe,"-$1").toLowerCase()),nn=$e(e=>e.charAt(0).toUpperCase()+e.slice(1));function tn(e,n){if(!n)return;if(e(n))return e(n);return n.includes("-")?e(nn(Ze(n))):e(nn(n))||e(en(n))}const on=Object.assign({},Ve,Je),rn=e=>on[e],an=e=>Je[e],sn=e=>Ve[e],ln=e=>o.a.component(e);function un(e){return tn(an,e)}function cn(e){return tn(sn,e)}function dn(e){return tn(rn,e)}function hn(e){return tn(ln,e)}function pn(...e){return Promise.all(e.filter(e=>e).map(async e=>{if(!hn(e)&&dn(e)){const n=await dn(e)();o.a.component(e,n.default)}}))}function yn(e,n){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[e]=n)}var mn=t(60),gn=t.n(mn),bn={created(){if(this.siteMeta=this.$site.headTags.filter(([e])=>"meta"===e).map(([e,n])=>n),this.$ssrContext){const n=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(e=n)?e.map(e=>{let n="<meta";return Object.keys(e).forEach(t=>{n+=` ${t}="${e[t]}"`}),n+">"}).join("\n    "):"",this.$ssrContext.canonicalLink=wn(this.$canonicalUrl)}var e},mounted(){this.currentMetaTags=[...document.querySelectorAll("meta")],this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta(){document.title=this.$title,document.documentElement.lang=this.$lang;const e=this.getMergedMetaTags();this.currentMetaTags=vn(e,this.currentMetaTags)},getMergedMetaTags(){const e=this.$page.frontmatter.meta||[];return gn()([{name:"description",content:this.$description}],e,this.siteMeta,kn)},updateCanonicalLink(){fn(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",wn(this.$canonicalUrl))}},watch:{$page(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy(){vn(null,this.currentMetaTags),fn()}};function fn(){const e=document.querySelector("link[rel='canonical']");e&&e.remove()}function wn(e=""){return e?`<link href="${e}" rel="canonical" />`:""}function vn(e,n){if(n&&[...n].filter(e=>e.parentNode===document.head).forEach(e=>document.head.removeChild(e)),e)return e.map(e=>{const n=document.createElement("meta");return Object.keys(e).forEach(t=>{n.setAttribute(t,e[t])}),document.head.appendChild(n),n})}function kn(e){for(const n of["name","property","itemprop"])if(e.hasOwnProperty(n))return e[n]+n;return JSON.stringify(e)}var qn=t(15),xn=t.n(qn),jn={mounted(){xn.a.configure({showSpinner:!1}),this.$router.beforeEach((e,n,t)=>{e.path===n.path||o.a.component(e.name)||xn.a.start(),t()}),this.$router.afterEach(()=>{xn.a.done(),this.isSidebarOpen=!1})}},Sn=t(14),Tn=t.n(Sn);let Qn;var In=o.a.extend({mounted(){Qn=Tn()(()=>{this.setActiveHash()},300),window.addEventListener("scroll",Qn)},beforeDestroy(){window.removeEventListener("scroll",Qn)},methods:{setActiveHash(){const e=Array.from(document.querySelectorAll(".sidebar-link")),n=Array.from(document.querySelectorAll(".header-anchor")).filter(n=>0===e.length||e.some(e=>e.hash===n.hash)),t=document.querySelector(".theme-default-content").offsetTop,o=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),r=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),a=window.innerHeight+o,i=decodeURIComponent(this.$route.hash),s=(e,t)=>{if(a===r)for(let e=t+1;e<n.length;e++)if(i===decodeURIComponent(n[e].hash))return;this.$vuepress.$set("disableScrollBehavior",!0),this.$router.replace(decodeURIComponent(e),()=>{this.$nextTick(()=>{this.$vuepress.$set("disableScrollBehavior",!1)})})};if(o-t<0&&i)s("#",-1);else for(let e=0;e<n.length;e++){const r=n[e],a=n[e+1];if(o-t>=r.parentElement.offsetTop+0&&(!a||o-t<a.parentElement.offsetTop+0)&&i!==decodeURIComponent(r.hash))return void s(r.hash,e)}}}});t(159);class Pn{constructor(){const e=document.getElementById("message-container");e?this.containerElement=e:(this.containerElement=document.createElement("div"),this.containerElement.id="message-container",document.body.appendChild(this.containerElement))}pop(e,n=2e3){const t=document.createElement("div");t.className="message move-in",t.innerHTML=`<svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#06a35a"><path d="M822.812 824.618c-83.076 81.992-188.546 124.614-316.05 127.865-122.085-3.251-223.943-45.873-305.935-127.865S76.213 640.406 72.962 518.682c3.251-127.503 45.873-232.973 127.865-316.05 81.992-83.075 184.211-126.058 305.936-129.309 127.503 3.251 232.973 46.234 316.049 129.31 83.076 83.076 126.059 188.546 129.31 316.05-2.89 121.723-46.234 223.943-129.31 305.935zM432.717 684.111c3.973 3.974 8.307 5.78 13.364 6.14 5.057.362 9.753-1.444 13.365-5.417l292.57-287.515c3.974-3.973 5.78-8.307 5.78-13.364s-1.806-9.753-5.78-13.365l1.807 1.806c-3.973-3.973-8.669-5.779-14.087-6.14-5.418-.361-10.475 1.445-14.809 5.418L460.529 592.006c-3.973 3.25-8.669 4.695-14.448 4.695-5.78 0-10.836-1.445-15.531-3.973l-94.273-72.962c-4.335-3.251-9.392-4.335-14.448-3.973s-9.392 3.25-12.642 7.585l-2.89 3.973c-3.25 4.334-4.334 9.391-3.973 14.81.722 5.417 2.528 10.113 5.779 14.086L432.717 684.11z"/></svg><span>${e}</span>`,this.containerElement.appendChild(t),n>0&&setTimeout(()=>{this.close(t)},n)}close(e){e.className=e.className.replace("move-in",""),e.className+="move-out",e.addEventListener("animationend",()=>{e.remove()})}}t(160),t(62);let zn;const Cn={"/zh/":{copy:"复制成功 🎉",hint:"复制代码"},"/en/":{copy:"Copy successfully 🎉",hint:"Copy the code"},"/de/":{copy:"Kopieren erfolgreich 🎉",hint:"Kopiere den Code."},"/vi/":{copy:"Sao chép thành công 🎉",hint:"Sao chép code"},"/":{copy:"Copy successfully 🎉",hint:"Copy the code"}},_n={},An=()=>!!navigator&&/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/iu.test(navigator.userAgent);var En=[bn,jn,In,o.a.extend({mounted(){zn=new Pn,An()&&!_n.showInMobile||this.genCopyButton()},updated(){An()&&!_n.showInMobile||this.genCopyButton()},methods:{genCopyButton(){const e=_n.selector||'.theme-default-content div[class*="language-"] pre';setTimeout(()=>{"string"==typeof e?document.querySelectorAll(e).forEach(this.insertCopyButton.bind(this)):Array.isArray(e)&&e.forEach(e=>{document.querySelectorAll(e).forEach(this.insertCopyButton.bind(this))})},1e3)},insertCopyButton(e){if(!e.hasAttribute("copy-code-registerd")){const n=document.createElement("button");n.className="copy-code-button",n.innerHTML='<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" class="icon-copy-code"><path fill="currentColor" d="M384 112v352c0 26.51-21.49 48-48 48H48c-26.51 0-48-21.49-48-48V112c0-26.51 21.49-48 48-48h80c0-35.29 28.71-64 64-64s64 28.71 64 64h80c26.51 0 48 21.49 48 48zM192 40c-13.255 0-24 10.745-24 24s10.745 24 24 24 24-10.745 24-24-10.745-24-24-24m96 114v-20a6 6 0 00-6-6H102a6 6 0 00-6 6v20a6 6 0 006 6h180a6 6 0 006-6z" /></svg>',n.addEventListener("click",()=>{this.copyToClipboard(e.innerText)}),n.setAttribute("aria-label",Cn[this.$localePath||"/"].hint),n.setAttribute("data-balloon-pos","left"),e.parentElement&&e.parentElement.insertBefore(n,e),e.setAttribute("copy-code-registerd","")}},copyToClipboard(e){const n=document.getSelection(),t=!!(n&&n.rangeCount>0)&&n.getRangeAt(0),o=document.createElement("textarea");o.value=e,o.setAttribute("readonly",""),o.style.position="absolute",o.style.top="-9999px",document.body.appendChild(o),o.select(),document.execCommand("copy"),0!==_n.duration&&zn.pop(Cn[this.$localePath||"/"].copy,_n.duration),document.body.removeChild(o),t&&n&&(n.removeAllRanges(),n.addRange(t))}}})],Ln={name:"GlobalLayout",computed:{layout(){const e=this.getLayout();return yn("layout",e),o.a.component(e)}},methods:{getLayout(){if(this.$page.path){const e=this.$page.frontmatter.layout;return e&&(this.$vuepress.getLayoutAsyncComponent(e)||this.$vuepress.getVueComponent(e))?e:"Layout"}return"NotFound"}}},Hn=t(1),On=Object(Hn.a)(Ln,(function(){var e=this.$createElement;return(this._self._c||e)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(e,n,t){switch(n){case"components":e[n]||(e[n]={}),Object.assign(e[n],t);break;case"mixins":e[n]||(e[n]=[]),e[n].push(...t);break;default:throw new Error("Unknown option name.")}}(On,"mixins",En);const Dn=[{name:"v-47639a6e",path:"/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-47639a6e").then(t)}},{path:"/index.html",redirect:"/"},{name:"v-86b1f726",path:"/create/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-86b1f726").then(t)}},{path:"/create/graphql/index.html",redirect:"/create/graphql/"},{path:"/create/graphql.html",redirect:"/create/graphql/"},{name:"v-94114ee6",path:"/create/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-94114ee6").then(t)}},{path:"/create/introduction/index.html",redirect:"/create/introduction/"},{path:"/create/introduction.html",redirect:"/create/introduction/"},{name:"v-5d960c2d",path:"/create/manifest/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-5d960c2d").then(t)}},{path:"/create/manifest/index.html",redirect:"/create/manifest/"},{path:"/create/manifest.html",redirect:"/create/manifest/"},{name:"v-03d2d023",path:"/create/mapping/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-03d2d023").then(t)}},{path:"/create/mapping/index.html",redirect:"/create/mapping/"},{path:"/create/mapping.html",redirect:"/create/mapping/"},{name:"v-4806233e",path:"/de/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-4806233e").then(t)}},{path:"/de/index.html",redirect:"/de/"},{name:"v-64c45226",path:"/de/create/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-64c45226").then(t)}},{path:"/de/create/graphql/index.html",redirect:"/de/create/graphql/"},{path:"/de/create/graphql.html",redirect:"/de/create/graphql/"},{name:"v-19f3891b",path:"/de/create/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-19f3891b").then(t)}},{path:"/de/create/introduction/index.html",redirect:"/de/create/introduction/"},{path:"/de/create/introduction.html",redirect:"/de/create/introduction/"},{name:"v-4f881571",path:"/de/create/manifest/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-4f881571").then(t)}},{path:"/de/create/manifest/index.html",redirect:"/de/create/manifest/"},{path:"/de/create/manifest.html",redirect:"/de/create/manifest/"},{name:"v-f95dcc66",path:"/de/create/mapping/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-f95dcc66").then(t)}},{path:"/de/create/mapping/index.html",redirect:"/de/create/mapping/"},{path:"/de/create/mapping.html",redirect:"/de/create/mapping/"},{name:"v-3d649b57",path:"/de/faqs/faqs/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-3d649b57").then(t)}},{path:"/de/faqs/faqs/index.html",redirect:"/de/faqs/faqs/"},{path:"/de/faqs/faqs.html",redirect:"/de/faqs/faqs/"},{name:"v-46088ee7",path:"/de/install/install/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-46088ee7").then(t)}},{path:"/de/install/install/index.html",redirect:"/de/install/install/"},{path:"/de/install/install.html",redirect:"/de/install/install/"},{name:"v-4f6d6333",path:"/de/miscellaneous/ambassadors/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-4f6d6333").then(t)}},{path:"/de/miscellaneous/ambassadors/index.html",redirect:"/de/miscellaneous/ambassadors/"},{path:"/de/miscellaneous/ambassadors.html",redirect:"/de/miscellaneous/ambassadors/"},{name:"v-25b5132d",path:"/de/miscellaneous/branding/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-25b5132d").then(t)}},{path:"/de/miscellaneous/branding/index.html",redirect:"/de/miscellaneous/branding/"},{path:"/de/miscellaneous/branding.html",redirect:"/de/miscellaneous/branding/"},{name:"v-220de14d",path:"/de/miscellaneous/contributing/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-220de14d").then(t)}},{path:"/de/miscellaneous/contributing/index.html",redirect:"/de/miscellaneous/contributing/"},{path:"/de/miscellaneous/contributing.html",redirect:"/de/miscellaneous/contributing/"},{name:"v-8fd36766",path:"/de/miscellaneous/social_media/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-8fd36766").then(t)}},{path:"/de/miscellaneous/social_media/index.html",redirect:"/de/miscellaneous/social_media/"},{path:"/de/miscellaneous/social_media.html",redirect:"/de/miscellaneous/social_media/"},{name:"v-576a0161",path:"/de/publish/connect/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-576a0161").then(t)}},{path:"/de/publish/connect/index.html",redirect:"/de/publish/connect/"},{path:"/de/publish/connect.html",redirect:"/de/publish/connect/"},{name:"v-45bb1917",path:"/de/publish/publish/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-45bb1917").then(t)}},{path:"/de/publish/publish/index.html",redirect:"/de/publish/publish/"},{path:"/de/publish/publish.html",redirect:"/de/publish/publish/"},{name:"v-04677efd",path:"/de/publish/upgrade/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-04677efd").then(t)}},{path:"/de/publish/upgrade/index.html",redirect:"/de/publish/upgrade/"},{path:"/de/publish/upgrade.html",redirect:"/de/publish/upgrade/"},{name:"v-03e13271",path:"/de/query/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-03e13271").then(t)}},{path:"/de/query/graphql/index.html",redirect:"/de/query/graphql/"},{path:"/de/query/graphql.html",redirect:"/de/query/graphql/"},{name:"v-306d6933",path:"/de/query/query/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-306d6933").then(t)}},{path:"/de/query/query/index.html",redirect:"/de/query/query/"},{path:"/de/query/query.html",redirect:"/de/query/query/"},{name:"v-754465ed",path:"/de/quickstart/helloworld-hosted/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-754465ed").then(t)}},{path:"/de/quickstart/helloworld-hosted/index.html",redirect:"/de/quickstart/helloworld-hosted/"},{path:"/de/quickstart/helloworld-hosted.html",redirect:"/de/quickstart/helloworld-hosted/"},{name:"v-756db2b5",path:"/de/quickstart/helloworld-localhost/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-756db2b5").then(t)}},{path:"/de/quickstart/helloworld-localhost/index.html",redirect:"/de/quickstart/helloworld-localhost/"},{path:"/de/quickstart/helloworld-localhost.html",redirect:"/de/quickstart/helloworld-localhost/"},{name:"v-e30ce652",path:"/de/quickstart/quickstart/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-e30ce652").then(t)}},{path:"/de/quickstart/quickstart/index.html",redirect:"/de/quickstart/quickstart/"},{path:"/de/quickstart/quickstart.html",redirect:"/de/quickstart/quickstart/"},{name:"v-76f709af",path:"/de/quickstart/understanding-helloworld/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-76f709af").then(t)}},{path:"/de/quickstart/understanding-helloworld/index.html",redirect:"/de/quickstart/understanding-helloworld/"},{path:"/de/quickstart/understanding-helloworld.html",redirect:"/de/quickstart/understanding-helloworld/"},{name:"v-bc8b07b2",path:"/de/run/run/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-bc8b07b2").then(t)}},{path:"/de/run/run/index.html",redirect:"/de/run/run/"},{path:"/de/run/run.html",redirect:"/de/run/run/"},{name:"v-5c0f832f",path:"/de/run/sandbox/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-5c0f832f").then(t)}},{path:"/de/run/sandbox/index.html",redirect:"/de/run/sandbox/"},{path:"/de/run/sandbox.html",redirect:"/de/run/sandbox/"},{name:"v-89f298e6",path:"/de/tutorials_examples/howto/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-89f298e6").then(t)}},{path:"/de/tutorials_examples/howto/index.html",redirect:"/de/tutorials_examples/howto/"},{path:"/de/tutorials_examples/howto.html",redirect:"/de/tutorials_examples/howto/"},{name:"v-65f40cc9",path:"/de/tutorials_examples/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-65f40cc9").then(t)}},{path:"/de/tutorials_examples/introduction/index.html",redirect:"/de/tutorials_examples/introduction/"},{path:"/de/tutorials_examples/introduction.html",redirect:"/de/tutorials_examples/introduction/"},{name:"v-4162124d",path:"/de/tutorials_examples/terminology/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-4162124d").then(t)}},{path:"/de/tutorials_examples/terminology/index.html",redirect:"/de/tutorials_examples/terminology/"},{path:"/de/tutorials_examples/terminology.html",redirect:"/de/tutorials_examples/terminology/"},{name:"v-1397d61e",path:"/es/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-1397d61e").then(t)}},{path:"/es/index.html",redirect:"/es/"},{name:"v-514b550d",path:"/es/create/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-514b550d").then(t)}},{path:"/es/create/graphql/index.html",redirect:"/es/create/graphql/"},{path:"/es/create/graphql.html",redirect:"/es/create/graphql/"},{name:"v-7c3a4841",path:"/es/create/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-7c3a4841").then(t)}},{path:"/es/create/introduction/index.html",redirect:"/es/create/introduction/"},{path:"/es/create/introduction.html",redirect:"/es/create/introduction/"},{name:"v-38986917",path:"/es/create/manifest/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-38986917").then(t)}},{path:"/es/create/manifest/index.html",redirect:"/es/create/manifest/"},{path:"/es/create/manifest.html",redirect:"/es/create/manifest/"},{name:"v-06fe97ed",path:"/es/create/mapping/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-06fe97ed").then(t)}},{path:"/es/create/mapping/index.html",redirect:"/es/create/mapping/"},{path:"/es/create/mapping.html",redirect:"/es/create/mapping/"},{name:"v-56f85486",path:"/es/faqs/faqs/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-56f85486").then(t)}},{path:"/es/faqs/faqs/index.html",redirect:"/es/faqs/faqs/"},{path:"/es/faqs/faqs.html",redirect:"/es/faqs/faqs/"},{name:"v-2f18e28d",path:"/es/install/install/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-2f18e28d").then(t)}},{path:"/es/install/install/index.html",redirect:"/es/install/install/"},{path:"/es/install/install.html",redirect:"/es/install/install/"},{name:"v-76f64b99",path:"/es/miscellaneous/ambassadors/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-76f64b99").then(t)}},{path:"/es/miscellaneous/ambassadors/index.html",redirect:"/es/miscellaneous/ambassadors/"},{path:"/es/miscellaneous/ambassadors.html",redirect:"/es/miscellaneous/ambassadors/"},{name:"v-2e6d4e4d",path:"/es/miscellaneous/branding/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-2e6d4e4d").then(t)}},{path:"/es/miscellaneous/branding/index.html",redirect:"/es/miscellaneous/branding/"},{path:"/es/miscellaneous/branding.html",redirect:"/es/miscellaneous/branding/"},{name:"v-29564a26",path:"/es/miscellaneous/contributing/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-29564a26").then(t)}},{path:"/es/miscellaneous/contributing/index.html",redirect:"/es/miscellaneous/contributing/"},{path:"/es/miscellaneous/contributing.html",redirect:"/es/miscellaneous/contributing/"},{name:"v-fd457426",path:"/es/miscellaneous/social_media/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-fd457426").then(t)}},{path:"/es/miscellaneous/social_media/index.html",redirect:"/es/miscellaneous/social_media/"},{path:"/es/miscellaneous/social_media.html",redirect:"/es/miscellaneous/social_media/"},{name:"v-407a5507",path:"/es/publish/connect/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-407a5507").then(t)}},{path:"/es/publish/connect/index.html",redirect:"/es/publish/connect/"},{path:"/es/publish/connect.html",redirect:"/es/publish/connect/"},{name:"v-2ecb6cbd",path:"/es/publish/publish/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-2ecb6cbd").then(t)}},{path:"/es/publish/publish/index.html",redirect:"/es/publish/publish/"},{path:"/es/publish/publish.html",redirect:"/es/publish/publish/"},{name:"v-25105aba",path:"/es/publish/upgrade/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-25105aba").then(t)}},{path:"/es/publish/upgrade/index.html",redirect:"/es/publish/upgrade/"},{path:"/es/publish/upgrade.html",redirect:"/es/publish/upgrade/"},{name:"v-0b973857",path:"/es/query/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-0b973857").then(t)}},{path:"/es/query/graphql/index.html",redirect:"/es/query/graphql/"},{path:"/es/query/graphql.html",redirect:"/es/query/graphql/"},{name:"v-2d2f1159",path:"/es/query/query/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-2d2f1159").then(t)}},{path:"/es/query/query/index.html",redirect:"/es/query/query/"},{path:"/es/query/query.html",redirect:"/es/query/query/"},{name:"v-ee61d266",path:"/es/quickstart/helloworld-hosted/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-ee61d266").then(t)}},{path:"/es/quickstart/helloworld-hosted/index.html",redirect:"/es/quickstart/helloworld-hosted/"},{path:"/es/quickstart/helloworld-hosted.html",redirect:"/es/quickstart/helloworld-hosted/"},{name:"v-2f06345b",path:"/es/quickstart/helloworld-localhost/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-2f06345b").then(t)}},{path:"/es/quickstart/helloworld-localhost/index.html",redirect:"/es/quickstart/helloworld-localhost/"},{path:"/es/quickstart/helloworld-localhost.html",redirect:"/es/quickstart/helloworld-localhost/"},{name:"v-19c469bd",path:"/es/quickstart/quickstart/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-19c469bd").then(t)}},{path:"/es/quickstart/quickstart/index.html",redirect:"/es/quickstart/quickstart/"},{path:"/es/quickstart/quickstart.html",redirect:"/es/quickstart/quickstart/"},{name:"v-6ba4f6d5",path:"/es/quickstart/understanding-helloworld/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-6ba4f6d5").then(t)}},{path:"/es/quickstart/understanding-helloworld/index.html",redirect:"/es/quickstart/understanding-helloworld/"},{path:"/es/quickstart/understanding-helloworld.html",redirect:"/es/quickstart/understanding-helloworld/"},{name:"v-ab158e66",path:"/es/run/run/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-ab158e66").then(t)}},{path:"/es/run/run/index.html",redirect:"/es/run/run/"},{path:"/es/run/run.html",redirect:"/es/run/run/"},{name:"v-58d12b55",path:"/es/run/sandbox/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-58d12b55").then(t)}},{path:"/es/run/sandbox/index.html",redirect:"/es/run/sandbox/"},{path:"/es/run/sandbox.html",redirect:"/es/run/sandbox/"},{name:"v-76eb85ed",path:"/es/tutorials_examples/howto/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-76eb85ed").then(t)}},{path:"/es/tutorials_examples/howto/index.html",redirect:"/es/tutorials_examples/howto/"},{path:"/es/tutorials_examples/howto.html",redirect:"/es/tutorials_examples/howto/"},{name:"v-1f8c8e6f",path:"/es/tutorials_examples/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-1f8c8e6f").then(t)}},{path:"/es/tutorials_examples/introduction/index.html",redirect:"/es/tutorials_examples/introduction/"},{path:"/es/tutorials_examples/introduction.html",redirect:"/es/tutorials_examples/introduction/"},{name:"v-5bbe0a6d",path:"/es/tutorials_examples/terminology/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-5bbe0a6d").then(t)}},{path:"/es/tutorials_examples/terminology/index.html",redirect:"/es/tutorials_examples/terminology/"},{path:"/es/tutorials_examples/terminology.html",redirect:"/es/tutorials_examples/terminology/"},{name:"v-1265970d",path:"/faqs/faqs/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-1265970d").then(t)}},{path:"/faqs/faqs/index.html",redirect:"/faqs/faqs/"},{path:"/faqs/faqs.html",redirect:"/faqs/faqs/"},{name:"v-560420fe",path:"/id/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-560420fe").then(t)}},{path:"/id/index.html",redirect:"/id/"},{name:"v-56f909a6",path:"/id/create/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-56f909a6").then(t)}},{path:"/id/create/graphql/index.html",redirect:"/id/create/graphql/"},{path:"/id/create/graphql.html",redirect:"/id/create/graphql/"},{name:"v-6a073232",path:"/id/create/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-6a073232").then(t)}},{path:"/id/create/introduction/index.html",redirect:"/id/create/introduction/"},{path:"/id/create/introduction.html",redirect:"/id/create/introduction/"},{name:"v-7e31bc3d",path:"/id/create/manifest/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-7e31bc3d").then(t)}},{path:"/id/create/manifest/index.html",redirect:"/id/create/manifest/"},{path:"/id/create/manifest.html",redirect:"/id/create/manifest/"},{name:"v-eb9283e6",path:"/id/create/mapping/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-eb9283e6").then(t)}},{path:"/id/create/mapping/index.html",redirect:"/id/create/mapping/"},{path:"/id/create/mapping.html",redirect:"/id/create/mapping/"},{name:"v-47ab00ba",path:"/id/faqs/faqs/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-47ab00ba").then(t)}},{path:"/id/faqs/faqs/index.html",redirect:"/id/faqs/faqs/"},{path:"/id/faqs/faqs.html",redirect:"/id/faqs/faqs/"},{name:"v-74b235b3",path:"/id/install/install/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-74b235b3").then(t)}},{path:"/id/install/install/index.html",redirect:"/id/install/install/"},{path:"/id/install/install.html",redirect:"/id/install/install/"},{name:"v-42d0237f",path:"/id/miscellaneous/ambassadors/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-42d0237f").then(t)}},{path:"/id/miscellaneous/ambassadors/index.html",redirect:"/id/miscellaneous/ambassadors/"},{path:"/id/miscellaneous/ambassadors.html",redirect:"/id/miscellaneous/ambassadors/"},{name:"v-73371d26",path:"/id/miscellaneous/branding/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-73371d26").then(t)}},{path:"/id/miscellaneous/branding/index.html",redirect:"/id/miscellaneous/branding/"},{path:"/id/miscellaneous/branding.html",redirect:"/id/miscellaneous/branding/"},{name:"v-932646e6",path:"/id/miscellaneous/contributing/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-932646e6").then(t)}},{path:"/id/miscellaneous/contributing/index.html",redirect:"/id/miscellaneous/contributing/"},{path:"/id/miscellaneous/contributing.html",redirect:"/id/miscellaneous/contributing/"},{name:"v-4c75478d",path:"/id/miscellaneous/social_media/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-4c75478d").then(t)}},{path:"/id/miscellaneous/social_media/index.html",redirect:"/id/miscellaneous/social_media/"},{path:"/id/miscellaneous/social_media.html",redirect:"/id/miscellaneous/social_media/"},{name:"v-f3d8afa6",path:"/id/publish/connect/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-f3d8afa6").then(t)}},{path:"/id/publish/connect/index.html",redirect:"/id/publish/connect/"},{path:"/id/publish/connect.html",redirect:"/id/publish/connect/"},{name:"v-7464bfe3",path:"/id/publish/publish/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-7464bfe3").then(t)}},{path:"/id/publish/publish/index.html",redirect:"/id/publish/publish/"},{path:"/id/publish/publish.html",redirect:"/id/publish/publish/"},{name:"v-331125c9",path:"/id/publish/upgrade/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-331125c9").then(t)}},{path:"/id/publish/upgrade/index.html",redirect:"/id/publish/upgrade/"},{path:"/id/publish/upgrade.html",redirect:"/id/publish/upgrade/"},{name:"v-7981e486",path:"/id/query/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-7981e486").then(t)}},{path:"/id/query/graphql/index.html",redirect:"/id/query/graphql/"},{path:"/id/query/graphql.html",redirect:"/id/query/graphql/"},{name:"v-5e3758ff",path:"/id/query/query/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-5e3758ff").then(t)}},{path:"/id/query/query/index.html",redirect:"/id/query/query/"},{path:"/id/query/query.html",redirect:"/id/query/query/"},{name:"v-eabc40a6",path:"/id/quickstart/helloworld-hosted/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-eabc40a6").then(t)}},{path:"/id/quickstart/helloworld-hosted/index.html",redirect:"/id/quickstart/helloworld-hosted/"},{path:"/id/quickstart/helloworld-hosted.html",redirect:"/id/quickstart/helloworld-hosted/"},{name:"v-79dd94fe",path:"/id/quickstart/helloworld-localhost/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-79dd94fe").then(t)}},{path:"/id/quickstart/helloworld-localhost/index.html",redirect:"/id/quickstart/helloworld-localhost/"},{path:"/id/quickstart/helloworld-localhost.html",redirect:"/id/quickstart/helloworld-localhost/"},{name:"v-26e5d623",path:"/id/quickstart/quickstart/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-26e5d623").then(t)}},{path:"/id/quickstart/quickstart/index.html",redirect:"/id/quickstart/quickstart/"},{path:"/id/quickstart/quickstart.html",redirect:"/id/quickstart/quickstart/"},{name:"v-3977c37b",path:"/id/quickstart/understanding-helloworld/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-3977c37b").then(t)}},{path:"/id/quickstart/understanding-helloworld/index.html",redirect:"/id/quickstart/understanding-helloworld/"},{path:"/id/quickstart/understanding-helloworld.html",redirect:"/id/quickstart/understanding-helloworld/"},{name:"v-5ee434f3",path:"/id/run/run/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-5ee434f3").then(t)}},{path:"/id/run/run/index.html",redirect:"/id/run/run/"},{path:"/id/run/run.html",redirect:"/id/run/run/"},{name:"v-ec4d1a0a",path:"/id/run/sandbox/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-ec4d1a0a").then(t)}},{path:"/id/run/sandbox/index.html",redirect:"/id/run/sandbox/"},{path:"/id/run/sandbox.html",redirect:"/id/run/sandbox/"},{name:"v-7c9e504d",path:"/id/tutorials_examples/howto/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-7c9e504d").then(t)}},{path:"/id/tutorials_examples/howto/index.html",redirect:"/id/tutorials_examples/howto/"},{path:"/id/tutorials_examples/howto.html",redirect:"/id/tutorials_examples/howto/"},{name:"v-98d0e0d6",path:"/id/tutorials_examples/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-98d0e0d6").then(t)}},{path:"/id/tutorials_examples/introduction/index.html",redirect:"/id/tutorials_examples/introduction/"},{path:"/id/tutorials_examples/introduction.html",redirect:"/id/tutorials_examples/introduction/"},{name:"v-0765aae6",path:"/id/tutorials_examples/terminology/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-0765aae6").then(t)}},{path:"/id/tutorials_examples/terminology/index.html",redirect:"/id/tutorials_examples/terminology/"},{path:"/id/tutorials_examples/terminology.html",redirect:"/id/tutorials_examples/terminology/"},{name:"v-2680104d",path:"/install/install/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-2680104d").then(t)}},{path:"/install/install/index.html",redirect:"/install/install/"},{path:"/install/install.html",redirect:"/install/install/"},{name:"v-188a7204",path:"/it/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-188a7204").then(t)}},{path:"/it/index.html",redirect:"/it/"},{name:"v-1466252d",path:"/it/create/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-1466252d").then(t)}},{path:"/it/create/graphql/index.html",redirect:"/it/create/graphql/"},{path:"/it/create/graphql.html",redirect:"/it/create/graphql/"},{name:"v-73c98272",path:"/it/create/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-73c98272").then(t)}},{path:"/it/create/introduction/index.html",redirect:"/it/create/introduction/"},{path:"/it/create/introduction.html",redirect:"/it/create/introduction/"},{name:"v-1553fc1d",path:"/it/create/manifest/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-1553fc1d").then(t)}},{path:"/it/create/manifest/index.html",redirect:"/it/create/manifest/"},{path:"/it/create/manifest.html",redirect:"/it/create/manifest/"},{name:"v-6bcd2fe6",path:"/it/create/mapping/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-6bcd2fe6").then(t)}},{path:"/it/create/mapping/index.html",redirect:"/it/create/mapping/"},{path:"/it/create/mapping.html",redirect:"/it/create/mapping/"},{name:"v-784c5b83",path:"/it/faqs/faqs/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-784c5b83").then(t)}},{path:"/it/faqs/faqs/index.html",redirect:"/it/faqs/faqs/"},{path:"/it/faqs/faqs.html",redirect:"/it/faqs/faqs/"},{name:"v-0bd47593",path:"/it/install/install/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-0bd47593").then(t)}},{path:"/it/install/install/index.html",redirect:"/it/install/install/"},{path:"/it/install/install.html",redirect:"/it/install/install/"},{name:"v-a8374142",path:"/it/miscellaneous/ambassadors/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-a8374142").then(t)}},{path:"/it/miscellaneous/ambassadors/index.html",redirect:"/it/miscellaneous/ambassadors/"},{path:"/it/miscellaneous/ambassadors.html",redirect:"/it/miscellaneous/ambassadors/"},{name:"v-2a342b6d",path:"/it/miscellaneous/branding/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-2a342b6d").then(t)}},{path:"/it/miscellaneous/branding/index.html",redirect:"/it/miscellaneous/branding/"},{path:"/it/miscellaneous/branding.html",redirect:"/it/miscellaneous/branding/"},{name:"v-36e11e8d",path:"/it/miscellaneous/contributing/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-36e11e8d").then(t)}},{path:"/it/miscellaneous/contributing/index.html",redirect:"/it/miscellaneous/contributing/"},{path:"/it/miscellaneous/contributing.html",redirect:"/it/miscellaneous/contributing/"},{name:"v-662cece6",path:"/it/miscellaneous/social_media/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-662cece6").then(t)}},{path:"/it/miscellaneous/social_media/index.html",redirect:"/it/miscellaneous/social_media/"},{path:"/it/miscellaneous/social_media.html",redirect:"/it/miscellaneous/social_media/"},{name:"v-1d35e80d",path:"/it/publish/connect/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-1d35e80d").then(t)}},{path:"/it/publish/connect/index.html",redirect:"/it/publish/connect/"},{path:"/it/publish/connect.html",redirect:"/it/publish/connect/"},{name:"v-0b86ffc3",path:"/it/publish/publish/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-0b86ffc3").then(t)}},{path:"/it/publish/publish/index.html",redirect:"/it/publish/publish/"},{path:"/it/publish/publish.html",redirect:"/it/publish/publish/"},{name:"v-6b9934ae",path:"/it/publish/upgrade/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-6b9934ae").then(t)}},{path:"/it/publish/upgrade/index.html",redirect:"/it/publish/upgrade/"},{path:"/it/publish/upgrade.html",redirect:"/it/publish/upgrade/"},{name:"v-a188fcc6",path:"/it/query/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-a188fcc6").then(t)}},{path:"/it/query/graphql/index.html",redirect:"/it/query/graphql/"},{path:"/it/query/graphql.html",redirect:"/it/query/graphql/"},{name:"v-296dfe42",path:"/it/query/query/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-296dfe42").then(t)}},{path:"/it/query/query/index.html",redirect:"/it/query/query/"},{path:"/it/query/query.html",redirect:"/it/query/query/"},{name:"v-f39834a6",path:"/it/quickstart/helloworld-hosted/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-f39834a6").then(t)}},{path:"/it/quickstart/helloworld-hosted/index.html",redirect:"/it/quickstart/helloworld-hosted/"},{path:"/it/quickstart/helloworld-hosted.html",redirect:"/it/quickstart/helloworld-hosted/"},{name:"v-0ca4553e",path:"/it/quickstart/helloworld-localhost/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-0ca4553e").then(t)}},{path:"/it/quickstart/helloworld-localhost/index.html",redirect:"/it/quickstart/helloworld-localhost/"},{path:"/it/quickstart/helloworld-localhost.html",redirect:"/it/quickstart/helloworld-localhost/"},{name:"v-475b7a03",path:"/it/quickstart/quickstart/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-475b7a03").then(t)}},{path:"/it/quickstart/quickstart/index.html",redirect:"/it/quickstart/quickstart/"},{path:"/it/quickstart/quickstart.html",redirect:"/it/quickstart/quickstart/"},{name:"v-2fc0fb5b",path:"/it/quickstart/understanding-helloworld/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-2fc0fb5b").then(t)}},{path:"/it/quickstart/understanding-helloworld/index.html",redirect:"/it/quickstart/understanding-helloworld/"},{path:"/it/quickstart/understanding-helloworld.html",redirect:"/it/quickstart/understanding-helloworld/"},{name:"v-ec5d765a",path:"/it/run/run/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-ec5d765a").then(t)}},{path:"/it/run/run/index.html",redirect:"/it/run/run/"},{path:"/it/run/run.html",redirect:"/it/run/run/"},{name:"v-16eb1adb",path:"/it/run/sandbox/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-16eb1adb").then(t)}},{path:"/it/run/sandbox/index.html",redirect:"/it/run/sandbox/"},{path:"/it/run/sandbox.html",redirect:"/it/run/sandbox/"},{name:"v-0f11ce4d",path:"/it/tutorials_examples/howto/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-0f11ce4d").then(t)}},{path:"/it/tutorials_examples/howto/index.html",redirect:"/it/tutorials_examples/howto/"},{path:"/it/tutorials_examples/howto.html",redirect:"/it/tutorials_examples/howto/"},{name:"v-2b97a116",path:"/it/tutorials_examples/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-2b97a116").then(t)}},{path:"/it/tutorials_examples/introduction/index.html",redirect:"/it/tutorials_examples/introduction/"},{path:"/it/tutorials_examples/introduction.html",redirect:"/it/tutorials_examples/introduction/"},{name:"v-444c16e6",path:"/it/tutorials_examples/terminology/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-444c16e6").then(t)}},{path:"/it/tutorials_examples/terminology/index.html",redirect:"/it/tutorials_examples/terminology/"},{path:"/it/tutorials_examples/terminology.html",redirect:"/it/tutorials_examples/terminology/"},{name:"v-027260af",path:"/ja/create/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-027260af").then(t)}},{path:"/ja/create/introduction/index.html",redirect:"/ja/create/introduction/"},{path:"/ja/create/introduction.html",redirect:"/ja/create/introduction/"},{name:"v-f2a4a7f6",path:"/ja/create/manifest/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-f2a4a7f6").then(t)}},{path:"/ja/create/manifest/index.html",redirect:"/ja/create/manifest/"},{path:"/ja/create/manifest.html",redirect:"/ja/create/manifest/"},{name:"v-8bf930e6",path:"/ja/create/mapping/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-8bf930e6").then(t)}},{path:"/ja/create/mapping/index.html",redirect:"/ja/create/mapping/"},{path:"/ja/create/mapping.html",redirect:"/ja/create/mapping/"},{name:"v-6d65c06b",path:"/ja/faqs/faqs/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-6d65c06b").then(t)}},{path:"/ja/faqs/faqs/index.html",redirect:"/ja/faqs/faqs/"},{path:"/ja/faqs/faqs.html",redirect:"/ja/faqs/faqs/"},{name:"v-7d2e257b",path:"/ja/install/install/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-7d2e257b").then(t)}},{path:"/ja/install/install/index.html",redirect:"/ja/install/install/"},{path:"/ja/install/install.html",redirect:"/ja/install/install/"},{name:"v-0a98e772",path:"/ja/miscellaneous/ambassadors/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-0a98e772").then(t)}},{path:"/ja/miscellaneous/ambassadors/index.html",redirect:"/ja/miscellaneous/ambassadors/"},{path:"/ja/miscellaneous/ambassadors.html",redirect:"/ja/miscellaneous/ambassadors/"},{name:"v-95e01226",path:"/ja/miscellaneous/branding/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-95e01226").then(t)}},{path:"/ja/miscellaneous/branding/index.html",redirect:"/ja/miscellaneous/branding/"},{path:"/ja/miscellaneous/branding.html",redirect:"/ja/miscellaneous/branding/"},{name:"v-1738500d",path:"/ja/miscellaneous/contributing/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-1738500d").then(t)}},{path:"/ja/miscellaneous/contributing/index.html",redirect:"/ja/miscellaneous/contributing/"},{path:"/ja/miscellaneous/contributing.html",redirect:"/ja/miscellaneous/contributing/"},{name:"v-a57e89e6",path:"/ja/miscellaneous/social_media/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-a57e89e6").then(t)}},{path:"/ja/miscellaneous/social_media/index.html",redirect:"/ja/miscellaneous/social_media/"},{path:"/ja/miscellaneous/social_media.html",redirect:"/ja/miscellaneous/social_media/"},{name:"v-e2e0d016",path:"/ja/publish/connect/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-e2e0d016").then(t)}},{path:"/ja/publish/connect/index.html",redirect:"/ja/publish/connect/"},{path:"/ja/publish/connect.html",redirect:"/ja/publish/connect/"},{name:"v-7ce0afab",path:"/ja/publish/publish/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-7ce0afab").then(t)}},{path:"/ja/publish/publish/index.html",redirect:"/ja/publish/publish/"},{path:"/ja/publish/publish.html",redirect:"/ja/publish/publish/"},{name:"v-3b8d1591",path:"/ja/publish/upgrade/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-3b8d1591").then(t)}},{path:"/ja/publish/upgrade/index.html",redirect:"/ja/publish/upgrade/"},{path:"/ja/publish/upgrade.html",redirect:"/ja/publish/upgrade/"},{name:"v-bf8e4ef6",path:"/ja/query/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-bf8e4ef6").then(t)}},{path:"/ja/query/graphql/index.html",redirect:"/ja/query/graphql/"},{path:"/ja/query/graphql.html",redirect:"/ja/query/graphql/"},{name:"v-d5d38272",path:"/ja/query/query/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-d5d38272").then(t)}},{path:"/ja/query/query/index.html",redirect:"/ja/query/query/"},{path:"/ja/query/query.html",redirect:"/ja/query/query/"},{name:"v-02e16a2d",path:"/ja/quickstart/helloworld-hosted/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-02e16a2d").then(t)}},{path:"/ja/quickstart/helloworld-hosted/index.html",redirect:"/ja/quickstart/helloworld-hosted/"},{path:"/ja/quickstart/helloworld-hosted.html",redirect:"/ja/quickstart/helloworld-hosted/"},{name:"v-bab9656e",path:"/ja/quickstart/helloworld-localhost/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-bab9656e").then(t)}},{path:"/ja/quickstart/helloworld-localhost/index.html",redirect:"/ja/quickstart/helloworld-localhost/"},{path:"/ja/quickstart/helloworld-localhost.html",redirect:"/ja/quickstart/helloworld-localhost/"},{name:"v-c098962a",path:"/ja/quickstart/quickstart/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-c098962a").then(t)}},{path:"/ja/quickstart/quickstart/index.html",redirect:"/ja/quickstart/quickstart/"},{path:"/ja/quickstart/quickstart.html",redirect:"/ja/quickstart/quickstart/"},{name:"v-2f10357a",path:"/ja/quickstart/understanding-helloworld/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-2f10357a").then(t)}},{path:"/ja/quickstart/understanding-helloworld/index.html",redirect:"/ja/quickstart/understanding-helloworld/"},{path:"/ja/quickstart/understanding-helloworld.html",redirect:"/ja/quickstart/understanding-helloworld/"},{name:"v-6a0310bb",path:"/ja/run/run/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-6a0310bb").then(t)}},{path:"/ja/run/run/index.html",redirect:"/ja/run/run/"},{path:"/ja/run/run.html",redirect:"/ja/run/run/"},{name:"v-7e8f4e7a",path:"/ja/run/sandbox/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-7e8f4e7a").then(t)}},{path:"/ja/run/sandbox/index.html",redirect:"/ja/run/sandbox/"},{path:"/ja/run/sandbox.html",redirect:"/ja/run/sandbox/"},{name:"v-062f2666",path:"/ja/tutorials_examples/howto/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-062f2666").then(t)}},{path:"/ja/tutorials_examples/howto/index.html",redirect:"/ja/tutorials_examples/howto/"},{path:"/ja/tutorials_examples/howto.html",redirect:"/ja/tutorials_examples/howto/"},{name:"v-d9acb146",path:"/ja/tutorials_examples/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-d9acb146").then(t)}},{path:"/ja/tutorials_examples/introduction/index.html",redirect:"/ja/tutorials_examples/introduction/"},{path:"/ja/tutorials_examples/introduction.html",redirect:"/ja/tutorials_examples/introduction/"},{name:"v-07038c0d",path:"/ja/tutorials_examples/terminology/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-07038c0d").then(t)}},{path:"/ja/tutorials_examples/terminology/index.html",redirect:"/ja/tutorials_examples/terminology/"},{path:"/ja/tutorials_examples/terminology.html",redirect:"/ja/tutorials_examples/terminology/"},{name:"v-14d51344",path:"/ko/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-14d51344").then(t)}},{path:"/ko/index.html",redirect:"/ko/"},{name:"v-f004ba66",path:"/ko/create/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-f004ba66").then(t)}},{path:"/ko/create/graphql/index.html",redirect:"/ko/create/graphql/"},{path:"/ko/create/graphql.html",redirect:"/ko/create/graphql/"},{name:"v-64b91fd5",path:"/ko/create/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-64b91fd5").then(t)}},{path:"/ko/create/introduction/index.html",redirect:"/ko/create/introduction/"},{path:"/ko/create/introduction.html",redirect:"/ko/create/introduction/"},{name:"v-6fbdffab",path:"/ko/create/manifest/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-6fbdffab").then(t)}},{path:"/ko/create/manifest/index.html",redirect:"/ko/create/manifest/"},{path:"/ko/create/manifest.html",redirect:"/ko/create/manifest/"},{name:"v-3db0e5ad",path:"/ko/create/mapping/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-3db0e5ad").then(t)}},{path:"/ko/create/mapping/index.html",redirect:"/ko/create/mapping/"},{path:"/ko/create/mapping.html",redirect:"/ko/create/mapping/"},{name:"v-0484fad1",path:"/ko/faqs/faqs/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-0484fad1").then(t)}},{path:"/ko/faqs/faqs/index.html",redirect:"/ko/faqs/faqs/"},{path:"/ko/faqs/faqs.html",redirect:"/ko/faqs/faqs/"},{name:"v-663e7921",path:"/ko/install/install/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-663e7921").then(t)}},{path:"/ko/install/install/index.html",redirect:"/ko/install/install/"},{path:"/ko/install/install.html",redirect:"/ko/install/install/"},{name:"v-223c74ad",path:"/ko/miscellaneous/ambassadors/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-223c74ad").then(t)}},{path:"/ko/miscellaneous/ambassadors/index.html",redirect:"/ko/miscellaneous/ambassadors/"},{path:"/ko/miscellaneous/ambassadors.html",redirect:"/ko/miscellaneous/ambassadors/"},{name:"v-846f9be6",path:"/ko/miscellaneous/branding/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-846f9be6").then(t)}},{path:"/ko/miscellaneous/branding/index.html",redirect:"/ko/miscellaneous/branding/"},{path:"/ko/miscellaneous/branding.html",redirect:"/ko/miscellaneous/branding/"},{name:"v-3f016ca6",path:"/ko/miscellaneous/contributing/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-3f016ca6").then(t)}},{path:"/ko/miscellaneous/contributing/index.html",redirect:"/ko/miscellaneous/contributing/"},{path:"/ko/miscellaneous/contributing.html",redirect:"/ko/miscellaneous/contributing/"},{name:"v-7687b4ad",path:"/ko/miscellaneous/social_media/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-7687b4ad").then(t)}},{path:"/ko/miscellaneous/social_media/index.html",redirect:"/ko/miscellaneous/social_media/"},{path:"/ko/miscellaneous/social_media.html",redirect:"/ko/miscellaneous/social_media/"},{name:"v-779feb9b",path:"/ko/publish/connect/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-779feb9b").then(t)}},{path:"/ko/publish/connect/index.html",redirect:"/ko/publish/connect/"},{path:"/ko/publish/connect.html",redirect:"/ko/publish/connect/"},{name:"v-65f10351",path:"/ko/publish/publish/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-65f10351").then(t)}},{path:"/ko/publish/publish/index.html",redirect:"/ko/publish/publish/"},{path:"/ko/publish/publish.html",redirect:"/ko/publish/publish/"},{name:"v-249d6937",path:"/ko/publish/upgrade/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-249d6937").then(t)}},{path:"/ko/publish/upgrade/index.html",redirect:"/ko/publish/upgrade/"},{path:"/ko/publish/upgrade.html",redirect:"/ko/publish/upgrade/"},{name:"v-b022432a",path:"/ko/query/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-b022432a").then(t)}},{path:"/ko/query/graphql/index.html",redirect:"/ko/query/graphql/"},{path:"/ko/query/graphql.html",redirect:"/ko/query/graphql/"},{name:"v-dc503226",path:"/ko/query/query/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-dc503226").then(t)}},{path:"/ko/query/query/index.html",redirect:"/ko/query/query/"},{path:"/ko/query/query.html",redirect:"/ko/query/query/"},{name:"v-166c1b0d",path:"/ko/quickstart/helloworld-hosted/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-166c1b0d").then(t)}},{path:"/ko/quickstart/helloworld-hosted/index.html",redirect:"/ko/quickstart/helloworld-hosted/"},{path:"/ko/quickstart/helloworld-hosted.html",redirect:"/ko/quickstart/helloworld-hosted/"},{name:"v-5c3bceef",path:"/ko/quickstart/helloworld-localhost/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-5c3bceef").then(t)}},{path:"/ko/quickstart/helloworld-localhost/index.html",redirect:"/ko/quickstart/helloworld-localhost/"},{path:"/ko/quickstart/helloworld-localhost.html",redirect:"/ko/quickstart/helloworld-localhost/"},{name:"v-2afe91d1",path:"/ko/quickstart/quickstart/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-2afe91d1").then(t)}},{path:"/ko/quickstart/quickstart/index.html",redirect:"/ko/quickstart/quickstart/"},{path:"/ko/quickstart/quickstart.html",redirect:"/ko/quickstart/quickstart/"},{name:"v-45b45b2e",path:"/ko/quickstart/understanding-helloworld/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-45b45b2e").then(t)}},{path:"/ko/quickstart/understanding-helloworld/index.html",redirect:"/ko/quickstart/understanding-helloworld/"},{path:"/ko/quickstart/understanding-helloworld.html",redirect:"/ko/quickstart/understanding-helloworld/"},{name:"v-72bdcd61",path:"/ko/run/run/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-72bdcd61").then(t)}},{path:"/ko/run/run/index.html",redirect:"/ko/run/run/"},{path:"/ko/run/run.html",redirect:"/ko/run/run/"},{name:"v-850bfe2e",path:"/ko/run/sandbox/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-850bfe2e").then(t)}},{path:"/ko/run/sandbox/index.html",redirect:"/ko/run/sandbox/"},{path:"/ko/run/sandbox.html",redirect:"/ko/run/sandbox/"},{name:"v-8e6581a6",path:"/ko/tutorials_examples/howto/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-8e6581a6").then(t)}},{path:"/ko/tutorials_examples/howto/index.html",redirect:"/ko/tutorials_examples/howto/"},{path:"/ko/tutorials_examples/howto.html",redirect:"/ko/tutorials_examples/howto/"},{name:"v-4cc22903",path:"/ko/tutorials_examples/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-4cc22903").then(t)}},{path:"/ko/tutorials_examples/introduction/index.html",redirect:"/ko/tutorials_examples/introduction/"},{path:"/ko/tutorials_examples/introduction.html",redirect:"/ko/tutorials_examples/introduction/"},{name:"v-215f842d",path:"/ko/tutorials_examples/terminology/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-215f842d").then(t)}},{path:"/ko/tutorials_examples/terminology/index.html",redirect:"/ko/tutorials_examples/terminology/"},{path:"/ko/tutorials_examples/terminology.html",redirect:"/ko/tutorials_examples/terminology/"},{name:"v-ae40a866",path:"/miscellaneous/ambassadors/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-ae40a866").then(t)}},{path:"/miscellaneous/ambassadors/index.html",redirect:"/miscellaneous/ambassadors/"},{path:"/miscellaneous/ambassadors.html",redirect:"/miscellaneous/ambassadors/"},{name:"v-a45391be",path:"/miscellaneous/branding/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-a45391be").then(t)}},{path:"/miscellaneous/branding/index.html",redirect:"/miscellaneous/branding/"},{path:"/miscellaneous/branding.html",redirect:"/miscellaneous/branding/"},{name:"v-6d299e43",path:"/miscellaneous/contributing/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-6d299e43").then(t)}},{path:"/miscellaneous/contributing/index.html",redirect:"/miscellaneous/contributing/"},{path:"/miscellaneous/contributing.html",redirect:"/miscellaneous/contributing/"},{name:"v-034044f3",path:"/miscellaneous/social_media/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-034044f3").then(t)}},{path:"/miscellaneous/social_media/index.html",redirect:"/miscellaneous/social_media/"},{path:"/miscellaneous/social_media.html",redirect:"/miscellaneous/social_media/"},{name:"v-b6710da6",path:"/publish/connect/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-b6710da6").then(t)}},{path:"/publish/connect/index.html",redirect:"/publish/connect/"},{path:"/publish/connect.html",redirect:"/publish/connect/"},{name:"v-5be2726d",path:"/publish/upgrade/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-5be2726d").then(t)}},{path:"/publish/upgrade/index.html",redirect:"/publish/upgrade/"},{path:"/publish/upgrade.html",redirect:"/publish/upgrade/"},{name:"v-529f2d66",path:"/publish/publish/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-529f2d66").then(t)}},{path:"/publish/publish/index.html",redirect:"/publish/publish/"},{path:"/publish/publish.html",redirect:"/publish/publish/"},{name:"v-31c257a6",path:"/query/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-31c257a6").then(t)}},{path:"/query/graphql/index.html",redirect:"/query/graphql/"},{path:"/query/graphql.html",redirect:"/query/graphql/"},{name:"v-ecedcbe6",path:"/query/query/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-ecedcbe6").then(t)}},{path:"/query/query/index.html",redirect:"/query/query/"},{path:"/query/query.html",redirect:"/query/query/"},{name:"v-562bf2a5",path:"/quickstart/helloworld-hosted/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-562bf2a5").then(t)}},{path:"/quickstart/helloworld-hosted/index.html",redirect:"/quickstart/helloworld-hosted/"},{path:"/quickstart/helloworld-hosted.html",redirect:"/quickstart/helloworld-hosted/"},{name:"v-bc9cfe26",path:"/quickstart/helloworld-localhost/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-bc9cfe26").then(t)}},{path:"/quickstart/helloworld-localhost/index.html",redirect:"/quickstart/helloworld-localhost/"},{path:"/quickstart/helloworld-localhost.html",redirect:"/quickstart/helloworld-localhost/"},{name:"v-867568e6",path:"/quickstart/quickstart/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-867568e6").then(t)}},{path:"/quickstart/quickstart/index.html",redirect:"/quickstart/quickstart/"},{path:"/quickstart/quickstart.html",redirect:"/quickstart/quickstart/"},{name:"v-d4874966",path:"/quickstart/understanding-helloworld/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-d4874966").then(t)}},{path:"/quickstart/understanding-helloworld/index.html",redirect:"/quickstart/understanding-helloworld/"},{path:"/quickstart/understanding-helloworld.html",redirect:"/quickstart/understanding-helloworld/"},{name:"v-b4ffb0e6",path:"/references/references/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-b4ffb0e6").then(t)}},{path:"/references/references/index.html",redirect:"/references/references/"},{path:"/references/references.html",redirect:"/references/references/"},{name:"v-3bb71ffe",path:"/ru/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-3bb71ffe").then(t)}},{path:"/ru/index.html",redirect:"/ru/"},{name:"v-1b3677a6",path:"/ru/create/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-1b3677a6").then(t)}},{path:"/ru/create/graphql/index.html",redirect:"/ru/create/graphql/"},{path:"/ru/create/graphql.html",redirect:"/ru/create/graphql/"},{name:"v-1e91fed2",path:"/ru/create/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-1e91fed2").then(t)}},{path:"/ru/create/introduction/index.html",redirect:"/ru/create/introduction/"},{path:"/ru/create/introduction.html",redirect:"/ru/create/introduction/"},{name:"v-6a2b59ed",path:"/ru/create/manifest/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-6a2b59ed").then(t)}},{path:"/ru/create/manifest/index.html",redirect:"/ru/create/manifest/"},{path:"/ru/create/manifest.html",redirect:"/ru/create/manifest/"},{name:"v-afcff1e6",path:"/ru/create/mapping/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-afcff1e6").then(t)}},{path:"/ru/create/mapping/index.html",redirect:"/ru/create/mapping/"},{path:"/ru/create/mapping.html",redirect:"/ru/create/mapping/"},{name:"v-249ce353",path:"/ru/faqs/faqs/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-249ce353").then(t)}},{path:"/ru/faqs/faqs/index.html",redirect:"/ru/faqs/faqs/"},{path:"/ru/faqs/faqs.html",redirect:"/ru/faqs/faqs/"},{name:"v-60abd363",path:"/ru/install/install/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-60abd363").then(t)}},{path:"/ru/install/install/index.html",redirect:"/ru/install/install/"},{path:"/ru/install/install.html",redirect:"/ru/install/install/"},{name:"v-4a7311a2",path:"/ru/miscellaneous/ambassadors/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-4a7311a2").then(t)}},{path:"/ru/miscellaneous/ambassadors/index.html",redirect:"/ru/miscellaneous/ambassadors/"},{path:"/ru/miscellaneous/ambassadors.html",redirect:"/ru/miscellaneous/ambassadors/"},{name:"v-7ce7626d",path:"/ru/miscellaneous/branding/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-7ce7626d").then(t)}},{path:"/ru/miscellaneous/branding/index.html",redirect:"/ru/miscellaneous/branding/"},{path:"/ru/miscellaneous/branding.html",redirect:"/ru/miscellaneous/branding/"},{name:"v-0258bce6",path:"/ru/miscellaneous/contributing/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-0258bce6").then(t)}},{path:"/ru/miscellaneous/contributing/index.html",redirect:"/ru/miscellaneous/contributing/"},{path:"/ru/miscellaneous/contributing.html",redirect:"/ru/miscellaneous/contributing/"},{name:"v-d647e6e6",path:"/ru/miscellaneous/social_media/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-d647e6e6").then(t)}},{path:"/ru/miscellaneous/social_media/index.html",redirect:"/ru/miscellaneous/social_media/"},{path:"/ru/miscellaneous/social_media.html",redirect:"/ru/miscellaneous/social_media/"},{name:"v-720d45dd",path:"/ru/publish/connect/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-720d45dd").then(t)}},{path:"/ru/publish/connect/index.html",redirect:"/ru/publish/connect/"},{path:"/ru/publish/connect.html",redirect:"/ru/publish/connect/"},{name:"v-605e5d93",path:"/ru/publish/publish/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-605e5d93").then(t)}},{path:"/ru/publish/publish/index.html",redirect:"/ru/publish/publish/"},{path:"/ru/publish/publish.html",redirect:"/ru/publish/publish/"},{name:"v-1f0ac379",path:"/ru/publish/upgrade/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-1f0ac379").then(t)}},{path:"/ru/publish/upgrade/index.html",redirect:"/ru/publish/upgrade/"},{path:"/ru/publish/upgrade.html",redirect:"/ru/publish/upgrade/"},{name:"v-50fd6d6d",path:"/ru/query/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-50fd6d6d").then(t)}},{path:"/ru/query/graphql/index.html",redirect:"/ru/query/graphql/"},{path:"/ru/query/graphql.html",redirect:"/ru/query/graphql/"},{name:"v-0ffdfaaf",path:"/ru/query/query/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-0ffdfaaf").then(t)}},{path:"/ru/query/query/index.html",redirect:"/ru/query/query/"},{path:"/ru/query/query.html",redirect:"/ru/query/query/"},{name:"v-38af4ead",path:"/ru/quickstart/helloworld-hosted/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-38af4ead").then(t)}},{path:"/ru/quickstart/helloworld-hosted/index.html",redirect:"/ru/quickstart/helloworld-hosted/"},{path:"/ru/quickstart/helloworld-hosted.html",redirect:"/ru/quickstart/helloworld-hosted/"},{name:"v-953a799e",path:"/ru/quickstart/helloworld-localhost/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-953a799e").then(t)}},{path:"/ru/quickstart/helloworld-localhost/index.html",redirect:"/ru/quickstart/helloworld-localhost/"},{path:"/ru/quickstart/helloworld-localhost.html",redirect:"/ru/quickstart/helloworld-localhost/"},{name:"v-0133a45a",path:"/ru/quickstart/quickstart/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-0133a45a").then(t)}},{path:"/ru/quickstart/quickstart/index.html",redirect:"/ru/quickstart/quickstart/"},{path:"/ru/quickstart/quickstart.html",redirect:"/ru/quickstart/quickstart/"},{name:"v-05c24d2b",path:"/ru/quickstart/understanding-helloworld/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-05c24d2b").then(t)}},{path:"/ru/quickstart/understanding-helloworld/index.html",redirect:"/ru/quickstart/understanding-helloworld/"},{path:"/ru/quickstart/understanding-helloworld.html",redirect:"/ru/quickstart/understanding-helloworld/"},{name:"v-0df44aba",path:"/ru/run/run/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-0df44aba").then(t)}},{path:"/ru/run/run/index.html",redirect:"/ru/run/run/"},{path:"/ru/run/run.html",redirect:"/ru/run/run/"},{name:"v-3ba014ab",path:"/ru/run/sandbox/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-3ba014ab").then(t)}},{path:"/ru/run/sandbox/index.html",redirect:"/ru/run/sandbox/"},{path:"/ru/run/sandbox.html",redirect:"/ru/run/sandbox/"},{name:"v-11f6eb4d",path:"/ru/tutorials_examples/howto/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-11f6eb4d").then(t)}},{path:"/ru/tutorials_examples/howto/index.html",redirect:"/ru/tutorials_examples/howto/"},{path:"/ru/tutorials_examples/howto.html",redirect:"/ru/tutorials_examples/howto/"},{name:"v-b42dc576",path:"/ru/tutorials_examples/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-b42dc576").then(t)}},{path:"/ru/tutorials_examples/introduction/index.html",redirect:"/ru/tutorials_examples/introduction/"},{path:"/ru/tutorials_examples/introduction.html",redirect:"/ru/tutorials_examples/introduction/"},{name:"v-48f9c38d",path:"/ru/tutorials_examples/terminology/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-48f9c38d").then(t)}},{path:"/ru/tutorials_examples/terminology/index.html",redirect:"/ru/tutorials_examples/terminology/"},{path:"/ru/tutorials_examples/terminology.html",redirect:"/ru/tutorials_examples/terminology/"},{name:"v-09dfd14d",path:"/run/run/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-09dfd14d").then(t)}},{path:"/run/run/index.html",redirect:"/run/run/"},{path:"/run/run.html",redirect:"/run/run/"},{name:"v-07cf064d",path:"/run/sandbox/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-07cf064d").then(t)}},{path:"/run/sandbox/index.html",redirect:"/run/sandbox/"},{path:"/run/sandbox.html",redirect:"/run/sandbox/"},{name:"v-685a2e6d",path:"/tutorials_examples/batch-size/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-685a2e6d").then(t)}},{path:"/tutorials_examples/batch-size/index.html",redirect:"/tutorials_examples/batch-size/"},{path:"/tutorials_examples/batch-size.html",redirect:"/tutorials_examples/batch-size/"},{name:"v-295c5866",path:"/tutorials_examples/block-height/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-295c5866").then(t)}},{path:"/tutorials_examples/block-height/index.html",redirect:"/tutorials_examples/block-height/"},{path:"/tutorials_examples/block-height.html",redirect:"/tutorials_examples/block-height/"},{name:"v-1bc67126",path:"/tutorials_examples/debug-projects/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-1bc67126").then(t)}},{path:"/tutorials_examples/debug-projects/index.html",redirect:"/tutorials_examples/debug-projects/"},{path:"/tutorials_examples/debug-projects.html",redirect:"/tutorials_examples/debug-projects/"},{name:"v-1f91922d",path:"/tutorials_examples/dictionary/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-1f91922d").then(t)}},{path:"/tutorials_examples/dictionary/index.html",redirect:"/tutorials_examples/dictionary/"},{path:"/tutorials_examples/dictionary.html",redirect:"/tutorials_examples/dictionary/"},{name:"v-65affcad",path:"/tutorials_examples/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-65affcad").then(t)}},{path:"/tutorials_examples/introduction/index.html",redirect:"/tutorials_examples/introduction/"},{path:"/tutorials_examples/introduction.html",redirect:"/tutorials_examples/introduction/"},{name:"v-4e5b9057",path:"/tutorials_examples/run-indexer/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-4e5b9057").then(t)}},{path:"/tutorials_examples/run-indexer/index.html",redirect:"/tutorials_examples/run-indexer/"},{path:"/tutorials_examples/run-indexer.html",redirect:"/tutorials_examples/run-indexer/"},{name:"v-05bf836b",path:"/tutorials_examples/terminology/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-05bf836b").then(t)}},{path:"/tutorials_examples/terminology/index.html",redirect:"/tutorials_examples/terminology/"},{path:"/tutorials_examples/terminology.html",redirect:"/tutorials_examples/terminology/"},{name:"v-5dda9d1e",path:"/uk/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-5dda9d1e").then(t)}},{path:"/uk/index.html",redirect:"/uk/"},{name:"v-6dcc960d",path:"/uk/create/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-6dcc960d").then(t)}},{path:"/uk/create/graphql/index.html",redirect:"/uk/create/graphql/"},{path:"/uk/create/graphql.html",redirect:"/uk/create/graphql/"},{name:"v-67670071",path:"/uk/create/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-67670071").then(t)}},{path:"/uk/create/introduction/index.html",redirect:"/uk/create/introduction/"},{path:"/uk/create/introduction.html",redirect:"/uk/create/introduction/"},{name:"v-237fd8ed",path:"/uk/create/mapping/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-237fd8ed").then(t)}},{path:"/uk/create/mapping/index.html",redirect:"/uk/create/mapping/"},{path:"/uk/create/mapping.html",redirect:"/uk/create/mapping/"},{name:"v-3a2d0547",path:"/uk/create/manifest/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-3a2d0547").then(t)}},{path:"/uk/create/manifest/index.html",redirect:"/uk/create/manifest/"},{path:"/uk/create/manifest.html",redirect:"/uk/create/manifest/"},{name:"v-6e8c87ed",path:"/uk/faqs/faqs/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-6e8c87ed").then(t)}},{path:"/uk/faqs/faqs/index.html",redirect:"/uk/faqs/faqs/"},{path:"/uk/faqs/faqs.html",redirect:"/uk/faqs/faqs/"},{name:"v-30ad7ebd",path:"/uk/install/install/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-30ad7ebd").then(t)}},{path:"/uk/install/install/index.html",redirect:"/uk/install/install/"},{path:"/uk/install/install.html",redirect:"/uk/install/install/"},{name:"v-0841246e",path:"/uk/miscellaneous/ambassadors/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-0841246e").then(t)}},{path:"/uk/miscellaneous/ambassadors/index.html",redirect:"/uk/miscellaneous/ambassadors/"},{path:"/uk/miscellaneous/ambassadors.html",redirect:"/uk/miscellaneous/ambassadors/"},{name:"v-daa61166",path:"/uk/miscellaneous/branding/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-daa61166").then(t)}},{path:"/uk/miscellaneous/branding/index.html",redirect:"/uk/miscellaneous/branding/"},{path:"/uk/miscellaneous/branding.html",redirect:"/uk/miscellaneous/branding/"},{name:"v-392eb7ed",path:"/uk/miscellaneous/contributing/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-392eb7ed").then(t)}},{path:"/uk/miscellaneous/contributing/index.html",redirect:"/uk/miscellaneous/contributing/"},{path:"/uk/miscellaneous/contributing.html",redirect:"/uk/miscellaneous/contributing/"},{name:"v-6191ba26",path:"/uk/miscellaneous/social_media/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-6191ba26").then(t)}},{path:"/uk/miscellaneous/social_media/index.html",redirect:"/uk/miscellaneous/social_media/"},{path:"/uk/miscellaneous/social_media.html",redirect:"/uk/miscellaneous/social_media/"},{name:"v-420ef137",path:"/uk/publish/connect/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-420ef137").then(t)}},{path:"/uk/publish/connect/index.html",redirect:"/uk/publish/connect/"},{path:"/uk/publish/connect.html",redirect:"/uk/publish/connect/"},{name:"v-306008ed",path:"/uk/publish/publish/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-306008ed").then(t)}},{path:"/uk/publish/publish/index.html",redirect:"/uk/publish/publish/"},{path:"/uk/publish/publish.html",redirect:"/uk/publish/publish/"},{name:"v-21e7225a",path:"/uk/publish/upgrade/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-21e7225a").then(t)}},{path:"/uk/publish/upgrade/index.html",redirect:"/uk/publish/upgrade/"},{path:"/uk/publish/upgrade.html",redirect:"/uk/publish/upgrade/"},{name:"v-7bc99189",path:"/uk/query/query/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-7bc99189").then(t)}},{path:"/uk/query/query/index.html",redirect:"/uk/query/query/"},{path:"/uk/query/query.html",redirect:"/uk/query/query/"},{name:"v-ada9f2f2",path:"/uk/query/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-ada9f2f2").then(t)}},{path:"/uk/query/graphql/index.html",redirect:"/uk/query/graphql/"},{path:"/uk/query/graphql.html",redirect:"/uk/query/graphql/"},{name:"v-01b4cdcd",path:"/uk/quickstart/helloworld-hosted/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-01b4cdcd").then(t)}},{path:"/uk/quickstart/helloworld-hosted/index.html",redirect:"/uk/quickstart/helloworld-hosted/"},{path:"/uk/quickstart/helloworld-hosted.html",redirect:"/uk/quickstart/helloworld-hosted/"},{name:"v-77c86fed",path:"/uk/quickstart/quickstart/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-77c86fed").then(t)}},{path:"/uk/quickstart/quickstart/index.html",redirect:"/uk/quickstart/quickstart/"},{path:"/uk/quickstart/quickstart.html",redirect:"/uk/quickstart/quickstart/"},{name:"v-9ea17eea",path:"/uk/quickstart/helloworld-localhost/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-9ea17eea").then(t)}},{path:"/uk/quickstart/helloworld-localhost/index.html",redirect:"/uk/quickstart/helloworld-localhost/"},{path:"/uk/quickstart/helloworld-localhost.html",redirect:"/uk/quickstart/helloworld-localhost/"},{name:"v-7943c1f6",path:"/uk/quickstart/understanding-helloworld/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-7943c1f6").then(t)}},{path:"/uk/quickstart/understanding-helloworld/index.html",redirect:"/uk/quickstart/understanding-helloworld/"},{path:"/uk/quickstart/understanding-helloworld.html",redirect:"/uk/quickstart/understanding-helloworld/"},{name:"v-47b39cfd",path:"/uk/run/run/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-47b39cfd").then(t)}},{path:"/uk/run/run/index.html",redirect:"/uk/run/run/"},{path:"/uk/run/run.html",redirect:"/uk/run/run/"},{name:"v-b128a8f6",path:"/uk/run/sandbox/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-b128a8f6").then(t)}},{path:"/uk/run/sandbox/index.html",redirect:"/uk/run/sandbox/"},{path:"/uk/run/sandbox.html",redirect:"/uk/run/sandbox/"},{name:"v-2ca3ee26",path:"/uk/tutorials_examples/howto/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-2ca3ee26").then(t)}},{path:"/uk/tutorials_examples/howto/index.html",redirect:"/uk/tutorials_examples/howto/"},{path:"/uk/tutorials_examples/howto.html",redirect:"/uk/tutorials_examples/howto/"},{name:"v-bd94cac2",path:"/uk/tutorials_examples/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-bd94cac2").then(t)}},{path:"/uk/tutorials_examples/introduction/index.html",redirect:"/uk/tutorials_examples/introduction/"},{path:"/uk/tutorials_examples/introduction.html",redirect:"/uk/tutorials_examples/introduction/"},{name:"v-3b041b6d",path:"/uk/tutorials_examples/terminology/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-3b041b6d").then(t)}},{path:"/uk/tutorials_examples/terminology/index.html",redirect:"/uk/tutorials_examples/terminology/"},{path:"/uk/tutorials_examples/terminology.html",redirect:"/uk/tutorials_examples/terminology/"},{name:"v-e894ac04",path:"/vi/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-e894ac04").then(t)}},{path:"/vi/index.html",redirect:"/vi/"},{name:"v-9cd12ba6",path:"/vi/create/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-9cd12ba6").then(t)}},{path:"/vi/create/graphql/index.html",redirect:"/vi/create/graphql/"},{path:"/vi/create/graphql.html",redirect:"/vi/create/graphql/"},{name:"v-62e23092",path:"/vi/create/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-62e23092").then(t)}},{path:"/vi/create/introduction/index.html",redirect:"/vi/create/introduction/"},{path:"/vi/create/introduction.html",redirect:"/vi/create/introduction/"},{name:"v-e7c9cde6",path:"/vi/create/manifest/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-e7c9cde6").then(t)}},{path:"/vi/create/manifest/index.html",redirect:"/vi/create/manifest/"},{path:"/vi/create/manifest.html",redirect:"/vi/create/manifest/"},{name:"v-674aad0d",path:"/vi/create/mapping/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-674aad0d").then(t)}},{path:"/vi/create/mapping/index.html",redirect:"/vi/create/mapping/"},{path:"/vi/create/mapping.html",redirect:"/vi/create/mapping/"},{name:"v-6989e673",path:"/vi/faqs/faqs/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-6989e673").then(t)}},{path:"/vi/faqs/faqs/index.html",redirect:"/vi/faqs/faqs/"},{path:"/vi/faqs/faqs.html",redirect:"/vi/faqs/faqs/"},{name:"v-fac8dafa",path:"/vi/install/install/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-fac8dafa").then(t)}},{path:"/vi/install/install/index.html",redirect:"/vi/install/install/"},{path:"/vi/install/install.html",redirect:"/vi/install/install/"},{name:"v-8b57cb62",path:"/vi/miscellaneous/ambassadors/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-8b57cb62").then(t)}},{path:"/vi/miscellaneous/ambassadors/index.html",redirect:"/vi/miscellaneous/ambassadors/"},{path:"/vi/miscellaneous/ambassadors.html",redirect:"/vi/miscellaneous/ambassadors/"},{name:"v-3795786d",path:"/vi/miscellaneous/branding/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-3795786d").then(t)}},{path:"/vi/miscellaneous/branding/index.html",redirect:"/vi/miscellaneous/branding/"},{path:"/vi/miscellaneous/branding.html",redirect:"/vi/miscellaneous/branding/"},{name:"v-1809da8d",path:"/vi/miscellaneous/social_media/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-1809da8d").then(t)}},{path:"/vi/miscellaneous/social_media/index.html",redirect:"/vi/miscellaneous/social_media/"},{path:"/vi/miscellaneous/social_media.html",redirect:"/vi/miscellaneous/social_media/"},{name:"v-fbfd20e6",path:"/vi/miscellaneous/contributing/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-fbfd20e6").then(t)}},{path:"/vi/miscellaneous/contributing/index.html",redirect:"/vi/miscellaneous/contributing/"},{path:"/vi/miscellaneous/contributing.html",redirect:"/vi/miscellaneous/contributing/"},{name:"v-d805f606",path:"/vi/publish/connect/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-d805f606").then(t)}},{path:"/vi/publish/connect/index.html",redirect:"/vi/publish/connect/"},{path:"/vi/publish/connect.html",redirect:"/vi/publish/connect/"},{name:"v-fb63c69a",path:"/vi/publish/publish/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-fb63c69a").then(t)}},{path:"/vi/publish/publish/index.html",redirect:"/vi/publish/publish/"},{path:"/vi/publish/publish.html",redirect:"/vi/publish/publish/"},{name:"v-40fa8299",path:"/vi/publish/upgrade/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-40fa8299").then(t)}},{path:"/vi/publish/upgrade/index.html",redirect:"/vi/publish/upgrade/"},{path:"/vi/publish/upgrade.html",redirect:"/vi/publish/upgrade/"},{name:"v-7636cee6",path:"/vi/query/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-7636cee6").then(t)}},{path:"/vi/query/graphql/index.html",redirect:"/vi/query/graphql/"},{path:"/vi/query/graphql.html",redirect:"/vi/query/graphql/"},{name:"v-290cdc62",path:"/vi/query/query/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-290cdc62").then(t)}},{path:"/vi/query/query/index.html",redirect:"/vi/query/query/"},{path:"/vi/query/query.html",redirect:"/vi/query/query/"},{name:"v-19ad78ad",path:"/vi/quickstart/helloworld-hosted/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-19ad78ad").then(t)}},{path:"/vi/quickstart/helloworld-hosted/index.html",redirect:"/vi/quickstart/helloworld-hosted/"},{path:"/vi/quickstart/helloworld-hosted.html",redirect:"/vi/quickstart/helloworld-hosted/"},{name:"v-33ab2251",path:"/vi/quickstart/helloworld-localhost/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-33ab2251").then(t)}},{path:"/vi/quickstart/helloworld-localhost/index.html",redirect:"/vi/quickstart/helloworld-localhost/"},{path:"/vi/quickstart/helloworld-localhost.html",redirect:"/vi/quickstart/helloworld-localhost/"},{name:"v-3ac4ae1a",path:"/vi/quickstart/quickstart/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-3ac4ae1a").then(t)}},{path:"/vi/quickstart/quickstart/index.html",redirect:"/vi/quickstart/quickstart/"},{path:"/vi/quickstart/quickstart.html",redirect:"/vi/quickstart/quickstart/"},{name:"v-7c7a576a",path:"/vi/quickstart/understanding-helloworld/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-7c7a576a").then(t)}},{path:"/vi/quickstart/understanding-helloworld/index.html",redirect:"/vi/quickstart/understanding-helloworld/"},{path:"/vi/quickstart/understanding-helloworld.html",redirect:"/vi/quickstart/understanding-helloworld/"},{name:"v-258149c3",path:"/vi/run/run/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-258149c3").then(t)}},{path:"/vi/run/run/index.html",redirect:"/vi/run/run/"},{path:"/vi/run/run.html",redirect:"/vi/run/run/"},{name:"v-171babcb",path:"/vi/run/sandbox/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-171babcb").then(t)}},{path:"/vi/run/sandbox/index.html",redirect:"/vi/run/sandbox/"},{path:"/vi/run/sandbox.html",redirect:"/vi/run/sandbox/"},{name:"v-131f5d4d",path:"/vi/tutorials_examples/howto/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-131f5d4d").then(t)}},{path:"/vi/tutorials_examples/howto/index.html",redirect:"/vi/tutorials_examples/howto/"},{path:"/vi/tutorials_examples/howto.html",redirect:"/vi/tutorials_examples/howto/"},{name:"v-24317c65",path:"/vi/tutorials_examples/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-24317c65").then(t)}},{path:"/vi/tutorials_examples/introduction/index.html",redirect:"/vi/tutorials_examples/introduction/"},{path:"/vi/tutorials_examples/introduction.html",redirect:"/vi/tutorials_examples/introduction/"},{name:"v-73d3498d",path:"/vi/tutorials_examples/terminology/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-73d3498d").then(t)}},{path:"/vi/tutorials_examples/terminology/index.html",redirect:"/vi/tutorials_examples/terminology/"},{path:"/vi/tutorials_examples/terminology.html",redirect:"/vi/tutorials_examples/terminology/"},{name:"v-8fbc73c4",path:"/zh/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-8fbc73c4").then(t)}},{path:"/zh/index.html",redirect:"/zh/"},{name:"v-4cb5e50d",path:"/zh/create/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-4cb5e50d").then(t)}},{path:"/zh/create/graphql/index.html",redirect:"/zh/create/graphql/"},{path:"/zh/create/graphql.html",redirect:"/zh/create/graphql/"},{name:"v-8de7f97e",path:"/zh/create/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-8de7f97e").then(t)}},{path:"/zh/create/introduction/index.html",redirect:"/zh/create/introduction/"},{path:"/zh/create/introduction.html",redirect:"/zh/create/introduction/"},{name:"v-541b37d2",path:"/zh/create/manifest/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-541b37d2").then(t)}},{path:"/zh/create/manifest/index.html",redirect:"/zh/create/manifest/"},{path:"/zh/create/manifest.html",redirect:"/zh/create/manifest/"},{name:"v-026927ed",path:"/zh/create/mapping/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-026927ed").then(t)}},{path:"/zh/create/mapping/index.html",redirect:"/zh/create/mapping/"},{path:"/zh/create/mapping.html",redirect:"/zh/create/mapping/"},{name:"v-39ce30bd",path:"/zh/faqs/faqs/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-39ce30bd").then(t)}},{path:"/zh/faqs/faqs/index.html",redirect:"/zh/faqs/faqs/"},{path:"/zh/faqs/faqs.html",redirect:"/zh/faqs/faqs/"},{name:"v-671a44e6",path:"/zh/install/install/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-671a44e6").then(t)}},{path:"/zh/install/install/index.html",redirect:"/zh/install/install/"},{path:"/zh/install/install.html",redirect:"/zh/install/install/"},{name:"v-3bc0b2ce",path:"/zh/miscellaneous/ambassadors/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-3bc0b2ce").then(t)}},{path:"/zh/miscellaneous/ambassadors/index.html",redirect:"/zh/miscellaneous/ambassadors/"},{path:"/zh/miscellaneous/ambassadors.html",redirect:"/zh/miscellaneous/ambassadors/"},{name:"v-723b4366",path:"/zh/miscellaneous/branding/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-723b4366").then(t)}},{path:"/zh/miscellaneous/branding/index.html",redirect:"/zh/miscellaneous/branding/"},{path:"/zh/miscellaneous/branding.html",redirect:"/zh/miscellaneous/branding/"},{name:"v-0501aa26",path:"/zh/miscellaneous/contributing/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-0501aa26").then(t)}},{path:"/zh/miscellaneous/contributing/index.html",redirect:"/zh/miscellaneous/contributing/"},{path:"/zh/miscellaneous/contributing.html",redirect:"/zh/miscellaneous/contributing/"},{name:"v-d8f0d426",path:"/zh/miscellaneous/social_media/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-d8f0d426").then(t)}},{path:"/zh/miscellaneous/social_media/index.html",redirect:"/zh/miscellaneous/social_media/"},{path:"/zh/miscellaneous/social_media.html",redirect:"/zh/miscellaneous/social_media/"},{name:"v-44575ff2",path:"/zh/publish/connect/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-44575ff2").then(t)}},{path:"/zh/publish/connect/index.html",redirect:"/zh/publish/connect/"},{path:"/zh/publish/connect.html",redirect:"/zh/publish/connect/"},{name:"v-67b53086",path:"/zh/publish/publish/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-67b53086").then(t)}},{path:"/zh/publish/publish/index.html",redirect:"/zh/publish/publish/"},{path:"/zh/publish/publish.html",redirect:"/zh/publish/publish/"},{name:"v-ea5c64ba",path:"/zh/publish/upgrade/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-ea5c64ba").then(t)}},{path:"/zh/publish/upgrade/index.html",redirect:"/zh/publish/upgrade/"},{path:"/zh/publish/upgrade.html",redirect:"/zh/publish/upgrade/"},{name:"v-29ed5952",path:"/zh/query/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-29ed5952").then(t)}},{path:"/zh/query/graphql/index.html",redirect:"/zh/query/graphql/"},{path:"/zh/query/graphql.html",redirect:"/zh/query/graphql/"},{name:"v-37f14c59",path:"/zh/query/query/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-37f14c59").then(t)}},{path:"/zh/query/query/index.html",redirect:"/zh/query/query/"},{path:"/zh/query/query.html",redirect:"/zh/query/query/"},{name:"v-50bff266",path:"/zh/quickstart/helloworld-hosted/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-50bff266").then(t)}},{path:"/zh/quickstart/helloworld-hosted/index.html",redirect:"/zh/quickstart/helloworld-hosted/"},{path:"/zh/quickstart/helloworld-hosted.html",redirect:"/zh/quickstart/helloworld-hosted/"},{name:"v-9101a14a",path:"/zh/quickstart/helloworld-localhost/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-9101a14a").then(t)}},{path:"/zh/quickstart/helloworld-localhost/index.html",redirect:"/zh/quickstart/helloworld-localhost/"},{path:"/zh/quickstart/helloworld-localhost.html",redirect:"/zh/quickstart/helloworld-localhost/"},{name:"v-2c2604bd",path:"/zh/quickstart/quickstart/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-2c2604bd").then(t)}},{path:"/zh/quickstart/quickstart/index.html",redirect:"/zh/quickstart/quickstart/"},{path:"/zh/quickstart/quickstart.html",redirect:"/zh/quickstart/quickstart/"},{name:"v-31d49c56",path:"/zh/quickstart/understanding-helloworld/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-31d49c56").then(t)}},{path:"/zh/quickstart/understanding-helloworld/index.html",redirect:"/zh/quickstart/understanding-helloworld/"},{path:"/zh/quickstart/understanding-helloworld.html",redirect:"/zh/quickstart/understanding-helloworld/"},{name:"v-63936655",path:"/zh/run/sandbox/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-63936655").then(t)}},{path:"/zh/run/sandbox/index.html",redirect:"/zh/run/sandbox/"},{path:"/zh/run/sandbox.html",redirect:"/zh/run/sandbox/"},{name:"v-5f7fb3cd",path:"/zh/run/run/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-5f7fb3cd").then(t)}},{path:"/zh/run/run/index.html",redirect:"/zh/run/run/"},{path:"/zh/run/run.html",redirect:"/zh/run/run/"},{name:"v-58f735ed",path:"/zh/tutorials_examples/howto/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-58f735ed").then(t)}},{path:"/zh/tutorials_examples/howto/index.html",redirect:"/zh/tutorials_examples/howto/"},{path:"/zh/tutorials_examples/howto.html",redirect:"/zh/tutorials_examples/howto/"},{name:"v-cc84cb26",path:"/zh/tutorials_examples/terminology/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-cc84cb26").then(t)}},{path:"/zh/tutorials_examples/terminology/index.html",redirect:"/zh/tutorials_examples/terminology/"},{path:"/zh/tutorials_examples/terminology.html",redirect:"/zh/tutorials_examples/terminology/"},{name:"v-aff4ed22",path:"/zh/tutorials_examples/introduction/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-aff4ed22").then(t)}},{path:"/zh/tutorials_examples/introduction/index.html",redirect:"/zh/tutorials_examples/introduction/"},{path:"/zh/tutorials_examples/introduction.html",redirect:"/zh/tutorials_examples/introduction/"},{name:"v-2a03c37e",path:"/ja/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-2a03c37e").then(t)}},{path:"/ja/index.html",redirect:"/ja/"},{name:"v-045024ad",path:"/ja/create/graphql/",component:On,beforeEnter:(e,n,t)=>{pn("Layout","v-045024ad").then(t)}},{path:"/ja/create/graphql/index.html",redirect:"/ja/create/graphql/"},{path:"/ja/create/graphql.html",redirect:"/ja/create/graphql/"},{name:"v-6453f364",path:"/article/",component:On,beforeEnter:(e,n,t)=>{pn("Blog","v-6453f364").then(t)}},{path:"/article/index.html",redirect:"/article/"},{name:"v-4340f7e8",path:"/star/",component:On,beforeEnter:(e,n,t)=>{pn("Blog","v-4340f7e8").then(t)}},{path:"/star/index.html",redirect:"/star/"},{name:"v-7d484ebf",path:"/encrypt/",component:On,beforeEnter:(e,n,t)=>{pn("Blog","v-7d484ebf").then(t)}},{path:"/encrypt/index.html",redirect:"/encrypt/"},{name:"v-2470be33",path:"/slide/",component:On,beforeEnter:(e,n,t)=>{pn("Blog","v-2470be33").then(t)}},{path:"/slide/index.html",redirect:"/slide/"},{name:"v-6319eb4e",path:"/timeline/",component:On,beforeEnter:(e,n,t)=>{pn("Blog","v-6319eb4e").then(t)}},{path:"/timeline/index.html",redirect:"/timeline/"},{name:"v-b1564aac",path:"/tag/",component:On,beforeEnter:(e,n,t)=>{pn("Blog","v-b1564aac").then(t)},meta:{pid:"tag",id:"tag"}},{path:"/tag/index.html",redirect:"/tag/"},{name:"v-28e6393c",path:"/category/",component:On,beforeEnter:(e,n,t)=>{pn("Blog","v-28e6393c").then(t)},meta:{pid:"category",id:"category"}},{path:"/category/index.html",redirect:"/category/"},{path:"*",component:On}],Gn={title:"",description:"",base:"/",headTags:[["link",{rel:"manifest",href:"/manifest.webmanifest",crossorigin:"use-credentials"}],["meta",{name:"theme-color",content:"#46bd87"}],["meta",{name:"viewport",content:"width=device-width, initial-scale=1.0, viewport-fit=cover"}]],pages:[{title:"Welcome to SubQuery",frontmatter:{summary:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello",meta:[{property:"og:url",content:"/"},{property:"og:description",content:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/",relativePath:"README.md",key:"v-47639a6e",path:"/",readingTime:{minutes:3.03,words:910},headersStr:null,content:"Welcome to SubQuery’s Docs\n\nExplore and transform your chain data to build intuitive dApps faster!\n\n\nQuick Start Guide\n\nUnderstand SubQuery by getting hands on with a traditional Hello World example. Using a template project within a Docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * The SubQuery Network\n   \n   SubQuery’s decentralised future. Read more about how indexers and consumers are rewarded.\n\n\nFAQ\n\n * What is SubQuery?\n   \n   SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n   \n   READ MORE\n * What is the best way to get started with SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n * How can I contribute or give feedback to SubQuery?\n   \n   We love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guidelines (coming soon).\n   \n   READ MORE\n * How much does it cost to host my project in SubQuery Projects?\n   \n   Hosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nIntegrating with your Custom Chain?\n\nWhether you're building a new parachain or an entirely new blockchain on Substrate - SubQuery can help you index and troubleshoot your chain's data. SubQuery is designed to easily integrate with a custom Substrate based chain.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nSupport and Contribute\n\nHave a question or interested to know more or how you can contribute? We’d love to hear from you. Please contact us via email or social media from the links below. Need technical expertise? Join our Discord community and receive support from our passionate community members.\n\nJOIN THE CONVERSATION ON DISCORD\nContact us hello@subquery.network\nFollow us on social\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"welcome to subquery’s docs\n\nexplore and transform your chain data to build intuitive dapps faster!\n\n\nquick start guide\n\nunderstand subquery by getting hands on with a traditional hello world example. using a template project within a docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * the subquery network\n   \n   subquery’s decentralised future. read more about how indexers and consumers are rewarded.\n\n\nfaq\n\n * what is subquery?\n   \n   subquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n   \n   read more\n * what is the best way to get started with subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n * how can i contribute or give feedback to subquery?\n   \n   we love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guidelines (coming soon).\n   \n   read more\n * how much does it cost to host my project in subquery projects?\n   \n   hosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nintegrating with your custom chain?\n\nwhether you're building a new parachain or an entirely new blockchain on substrate - subquery can help you index and troubleshoot your chain's data. subquery is designed to easily integrate with a custom substrate based chain.\n\nlearn how to integrate with your chain\n\nsupport and contribute\n\nhave a question or interested to know more or how you can contribute? we’d love to hear from you. please contact us via email or social media from the links below. need technical expertise? join our discord community and receive support from our passionate community members.\n\njoin the conversation on discord\ncontact us hello@subquery.network\nfollow us on social\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"GraphQL Schema",frontmatter:{summary:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict",meta:[{property:"og:url",content:"/create/graphql.html"},{property:"og:title",content:"GraphQL Schema"},{property:"og:description",content:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/create/graphql.html",relativePath:"create/graphql.md",key:"v-86b1f726",path:"/create/graphql/",headers:[{level:2,title:"Defining Entities",slug:"defining-entities",normalizedTitle:"defining entities",charIndex:21},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:30},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:931},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1282},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1186},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3290},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3759},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:4063},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5097},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1268},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6446},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7146}],readingTime:{minutes:3.9,words:1170},headersStr:"Defining Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL Schema\n\n\n# Defining Entities\n\nThe schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates the shape of your data from SubQuery. To learn more about how to write in GraphQL schema language, we recommend checking out Schemas and Types.\n\nImportant: When you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# Entities\n\nEach entity must define its required fields id with the type of ID!. It is used as the primary key and unique among all entities of the same type.\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field \n}\n\ntype Title @entity {\n  id: ID!  \n  name: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nWhen code generation is run, this will automatically create a getByName under the User model, and the foreign key field title will create a getByTitleId method, which both can directly be accessed in the mapping function.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from \"../types/models/User\"\nimport {Title} from \"../types/models/Title\"\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account] \n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID! \n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactCard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# graphql schema\n\n\n# defining entities\n\nthe schema.graphql file defines the various graphql schemas. due to the way that the graphql query language works, the schema file essentially dictates the shape of your data from subquery. to learn more about how to write in graphql schema language, we recommend checking out schemas and types.\n\nimportant: when you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# entities\n\neach entity must define its required fields id with the type of id!. it is used as the primary key and unique among all entities of the same type.\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field \n}\n\ntype title @entity {\n  id: id!  \n  name: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nwhen code generation is run, this will automatically create a getbyname under the user model, and the foreign key field title will create a getbytitleid method, which both can directly be accessed in the mapping function.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from \"../types/models/user\"\nimport {title} from \"../types/models/title\"\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account] \n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id! \n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactcard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/create/introduction.html",relativePath:"create/introduction.md",key:"v-94114ee6",path:"/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2311}],readingTime:{minutes:1.79,words:537},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\nyarn build\n\n\n1\n\n\nnpm run-script build\n\n\n1\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\nyarn build\n\n\n1\n\n\nnpm run-script build\n\n\n1\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/create/manifest.html",relativePath:"create/manifest.md",key:"v-5d960c2d",path:"/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:2013},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3238},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4555}],readingTime:{minutes:2.5,words:751},headersStr:"Network Filters Mapping Filters Custom Chains",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - read how a SubQuery Dictionary works.\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - read how a subquery dictionary works.\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/create/mapping.html",relativePath:"create/mapping.md",key:"v-03d2d023",path:"/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3141},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4151},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5111},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5541},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6209},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5061},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6926},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10271},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11506},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11728}],readingTime:{minutes:6.93,words:2080},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from "@subql/types";\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n    // Create a new StarterEntity with the block hash as it\'s ID\n    const record = new starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from "ethers/lib/utils"; //Good way\nimport {utils} from "ethers" //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api.query.kitties.nextKittyId();\n    // return the Kitty type, input parameters types are AccountId and KittyIndex\n    const allKitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`Next kitty id ${nextKittyId}`)\n    //Custom rpc, set undefined to blockhash\n    const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined,nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from "@subql/types";\n\nexport async function handleblock(block: substrateblock): promise<void> {\n    // create a new starterentity with the block hash as it\'s id\n    const record = new starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from "ethers/lib/utils"; //good way\nimport {utils} from "ethers" //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api.query.kitties.nextkittyid();\n    // return the kitty type, input parameters types are accountid and kittyindex\n    const allkitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`next kitty id ${nextkittyid}`)\n    //custom rpc, set undefined to blockhash\n    const kittyprice = await api.rpc.kitties.getkittyprice(undefined,nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{frontmatter:{summary:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello",meta:[{property:"og:url",content:"/de/"},{property:"og:description",content:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/",relativePath:"de/README.md",key:"v-4806233e",path:"/de/",readingTime:{minutes:3.03,words:910},headersStr:null,content:"Welcome to SubQuery’s Docs\n\nExplore and transform your chain data to build intuitive dApps faster!\n\n\nQuick Start Guide\n\nUnderstand SubQuery by getting hands on with a traditional Hello World example. Using a template project within a Docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * The SubQuery Network\n   \n   SubQuery’s decentralised future. Read more about how indexers and consumers are rewarded.\n\n\nFAQ\n\n * What is SubQuery?\n   \n   SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n   \n   READ MORE\n * What is the best way to get started with SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n * How can I contribute or give feedback to SubQuery?\n   \n   We love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guidelines (coming soon).\n   \n   READ MORE\n * How much does it cost to host my project in SubQuery Projects?\n   \n   Hosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nIntegrating with your Custom Chain?\n\nWhether you're building a new parachain or an entirely new blockchain on Substrate - SubQuery can help you index and troubleshoot your chain's data. SubQuery is designed to easily integrate with a custom Substrate based chain.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nSupport and Contribute\n\nHave a question or interested to know more or how you can contribute? We’d love to hear from you. Please contact us via email or social media from the links below. Need technical expertise? Join our Discord community and receive support from our passionate community members.\n\nJOIN THE CONVERSATION ON DISCORD\nContact us hello@subquery.network\nFollow us on social\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"welcome to subquery’s docs\n\nexplore and transform your chain data to build intuitive dapps faster!\n\n\nquick start guide\n\nunderstand subquery by getting hands on with a traditional hello world example. using a template project within a docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * the subquery network\n   \n   subquery’s decentralised future. read more about how indexers and consumers are rewarded.\n\n\nfaq\n\n * what is subquery?\n   \n   subquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n   \n   read more\n * what is the best way to get started with subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n * how can i contribute or give feedback to subquery?\n   \n   we love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guidelines (coming soon).\n   \n   read more\n * how much does it cost to host my project in subquery projects?\n   \n   hosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nintegrating with your custom chain?\n\nwhether you're building a new parachain or an entirely new blockchain on substrate - subquery can help you index and troubleshoot your chain's data. subquery is designed to easily integrate with a custom substrate based chain.\n\nlearn how to integrate with your chain\n\nsupport and contribute\n\nhave a question or interested to know more or how you can contribute? we’d love to hear from you. please contact us via email or social media from the links below. need technical expertise? join our discord community and receive support from our passionate community members.\n\njoin the conversation on discord\ncontact us hello@subquery.network\nfollow us on social\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"GraphQL Schema",frontmatter:{summary:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict",meta:[{property:"og:url",content:"/de/create/graphql.html"},{property:"og:title",content:"GraphQL Schema"},{property:"og:description",content:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/create/graphql.html",relativePath:"de/create/graphql.md",key:"v-64c45226",path:"/de/create/graphql/",headers:[{level:2,title:"Defining Entities",slug:"defining-entities",normalizedTitle:"defining entities",charIndex:21},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:30},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:931},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1282},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1186},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3290},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3759},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:4063},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5097},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1268},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6446},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7146}],readingTime:{minutes:3.9,words:1170},headersStr:"Defining Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL Schema\n\n\n# Defining Entities\n\nThe schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates the shape of your data from SubQuery. To learn more about how to write in GraphQL schema language, we recommend checking out Schemas and Types.\n\nImportant: When you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# Entities\n\nEach entity must define its required fields id with the type of ID!. It is used as the primary key and unique among all entities of the same type.\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field \n}\n\ntype Title @entity {\n  id: ID!  \n  name: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nWhen code generation is run, this will automatically create a getByName under the User model, and the foreign key field title will create a getByTitleId method, which both can directly be accessed in the mapping function.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from \"../types/models/User\"\nimport {Title} from \"../types/models/Title\"\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account] \n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID! \n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactCard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# graphql schema\n\n\n# defining entities\n\nthe schema.graphql file defines the various graphql schemas. due to the way that the graphql query language works, the schema file essentially dictates the shape of your data from subquery. to learn more about how to write in graphql schema language, we recommend checking out schemas and types.\n\nimportant: when you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# entities\n\neach entity must define its required fields id with the type of id!. it is used as the primary key and unique among all entities of the same type.\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field \n}\n\ntype title @entity {\n  id: id!  \n  name: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nwhen code generation is run, this will automatically create a getbyname under the user model, and the foreign key field title will create a getbytitleid method, which both can directly be accessed in the mapping function.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from \"../types/models/user\"\nimport {title} from \"../types/models/title\"\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account] \n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id! \n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactcard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/de/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/create/introduction.html",relativePath:"de/create/introduction.md",key:"v-19f3891b",path:"/de/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2327}],readingTime:{minutes:1.76,words:527},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/de/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/create/manifest.html",relativePath:"de/create/manifest.md",key:"v-4f881571",path:"/de/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:1998},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3223},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4540}],readingTime:{minutes:2.51,words:752},headersStr:"Network Filters Mapping Filters Custom Chains",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - see Running an Indexer\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - see running an indexer\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/de/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/create/mapping.html",relativePath:"de/create/mapping.md",key:"v-f95dcc66",path:"/de/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3141},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4151},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5111},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5541},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6209},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5061},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6926},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10271},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11506},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11728}],readingTime:{minutes:6.93,words:2080},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from "@subql/types";\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n    // Create a new StarterEntity with the block hash as it\'s ID\n    const record = new starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from "ethers/lib/utils"; //Good way\nimport {utils} from "ethers" //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api.query.kitties.nextKittyId();\n    // return the Kitty type, input parameters types are AccountId and KittyIndex\n    const allKitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`Next kitty id ${nextKittyId}`)\n    //Custom rpc, set undefined to blockhash\n    const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined,nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from "@subql/types";\n\nexport async function handleblock(block: substrateblock): promise<void> {\n    // create a new starterentity with the block hash as it\'s id\n    const record = new starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from "ethers/lib/utils"; //good way\nimport {utils} from "ethers" //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api.query.kitties.nextkittyid();\n    // return the kitty type, input parameters types are accountid and kittyindex\n    const allkitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`next kitty id ${nextkittyid}`)\n    //custom rpc, set undefined to blockhash\n    const kittyprice = await api.rpc.kitties.getkittyprice(undefined,nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/de/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/faqs/faqs.html",relativePath:"de/faqs/faqs.md",key:"v-3d649b57",path:"/de/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/de/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/install/install.html",relativePath:"de/install/install.md",key:"v-46088ee7",path:"/de/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/de/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/miscellaneous/ambassadors.html",relativePath:"de/miscellaneous/ambassadors.md",key:"v-4f6d6333",path:"/de/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/de/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/miscellaneous/branding.html",relativePath:"de/miscellaneous/branding.md",key:"v-25b5132d",path:"/de/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/de/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/miscellaneous/contributing.html",relativePath:"de/miscellaneous/contributing.md",key:"v-220de14d",path:"/de/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/de/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/miscellaneous/social_media.html",relativePath:"de/miscellaneous/social_media.md",key:"v-8fd36766",path:"/de/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/de/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/publish/connect.html",relativePath:"de/publish/connect.md",key:"v-576a0161",path:"/de/publish/connect/",readingTime:{minutes:.61,words:182},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/de/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/publish/publish.html",relativePath:"de/publish/publish.md",key:"v-45bb1917",path:"/de/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1133},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. *We're almost there! We just need to deploy a new version of it. *\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. *we're almost there! we just need to deploy a new version of it. *\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/de/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/publish/upgrade.html",relativePath:"de/publish/upgrade.md",key:"v-04677efd",path:"/de/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/de/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/query/graphql.html",relativePath:"de/query/graphql.md",key:"v-03e13271",path:"/de/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/de/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/query/query.html",relativePath:"de/query/query.md",key:"v-306d6933",path:"/de/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/de/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/quickstart/helloworld-hosted.html",relativePath:"de/quickstart/helloworld-hosted.md",key:"v-754465ed",path:"/de/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/de/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/quickstart/helloworld-localhost.html",relativePath:"de/quickstart/helloworld-localhost.md",key:"v-756db2b5",path:"/de/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"Step 1: Initialise project",slug:"step-1-initialise-project",normalizedTitle:"step 1: initialise project",charIndex:1455},{level:2,title:"Step 2: Install dependencies",slug:"step-2-install-dependencies",normalizedTitle:"step 2: install dependencies",charIndex:2035},{level:2,title:"Step 3: Generate code",slug:"step-3-generate-code",normalizedTitle:"step 3: generate code",charIndex:2477},{level:2,title:"Step 4: Build code",slug:"step-4-build-code",normalizedTitle:"step 4: build code",charIndex:3087},{level:2,title:"Step 5: Run Docker",slug:"step-5-run-docker",normalizedTitle:"step 5: run docker",charIndex:3319},{level:2,title:"Step 6: Browse playground",slug:"step-6-browse-playground",normalizedTitle:"step 6: browse playground",charIndex:4586},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:5027}],readingTime:{minutes:2.85,words:855},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Initialise project Step 2: Install dependencies Step 3: Generate code Step 4: Build code Step 5: Run Docker Step 6: Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Step 5: Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Step 6: Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# step 5: run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# step 6: browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/de/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/quickstart/quickstart.html",relativePath:"de/quickstart/quickstart.md",key:"v-e30ce652",path:"/de/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2566},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3009},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3388},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3628},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3981},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4548},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5235}],readingTime:{minutes:3.22,words:967},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/de/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/quickstart/understanding-helloworld.html",relativePath:"de/quickstart/understanding-helloworld.md",key:"v-76f709af",path:"/de/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/de/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/run/run.html",relativePath:"de/run/run.md",key:"v-bc8b07b2",path:"/de/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3940},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4183}],readingTime:{minutes:2.57,words:772},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/de/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/run/sandbox.html",relativePath:"de/run/sandbox.md",key:"v-5c0f832f",path:"/de/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/de/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/tutorials_examples/howto.html",relativePath:"de/tutorials_examples/howto.md",key:"v-89f298e6",path:"/de/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri",meta:[{property:"og:url",content:"/de/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/tutorials_examples/introduction.html",relativePath:"de/tutorials_examples/introduction.md",key:"v-65f40cc9",path:"/de/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:155}],readingTime:{minutes:.77,words:231},headersStr:"SubQuery Examples",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# SubQuery Examples\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# subquery examples\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/de/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/tutorials_examples/terminology.html",relativePath:"de/tutorials_examples/terminology.md",key:"v-4162124d",path:"/de/tutorials_examples/terminology/",headers:[{level:2,title:"Terminology",slug:"terminology",normalizedTitle:"terminology",charIndex:2}],readingTime:{minutes:.49,words:147},headersStr:"Terminology",content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{frontmatter:{summary:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello",meta:[{property:"og:url",content:"/es/"},{property:"og:description",content:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/",relativePath:"es/README.md",key:"v-1397d61e",path:"/es/",readingTime:{minutes:3.03,words:910},headersStr:null,content:"Welcome to SubQuery’s Docs\n\nExplore and transform your chain data to build intuitive dApps faster!\n\n\nQuick Start Guide\n\nUnderstand SubQuery by getting hands on with a traditional Hello World example. Using a template project within a Docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * The SubQuery Network\n   \n   SubQuery’s decentralised future. Read more about how indexers and consumers are rewarded.\n\n\nFAQ\n\n * What is SubQuery?\n   \n   SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n   \n   READ MORE\n * What is the best way to get started with SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n * How can I contribute or give feedback to SubQuery?\n   \n   We love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guidelines (coming soon).\n   \n   READ MORE\n * How much does it cost to host my project in SubQuery Projects?\n   \n   Hosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nIntegrating with your Custom Chain?\n\nWhether you're building a new parachain or an entirely new blockchain on Substrate - SubQuery can help you index and troubleshoot your chain's data. SubQuery is designed to easily integrate with a custom Substrate based chain.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nSupport and Contribute\n\nHave a question or interested to know more or how you can contribute? We’d love to hear from you. Please contact us via email or social media from the links below. Need technical expertise? Join our Discord community and receive support from our passionate community members.\n\nJOIN THE CONVERSATION ON DISCORD\nContact us hello@subquery.network\nFollow us on social\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"welcome to subquery’s docs\n\nexplore and transform your chain data to build intuitive dapps faster!\n\n\nquick start guide\n\nunderstand subquery by getting hands on with a traditional hello world example. using a template project within a docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * the subquery network\n   \n   subquery’s decentralised future. read more about how indexers and consumers are rewarded.\n\n\nfaq\n\n * what is subquery?\n   \n   subquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n   \n   read more\n * what is the best way to get started with subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n * how can i contribute or give feedback to subquery?\n   \n   we love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guidelines (coming soon).\n   \n   read more\n * how much does it cost to host my project in subquery projects?\n   \n   hosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nintegrating with your custom chain?\n\nwhether you're building a new parachain or an entirely new blockchain on substrate - subquery can help you index and troubleshoot your chain's data. subquery is designed to easily integrate with a custom substrate based chain.\n\nlearn how to integrate with your chain\n\nsupport and contribute\n\nhave a question or interested to know more or how you can contribute? we’d love to hear from you. please contact us via email or social media from the links below. need technical expertise? join our discord community and receive support from our passionate community members.\n\njoin the conversation on discord\ncontact us hello@subquery.network\nfollow us on social\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"GraphQL Schema",frontmatter:{summary:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict",meta:[{property:"og:url",content:"/es/create/graphql.html"},{property:"og:title",content:"GraphQL Schema"},{property:"og:description",content:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/create/graphql.html",relativePath:"es/create/graphql.md",key:"v-514b550d",path:"/es/create/graphql/",headers:[{level:2,title:"Defining Entities",slug:"defining-entities",normalizedTitle:"defining entities",charIndex:21},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:30},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:931},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1282},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1186},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3290},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3759},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:4063},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5097},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1268},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6446},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7146}],readingTime:{minutes:3.9,words:1170},headersStr:"Defining Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL Schema\n\n\n# Defining Entities\n\nThe schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates the shape of your data from SubQuery. To learn more about how to write in GraphQL schema language, we recommend checking out Schemas and Types.\n\nImportant: When you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# Entities\n\nEach entity must define its required fields id with the type of ID!. It is used as the primary key and unique among all entities of the same type.\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field \n}\n\ntype Title @entity {\n  id: ID!  \n  name: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nWhen code generation is run, this will automatically create a getByName under the User model, and the foreign key field title will create a getByTitleId method, which both can directly be accessed in the mapping function.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from \"../types/models/User\"\nimport {Title} from \"../types/models/Title\"\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account] \n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID! \n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactCard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# graphql schema\n\n\n# defining entities\n\nthe schema.graphql file defines the various graphql schemas. due to the way that the graphql query language works, the schema file essentially dictates the shape of your data from subquery. to learn more about how to write in graphql schema language, we recommend checking out schemas and types.\n\nimportant: when you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# entities\n\neach entity must define its required fields id with the type of id!. it is used as the primary key and unique among all entities of the same type.\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field \n}\n\ntype title @entity {\n  id: id!  \n  name: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nwhen code generation is run, this will automatically create a getbyname under the user model, and the foreign key field title will create a getbytitleid method, which both can directly be accessed in the mapping function.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from \"../types/models/user\"\nimport {title} from \"../types/models/title\"\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account] \n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id! \n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactcard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/es/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/create/introduction.html",relativePath:"es/create/introduction.md",key:"v-7c3a4841",path:"/es/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2327}],readingTime:{minutes:1.76,words:527},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/es/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/create/manifest.html",relativePath:"es/create/manifest.md",key:"v-38986917",path:"/es/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:1998},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3223},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4540}],readingTime:{minutes:2.51,words:752},headersStr:"Network Filters Mapping Filters Custom Chains",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - see Running an Indexer\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - see running an indexer\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/es/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/create/mapping.html",relativePath:"es/create/mapping.md",key:"v-06fe97ed",path:"/es/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3141},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4151},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5111},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5541},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6209},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5061},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6926},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10271},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11506},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11728}],readingTime:{minutes:6.93,words:2080},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from "@subql/types";\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n    // Create a new StarterEntity with the block hash as it\'s ID\n    const record = new starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from "ethers/lib/utils"; //Good way\nimport {utils} from "ethers" //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api.query.kitties.nextKittyId();\n    // return the Kitty type, input parameters types are AccountId and KittyIndex\n    const allKitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`Next kitty id ${nextKittyId}`)\n    //Custom rpc, set undefined to blockhash\n    const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined,nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from "@subql/types";\n\nexport async function handleblock(block: substrateblock): promise<void> {\n    // create a new starterentity with the block hash as it\'s id\n    const record = new starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from "ethers/lib/utils"; //good way\nimport {utils} from "ethers" //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api.query.kitties.nextkittyid();\n    // return the kitty type, input parameters types are accountid and kittyindex\n    const allkitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`next kitty id ${nextkittyid}`)\n    //custom rpc, set undefined to blockhash\n    const kittyprice = await api.rpc.kitties.getkittyprice(undefined,nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/es/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/faqs/faqs.html",relativePath:"es/faqs/faqs.md",key:"v-56f85486",path:"/es/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/es/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/install/install.html",relativePath:"es/install/install.md",key:"v-2f18e28d",path:"/es/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/es/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/miscellaneous/ambassadors.html",relativePath:"es/miscellaneous/ambassadors.md",key:"v-76f64b99",path:"/es/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/es/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/miscellaneous/branding.html",relativePath:"es/miscellaneous/branding.md",key:"v-2e6d4e4d",path:"/es/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/es/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/miscellaneous/contributing.html",relativePath:"es/miscellaneous/contributing.md",key:"v-29564a26",path:"/es/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/es/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/miscellaneous/social_media.html",relativePath:"es/miscellaneous/social_media.md",key:"v-fd457426",path:"/es/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/es/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/publish/connect.html",relativePath:"es/publish/connect.md",key:"v-407a5507",path:"/es/publish/connect/",readingTime:{minutes:.61,words:182},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/es/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/publish/publish.html",relativePath:"es/publish/publish.md",key:"v-2ecb6cbd",path:"/es/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1133},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. *We're almost there! We just need to deploy a new version of it. *\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. *we're almost there! we just need to deploy a new version of it. *\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/es/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/publish/upgrade.html",relativePath:"es/publish/upgrade.md",key:"v-25105aba",path:"/es/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/es/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/query/graphql.html",relativePath:"es/query/graphql.md",key:"v-0b973857",path:"/es/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/es/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/query/query.html",relativePath:"es/query/query.md",key:"v-2d2f1159",path:"/es/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/es/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/quickstart/helloworld-hosted.html",relativePath:"es/quickstart/helloworld-hosted.md",key:"v-ee61d266",path:"/es/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/es/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/quickstart/helloworld-localhost.html",relativePath:"es/quickstart/helloworld-localhost.md",key:"v-2f06345b",path:"/es/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"Step 1: Initialise project",slug:"step-1-initialise-project",normalizedTitle:"step 1: initialise project",charIndex:1455},{level:2,title:"Step 2: Install dependencies",slug:"step-2-install-dependencies",normalizedTitle:"step 2: install dependencies",charIndex:2035},{level:2,title:"Step 3: Generate code",slug:"step-3-generate-code",normalizedTitle:"step 3: generate code",charIndex:2477},{level:2,title:"Step 4: Build code",slug:"step-4-build-code",normalizedTitle:"step 4: build code",charIndex:3087},{level:2,title:"Step 5: Run Docker",slug:"step-5-run-docker",normalizedTitle:"step 5: run docker",charIndex:3319},{level:2,title:"Step 6: Browse playground",slug:"step-6-browse-playground",normalizedTitle:"step 6: browse playground",charIndex:4586},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:5027}],readingTime:{minutes:2.85,words:855},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Initialise project Step 2: Install dependencies Step 3: Generate code Step 4: Build code Step 5: Run Docker Step 6: Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Step 5: Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Step 6: Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# step 5: run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# step 6: browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/es/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/quickstart/quickstart.html",relativePath:"es/quickstart/quickstart.md",key:"v-19c469bd",path:"/es/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2566},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3009},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3388},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3628},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3981},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4548},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5235}],readingTime:{minutes:3.22,words:967},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/es/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/quickstart/understanding-helloworld.html",relativePath:"es/quickstart/understanding-helloworld.md",key:"v-6ba4f6d5",path:"/es/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/es/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/run/run.html",relativePath:"es/run/run.md",key:"v-ab158e66",path:"/es/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3940},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4183}],readingTime:{minutes:2.57,words:772},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/es/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/run/sandbox.html",relativePath:"es/run/sandbox.md",key:"v-58d12b55",path:"/es/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/es/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/tutorials_examples/howto.html",relativePath:"es/tutorials_examples/howto.md",key:"v-76eb85ed",path:"/es/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri",meta:[{property:"og:url",content:"/es/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/tutorials_examples/introduction.html",relativePath:"es/tutorials_examples/introduction.md",key:"v-1f8c8e6f",path:"/es/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:155}],readingTime:{minutes:.77,words:231},headersStr:"SubQuery Examples",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# SubQuery Examples\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# subquery examples\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/es/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/tutorials_examples/terminology.html",relativePath:"es/tutorials_examples/terminology.md",key:"v-5bbe0a6d",path:"/es/tutorials_examples/terminology/",headers:[{level:2,title:"Terminology",slug:"terminology",normalizedTitle:"terminology",charIndex:2}],readingTime:{minutes:.49,words:147},headersStr:"Terminology",content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/faqs/faqs.html",relativePath:"faqs/faqs.md",key:"v-1265970d",path:"/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566},{level:2,title:"What is the endpoint for the Kusama network?",slug:"what-is-the-endpoint-for-the-kusama-network",normalizedTitle:"what is the endpoint for the kusama network?",charIndex:3600},{level:2,title:"What is the endpoint for the Polkadot mainnet network?",slug:"what-is-the-endpoint-for-the-polkadot-mainnet-network",normalizedTitle:"what is the endpoint for the polkadot mainnet network?",charIndex:3739}],readingTime:{minutes:2.2,words:659},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics? What is the endpoint for the Kusama network? What is the endpoint for the Polkadot mainnet network?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.\n\n\n# What is the endpoint for the Kusama network?\n\nThe network.endpoint for the Kusama network is wss://kusama.api.onfinality.io/public-ws.\n\n\n# What is the endpoint for the Polkadot mainnet network?\n\nThe network.endpoint for the Polkadot network is wss://polkadot.api.onfinality.io/public-ws.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.\n\n\n# what is the endpoint for the kusama network?\n\nthe network.endpoint for the kusama network is wss://kusama.api.onfinality.io/public-ws.\n\n\n# what is the endpoint for the polkadot mainnet network?\n\nthe network.endpoint for the polkadot network is wss://polkadot.api.onfinality.io/public-ws.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{frontmatter:{summary:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello",meta:[{property:"og:url",content:"/id/"},{property:"og:description",content:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/",relativePath:"id/README.md",key:"v-560420fe",path:"/id/",readingTime:{minutes:3.03,words:910},headersStr:null,content:"Welcome to SubQuery’s Docs\n\nExplore and transform your chain data to build intuitive dApps faster!\n\n\nQuick Start Guide\n\nUnderstand SubQuery by getting hands on with a traditional Hello World example. Using a template project within a Docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * The SubQuery Network\n   \n   SubQuery’s decentralised future. Read more about how indexers and consumers are rewarded.\n\n\nFAQ\n\n * What is SubQuery?\n   \n   SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n   \n   READ MORE\n * What is the best way to get started with SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n * How can I contribute or give feedback to SubQuery?\n   \n   We love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guidelines (coming soon).\n   \n   READ MORE\n * How much does it cost to host my project in SubQuery Projects?\n   \n   Hosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nIntegrating with your Custom Chain?\n\nWhether you're building a new parachain or an entirely new blockchain on Substrate - SubQuery can help you index and troubleshoot your chain's data. SubQuery is designed to easily integrate with a custom Substrate based chain.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nSupport and Contribute\n\nHave a question or interested to know more or how you can contribute? We’d love to hear from you. Please contact us via email or social media from the links below. Need technical expertise? Join our Discord community and receive support from our passionate community members.\n\nJOIN THE CONVERSATION ON DISCORD\nContact us hello@subquery.network\nFollow us on social\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"welcome to subquery’s docs\n\nexplore and transform your chain data to build intuitive dapps faster!\n\n\nquick start guide\n\nunderstand subquery by getting hands on with a traditional hello world example. using a template project within a docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * the subquery network\n   \n   subquery’s decentralised future. read more about how indexers and consumers are rewarded.\n\n\nfaq\n\n * what is subquery?\n   \n   subquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n   \n   read more\n * what is the best way to get started with subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n * how can i contribute or give feedback to subquery?\n   \n   we love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guidelines (coming soon).\n   \n   read more\n * how much does it cost to host my project in subquery projects?\n   \n   hosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nintegrating with your custom chain?\n\nwhether you're building a new parachain or an entirely new blockchain on substrate - subquery can help you index and troubleshoot your chain's data. subquery is designed to easily integrate with a custom substrate based chain.\n\nlearn how to integrate with your chain\n\nsupport and contribute\n\nhave a question or interested to know more or how you can contribute? we’d love to hear from you. please contact us via email or social media from the links below. need technical expertise? join our discord community and receive support from our passionate community members.\n\njoin the conversation on discord\ncontact us hello@subquery.network\nfollow us on social\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"GraphQL Schema",frontmatter:{summary:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict",meta:[{property:"og:url",content:"/id/create/graphql.html"},{property:"og:title",content:"GraphQL Schema"},{property:"og:description",content:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/create/graphql.html",relativePath:"id/create/graphql.md",key:"v-56f909a6",path:"/id/create/graphql/",headers:[{level:2,title:"Defining Entities",slug:"defining-entities",normalizedTitle:"defining entities",charIndex:21},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:30},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:931},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1282},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1186},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3290},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3759},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:4063},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5097},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1268},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6446},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7146}],readingTime:{minutes:3.9,words:1170},headersStr:"Defining Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL Schema\n\n\n# Defining Entities\n\nThe schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates the shape of your data from SubQuery. To learn more about how to write in GraphQL schema language, we recommend checking out Schemas and Types.\n\nImportant: When you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# Entities\n\nEach entity must define its required fields id with the type of ID!. It is used as the primary key and unique among all entities of the same type.\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field \n}\n\ntype Title @entity {\n  id: ID!  \n  name: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nWhen code generation is run, this will automatically create a getByName under the User model, and the foreign key field title will create a getByTitleId method, which both can directly be accessed in the mapping function.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from \"../types/models/User\"\nimport {Title} from \"../types/models/Title\"\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account] \n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID! \n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactCard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# graphql schema\n\n\n# defining entities\n\nthe schema.graphql file defines the various graphql schemas. due to the way that the graphql query language works, the schema file essentially dictates the shape of your data from subquery. to learn more about how to write in graphql schema language, we recommend checking out schemas and types.\n\nimportant: when you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# entities\n\neach entity must define its required fields id with the type of id!. it is used as the primary key and unique among all entities of the same type.\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field \n}\n\ntype title @entity {\n  id: id!  \n  name: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nwhen code generation is run, this will automatically create a getbyname under the user model, and the foreign key field title will create a getbytitleid method, which both can directly be accessed in the mapping function.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from \"../types/models/user\"\nimport {title} from \"../types/models/title\"\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account] \n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id! \n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactcard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/id/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/create/introduction.html",relativePath:"id/create/introduction.md",key:"v-6a073232",path:"/id/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2327}],readingTime:{minutes:1.76,words:527},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/id/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/create/manifest.html",relativePath:"id/create/manifest.md",key:"v-7e31bc3d",path:"/id/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:1998},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3223},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4540}],readingTime:{minutes:2.51,words:752},headersStr:"Network Filters Mapping Filters Custom Chains",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - see Running an Indexer\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - see running an indexer\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/id/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/create/mapping.html",relativePath:"id/create/mapping.md",key:"v-eb9283e6",path:"/id/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3141},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4151},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5111},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5541},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6209},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5061},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6926},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10271},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11506},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11728}],readingTime:{minutes:6.93,words:2080},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from "@subql/types";\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n    // Create a new StarterEntity with the block hash as it\'s ID\n    const record = new starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from "ethers/lib/utils"; //Good way\nimport {utils} from "ethers" //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api.query.kitties.nextKittyId();\n    // return the Kitty type, input parameters types are AccountId and KittyIndex\n    const allKitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`Next kitty id ${nextKittyId}`)\n    //Custom rpc, set undefined to blockhash\n    const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined,nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from "@subql/types";\n\nexport async function handleblock(block: substrateblock): promise<void> {\n    // create a new starterentity with the block hash as it\'s id\n    const record = new starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from "ethers/lib/utils"; //good way\nimport {utils} from "ethers" //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api.query.kitties.nextkittyid();\n    // return the kitty type, input parameters types are accountid and kittyindex\n    const allkitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`next kitty id ${nextkittyid}`)\n    //custom rpc, set undefined to blockhash\n    const kittyprice = await api.rpc.kitties.getkittyprice(undefined,nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/id/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/faqs/faqs.html",relativePath:"id/faqs/faqs.md",key:"v-47ab00ba",path:"/id/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/id/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/install/install.html",relativePath:"id/install/install.md",key:"v-74b235b3",path:"/id/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/id/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/miscellaneous/ambassadors.html",relativePath:"id/miscellaneous/ambassadors.md",key:"v-42d0237f",path:"/id/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/id/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/miscellaneous/branding.html",relativePath:"id/miscellaneous/branding.md",key:"v-73371d26",path:"/id/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/id/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/miscellaneous/contributing.html",relativePath:"id/miscellaneous/contributing.md",key:"v-932646e6",path:"/id/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/id/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/miscellaneous/social_media.html",relativePath:"id/miscellaneous/social_media.md",key:"v-4c75478d",path:"/id/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/id/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/publish/connect.html",relativePath:"id/publish/connect.md",key:"v-f3d8afa6",path:"/id/publish/connect/",readingTime:{minutes:.61,words:182},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/id/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/publish/publish.html",relativePath:"id/publish/publish.md",key:"v-7464bfe3",path:"/id/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1133},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. *We're almost there! We just need to deploy a new version of it. *\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. *we're almost there! we just need to deploy a new version of it. *\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/id/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/publish/upgrade.html",relativePath:"id/publish/upgrade.md",key:"v-331125c9",path:"/id/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/id/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/query/graphql.html",relativePath:"id/query/graphql.md",key:"v-7981e486",path:"/id/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/id/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/query/query.html",relativePath:"id/query/query.md",key:"v-5e3758ff",path:"/id/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/id/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/quickstart/helloworld-hosted.html",relativePath:"id/quickstart/helloworld-hosted.md",key:"v-eabc40a6",path:"/id/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/id/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/quickstart/helloworld-localhost.html",relativePath:"id/quickstart/helloworld-localhost.md",key:"v-79dd94fe",path:"/id/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"Step 1: Initialise project",slug:"step-1-initialise-project",normalizedTitle:"step 1: initialise project",charIndex:1455},{level:2,title:"Step 2: Install dependencies",slug:"step-2-install-dependencies",normalizedTitle:"step 2: install dependencies",charIndex:2035},{level:2,title:"Step 3: Generate code",slug:"step-3-generate-code",normalizedTitle:"step 3: generate code",charIndex:2477},{level:2,title:"Step 4: Build code",slug:"step-4-build-code",normalizedTitle:"step 4: build code",charIndex:3087},{level:2,title:"Step 5: Run Docker",slug:"step-5-run-docker",normalizedTitle:"step 5: run docker",charIndex:3319},{level:2,title:"Step 6: Browse playground",slug:"step-6-browse-playground",normalizedTitle:"step 6: browse playground",charIndex:4586},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:5027}],readingTime:{minutes:2.85,words:855},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Initialise project Step 2: Install dependencies Step 3: Generate code Step 4: Build code Step 5: Run Docker Step 6: Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Step 5: Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Step 6: Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# step 5: run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# step 6: browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/id/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/quickstart/quickstart.html",relativePath:"id/quickstart/quickstart.md",key:"v-26e5d623",path:"/id/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2566},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3009},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3388},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3628},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3981},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4548},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5235}],readingTime:{minutes:3.22,words:967},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/id/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/quickstart/understanding-helloworld.html",relativePath:"id/quickstart/understanding-helloworld.md",key:"v-3977c37b",path:"/id/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/id/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/run/run.html",relativePath:"id/run/run.md",key:"v-5ee434f3",path:"/id/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3940},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4183}],readingTime:{minutes:2.57,words:772},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/id/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/run/sandbox.html",relativePath:"id/run/sandbox.md",key:"v-ec4d1a0a",path:"/id/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/id/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/tutorials_examples/howto.html",relativePath:"id/tutorials_examples/howto.md",key:"v-7c9e504d",path:"/id/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri",meta:[{property:"og:url",content:"/id/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/tutorials_examples/introduction.html",relativePath:"id/tutorials_examples/introduction.md",key:"v-98d0e0d6",path:"/id/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:155}],readingTime:{minutes:.77,words:231},headersStr:"SubQuery Examples",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# SubQuery Examples\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# subquery examples\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/id/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/tutorials_examples/terminology.html",relativePath:"id/tutorials_examples/terminology.md",key:"v-0765aae6",path:"/id/tutorials_examples/terminology/",headers:[{level:2,title:"Terminology",slug:"terminology",normalizedTitle:"terminology",charIndex:2}],readingTime:{minutes:.49,words:147},headersStr:"Terminology",content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/cli tool is used to create SubQuery projects. The @subql/node component is re",meta:[{property:"og:url",content:"/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/cli tool is used to create SubQuery projects. The @subql/node component is re"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/install/install.html",relativePath:"install/install.md",key:"v-2680104d",path:"/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:271},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:636},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1237}],readingTime:{minutes:1.22,words:367},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/cli tool is used to create SubQuery projects. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli tool helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\nyarn global add @subql/cli\n\n\n1\n\n\nnpm install -g @subql/cli\n\n\n1\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\nyarn global add @subql/node\n\n\n1\n\n\nnpm install -g @subql/node\n\n\n1\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\nyarn global add @subql/query\n\n\n1\n\n\nnpm install -g @subql/query\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/cli tool is used to create subquery projects. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli tool helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\nyarn global add @subql/cli\n\n\n1\n\n\nnpm install -g @subql/cli\n\n\n1\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\nyarn global add @subql/node\n\n\n1\n\n\nnpm install -g @subql/node\n\n\n1\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\nyarn global add @subql/query\n\n\n1\n\n\nnpm install -g @subql/query\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{frontmatter:{summary:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello",meta:[{property:"og:url",content:"/it/"},{property:"og:description",content:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/",relativePath:"it/README.md",key:"v-188a7204",path:"/it/",readingTime:{minutes:3.03,words:910},headersStr:null,content:"Welcome to SubQuery’s Docs\n\nExplore and transform your chain data to build intuitive dApps faster!\n\n\nQuick Start Guide\n\nUnderstand SubQuery by getting hands on with a traditional Hello World example. Using a template project within a Docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * The SubQuery Network\n   \n   SubQuery’s decentralised future. Read more about how indexers and consumers are rewarded.\n\n\nFAQ\n\n * What is SubQuery?\n   \n   SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n   \n   READ MORE\n * What is the best way to get started with SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n * How can I contribute or give feedback to SubQuery?\n   \n   We love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guidelines (coming soon).\n   \n   READ MORE\n * How much does it cost to host my project in SubQuery Projects?\n   \n   Hosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nIntegrating with your Custom Chain?\n\nWhether you're building a new parachain or an entirely new blockchain on Substrate - SubQuery can help you index and troubleshoot your chain's data. SubQuery is designed to easily integrate with a custom Substrate based chain.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nSupport and Contribute\n\nHave a question or interested to know more or how you can contribute? We’d love to hear from you. Please contact us via email or social media from the links below. Need technical expertise? Join our Discord community and receive support from our passionate community members.\n\nJOIN THE CONVERSATION ON DISCORD\nContact us hello@subquery.network\nFollow us on social\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"welcome to subquery’s docs\n\nexplore and transform your chain data to build intuitive dapps faster!\n\n\nquick start guide\n\nunderstand subquery by getting hands on with a traditional hello world example. using a template project within a docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * the subquery network\n   \n   subquery’s decentralised future. read more about how indexers and consumers are rewarded.\n\n\nfaq\n\n * what is subquery?\n   \n   subquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n   \n   read more\n * what is the best way to get started with subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n * how can i contribute or give feedback to subquery?\n   \n   we love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guidelines (coming soon).\n   \n   read more\n * how much does it cost to host my project in subquery projects?\n   \n   hosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nintegrating with your custom chain?\n\nwhether you're building a new parachain or an entirely new blockchain on substrate - subquery can help you index and troubleshoot your chain's data. subquery is designed to easily integrate with a custom substrate based chain.\n\nlearn how to integrate with your chain\n\nsupport and contribute\n\nhave a question or interested to know more or how you can contribute? we’d love to hear from you. please contact us via email or social media from the links below. need technical expertise? join our discord community and receive support from our passionate community members.\n\njoin the conversation on discord\ncontact us hello@subquery.network\nfollow us on social\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"GraphQL Schema",frontmatter:{summary:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict",meta:[{property:"og:url",content:"/it/create/graphql.html"},{property:"og:title",content:"GraphQL Schema"},{property:"og:description",content:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/create/graphql.html",relativePath:"it/create/graphql.md",key:"v-1466252d",path:"/it/create/graphql/",headers:[{level:2,title:"Defining Entities",slug:"defining-entities",normalizedTitle:"defining entities",charIndex:21},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:30},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:931},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1282},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1186},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3290},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3759},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:4063},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5097},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1268},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6446},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7146}],readingTime:{minutes:3.9,words:1170},headersStr:"Defining Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL Schema\n\n\n# Defining Entities\n\nThe schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates the shape of your data from SubQuery. To learn more about how to write in GraphQL schema language, we recommend checking out Schemas and Types.\n\nImportant: When you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# Entities\n\nEach entity must define its required fields id with the type of ID!. It is used as the primary key and unique among all entities of the same type.\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field \n}\n\ntype Title @entity {\n  id: ID!  \n  name: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nWhen code generation is run, this will automatically create a getByName under the User model, and the foreign key field title will create a getByTitleId method, which both can directly be accessed in the mapping function.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from \"../types/models/User\"\nimport {Title} from \"../types/models/Title\"\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account] \n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID! \n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactCard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# graphql schema\n\n\n# defining entities\n\nthe schema.graphql file defines the various graphql schemas. due to the way that the graphql query language works, the schema file essentially dictates the shape of your data from subquery. to learn more about how to write in graphql schema language, we recommend checking out schemas and types.\n\nimportant: when you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# entities\n\neach entity must define its required fields id with the type of id!. it is used as the primary key and unique among all entities of the same type.\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field \n}\n\ntype title @entity {\n  id: id!  \n  name: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nwhen code generation is run, this will automatically create a getbyname under the user model, and the foreign key field title will create a getbytitleid method, which both can directly be accessed in the mapping function.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from \"../types/models/user\"\nimport {title} from \"../types/models/title\"\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account] \n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id! \n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactcard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/it/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/create/introduction.html",relativePath:"it/create/introduction.md",key:"v-73c98272",path:"/it/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2327}],readingTime:{minutes:1.76,words:527},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/it/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/create/manifest.html",relativePath:"it/create/manifest.md",key:"v-1553fc1d",path:"/it/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:1998},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3223},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4540}],readingTime:{minutes:2.51,words:752},headersStr:"Network Filters Mapping Filters Custom Chains",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - see Running an Indexer\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - see running an indexer\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/it/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/create/mapping.html",relativePath:"it/create/mapping.md",key:"v-6bcd2fe6",path:"/it/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3141},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4151},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5111},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5541},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6209},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5061},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6926},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10271},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11506},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11728}],readingTime:{minutes:6.93,words:2080},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from "@subql/types";\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n    // Create a new StarterEntity with the block hash as it\'s ID\n    const record = new starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from "ethers/lib/utils"; //Good way\nimport {utils} from "ethers" //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api.query.kitties.nextKittyId();\n    // return the Kitty type, input parameters types are AccountId and KittyIndex\n    const allKitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`Next kitty id ${nextKittyId}`)\n    //Custom rpc, set undefined to blockhash\n    const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined,nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from "@subql/types";\n\nexport async function handleblock(block: substrateblock): promise<void> {\n    // create a new starterentity with the block hash as it\'s id\n    const record = new starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from "ethers/lib/utils"; //good way\nimport {utils} from "ethers" //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api.query.kitties.nextkittyid();\n    // return the kitty type, input parameters types are accountid and kittyindex\n    const allkitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`next kitty id ${nextkittyid}`)\n    //custom rpc, set undefined to blockhash\n    const kittyprice = await api.rpc.kitties.getkittyprice(undefined,nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/it/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/faqs/faqs.html",relativePath:"it/faqs/faqs.md",key:"v-784c5b83",path:"/it/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/it/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/install/install.html",relativePath:"it/install/install.md",key:"v-0bd47593",path:"/it/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/it/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/miscellaneous/ambassadors.html",relativePath:"it/miscellaneous/ambassadors.md",key:"v-a8374142",path:"/it/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/it/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/miscellaneous/branding.html",relativePath:"it/miscellaneous/branding.md",key:"v-2a342b6d",path:"/it/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/it/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/miscellaneous/contributing.html",relativePath:"it/miscellaneous/contributing.md",key:"v-36e11e8d",path:"/it/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/it/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/miscellaneous/social_media.html",relativePath:"it/miscellaneous/social_media.md",key:"v-662cece6",path:"/it/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/it/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/publish/connect.html",relativePath:"it/publish/connect.md",key:"v-1d35e80d",path:"/it/publish/connect/",readingTime:{minutes:.61,words:182},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/it/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/publish/publish.html",relativePath:"it/publish/publish.md",key:"v-0b86ffc3",path:"/it/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1133},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. *We're almost there! We just need to deploy a new version of it. *\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. *we're almost there! we just need to deploy a new version of it. *\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/it/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/publish/upgrade.html",relativePath:"it/publish/upgrade.md",key:"v-6b9934ae",path:"/it/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/it/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/query/graphql.html",relativePath:"it/query/graphql.md",key:"v-a188fcc6",path:"/it/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/it/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/query/query.html",relativePath:"it/query/query.md",key:"v-296dfe42",path:"/it/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/it/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/quickstart/helloworld-hosted.html",relativePath:"it/quickstart/helloworld-hosted.md",key:"v-f39834a6",path:"/it/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/it/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/quickstart/helloworld-localhost.html",relativePath:"it/quickstart/helloworld-localhost.md",key:"v-0ca4553e",path:"/it/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"Step 1: Initialise project",slug:"step-1-initialise-project",normalizedTitle:"step 1: initialise project",charIndex:1455},{level:2,title:"Step 2: Install dependencies",slug:"step-2-install-dependencies",normalizedTitle:"step 2: install dependencies",charIndex:2035},{level:2,title:"Step 3: Generate code",slug:"step-3-generate-code",normalizedTitle:"step 3: generate code",charIndex:2477},{level:2,title:"Step 4: Build code",slug:"step-4-build-code",normalizedTitle:"step 4: build code",charIndex:3087},{level:2,title:"Step 5: Run Docker",slug:"step-5-run-docker",normalizedTitle:"step 5: run docker",charIndex:3319},{level:2,title:"Step 6: Browse playground",slug:"step-6-browse-playground",normalizedTitle:"step 6: browse playground",charIndex:4586},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:5027}],readingTime:{minutes:2.85,words:855},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Initialise project Step 2: Install dependencies Step 3: Generate code Step 4: Build code Step 5: Run Docker Step 6: Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Step 5: Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Step 6: Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# step 5: run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# step 6: browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/it/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/quickstart/quickstart.html",relativePath:"it/quickstart/quickstart.md",key:"v-475b7a03",path:"/it/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2566},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3009},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3388},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3628},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3981},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4548},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5235}],readingTime:{minutes:3.22,words:967},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/it/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/quickstart/understanding-helloworld.html",relativePath:"it/quickstart/understanding-helloworld.md",key:"v-2fc0fb5b",path:"/it/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/it/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/run/run.html",relativePath:"it/run/run.md",key:"v-ec5d765a",path:"/it/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3940},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4183}],readingTime:{minutes:2.57,words:772},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/it/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/run/sandbox.html",relativePath:"it/run/sandbox.md",key:"v-16eb1adb",path:"/it/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/it/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/tutorials_examples/howto.html",relativePath:"it/tutorials_examples/howto.md",key:"v-0f11ce4d",path:"/it/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri",meta:[{property:"og:url",content:"/it/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/tutorials_examples/introduction.html",relativePath:"it/tutorials_examples/introduction.md",key:"v-2b97a116",path:"/it/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:155}],readingTime:{minutes:.77,words:231},headersStr:"SubQuery Examples",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# SubQuery Examples\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# subquery examples\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/it/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/tutorials_examples/terminology.html",relativePath:"it/tutorials_examples/terminology.md",key:"v-444c16e6",path:"/it/tutorials_examples/terminology/",headers:[{level:2,title:"Terminology",slug:"terminology",normalizedTitle:"terminology",charIndex:2}],readingTime:{minutes:.49,words:147},headersStr:"Terminology",content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/ja/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/create/introduction.html",relativePath:"ja/create/introduction.md",key:"v-027260af",path:"/ja/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2327}],readingTime:{minutes:1.76,words:527},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/ja/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/create/manifest.html",relativePath:"ja/create/manifest.md",key:"v-f2a4a7f6",path:"/ja/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:1998},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3223},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4540}],readingTime:{minutes:2.51,words:752},headersStr:"Network Filters Mapping Filters Custom Chains",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - see Running an Indexer\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - see running an indexer\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/ja/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/create/mapping.html",relativePath:"ja/create/mapping.md",key:"v-8bf930e6",path:"/ja/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3141},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4151},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5111},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5541},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6209},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5061},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6926},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10271},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11506},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11728}],readingTime:{minutes:6.93,words:2080},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from "@subql/types";\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n    // Create a new StarterEntity with the block hash as it\'s ID\n    const record = new starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from "ethers/lib/utils"; //Good way\nimport {utils} from "ethers" //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api.query.kitties.nextKittyId();\n    // return the Kitty type, input parameters types are AccountId and KittyIndex\n    const allKitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`Next kitty id ${nextKittyId}`)\n    //Custom rpc, set undefined to blockhash\n    const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined,nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from "@subql/types";\n\nexport async function handleblock(block: substrateblock): promise<void> {\n    // create a new starterentity with the block hash as it\'s id\n    const record = new starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from "ethers/lib/utils"; //good way\nimport {utils} from "ethers" //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api.query.kitties.nextkittyid();\n    // return the kitty type, input parameters types are accountid and kittyindex\n    const allkitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`next kitty id ${nextkittyid}`)\n    //custom rpc, set undefined to blockhash\n    const kittyprice = await api.rpc.kitties.getkittyprice(undefined,nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/ja/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/faqs/faqs.html",relativePath:"ja/faqs/faqs.md",key:"v-6d65c06b",path:"/ja/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/ja/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/install/install.html",relativePath:"ja/install/install.md",key:"v-7d2e257b",path:"/ja/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/ja/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/miscellaneous/ambassadors.html",relativePath:"ja/miscellaneous/ambassadors.md",key:"v-0a98e772",path:"/ja/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/ja/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/miscellaneous/branding.html",relativePath:"ja/miscellaneous/branding.md",key:"v-95e01226",path:"/ja/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/ja/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/miscellaneous/contributing.html",relativePath:"ja/miscellaneous/contributing.md",key:"v-1738500d",path:"/ja/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/ja/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/miscellaneous/social_media.html",relativePath:"ja/miscellaneous/social_media.md",key:"v-a57e89e6",path:"/ja/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/ja/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/publish/connect.html",relativePath:"ja/publish/connect.md",key:"v-e2e0d016",path:"/ja/publish/connect/",readingTime:{minutes:.61,words:182},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/ja/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/publish/publish.html",relativePath:"ja/publish/publish.md",key:"v-7ce0afab",path:"/ja/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1133},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. *We're almost there! We just need to deploy a new version of it. *\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. *we're almost there! we just need to deploy a new version of it. *\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/ja/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/publish/upgrade.html",relativePath:"ja/publish/upgrade.md",key:"v-3b8d1591",path:"/ja/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/ja/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/query/graphql.html",relativePath:"ja/query/graphql.md",key:"v-bf8e4ef6",path:"/ja/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/ja/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/query/query.html",relativePath:"ja/query/query.md",key:"v-d5d38272",path:"/ja/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/ja/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/quickstart/helloworld-hosted.html",relativePath:"ja/quickstart/helloworld-hosted.md",key:"v-02e16a2d",path:"/ja/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/ja/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/quickstart/helloworld-localhost.html",relativePath:"ja/quickstart/helloworld-localhost.md",key:"v-bab9656e",path:"/ja/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"Step 1: Initialise project",slug:"step-1-initialise-project",normalizedTitle:"step 1: initialise project",charIndex:1455},{level:2,title:"Step 2: Install dependencies",slug:"step-2-install-dependencies",normalizedTitle:"step 2: install dependencies",charIndex:2035},{level:2,title:"Step 3: Generate code",slug:"step-3-generate-code",normalizedTitle:"step 3: generate code",charIndex:2477},{level:2,title:"Step 4: Build code",slug:"step-4-build-code",normalizedTitle:"step 4: build code",charIndex:3087},{level:2,title:"Step 5: Run Docker",slug:"step-5-run-docker",normalizedTitle:"step 5: run docker",charIndex:3319},{level:2,title:"Step 6: Browse playground",slug:"step-6-browse-playground",normalizedTitle:"step 6: browse playground",charIndex:4586},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:5027}],readingTime:{minutes:2.85,words:855},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Initialise project Step 2: Install dependencies Step 3: Generate code Step 4: Build code Step 5: Run Docker Step 6: Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Step 5: Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Step 6: Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# step 5: run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# step 6: browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/ja/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/quickstart/quickstart.html",relativePath:"ja/quickstart/quickstart.md",key:"v-c098962a",path:"/ja/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2566},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3009},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3388},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3628},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3981},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4548},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5235}],readingTime:{minutes:3.22,words:967},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/ja/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/quickstart/understanding-helloworld.html",relativePath:"ja/quickstart/understanding-helloworld.md",key:"v-2f10357a",path:"/ja/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/ja/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/run/run.html",relativePath:"ja/run/run.md",key:"v-6a0310bb",path:"/ja/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3940},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4183}],readingTime:{minutes:2.57,words:772},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/ja/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/run/sandbox.html",relativePath:"ja/run/sandbox.md",key:"v-7e8f4e7a",path:"/ja/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/ja/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/tutorials_examples/howto.html",relativePath:"ja/tutorials_examples/howto.md",key:"v-062f2666",path:"/ja/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri",meta:[{property:"og:url",content:"/ja/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/tutorials_examples/introduction.html",relativePath:"ja/tutorials_examples/introduction.md",key:"v-d9acb146",path:"/ja/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:155}],readingTime:{minutes:.77,words:231},headersStr:"SubQuery Examples",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# SubQuery Examples\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# subquery examples\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/ja/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/tutorials_examples/terminology.html",relativePath:"ja/tutorials_examples/terminology.md",key:"v-07038c0d",path:"/ja/tutorials_examples/terminology/",headers:[{level:2,title:"Terminology",slug:"terminology",normalizedTitle:"terminology",charIndex:2}],readingTime:{minutes:.49,words:147},headersStr:"Terminology",content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{frontmatter:{summary:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello",meta:[{property:"og:url",content:"/ko/"},{property:"og:description",content:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/",relativePath:"ko/README.md",key:"v-14d51344",path:"/ko/",readingTime:{minutes:3.03,words:910},headersStr:null,content:"Welcome to SubQuery’s Docs\n\nExplore and transform your chain data to build intuitive dApps faster!\n\n\nQuick Start Guide\n\nUnderstand SubQuery by getting hands on with a traditional Hello World example. Using a template project within a Docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * The SubQuery Network\n   \n   SubQuery’s decentralised future. Read more about how indexers and consumers are rewarded.\n\n\nFAQ\n\n * What is SubQuery?\n   \n   SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n   \n   READ MORE\n * What is the best way to get started with SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n * How can I contribute or give feedback to SubQuery?\n   \n   We love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guidelines (coming soon).\n   \n   READ MORE\n * How much does it cost to host my project in SubQuery Projects?\n   \n   Hosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nIntegrating with your Custom Chain?\n\nWhether you're building a new parachain or an entirely new blockchain on Substrate - SubQuery can help you index and troubleshoot your chain's data. SubQuery is designed to easily integrate with a custom Substrate based chain.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nSupport and Contribute\n\nHave a question or interested to know more or how you can contribute? We’d love to hear from you. Please contact us via email or social media from the links below. Need technical expertise? Join our Discord community and receive support from our passionate community members.\n\nJOIN THE CONVERSATION ON DISCORD\nContact us hello@subquery.network\nFollow us on social\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"welcome to subquery’s docs\n\nexplore and transform your chain data to build intuitive dapps faster!\n\n\nquick start guide\n\nunderstand subquery by getting hands on with a traditional hello world example. using a template project within a docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * the subquery network\n   \n   subquery’s decentralised future. read more about how indexers and consumers are rewarded.\n\n\nfaq\n\n * what is subquery?\n   \n   subquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n   \n   read more\n * what is the best way to get started with subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n * how can i contribute or give feedback to subquery?\n   \n   we love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guidelines (coming soon).\n   \n   read more\n * how much does it cost to host my project in subquery projects?\n   \n   hosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nintegrating with your custom chain?\n\nwhether you're building a new parachain or an entirely new blockchain on substrate - subquery can help you index and troubleshoot your chain's data. subquery is designed to easily integrate with a custom substrate based chain.\n\nlearn how to integrate with your chain\n\nsupport and contribute\n\nhave a question or interested to know more or how you can contribute? we’d love to hear from you. please contact us via email or social media from the links below. need technical expertise? join our discord community and receive support from our passionate community members.\n\njoin the conversation on discord\ncontact us hello@subquery.network\nfollow us on social\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"GraphQL Schema",frontmatter:{summary:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict",meta:[{property:"og:url",content:"/ko/create/graphql.html"},{property:"og:title",content:"GraphQL Schema"},{property:"og:description",content:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/create/graphql.html",relativePath:"ko/create/graphql.md",key:"v-f004ba66",path:"/ko/create/graphql/",headers:[{level:2,title:"Defining Entities",slug:"defining-entities",normalizedTitle:"defining entities",charIndex:21},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:30},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:931},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1282},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1186},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3290},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3759},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:4063},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5097},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1268},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6446},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7146}],readingTime:{minutes:3.9,words:1170},headersStr:"Defining Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL Schema\n\n\n# Defining Entities\n\nThe schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates the shape of your data from SubQuery. To learn more about how to write in GraphQL schema language, we recommend checking out Schemas and Types.\n\nImportant: When you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# Entities\n\nEach entity must define its required fields id with the type of ID!. It is used as the primary key and unique among all entities of the same type.\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field \n}\n\ntype Title @entity {\n  id: ID!  \n  name: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nWhen code generation is run, this will automatically create a getByName under the User model, and the foreign key field title will create a getByTitleId method, which both can directly be accessed in the mapping function.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from \"../types/models/User\"\nimport {Title} from \"../types/models/Title\"\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account] \n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID! \n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactCard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# graphql schema\n\n\n# defining entities\n\nthe schema.graphql file defines the various graphql schemas. due to the way that the graphql query language works, the schema file essentially dictates the shape of your data from subquery. to learn more about how to write in graphql schema language, we recommend checking out schemas and types.\n\nimportant: when you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# entities\n\neach entity must define its required fields id with the type of id!. it is used as the primary key and unique among all entities of the same type.\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field \n}\n\ntype title @entity {\n  id: id!  \n  name: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nwhen code generation is run, this will automatically create a getbyname under the user model, and the foreign key field title will create a getbytitleid method, which both can directly be accessed in the mapping function.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from \"../types/models/user\"\nimport {title} from \"../types/models/title\"\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account] \n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id! \n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactcard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/ko/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/create/introduction.html",relativePath:"ko/create/introduction.md",key:"v-64b91fd5",path:"/ko/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2327}],readingTime:{minutes:1.76,words:527},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/ko/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/create/manifest.html",relativePath:"ko/create/manifest.md",key:"v-6fbdffab",path:"/ko/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:1998},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3223},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4540}],readingTime:{minutes:2.51,words:752},headersStr:"Network Filters Mapping Filters Custom Chains",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - see Running an Indexer\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - see running an indexer\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/ko/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/create/mapping.html",relativePath:"ko/create/mapping.md",key:"v-3db0e5ad",path:"/ko/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3141},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4151},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5111},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5541},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6209},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5061},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6926},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10271},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11506},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11728}],readingTime:{minutes:6.93,words:2080},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from "@subql/types";\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n    // Create a new StarterEntity with the block hash as it\'s ID\n    const record = new starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from "ethers/lib/utils"; //Good way\nimport {utils} from "ethers" //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api.query.kitties.nextKittyId();\n    // return the Kitty type, input parameters types are AccountId and KittyIndex\n    const allKitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`Next kitty id ${nextKittyId}`)\n    //Custom rpc, set undefined to blockhash\n    const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined,nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from "@subql/types";\n\nexport async function handleblock(block: substrateblock): promise<void> {\n    // create a new starterentity with the block hash as it\'s id\n    const record = new starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from "ethers/lib/utils"; //good way\nimport {utils} from "ethers" //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api.query.kitties.nextkittyid();\n    // return the kitty type, input parameters types are accountid and kittyindex\n    const allkitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`next kitty id ${nextkittyid}`)\n    //custom rpc, set undefined to blockhash\n    const kittyprice = await api.rpc.kitties.getkittyprice(undefined,nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/ko/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/faqs/faqs.html",relativePath:"ko/faqs/faqs.md",key:"v-0484fad1",path:"/ko/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/ko/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/install/install.html",relativePath:"ko/install/install.md",key:"v-663e7921",path:"/ko/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/ko/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/miscellaneous/ambassadors.html",relativePath:"ko/miscellaneous/ambassadors.md",key:"v-223c74ad",path:"/ko/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/ko/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/miscellaneous/branding.html",relativePath:"ko/miscellaneous/branding.md",key:"v-846f9be6",path:"/ko/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/ko/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/miscellaneous/contributing.html",relativePath:"ko/miscellaneous/contributing.md",key:"v-3f016ca6",path:"/ko/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/ko/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/miscellaneous/social_media.html",relativePath:"ko/miscellaneous/social_media.md",key:"v-7687b4ad",path:"/ko/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/ko/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/publish/connect.html",relativePath:"ko/publish/connect.md",key:"v-779feb9b",path:"/ko/publish/connect/",readingTime:{minutes:.61,words:182},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/ko/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/publish/publish.html",relativePath:"ko/publish/publish.md",key:"v-65f10351",path:"/ko/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1133},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. *We're almost there! We just need to deploy a new version of it. *\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. *we're almost there! we just need to deploy a new version of it. *\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/ko/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/publish/upgrade.html",relativePath:"ko/publish/upgrade.md",key:"v-249d6937",path:"/ko/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/ko/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/query/graphql.html",relativePath:"ko/query/graphql.md",key:"v-b022432a",path:"/ko/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/ko/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/query/query.html",relativePath:"ko/query/query.md",key:"v-dc503226",path:"/ko/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/ko/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/quickstart/helloworld-hosted.html",relativePath:"ko/quickstart/helloworld-hosted.md",key:"v-166c1b0d",path:"/ko/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/ko/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/quickstart/helloworld-localhost.html",relativePath:"ko/quickstart/helloworld-localhost.md",key:"v-5c3bceef",path:"/ko/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"Step 1: Initialise project",slug:"step-1-initialise-project",normalizedTitle:"step 1: initialise project",charIndex:1455},{level:2,title:"Step 2: Install dependencies",slug:"step-2-install-dependencies",normalizedTitle:"step 2: install dependencies",charIndex:2035},{level:2,title:"Step 3: Generate code",slug:"step-3-generate-code",normalizedTitle:"step 3: generate code",charIndex:2477},{level:2,title:"Step 4: Build code",slug:"step-4-build-code",normalizedTitle:"step 4: build code",charIndex:3087},{level:2,title:"Step 5: Run Docker",slug:"step-5-run-docker",normalizedTitle:"step 5: run docker",charIndex:3319},{level:2,title:"Step 6: Browse playground",slug:"step-6-browse-playground",normalizedTitle:"step 6: browse playground",charIndex:4586},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:5027}],readingTime:{minutes:2.85,words:855},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Initialise project Step 2: Install dependencies Step 3: Generate code Step 4: Build code Step 5: Run Docker Step 6: Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Step 5: Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Step 6: Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# step 5: run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# step 6: browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/ko/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/quickstart/quickstart.html",relativePath:"ko/quickstart/quickstart.md",key:"v-2afe91d1",path:"/ko/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2566},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3009},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3388},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3628},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3981},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4548},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5235}],readingTime:{minutes:3.22,words:967},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/ko/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/quickstart/understanding-helloworld.html",relativePath:"ko/quickstart/understanding-helloworld.md",key:"v-45b45b2e",path:"/ko/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/ko/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/run/run.html",relativePath:"ko/run/run.md",key:"v-72bdcd61",path:"/ko/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3940},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4183}],readingTime:{minutes:2.57,words:772},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/ko/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/run/sandbox.html",relativePath:"ko/run/sandbox.md",key:"v-850bfe2e",path:"/ko/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/ko/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/tutorials_examples/howto.html",relativePath:"ko/tutorials_examples/howto.md",key:"v-8e6581a6",path:"/ko/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri",meta:[{property:"og:url",content:"/ko/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/tutorials_examples/introduction.html",relativePath:"ko/tutorials_examples/introduction.md",key:"v-4cc22903",path:"/ko/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:155}],readingTime:{minutes:.77,words:231},headersStr:"SubQuery Examples",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# SubQuery Examples\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# subquery examples\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/ko/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/tutorials_examples/terminology.html",relativePath:"ko/tutorials_examples/terminology.md",key:"v-215f842d",path:"/ko/tutorials_examples/terminology/",headers:[{level:2,title:"Terminology",slug:"terminology",normalizedTitle:"terminology",charIndex:2}],readingTime:{minutes:.49,words:147},headersStr:"Terminology",content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/miscellaneous/ambassadors.html",relativePath:"miscellaneous/ambassadors.md",key:"v-ae40a866",path:"/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/miscellaneous/branding.html",relativePath:"miscellaneous/branding.md",key:"v-a45391be",path:"/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/miscellaneous/contributing.html",relativePath:"miscellaneous/contributing.md",key:"v-6d299e43",path:"/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/miscellaneous/social_media.html",relativePath:"miscellaneous/social_media.md",key:"v-034044f3",path:"/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Connect to your new project",frontmatter:{summary:"Connect to your new project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/publish/connect.html"},{property:"og:title",content:"Connect to your new project"},{property:"og:description",content:"Connect to your new project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/publish/connect.html",relativePath:"publish/connect.md",key:"v-b6710da6",path:"/publish/connect/",readingTime:{minutes:.58,words:174},headersStr:null,content:"# Connect to your new project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Deploy a new version of your SubQuery project",frontmatter:{summary:"Deploy a new version of your SubQuery project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/publish/upgrade.html"},{property:"og:title",content:"Deploy a new version of your SubQuery project"},{property:"og:description",content:"Deploy a new version of your SubQuery project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/publish/upgrade.html",relativePath:"publish/upgrade.md",key:"v-5be2726d",path:"/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:2306}],readingTime:{minutes:1.69,words:506},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a new version of your SubQuery project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLog into SubQuery Project and select the project you want to deploy a new version of. You can choose to either deploy to the production or staging slot. These two slots are isolated environments and each has their own databases and synchronise independently.\n\nWe recommend deploying to your staging slot only for final staging testing or when you need to resync your project data. You can then promote it to production with zero downtime. You will find testing is faster when running a project locally as you can more easily debug issues.\n\nThe staging slot is perfect for:\n\n * Final validation of changes to your SubQuery Project in a separate environment. The staging slot has a different URL to production that you can use in your dApps.\n * Warming up and indexing data for an updated SubQuery project to eliminate downtime in your dApp\n * Preparing a new release for your SubQuery Project without exposing it publicly. The staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlog into subquery project and select the project you want to deploy a new version of. you can choose to either deploy to the production or staging slot. these two slots are isolated environments and each has their own databases and synchronise independently.\n\nwe recommend deploying to your staging slot only for final staging testing or when you need to resync your project data. you can then promote it to production with zero downtime. you will find testing is faster when running a project locally as you can more easily debug issues.\n\nthe staging slot is perfect for:\n\n * final validation of changes to your subquery project in a separate environment. the staging slot has a different url to production that you can use in your dapps.\n * warming up and indexing data for an updated subquery project to eliminate downtime in your dapp\n * preparing a new release for your subquery project without exposing it publicly. the staging slot is not shown to the public in the explorer and has a unique url that is visible only to you.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Publish your SubQuery project",frontmatter:{summary:"Publish your SubQuery project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery project"},{property:"og:description",content:"Publish your SubQuery project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/publish/publish.html",relativePath:"publish/publish.md",key:"v-529f2d66",path:"/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3805},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4260}],readingTime:{minutes:3.68,words:1105},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. We're almost there! We just need to deploy a new version of it.\n\n\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. we're almost there! we just need to deploy a new version of it.\n\n\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/query/graphql.html",relativePath:"query/graphql.md",key:"v-31c257a6",path:"/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/query/query.html",relativePath:"query/query.md",key:"v-ecedcbe6",path:"/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/quickstart/helloworld-hosted.html",relativePath:"quickstart/helloworld-hosted.md",key:"v-562bf2a5",path:"/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"1. Create your project",slug:"_1-create-your-project",normalizedTitle:"1. create your project",charIndex:1058},{level:2,title:"2. Create a GitHub repo",slug:"_2-create-a-github-repo",normalizedTitle:"2. create a github repo",charIndex:1349},{level:2,title:"3. Push to GitHub",slug:"_3-push-to-github",normalizedTitle:"3. push to github",charIndex:1602},{level:2,title:"4. Create your project",slug:"_4-create-your-project",normalizedTitle:"4. create your project",charIndex:3346},{level:2,title:"5. Deploy your project",slug:"_5-deploy-your-project",normalizedTitle:"5. deploy your project",charIndex:4559},{level:2,title:"6. Testing your project",slug:"_6-testing-your-project",normalizedTitle:"6. testing your project",charIndex:6068},{level:2,title:"7. Bonus step",slug:"_7-bonus-step",normalizedTitle:"7. bonus step",charIndex:6311},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7763}],readingTime:{minutes:4.66,words:1398},headersStr:"Learning objectives Intended audience Video guide Pre-requisites 1. Create your project 2. Create a GitHub repo 3. Push to GitHub 4. Create your project 5. Deploy your project 6. Testing your project 7. Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# 1. Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# 2. Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# 3. Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# 4. Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# 5. Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# 6. Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# 7. Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# 1. create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# 2. create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# 3. push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# 4. create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# 5. deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# 6. testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# 7. bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/quickstart/helloworld-localhost.html",relativePath:"quickstart/helloworld-localhost.md",key:"v-bc9cfe26",path:"/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"1. Initialise project",slug:"_1-initialise-project",normalizedTitle:"1. initialise project",charIndex:1455},{level:2,title:"2. Install dependencies",slug:"_2-install-dependencies",normalizedTitle:"2. install dependencies",charIndex:2030},{level:2,title:"3. Generate code",slug:"_3-generate-code",normalizedTitle:"3. generate code",charIndex:2451},{level:2,title:"4. Build code",slug:"_4-build-code",normalizedTitle:"4. build code",charIndex:3040},{level:2,title:"5. Run Docker",slug:"_5-run-docker",normalizedTitle:"5. run docker",charIndex:3251},{level:2,title:"6. Browse playground",slug:"_6-browse-playground",normalizedTitle:"6. browse playground",charIndex:4513},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:4949}],readingTime:{minutes:2.93,words:879},headersStr:"Learning objectives Intended audience Video guide Pre-requisites 1. Initialise project 2. Install dependencies 3. Generate code 4. Build code 5. Run Docker 6. Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# 1. Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# 2. Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\nyarn install\n\n\n1\n\n\nnpm install\n\n\n1\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 3. Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\nyarn codegen\n\n\n1\n\n\nnpm run-script codegen\n\n\n1\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# 4. Build code\n\nThe next step is to build the code with yarn build.\n\nyarn build\n\n\n1\n\n\nnpm run-script build\n\n\n1\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# 5. Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 6. Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# 1. initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# 2. install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\nyarn install\n\n\n1\n\n\nnpm install\n\n\n1\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 3. generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\nyarn codegen\n\n\n1\n\n\nnpm run-script codegen\n\n\n1\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# 4. build code\n\nthe next step is to build the code with yarn build.\n\nyarn build\n\n\n1\n\n\nnpm run-script build\n\n\n1\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# 5. run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 6. browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/quickstart/quickstart.html",relativePath:"quickstart/quickstart.md",key:"v-867568e6",path:"/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2565},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3008},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3371},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3595},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3948},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4515},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5202}],readingTime:{minutes:3.33,words:999},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\nyarn install\n\n\n1\n2\n\n\ncd PROJECT_NAME\nnpm install\n\n\n1\n2\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\nyarn codegen\n\n\n1\n\n\nnpm run-script codegen\n\n\n1\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\nyarn build\n\n\n1\n\n\nnpm run-script build\n\n\n1\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\nyarn install\n\n\n1\n2\n\n\ncd project_name\nnpm install\n\n\n1\n2\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\nyarn codegen\n\n\n1\n\n\nnpm run-script codegen\n\n\n1\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\nyarn build\n\n\n1\n\n\nnpm run-script build\n\n\n1\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/quickstart/understanding-helloworld.html",relativePath:"quickstart/understanding-helloworld.md",key:"v-d4874966",path:"/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Command Line Flags",frontmatter:{summary:"Command Line Flags subql-node --help This shows the help options. --version This displays the current version. -f, --subquery Use this flag to start the SubQuery project. --subquer",meta:[{property:"og:url",content:"/references/references.html"},{property:"og:title",content:"Command Line Flags"},{property:"og:description",content:"Command Line Flags subql-node --help This shows the help options. --version This displays the current version. -f, --subquery Use this flag to start the SubQuery project. --subquer"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/references/references.html",relativePath:"references/references.md",key:"v-b4ffb0e6",path:"/references/references/",headers:[{level:2,title:"subql-node",slug:"subql-node",normalizedTitle:"subql-node",charIndex:25},{level:3,title:"--help",slug:"help",normalizedTitle:"--help",charIndex:40},{level:3,title:"--version",slug:"version",normalizedTitle:"--version",charIndex:194},{level:3,title:"-f, --subquery",slug:"f-subquery",normalizedTitle:"-f, --subquery",charIndex:271},{level:3,title:"--subquery-name",slug:"subquery-name",normalizedTitle:"--subquery-name",charIndex:356},{level:3,title:"-c, --config",slug:"c-config",normalizedTitle:"-c, --config",charIndex:433},{level:3,title:"--local",slug:"local",normalizedTitle:"--local",charIndex:518},{level:3,title:"--batch-size",slug:"batch-size",normalizedTitle:"--batch-size",charIndex:599},{level:3,title:"--debug",slug:"debug",normalizedTitle:"--debug",charIndex:840},{level:3,title:"--profiler",slug:"profiler",normalizedTitle:"--profiler",charIndex:1058},{level:3,title:"--network-endpoint",slug:"network-endpoint",normalizedTitle:"--network-endpoint",charIndex:1211},{level:3,title:"--output-fmt",slug:"output-fmt",normalizedTitle:"--output-fmt",charIndex:1292},{level:3,title:"--log-level",slug:"log-level",normalizedTitle:"--log-level",charIndex:1433},{level:3,title:"--timestamp-field",slug:"timestamp-field",normalizedTitle:"--timestamp-field",charIndex:1864},{level:3,title:"-d, --network-dictionary",slug:"d-network-dictionary",normalizedTitle:"-d, --network-dictionary",charIndex:2020},{level:2,title:"subql-query",slug:"subql-query",normalizedTitle:"subql-query",charIndex:8991},{level:3,title:"--help",slug:"help-2",normalizedTitle:"--help",charIndex:40},{level:3,title:"--version",slug:"version-2",normalizedTitle:"--version",charIndex:194},{level:3,title:"-n, --name",slug:"n-name",normalizedTitle:"-n, --name",charIndex:9213},{level:3,title:"--playground",slug:"playground",normalizedTitle:"--playground",charIndex:9298},{level:3,title:"--output-fmt",slug:"output-fmt-2",normalizedTitle:"--output-fmt",charIndex:1292},{level:3,title:"--log-level",slug:"log-level-2",normalizedTitle:"--log-level",charIndex:1433}],readingTime:{minutes:4.82,words:1446},headersStr:"subql-node --help --version -f, --subquery --subquery-name -c, --config --local --batch-size --debug --profiler --network-endpoint --output-fmt --log-level --timestamp-field -d, --network-dictionary subql-query --help --version -n, --name --playground --output-fmt --log-level",content:'# Command Line Flags\n\n\n# subql-node\n\n\n# --help\n\nThis shows the help options.\n\n> subql-node --help\nOptions:\n      --help                Show help                                  [boolean]\n      --version             Show version number                        [boolean]\n  -f, --subquery            Local path of the subquery project          [string]\n      --subquery-name       Name of the subquery project                [string]\n  -c, --config              Specify configuration file                  [string]\n      --local               Use local mode                             [boolean]\n      --batch-size          Batch size of blocks to fetch in one round  [number]\n      --timeout             Timeout for indexer sandbox to execute the mapping\n                            functions                                   [number]\n      --debug               Show debug information to console output. will\n                            forcefully set log level to debug\n                                                      [boolean] [default: false]\n      --profiler            Show profiler information to console output\n                                                      [boolean] [default: false]\n      --network-endpoint    Blockchain network endpoint to connect      [string]\n      --output-fmt          Print log as json or plain text\n                                           [string] [choices: "json", "colored"]\n      --log-level           Specify log level to print. Ignored when --debug is\n                            used\n          [string] [choices: "fatal", "error", "warn", "info", "debug", "trace",\n                                                                       "silent"]\n      --migrate             Migrate db schema (for management tables only)\n                                                      [boolean] [default: false]\n      --timestamp-field     Enable/disable created_at and updated_at in schema\n                                                       [boolean] [default: true]\n  -d, --network-dictionary  Specify the dictionary api for this network [string]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n# --version\n\nThis displays the current version.\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# -f, --subquery\n\nUse this flag to start the SubQuery project.\n\nsubql-node -f . // OR\nsubql-node --subquery .\n\n\n1\n2\n\n\n\n# --subquery-name\n\nThis flag allows you to provide a name for your project which acts as if it creates an instance of your project. Upon providing a new name, a new database schema is created and block synchronisation starts from zero.\n\nsubql-node -f . --subquery-name=test2\n\n\n1\n\n\n\n# -c, --config\n\nAll these various configurations can be placed into a .yml or .json file and then referenced with the config flag.\n\nSample subquery_config.yml file:\n\nsubquery: . // Mandatory. This is the local path of the project. The period here means the current local directory.\nsubqueryName: hello // Optional name\nbatchSize: 55 // Optional config\n\n\n1\n2\n3\n\n\nPlace this file in the same directory as the project. Then in the current project directory, run:\n\n> subql-node -c ./subquery_config.yml\n\n\n1\n\n\n\n# --local\n\nThis flag is primarily used for debugging purposes where it creates the default starter_entity table in the default "postgres" schema.\n\nsubql-node -f . --local\n\n\n1\n\n\nNote that once you use this flag, removing it won\'t mean that it will point to another database. To repoint to another database you will have to create a NEW database and change the env settings to this new database. In other words, "export DB_DATABASE=<new_db_here>"\n\n\n# --batch-size\n\nThis flag allows you to set the batch size in the command line. If batch size is also set in the config file, this takes precedent.\n\n> subql-node -f . --batch-size=20\n2021-08-09T23:24:43.775Z <fetch> INFO fetch block [6601,6620], total 20 blocks \n2021-08-09T23:24:45.606Z <fetch> INFO fetch block [6621,6640], total 20 blocks \n2021-08-09T23:24:47.415Z <fetch> INFO fetch block [6641,6660], total 20 blocks \n2021-08-09T23:24:49.235Z <fetch> INFO fetch block [6661,6680], total 20 blocks \n\n\n1\n2\n3\n4\n5\n\n\n\n# --debug\n\nThis outputs debug information to the console output and forcefully sets the log level to debug.\n\n> subql-node -f . --debug\n2021-08-10T11:45:39.471Z <db> DEBUG Executing (1b0d0c23-d7c7-4adb-a703-e4e5c414e035): INSERT INTO "subquery_1"."starter_entities" ("id","block_height","created_at","updated_at") VALUES ($1,$2,$3,$4) ON CONFLICT ("id") DO UPDATE SET "id"=EXCLUDED."id","block_height"=EXCLUDED."block_height","updated_at"=EXCLUDED."updated_at" RETURNING "id","block_height","created_at","updated_at"; \n2021-08-10T11:45:39.472Z <db> DEBUG Executing (default): UPDATE "subqueries" SET "next_block_height"=$1,"updated_at"=$2 WHERE "id" = $3 \n2021-08-10T11:45:39.472Z <db> DEBUG Executing (1b0d0c23-d7c7-4adb-a703-e4e5c414e035): COMMIT; \n\n\n1\n2\n3\n4\n\n\n\n# --profiler\n\nThis shows profiler information.\n\nsubql-node -f . --local --profiler\n2021-08-10T10:57:07.234Z <profiler> INFO FetchService, fetchMeta, 3876 ms \n2021-08-10T10:57:08.095Z <profiler> INFO FetchService, fetchMeta, 774 ms \n2021-08-10T10:57:10.361Z <profiler> INFO SubstrateUtil, fetchBlocksBatches, 2265 ms \n2021-08-10T10:57:10.361Z <fetch> INFO fetch block [3801,3900], total 100 blocks \n\n\n1\n2\n3\n4\n5\n\n\n\n# --network-endpoint\n\nThis flag allows users to override the network endpoint configuration from the manifest file.\n\nsubql-node -f . --network-endpoint="wss://polkadot.api.onfinality.io/public-ws"\n\n\n1\n\n\nNote that this must also be set in the manifest file, otherwise you\'ll get:\n\nERROR Create Subquery project from given path failed! Error: failed to parse project.yaml.\nAn instance of ProjectManifestImpl has failed the validation:\n - property network has failed the following constraints: isObject \n - property network.network has failed the following constraints: nestedValidation \n\n\n1\n2\n3\n4\n\n\n\n# --output-fmt\n\nThere are two different terminal output formats. JSON or colored. Colored is the default and contains colored text.\n\n> subql-node -f . --output-fmt=json\n{"level":"info","timestamp":"2021-08-10T11:58:18.087Z","pid":24714,"hostname":"P.local","category":"fetch","message":"fetch block [10501,10600], total 100 blocks"}\n\n\n1\n2\n\n\n> subql-node -f . --output-fmt=colored\n2021-08-10T11:57:41.480Z <subql-node> INFO node started \n(node:24707) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n2021-08-10T11:57:48.981Z <fetch> INFO fetch block [10201,10300], total 100 blocks \n2021-08-10T11:57:51.862Z <fetch> INFO fetch block [10301,10400], total 100 blocks \n\n\n1\n2\n3\n4\n5\n\n\n\n# --log-level\n\nThere are 7 options to choose from. “fatal”, “error”, “warn”, “info”, “debug”, “trace”, “silent”. The example below shows silent. Nothing will be printed in the terminal so the only way to tell if the node is working or not is to query the database for row count (select count(*) from subquery_1.starter_entities) or query the block height.\n\n> subql-node -f . --log-level=silent\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [DEP0152] DeprecationWarning: Custom PerformanceEntry accessors are deprecated. Please use the detail property.\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# --timestamp-field\n\nBy default this is true. when set to false with:\n\n> subql-node -f . –timestamp-field=false\n\n\n1\n\n\nThis removes the created_at and updated_at columns in the starter_entities table.\n\n\n# -d, --network-dictionary\n\nThis allows you to specify a dictionary endpoint which is a free service that is provided and hosted at: https://explorer.subquery.network/ (search for dictionary) and presents an API endpoint of: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\nTypically this would be set in your manifest file but below shows an example of using it as an argument in the command line.\n\nsubql-node -f . -d "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\n\n1\n\n\nRead more about how a SubQuery Dictionary works.\n\n\n# subql-query\n\n\n# --help\n\nThis shows the help options.\n\nns:\n      --help        Show help                                          [boolean]\n      --version     Show version number                                [boolean]\n  -n, --name        project name                             [string] [required]\n      --playground  enable graphql playground                          [boolean]\n      --output-fmt  Print log as json or plain text\n                      [string] [choices: "json", "colored"] [default: "colored"]\n      --log-level   Specify log level to print.\n          [string] [choices: "fatal", "error", "warn", "info", "debug", "trace",\n                                                     "silent"] [default: "info"]\n      --indexer     Url that allow query to access indexer metadata     [string]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# --version\n\nThis displays the current version.\n\n> subql-query --version\n0.7.0\n\n\n1\n2\n\n\n\n# -n, --name\n\nThis flag is used to start the query service. If the --subquery-name flag is not provided when running an indexer, the name here will refer to the default project name. If --subquery-name is set, then the name here should match what was set.\n\n> subql-node -f . // --subquery-name not set\n\n> subql-query -n subql-helloworld  --playground // the name defaults to the project directory name\n\n\n1\n2\n3\n\n\n> subql-node -f . --subquery-name=hiworld // --subquery-name set\n\n> subql-query -n hiworld --playground  // the name points to the subql-helloworld project but with the name of hiworld\n\n\n1\n2\n3\n\n\n\n# --playground\n\nThis flag enables the graphql playground so should always be included by default to be of any use.\n\n\n# --output-fmt\n\nSee --output-fmt\n\n\n# --log-level\n\nSee --log-level',normalizedContent:'# command line flags\n\n\n# subql-node\n\n\n# --help\n\nthis shows the help options.\n\n> subql-node --help\noptions:\n      --help                show help                                  [boolean]\n      --version             show version number                        [boolean]\n  -f, --subquery            local path of the subquery project          [string]\n      --subquery-name       name of the subquery project                [string]\n  -c, --config              specify configuration file                  [string]\n      --local               use local mode                             [boolean]\n      --batch-size          batch size of blocks to fetch in one round  [number]\n      --timeout             timeout for indexer sandbox to execute the mapping\n                            functions                                   [number]\n      --debug               show debug information to console output. will\n                            forcefully set log level to debug\n                                                      [boolean] [default: false]\n      --profiler            show profiler information to console output\n                                                      [boolean] [default: false]\n      --network-endpoint    blockchain network endpoint to connect      [string]\n      --output-fmt          print log as json or plain text\n                                           [string] [choices: "json", "colored"]\n      --log-level           specify log level to print. ignored when --debug is\n                            used\n          [string] [choices: "fatal", "error", "warn", "info", "debug", "trace",\n                                                                       "silent"]\n      --migrate             migrate db schema (for management tables only)\n                                                      [boolean] [default: false]\n      --timestamp-field     enable/disable created_at and updated_at in schema\n                                                       [boolean] [default: true]\n  -d, --network-dictionary  specify the dictionary api for this network [string]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n# --version\n\nthis displays the current version.\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# -f, --subquery\n\nuse this flag to start the subquery project.\n\nsubql-node -f . // or\nsubql-node --subquery .\n\n\n1\n2\n\n\n\n# --subquery-name\n\nthis flag allows you to provide a name for your project which acts as if it creates an instance of your project. upon providing a new name, a new database schema is created and block synchronisation starts from zero.\n\nsubql-node -f . --subquery-name=test2\n\n\n1\n\n\n\n# -c, --config\n\nall these various configurations can be placed into a .yml or .json file and then referenced with the config flag.\n\nsample subquery_config.yml file:\n\nsubquery: . // mandatory. this is the local path of the project. the period here means the current local directory.\nsubqueryname: hello // optional name\nbatchsize: 55 // optional config\n\n\n1\n2\n3\n\n\nplace this file in the same directory as the project. then in the current project directory, run:\n\n> subql-node -c ./subquery_config.yml\n\n\n1\n\n\n\n# --local\n\nthis flag is primarily used for debugging purposes where it creates the default starter_entity table in the default "postgres" schema.\n\nsubql-node -f . --local\n\n\n1\n\n\nnote that once you use this flag, removing it won\'t mean that it will point to another database. to repoint to another database you will have to create a new database and change the env settings to this new database. in other words, "export db_database=<new_db_here>"\n\n\n# --batch-size\n\nthis flag allows you to set the batch size in the command line. if batch size is also set in the config file, this takes precedent.\n\n> subql-node -f . --batch-size=20\n2021-08-09t23:24:43.775z <fetch> info fetch block [6601,6620], total 20 blocks \n2021-08-09t23:24:45.606z <fetch> info fetch block [6621,6640], total 20 blocks \n2021-08-09t23:24:47.415z <fetch> info fetch block [6641,6660], total 20 blocks \n2021-08-09t23:24:49.235z <fetch> info fetch block [6661,6680], total 20 blocks \n\n\n1\n2\n3\n4\n5\n\n\n\n# --debug\n\nthis outputs debug information to the console output and forcefully sets the log level to debug.\n\n> subql-node -f . --debug\n2021-08-10t11:45:39.471z <db> debug executing (1b0d0c23-d7c7-4adb-a703-e4e5c414e035): insert into "subquery_1"."starter_entities" ("id","block_height","created_at","updated_at") values ($1,$2,$3,$4) on conflict ("id") do update set "id"=excluded."id","block_height"=excluded."block_height","updated_at"=excluded."updated_at" returning "id","block_height","created_at","updated_at"; \n2021-08-10t11:45:39.472z <db> debug executing (default): update "subqueries" set "next_block_height"=$1,"updated_at"=$2 where "id" = $3 \n2021-08-10t11:45:39.472z <db> debug executing (1b0d0c23-d7c7-4adb-a703-e4e5c414e035): commit; \n\n\n1\n2\n3\n4\n\n\n\n# --profiler\n\nthis shows profiler information.\n\nsubql-node -f . --local --profiler\n2021-08-10t10:57:07.234z <profiler> info fetchservice, fetchmeta, 3876 ms \n2021-08-10t10:57:08.095z <profiler> info fetchservice, fetchmeta, 774 ms \n2021-08-10t10:57:10.361z <profiler> info substrateutil, fetchblocksbatches, 2265 ms \n2021-08-10t10:57:10.361z <fetch> info fetch block [3801,3900], total 100 blocks \n\n\n1\n2\n3\n4\n5\n\n\n\n# --network-endpoint\n\nthis flag allows users to override the network endpoint configuration from the manifest file.\n\nsubql-node -f . --network-endpoint="wss://polkadot.api.onfinality.io/public-ws"\n\n\n1\n\n\nnote that this must also be set in the manifest file, otherwise you\'ll get:\n\nerror create subquery project from given path failed! error: failed to parse project.yaml.\nan instance of projectmanifestimpl has failed the validation:\n - property network has failed the following constraints: isobject \n - property network.network has failed the following constraints: nestedvalidation \n\n\n1\n2\n3\n4\n\n\n\n# --output-fmt\n\nthere are two different terminal output formats. json or colored. colored is the default and contains colored text.\n\n> subql-node -f . --output-fmt=json\n{"level":"info","timestamp":"2021-08-10t11:58:18.087z","pid":24714,"hostname":"p.local","category":"fetch","message":"fetch block [10501,10600], total 100 blocks"}\n\n\n1\n2\n\n\n> subql-node -f . --output-fmt=colored\n2021-08-10t11:57:41.480z <subql-node> info node started \n(node:24707) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n2021-08-10t11:57:48.981z <fetch> info fetch block [10201,10300], total 100 blocks \n2021-08-10t11:57:51.862z <fetch> info fetch block [10301,10400], total 100 blocks \n\n\n1\n2\n3\n4\n5\n\n\n\n# --log-level\n\nthere are 7 options to choose from. “fatal”, “error”, “warn”, “info”, “debug”, “trace”, “silent”. the example below shows silent. nothing will be printed in the terminal so the only way to tell if the node is working or not is to query the database for row count (select count(*) from subquery_1.starter_entities) or query the block height.\n\n> subql-node -f . --log-level=silent\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(use `node --trace-warnings ...` to show where the warning was created)\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [dep0152] deprecationwarning: custom performanceentry accessors are deprecated. please use the detail property.\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# --timestamp-field\n\nby default this is true. when set to false with:\n\n> subql-node -f . –timestamp-field=false\n\n\n1\n\n\nthis removes the created_at and updated_at columns in the starter_entities table.\n\n\n# -d, --network-dictionary\n\nthis allows you to specify a dictionary endpoint which is a free service that is provided and hosted at: https://explorer.subquery.network/ (search for dictionary) and presents an api endpoint of: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\ntypically this would be set in your manifest file but below shows an example of using it as an argument in the command line.\n\nsubql-node -f . -d "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\n\n1\n\n\nread more about how a subquery dictionary works.\n\n\n# subql-query\n\n\n# --help\n\nthis shows the help options.\n\nns:\n      --help        show help                                          [boolean]\n      --version     show version number                                [boolean]\n  -n, --name        project name                             [string] [required]\n      --playground  enable graphql playground                          [boolean]\n      --output-fmt  print log as json or plain text\n                      [string] [choices: "json", "colored"] [default: "colored"]\n      --log-level   specify log level to print.\n          [string] [choices: "fatal", "error", "warn", "info", "debug", "trace",\n                                                     "silent"] [default: "info"]\n      --indexer     url that allow query to access indexer metadata     [string]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# --version\n\nthis displays the current version.\n\n> subql-query --version\n0.7.0\n\n\n1\n2\n\n\n\n# -n, --name\n\nthis flag is used to start the query service. if the --subquery-name flag is not provided when running an indexer, the name here will refer to the default project name. if --subquery-name is set, then the name here should match what was set.\n\n> subql-node -f . // --subquery-name not set\n\n> subql-query -n subql-helloworld  --playground // the name defaults to the project directory name\n\n\n1\n2\n3\n\n\n> subql-node -f . --subquery-name=hiworld // --subquery-name set\n\n> subql-query -n hiworld --playground  // the name points to the subql-helloworld project but with the name of hiworld\n\n\n1\n2\n3\n\n\n\n# --playground\n\nthis flag enables the graphql playground so should always be included by default to be of any use.\n\n\n# --output-fmt\n\nsee --output-fmt\n\n\n# --log-level\n\nsee --log-level',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{frontmatter:{summary:"Добро пожаловать в SubQuery’s Docs Изучите и преобразуйте свои ончейн данные, чтобы быстрее создавать интуитивно понятные приложения! Быстрый старт руководства Понимайте SubQuery, ",meta:[{property:"og:url",content:"/ru/"},{property:"og:description",content:"Добро пожаловать в SubQuery’s Docs Изучите и преобразуйте свои ончейн данные, чтобы быстрее создавать интуитивно понятные приложения! Быстрый старт руководства Понимайте SubQuery, "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/",relativePath:"ru/README.md",key:"v-3bb71ffe",path:"/ru/",readingTime:{minutes:1.73,words:519},headersStr:null,content:"Добро пожаловать в SubQuery’s Docs\n\nИзучите и преобразуйте свои ончейн данные, чтобы быстрее создавать интуитивно понятные приложения!\n\n\nБыстрый старт руководства\n\nПонимайте SubQuery, используя традиционный пример Hello World. Использование шаблона проекта с помощью Докера , вы можете быстро запустить узел и начать искать данные в блокчейне всего за несколько минут с помощью нескольких простых команд.\n\nНачать работу\n * Учебные материалы и примеры\n   \n   Обучение, делая. Учебники и примеры по созданию различных проектов SubQuery.\n\n * Технические документы\n   \n   Написанные разработчиками для разработчиков. Найдите то, что нужно для быстрого создания приложений.\n\n * The SubQuery Network\n   \n   Децентрализованное будущее SubQuery. Подробнее о вознаграждении индексаторов и потребителей.\n\n\nFAQ\n\n * Что такое SubQuery?\n   \n   SubQuery - это проект с открытым исходным кодом, который позволяет разработчикам индексировать, преобразовывать и запрашивать данные блокчейна Substrate для своих приложений.\n   \n   ПРОЧИТАЙТЕ ЕЩЕ\n * Какой лучший способ начать работу с SubQuery?\n   \n   Лучший способ начать работу с SubQuery - попробовать наш урок «Приветствуем мир». Это простая 5-минутка по скачиванию стартового шаблона, созданию проекта, а затем запуска узла на локальном хосте и выполнения простого запроса с помощью Docker.\n\n * Как я могу внести свой вклад или оставить отзыв на SubQuery?\n   \n   Мы любим вносить свой вклад и получать обратную связь от сообщества. Чтобы дополнить код, форкните репозиторий интересов и внесите изменения. Затем отправьте PR или Pull Request. Кстати, не забудьте проверить! Также ознакомьтесь с нашими рекомендациями внесению дополнений (скоро).\n   \n   ПРОЧИТАЙТЕ ЕЩЕ\n * Сколько стоит разместить мой проект в SubQuery?\n   \n   Размещение вашего проекта в SubQuery Projects абсолютно бесплатно - это наш способ вернуть сообщество в будущем. Чтобы научиться размещать ваш проект вместе с нами, ознакомьтесь с обучением Hello World (SubQuery Hosted).\n   \n   Организуйте ваш проект\n\n\nДля получения ответов на часто задаваемые вопросы пожалуйста, посмотрите наш FAQ.\n\nИнтеграция с вашей собственной цепочкой?\n\nСоздаете ли вы новый парачейн или совершенно новый блокчейн в Substrate - SubQuery может помочь вам индексировать и диагностировать данные цепочки. SubQuery разработан для того, чтобы легко интегрироваться с пользовательской цепочкой Substrate.\n\nУЗНАЙТЕ КАК ИНТЕГРИРОВАТЬ ВАШУ ЦЕПОЧКУ ДАННЫХ\n\nПоддержка и содействие\n\nУ Вас есть вопрос или интересно узнать больше или как Вы можете помочь? Мы будем рады услышать от вас. Пожалуйста, свяжитесь с нами по электронной почте или через социальные сети по ссылкам ниже. Нужна техническая экспертиза? Присоединяйтесь к нашему сообществу Discord и получите поддержку от наших членов сообщества.\n\nПРИСОЕДИНЯЙТЕСЬ К ОБСУЖДЕНИЮ В ДИСКОРДЕ\nСвяжитесь с нами hello@subquery.network\nПодпишитесь на нас в социальных сетях\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"добро пожаловать в subquery’s docs\n\nизучите и преобразуите свои ончеин данные, чтобы быстрее создавать интуитивно понятные приложения!\n\n\nбыстрыи старт руководства\n\nпонимаите subquery, используя традиционныи пример hello world. использование шаблона проекта с помощью докера , вы можете быстро запустить узел и начать искать данные в блокчеине всего за несколько минут с помощью нескольких простых команд.\n\nначать работу\n * учебные материалы и примеры\n   \n   обучение, делая. учебники и примеры по созданию различных проектов subquery.\n\n * технические документы\n   \n   написанные разработчиками для разработчиков. наидите то, что нужно для быстрого создания приложении.\n\n * the subquery network\n   \n   децентрализованное будущее subquery. подробнее о вознаграждении индексаторов и потребителеи.\n\n\nfaq\n\n * что такое subquery?\n   \n   subquery - это проект с открытым исходным кодом, которыи позволяет разработчикам индексировать, преобразовывать и запрашивать данные блокчеина substrate для своих приложении.\n   \n   прочитаите еще\n * какои лучшии способ начать работу с subquery?\n   \n   лучшии способ начать работу с subquery - попробовать наш урок «приветствуем мир». это простая 5-минутка по скачиванию стартового шаблона, созданию проекта, а затем запуска узла на локальном хосте и выполнения простого запроса с помощью docker.\n\n * как я могу внести свои вклад или оставить отзыв на subquery?\n   \n   мы любим вносить свои вклад и получать обратную связь от сообщества. чтобы дополнить код, форкните репозитории интересов и внесите изменения. затем отправьте pr или pull request. кстати, не забудьте проверить! также ознакомьтесь с нашими рекомендациями внесению дополнении (скоро).\n   \n   прочитаите еще\n * сколько стоит разместить мои проект в subquery?\n   \n   размещение вашего проекта в subquery projects абсолютно бесплатно - это наш способ вернуть сообщество в будущем. чтобы научиться размещать ваш проект вместе с нами, ознакомьтесь с обучением hello world (subquery hosted).\n   \n   организуите ваш проект\n\n\nдля получения ответов на часто задаваемые вопросы пожалуиста, посмотрите наш faq.\n\nинтеграция с вашеи собственнои цепочкои?\n\nсоздаете ли вы новыи парачеин или совершенно новыи блокчеин в substrate - subquery может помочь вам индексировать и диагностировать данные цепочки. subquery разработан для того, чтобы легко интегрироваться с пользовательскои цепочкои substrate.\n\nузнаите как интегрировать вашу цепочку данных\n\nподдержка и содеиствие\n\nу вас есть вопрос или интересно узнать больше или как вы можете помочь? мы будем рады услышать от вас. пожалуиста, свяжитесь с нами по электроннои почте или через социальные сети по ссылкам ниже. нужна техническая экспертиза? присоединяитесь к нашему сообществу discord и получите поддержку от наших членов сообщества.\n\nприсоединяитесь к обсуждению в дискорде\nсвяжитесь с нами hello@subquery.network\nподпишитесь на нас в социальных сетях\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{cyrillic:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Схема GraphQL",frontmatter:{summary:"Схема GraphQL Определение объектов Файл schema.graphql определяет различные схемы GraphQL. Из-за того, как работает язык запросов GraphQL, схема файлов по сути диктует форму ваших ",meta:[{property:"og:url",content:"/ru/create/graphql.html"},{property:"og:title",content:"Схема GraphQL"},{property:"og:description",content:"Схема GraphQL Определение объектов Файл schema.graphql определяет различные схемы GraphQL. Из-за того, как работает язык запросов GraphQL, схема файлов по сути диктует форму ваших "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/create/graphql.html",relativePath:"ru/create/graphql.md",key:"v-1b3677a6",path:"/ru/create/graphql/",headers:[{level:2,title:"Определение объектов",slug:"определение-объектов",normalizedTitle:"определение объектов",charIndex:20},{level:3,title:"Сущности",slug:"сущности",normalizedTitle:"сущности",charIndex:449},{level:3,title:"Поддерживаемые скаляры и типы",slug:"поддерживаемые-скаляры-и-типы",normalizedTitle:"поддерживаемые скаляры и типы",charIndex:953},{level:2,title:"Индексирование с помощью не первичного ключа",slug:"индексирование-с-помощью-не-первичного-ключа",normalizedTitle:"индексирование с помощью не первичного ключа",charIndex:1341},{level:2,title:"Связи субъектов",slug:"связи-субъектов",normalizedTitle:"связи субъектов",charIndex:3166},{level:3,title:"Индивидуальные отношения",slug:"индивидуальные-отношения",normalizedTitle:"индивидуальные отношения",charIndex:3467},{level:3,title:"Отношения от одного до нескольких",slug:"отношения-от-одного-до-нескольких",normalizedTitle:"отношения от одного до нескольких",charIndex:3965},{level:3,title:'Отношения "многие ко многим"',slug:"отношения-многие-ко-многим",normalizedTitle:"отношения &quot;многие ко многим&quot;",charIndex:null},{level:3,title:"Обратные запросы",slug:"обратные-запросы",normalizedTitle:"обратные запросы",charIndex:5338},{level:2,title:"Тип JSON",slug:"тип-json",normalizedTitle:"тип json",charIndex:6037},{level:3,title:"Определить директиву JSON",slug:"определить-директиву-json",normalizedTitle:"определить директиву json",charIndex:6736},{level:3,title:"Запрос полей JSON",slug:"запрос-полеи-json",normalizedTitle:"запрос полеи json",charIndex:7431}],readingTime:{minutes:.91,words:272},headersStr:'Определение объектов Сущности Поддерживаемые скаляры и типы Индексирование с помощью не первичного ключа Связи субъектов Индивидуальные отношения Отношения от одного до нескольких Отношения "многие ко многим" Обратные запросы Тип JSON Определить директиву JSON Запрос полей JSON',content:"# Схема GraphQL\n\n\n# Определение объектов\n\nФайл schema.graphql определяет различные схемы GraphQL. Из-за того, как работает язык запросов GraphQL, схема файлов по сути диктует форму ваших данных из SubQuery. Чтобы узнать больше о том, как писать в GraphQL-языке мы рекомендуем проверить Schemas and Type.\n\nВажно: При внесении каких-либо изменений в файл, убедитесь, что вы регенерируете директорию типов, используя следующую команду yarn codegen\n\n\n# Сущности\n\nКаждая сущность должна определить свои требуемые поля id с типом ID!. Он используется в качестве первичного ключа и уникален между всеми сущностями одного типа.\n\nПоля, не допускающие значения NULL, в сущности обозначены !. Пожалуйста, смотрите пример ниже:\n\nнапечатайте Пример @entity {\n  id: ID! поле # id всегда необходимо заполнять и оно должно выглядеть следующим образом\n  name: String! # Это обязательное поле для заполнения\n  address: String # Это необязательное поле\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Поддерживаемые скаляры и типы\n\nВ настоящее время мы поддерживаем следующие скалярные типы:\n\n * ID\n * Int\n * Строка\n * BigInt\n * Дата\n * Логический\n * <EntityName> для вложенных сущностей связей вы можете использовать определенное имя сущности в качестве одного из полей. Пожалуйста, смотрите в Entity Relationships.\n * JSON может также хранить структурированные данные, см. JSON type\n\n\n# Индексирование с помощью не первичного ключа\n\nЧтобы улучшить производительность поисковых запросов, индексируйте выбранные области просто внедрив аннотацию @index в поле непервичного ключа.\n\nТем не менее, мы не позволяем пользователям добавлять аннотации @index к любому объекту JSON. По умолчанию, индексы автоматически добавляются к внешним ключам и для полей JSON в базе данных, но только для повышения производительности службы запросов.\n\nВот пример.\n\nтип пользователя @entity {\n  id: ID!\n  имя: String! @index(unique: true) # уникальное может быть установлено в true или false\n  title: Title! # Индексы автоматически добавляются в поле внешнего ключа \n}\n\nтип Title @entity {\n  id: ID!  \n  имя: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nПредполагая, что мы знали имя этого пользователя, но мы не знаем его точное значение id, вместо того, чтобы извлекать всех пользователей, а затем фильтровать их по имени, мы можем добавить @index за полем имени. Это делает поиск гораздо более быстрее, и мы можем дополнительно пройти unique: true для обеспечения уникальности.\n\nЕсли поле не уникальное, то максимальный размер набора результатов равен 100\n\nКогда выполняется генерация кода, автоматически создастся getByName в соответствии с моделью User , и внешний ключ title создаст метод `getByTitleId</0>, к которым оба могут быть напрямую доступны в функции сопоставления.\n\n\n\n/* Подготовить запись заголовка */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n`\n\n// Обработчик в функции сопоставления\nimport {User} from \"../types/models/User\"\nimport {Title} from \"../types/models/Title\"\n\nconst jack = await User. etByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // Список всех капитанов\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Связи субъектов\n\nСущность часто имеет вложенные отношения с другими субъектами. Установка значения поля на другое имя объекта определит связь между этими двумя объектами по умолчанию.\n\nРазличные отношения объектов (один-на-один, и многие) могут быть настроены с помощью приведенных ниже примеров.\n\n\n# Индивидуальные отношения\n\nОтношения «один к одному» используются по умолчанию, когда только один объект сопоставляется с другим.\n\nПример: паспорт будет принадлежать только одному человеку, и у человека есть только один паспорт (в данном примере):\n\nтип Person @entity {\n  id: ID!\n}\n\nтип Passport @entity {\n  id: ID!\n  владелец: Человек!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nили\n\nтип Person @entity {\n  id: ID!\n  паспорт: Passport!\n}\n\nтип Passport @entity {\n  id: ID!\n  владелец: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Отношения от одного до нескольких\n\nВы можете использовать квадратные скобки, чтобы указать, что тип поля включает несколько сущностей.\n\nПример: Человек может иметь несколько учетных записей.\n\nтип Person @entity {\n  id: ID!\n  аккаунты: [Account] \n}\n\nтип аккаунта @entity {\n  id: ID!\n  публичный адрес: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Отношения \"многие ко многим\"\n\nОтношения «многие ко многим» могут быть достигнуты путем реализации объекта сопоставления для соединения двух других объектов.\n\nПример: каждый человек является частью нескольких групп (PersonGroup), а в группах есть несколько разных людей (PersonGroup).\n\nтип Person @entity {\n  id: ID!\n  имя: String!\n  группы: [PersonGroup]\n}\n\nтип PersonGroup @entity {\n  id: ID!\n  человек: Person!\n  Группа: Group!\n}\n\nтип Group @entity {\n  id: ID!\n  имя: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nКроме того, можно создать соединение одной и той же сущности в нескольких полях средней сущности.\n\nНапример, учетная запись может иметь несколько переводов, и каждая передача имеет исходную и целевую учетные записи.\n\nЭто установит двусторонние отношения между двумя аккаунтами (от и до) через таблицу передачи.\n\nтип Account @entity {\n  id: ID!\n  публичный адрес: String!\n}\n\nтип Transfer @entity {\n  id: ID!\n  сумма: BigInt\n  от: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Обратные запросы\n\nЧтобы разрешить обратный поиск объекта в отношении, присоедините @dehibitedFrom к полю и укажите на его поле обратного просмотра другого объекта.\n\nЭто создает виртуальное поле на объекте, который может быть запрошен.\n\nПередача «от» учетной записи доступна из объекта аккаунта путем установки значения sentTransfer или receiveTransfer, полученного из соответствующих полей from или to.\n\nтип Account @entity {\n  id: ID!\n  публичный адрес: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  сумма: BigInt\n  от: Account!\n  от: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Тип JSON\n\nМы поддерживаем сохранение данных в формате JSON, что является быстрым способом хранения структурированных данных. Мы автоматически сгенерируем соответствующие интерфейсы JSON для запроса данных и сэкономим время для определения и управления сущностями.\n\nМы рекомендуем пользователям использовать тип JSON в следующих сценариях:\n\n * Хранение структурированных данных в одном поле более управляемо, чем создание нескольких отдельных сущностей.\n * Сохранение произвольных пользовательских настроек ключа / значения (где значение может быть логическим, текстовым или числовым, и вы не хотите иметь отдельные столбцы для разных типов данных)\n * Схема является волатильной и часто меняется\n\n\n# Определить директиву JSON\n\nОпределите свойство как тип JSON файла, добавив аннотацию jsonField в объекте. Это автоматически создаст интерфейсы для всех JSON объектов в вашем проекте в types/interfaces.ts, и вы можете получить доступ к ним в функции сопоставления.\n\nВ отличие от объекта, директивный jsonField объект не требует поля id. Объект JSON также способен соединиться с другими объектами JSON.\n\nтип AddressDetail @jsonField {\n  улица: String!\n  округ: String!\n}\n\nвведите ContactCard @jsonField {\n  телефон: String!\n  адрес: AddressDetail # Вложенный JSON\n}\n\nтип User @entity {\n  id: ID! \n  контакт: [ContactCard] # Сохраните список JSON объектов\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Запрос полей JSON\n\nНедостатком использования файлов типа JSON является слабое влияние на эффективность запроса при фильтрации, поскольку каждый раз, когда выполняется текстовый поиск, он выполняется по всему объекту.\n\nТем не менее, влияние на нашу работу по поисковым запросам все еще приемлемо. Вот пример того, как использовать contains оператора в запросе GraphQL на JSON файл, чтобы найти пять первых пользователей, у которых есть номер телефона, содержащий '0064'.\n\n#Чтобы найти первых 5 пользователей телефоны которых содержат '0064'.\n\nquery{\n  пользователь (\n    первый: 5,\n    filter: {\n      contactCard: {\n        содержит : [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# схема graphql\n\n\n# определение объектов\n\nфаил schema.graphql определяет различные схемы graphql. из-за того, как работает язык запросов graphql, схема фаилов по сути диктует форму ваших данных из subquery. чтобы узнать больше о том, как писать в graphql-языке мы рекомендуем проверить schemas and type.\n\nважно: при внесении каких-либо изменении в фаил, убедитесь, что вы регенерируете директорию типов, используя следующую команду yarn codegen\n\n\n# сущности\n\nкаждая сущность должна определить свои требуемые поля id с типом id!. он используется в качестве первичного ключа и уникален между всеми сущностями одного типа.\n\nполя, не допускающие значения null, в сущности обозначены !. пожалуиста, смотрите пример ниже:\n\nнапечатаите пример @entity {\n  id: id! поле # id всегда необходимо заполнять и оно должно выглядеть следующим образом\n  name: string! # это обязательное поле для заполнения\n  address: string # это необязательное поле\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# поддерживаемые скаляры и типы\n\nв настоящее время мы поддерживаем следующие скалярные типы:\n\n * id\n * int\n * строка\n * bigint\n * дата\n * логическии\n * <entityname> для вложенных сущностеи связеи вы можете использовать определенное имя сущности в качестве одного из полеи. пожалуиста, смотрите в entity relationships.\n * json может также хранить структурированные данные, см. json type\n\n\n# индексирование с помощью не первичного ключа\n\nчтобы улучшить производительность поисковых запросов, индексируите выбранные области просто внедрив аннотацию @index в поле непервичного ключа.\n\nтем не менее, мы не позволяем пользователям добавлять аннотации @index к любому объекту json. по умолчанию, индексы автоматически добавляются к внешним ключам и для полеи json в базе данных, но только для повышения производительности службы запросов.\n\nвот пример.\n\nтип пользователя @entity {\n  id: id!\n  имя: string! @index(unique: true) # уникальное может быть установлено в true или false\n  title: title! # индексы автоматически добавляются в поле внешнего ключа \n}\n\nтип title @entity {\n  id: id!  \n  имя: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nпредполагая, что мы знали имя этого пользователя, но мы не знаем его точное значение id, вместо того, чтобы извлекать всех пользователеи, а затем фильтровать их по имени, мы можем добавить @index за полем имени. это делает поиск гораздо более быстрее, и мы можем дополнительно проити unique: true для обеспечения уникальности.\n\nесли поле не уникальное, то максимальныи размер набора результатов равен 100\n\nкогда выполняется генерация кода, автоматически создастся getbyname в соответствии с моделью user , и внешнии ключ title создаст метод `getbytitleid</0>, к которым оба могут быть напрямую доступны в функции сопоставления.\n\n\n\n/* подготовить запись заголовка */\ninsert into titles (id, name) values ('id_1', 'captain')\n`\n\n// обработчик в функции сопоставления\nimport {user} from \"../types/models/user\"\nimport {title} from \"../types/models/title\"\n\nconst jack = await user. etbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // список всех капитанов\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# связи субъектов\n\nсущность часто имеет вложенные отношения с другими субъектами. установка значения поля на другое имя объекта определит связь между этими двумя объектами по умолчанию.\n\nразличные отношения объектов (один-на-один, и многие) могут быть настроены с помощью приведенных ниже примеров.\n\n\n# индивидуальные отношения\n\nотношения «один к одному» используются по умолчанию, когда только один объект сопоставляется с другим.\n\nпример: паспорт будет принадлежать только одному человеку, и у человека есть только один паспорт (в данном примере):\n\nтип person @entity {\n  id: id!\n}\n\nтип passport @entity {\n  id: id!\n  владелец: человек!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nили\n\nтип person @entity {\n  id: id!\n  паспорт: passport!\n}\n\nтип passport @entity {\n  id: id!\n  владелец: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# отношения от одного до нескольких\n\nвы можете использовать квадратные скобки, чтобы указать, что тип поля включает несколько сущностеи.\n\nпример: человек может иметь несколько учетных записеи.\n\nтип person @entity {\n  id: id!\n  аккаунты: [account] \n}\n\nтип аккаунта @entity {\n  id: id!\n  публичныи адрес: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# отношения \"многие ко многим\"\n\nотношения «многие ко многим» могут быть достигнуты путем реализации объекта сопоставления для соединения двух других объектов.\n\nпример: каждыи человек является частью нескольких групп (persongroup), а в группах есть несколько разных людеи (persongroup).\n\nтип person @entity {\n  id: id!\n  имя: string!\n  группы: [persongroup]\n}\n\nтип persongroup @entity {\n  id: id!\n  человек: person!\n  группа: group!\n}\n\nтип group @entity {\n  id: id!\n  имя: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nкроме того, можно создать соединение однои и тои же сущности в нескольких полях среднеи сущности.\n\nнапример, учетная запись может иметь несколько переводов, и каждая передача имеет исходную и целевую учетные записи.\n\nэто установит двусторонние отношения между двумя аккаунтами (от и до) через таблицу передачи.\n\nтип account @entity {\n  id: id!\n  публичныи адрес: string!\n}\n\nтип transfer @entity {\n  id: id!\n  сумма: bigint\n  от: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# обратные запросы\n\nчтобы разрешить обратныи поиск объекта в отношении, присоедините @dehibitedfrom к полю и укажите на его поле обратного просмотра другого объекта.\n\nэто создает виртуальное поле на объекте, которыи может быть запрошен.\n\nпередача «от» учетнои записи доступна из объекта аккаунта путем установки значения senttransfer или receivetransfer, полученного из соответствующих полеи from или to.\n\nтип account @entity {\n  id: id!\n  публичныи адрес: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  сумма: bigint\n  от: account!\n  от: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# тип json\n\nмы поддерживаем сохранение данных в формате json, что является быстрым способом хранения структурированных данных. мы автоматически сгенерируем соответствующие интерфеисы json для запроса данных и сэкономим время для определения и управления сущностями.\n\nмы рекомендуем пользователям использовать тип json в следующих сценариях:\n\n * хранение структурированных данных в одном поле более управляемо, чем создание нескольких отдельных сущностеи.\n * сохранение произвольных пользовательских настроек ключа / значения (где значение может быть логическим, текстовым или числовым, и вы не хотите иметь отдельные столбцы для разных типов данных)\n * схема является волатильнои и часто меняется\n\n\n# определить директиву json\n\nопределите своиство как тип json фаила, добавив аннотацию jsonfield в объекте. это автоматически создаст интерфеисы для всех json объектов в вашем проекте в types/interfaces.ts, и вы можете получить доступ к ним в функции сопоставления.\n\nв отличие от объекта, директивныи jsonfield объект не требует поля id. объект json также способен соединиться с другими объектами json.\n\nтип addressdetail @jsonfield {\n  улица: string!\n  округ: string!\n}\n\nвведите contactcard @jsonfield {\n  телефон: string!\n  адрес: addressdetail # вложенныи json\n}\n\nтип user @entity {\n  id: id! \n  контакт: [contactcard] # сохраните список json объектов\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# запрос полеи json\n\nнедостатком использования фаилов типа json является слабое влияние на эффективность запроса при фильтрации, поскольку каждыи раз, когда выполняется текстовыи поиск, он выполняется по всему объекту.\n\nтем не менее, влияние на нашу работу по поисковым запросам все еще приемлемо. вот пример того, как использовать contains оператора в запросе graphql на json фаил, чтобы наити пять первых пользователеи, у которых есть номер телефона, содержащии '0064'.\n\n#чтобы наити первых 5 пользователеи телефоны которых содержат '0064'.\n\nquery{\n  пользователь (\n    первыи: 5,\n    filter: {\n      contactcard: {\n        содержит : [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{cyrillic:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Создание SubQuery проекта",frontmatter:{summary:"Создание SubQuery проекта In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look a",meta:[{property:"og:url",content:"/ru/create/introduction.html"},{property:"og:title",content:"Создание SubQuery проекта"},{property:"og:description",content:"Создание SubQuery проекта In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look a"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/create/introduction.html",relativePath:"ru/create/introduction.md",key:"v-1e91fed2",path:"/ru/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:271},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1241},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1634},{level:2,title:"Сборка",slug:"сборка",normalizedTitle:"сборка",charIndex:2095},{level:2,title:"Ведение журнала",slug:"ведение-журнала",normalizedTitle:"ведение журнала",charIndex:2333}],readingTime:{minutes:1.63,words:489},headersStr:"The Basic Workflow Directory Structure Code Generation Сборка Ведение журнала",content:"# Создание SubQuery проекта\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Инициализируйте ваш проект с помощью subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Сборка\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Ведение журнала\n\nМетод console.log больше не поддерживается. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nЧтобы использовать logger.info или logger.warn, просто поместите строку в файл сопоставления.\n\n\n\nДля использования logger.debugтребуется дополнительный шаг. Добавьте --log-level=debug в вашу командную строку.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# создание subquery проекта\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. инициализируите ваш проект с помощью subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# сборка\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# ведение журнала\n\nметод console.log больше не поддерживается. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nчтобы использовать logger.info или logger.warn, просто поместите строку в фаил сопоставления.\n\n\n\nдля использования logger.debugтребуется дополнительныи шаг. добавьте --log-level=debug в вашу командную строку.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{cyrillic:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/ru/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/create/manifest.html",relativePath:"ru/create/manifest.md",key:"v-6a2b59ed",path:"/ru/create/manifest/",headers:[{level:2,title:"Сетевые Фильтры",slug:"сетевые-фильтры",normalizedTitle:"сетевые фильтры",charIndex:2034},{level:2,title:"Фильтры сопоставления",slug:"фильтры-сопоставления",normalizedTitle:"фильтры сопоставления",charIndex:3325},{level:2,title:"Пользовательские цепочки",slug:"пользовательские-цепочки",normalizedTitle:"пользовательские цепочки",charIndex:4743}],readingTime:{minutes:1.3,words:390},headersStr:"Сетевые Фильтры Фильтры сопоставления Пользовательские цепочки",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. В этом документе мы будем использовать YAML во всех примерах. Ниже приведен стандартный пример базового project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n * network. \\endpoint определяет конечную точку wss или ws для индексирования блокчейна - Это должно быть полный архивный узел.\n * network.dictionary при необходимости предоставляет HTTP конечную точку полного словаря для ускорения обработки - см. Running an Indexer\n * dataSources определяет данные, которые будут отфильтрованы и извлечены, а также расположение обработчика карты для применения преобразования данных.\n   * kind поддерживает только substrate/Runtime сейчас.\n   * startBlock определяет высоту блока для начала индексации.\n   * filter фильтрует источник данных для выполнения по сетевому имени спецификации конечной точки, см. сетевые фильтры\n   * mapping.handlers выведет список всех mapping functions и соответствующих типов обработчиков, с дополнительными mapping filters.\n\n\n# Сетевые Фильтры\n\nОбычно пользователь создаст SubQuery и будет повторно использовать его как для тестнетов, так и для майннет среды(например, Polkadot и Kusama). Между сетями различные опции, вероятно, отличаются (например, стартовый блок индекса). Поэтому мы позволяем пользователям определять различные детали для каждого источника данных, что означает, что один проект SubQuery по-прежнему может использоваться в нескольких сетях.\n\nПользователи могут добавить filter на dataSources для решения о том, какой источник данных запускать в каждой сети.\n\nНиже приведен пример, который показывает различные источники данных как для Polkadot так и для Kusama.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Фильтры сопоставления\n\nФильтры сопоставления являются чрезвычайно полезной функцией, чтобы решить, что блок, событие или надпись вызовут обработчик сопоставления.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Фильтры сопоставления являются необязательными, но рекомендуются, поскольку они значительно уменьшают объем данных, обрабатываемых вашим проектом SubQuery и повышают производительность индексации.\n\n#Пример фильтра из callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nВ следующей таблице описываются фильтры поддерживаемые различными обработчиками.\n\nHANDLER             ПОДДЕРЖИВАЕМЫЙ ФИЛЬТР\nОбработчик блоков   специализация\nEventHandler        module,method\nCallHandler         module,method ,success\n\n * Фильтры модулей и методов поддерживаются в любой блокчейн цепи, построенной на Substrate.\n * success фильтр принимает логическое значение и может быть использован для фильтрации дополнительных по его статусу успеха.\n * specVersion определяет диапазон версии спецификации для блока substrate. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24] #Index блок с specVersion в диапазоне от 23 до 24 (включительно).\n  specVersion: [100]      #Index блок со спецификацией больше или равно 100.\n  specVersion: [null, 23] #Индекс блок со специализацией менее 23.\n\n\n1\n2\n3\n4\n\n\n\n# Пользовательские цепочки\n\nВы можете проиндексировать данные из пользовательских цепей, включив в project.yaml. Объявить конкретные типы, поддерживаемые блокчейном в network.types. Мы поддерживаем дополнительные типы, используемые модулями выполнения substrate.\n\nТакже поддерживаются typesAlias, typesBundle, typesChain, и typesSpec.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain. o/public-ws"\n  типы: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter: #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. в этом документе мы будем использовать yaml во всех примерах. ниже приведен стандартныи пример базового project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n * network. \\endpoint определяет конечную точку wss или ws для индексирования блокчеина - это должно быть полныи архивныи узел.\n * network.dictionary при необходимости предоставляет http конечную точку полного словаря для ускорения обработки - см. running an indexer\n * datasources определяет данные, которые будут отфильтрованы и извлечены, а также расположение обработчика карты для применения преобразования данных.\n   * kind поддерживает только substrate/runtime сеичас.\n   * startblock определяет высоту блока для начала индексации.\n   * filter фильтрует источник данных для выполнения по сетевому имени спецификации конечнои точки, см. сетевые фильтры\n   * mapping.handlers выведет список всех mapping functions и соответствующих типов обработчиков, с дополнительными mapping filters.\n\n\n# сетевые фильтры\n\nобычно пользователь создаст subquery и будет повторно использовать его как для тестнетов, так и для маиннет среды(например, polkadot и kusama). между сетями различные опции, вероятно, отличаются (например, стартовыи блок индекса). поэтому мы позволяем пользователям определять различные детали для каждого источника данных, что означает, что один проект subquery по-прежнему может использоваться в нескольких сетях.\n\nпользователи могут добавить filter на datasources для решения о том, какои источник данных запускать в каждои сети.\n\nниже приведен пример, которыи показывает различные источники данных как для polkadot так и для kusama.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# фильтры сопоставления\n\nфильтры сопоставления являются чрезвычаино полезнои функциеи, чтобы решить, что блок, событие или надпись вызовут обработчик сопоставления.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. фильтры сопоставления являются необязательными, но рекомендуются, поскольку они значительно уменьшают объем данных, обрабатываемых вашим проектом subquery и повышают производительность индексации.\n\n#пример фильтра из callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nв следующеи таблице описываются фильтры поддерживаемые различными обработчиками.\n\nhandler             поддерживаемыи фильтр\nобработчик блоков   специализация\neventhandler        module,method\ncallhandler         module,method ,success\n\n * фильтры модулеи и методов поддерживаются в любои блокчеин цепи, построеннои на substrate.\n * success фильтр принимает логическое значение и может быть использован для фильтрации дополнительных по его статусу успеха.\n * specversion определяет диапазон версии спецификации для блока substrate. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24] #index блок с specversion в диапазоне от 23 до 24 (включительно).\n  specversion: [100]      #index блок со спецификациеи больше или равно 100.\n  specversion: [null, 23] #индекс блок со специализациеи менее 23.\n\n\n1\n2\n3\n4\n\n\n\n# пользовательские цепочки\n\nвы можете проиндексировать данные из пользовательских цепеи, включив в project.yaml. объявить конкретные типы, поддерживаемые блокчеином в network.types. мы поддерживаем дополнительные типы, используемые модулями выполнения substrate.\n\nтакже поддерживаются typesalias, typesbundle, typeschain, и typesspec.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain. o/public-ws"\n  типы: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter: #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{cyrillic:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Сопоставление",frontmatter:{summary:"Сопоставление Функции сопоставления определяют, как данные цепи преобразуются в оптимизированные GraphQL-сущности, которые мы ранее определили в файле schema.graphql. Сопоставления",meta:[{property:"og:url",content:"/ru/create/mapping.html"},{property:"og:title",content:"Сопоставление"},{property:"og:description",content:"Сопоставление Функции сопоставления определяют, как данные цепи преобразуются в оптимизированные GraphQL-сущности, которые мы ранее определили в файле schema.graphql. Сопоставления"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/create/mapping.html",relativePath:"ru/create/mapping.md",key:"v-afcff1e6",path:"/ru/create/mapping/",headers:[{level:2,title:"Обработчик блоков",slug:"обработчик-блоков",normalizedTitle:"обработчик блоков",charIndex:632},{level:2,title:"Обработчик событий",slug:"обработчик-событии",normalizedTitle:"обработчик событии",charIndex:1385},{level:2,title:"Обработчик вызовов",slug:"обработчик-вызовов",normalizedTitle:"обработчик вызовов",charIndex:2692},{level:2,title:"Состояния запроса",slug:"состояния-запроса",normalizedTitle:"состояния запроса",charIndex:3316},{level:2,title:"RPC-вызовы",slug:"rpc-вызовы",normalizedTitle:"rpc-вызовы",charIndex:4344},{level:2,title:"Модули и Библиотеки",slug:"модули-и-библиотеки",normalizedTitle:"модули и библиотеки",charIndex:5401},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5881},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6549},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5346},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:7266},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10611},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11846},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:12068}],readingTime:{minutes:5.06,words:1517},headersStr:"Обработчик блоков Обработчик событий Обработчик вызовов Состояния запроса RPC-вызовы Модули и Библиотеки Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Сопоставление\n\nФункции сопоставления определяют, как данные цепи преобразуются в оптимизированные GraphQL-сущности, которые мы ранее определили в файле schema.graphql.\n\nСопоставления написаны в подгруппе TypeScript называется AssemblyScript, который может быть скомпилирован в WASM (WebAssembly).\n\n * Сопоставления определяются в директории src/mapappings и экспортируются как функция\n * Эти сопоставления также экспортированы в src/index.ts\n * Файлы сопоставлений являются ссылками в project.yaml под обработчиками сопоставлений.\n\nСуществует три класса функций сопоставления; Block handlers, Event Handlers, и Call Handlers.\n\n\n# Обработчик блоков\n\nВы можете использовать обработчики блоков для создания информации каждый раз, когда новый блок прикрепляется к цепочке Substrate, например номер блока. Для достижения этой цели, определенный BlockHandler будет вызываться один раз для каждого блока.\n\nimport {SubstrateBlock} from "@subql/types";\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n    // Create a new StarterEntity with the block hash as it\'s ID\n    const record = new starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nSubstrateBlock является расширенным интерфейсом типа signedBlock, но также включает в себя specVersion и timestamp.\n\n\n# Обработчик событий\n\nВы можете использовать обработчики событий для сбора информации, когда определенные события включены в новый блок. События, входящие в стандартное время выполнения Substrate, и блок могут содержать несколько событий.\n\nВо время обработки события в качестве аргумента с напечатанными входами и выходами, обработчик событий будет получать подстрочное событие. Любой тип события запустит сопоставление, позволяя активность с источником данных для захвата. Вы должны использовать Mapping Filters в вашем манифесте для фильтрации событий, чтобы сократить время, необходимое для индексирования данных и улучшения производительности сопоставления.\n\nимпортировать {SubstrateEvent} из "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Получение записи по ее ID\n    const запись = new starterEntity(event). xtrinsic.block.block.header.hash.toString());\n    record.field2 = account. oString();\n    record.field3 = (баланс как баланс).toBigInt();\n    ожидание record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nSubstrateEvent является расширенным интерфейсом типа EventRecord. Помимо данных события, он также включает в себя id (блок к которому принадлежит это событие) и дополнительным внутри этого блока.\n\n\n# Обработчик вызовов\n\nОбработчики вызовов используются, когда вы хотите запечатлеть информацию о некоторых substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nSubstrateExtrinsic расширяет GenericExtrinsic. Назначенный id (блок, к которому принадлежит), и предоставляет дополнительное свойство, которое расширяет события среди этого блока. Кроме того, он регистрирует успешный статус этой надбавки.\n\n\n# Состояния запроса\n\nНаша цель - охватить все источники данных для пользователей для сопоставления обработчиков (более чем три типа событий интерфейса выше). Поэтому мы выставили некоторые из интерфейсов @polkadot/api для увеличения возможностей.\n\nЭто интерфейсы, которые мы поддерживаем в настоящее время:\n\n * api.query.<module>.<method>() будет запрашивать current блок.\n * api.query.<module>.<method>.multi() сделает несколько запросов типа same в текущем блоке.\n * api.queryMulti() сделает несколько запросов разных типов в текущем блоке.\n\nЭто интерфейсы, которые мы НЕ поддерживаем сейчас:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nСмотрите пример использования этого API в нашем validator-threshold варианте использования.\n\n\n# RPC-вызовы\n\nМы также поддерживаем некоторые методы API RPC, которые являются удалёнными вызовами, которые позволяют функции сопоставления взаимодействовать с реальным узлом, запросом и отправкой. Основной предпосылкой подзапроса является то, что он детерминирует и, следовательно, держать последовательные результаты мы разрешаем только исторические RPC-вызовы.\n\nДокументы в JSON-RPC предоставляют некоторые методы, которые используют BlockHash в качестве входного параметра (e. . в?: BlockHash), которые теперь разрешены. Мы также изменили эти методы, чтобы получить по умолчанию хэш текущего блока индексации.\n\n// Скажем, мы сейчас индексируем блок с этим хэшем номером\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Оригинальный метод имеет необязательный входной блок хэш\nconst b1 = ожидание api. pc.chain.getBlock(blockhash);\n\n// Он будет использовать текущий блок по умолчанию так:\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * Для Custom Substrate Chains RPC звонки смотрите usage.\n\n\n# Модули и Библиотеки\n\nДля улучшения возможностей обработки данных SubQuery, мы разрешили некоторые встроенные модули NodeJS для запущенных функций сопоставления в песочнице, и разрешили пользователям звонить в сторонние библиотеки.\n\nПожалуйста, обратите внимание, что это экспериментальная функция и вы можете столкнуться с ошибками или проблемами, которые могут негативно повлиять на ваши функции сопоставления. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from "ethers/lib/utils"; //Good way\nimport {utils} from "ethers" //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api.query.kitties.nextKittyId();\n    // return the Kitty type, input parameters types are AccountId and KittyIndex\n    const allKitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`Next kitty id ${nextKittyId}`)\n    //Custom rpc, set undefined to blockhash\n    const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined,nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# сопоставление\n\nфункции сопоставления определяют, как данные цепи преобразуются в оптимизированные graphql-сущности, которые мы ранее определили в фаиле schema.graphql.\n\nсопоставления написаны в подгруппе typescript называется assemblyscript, которыи может быть скомпилирован в wasm (webassembly).\n\n * сопоставления определяются в директории src/mapappings и экспортируются как функция\n * эти сопоставления также экспортированы в src/index.ts\n * фаилы сопоставлении являются ссылками в project.yaml под обработчиками сопоставлении.\n\nсуществует три класса функции сопоставления; block handlers, event handlers, и call handlers.\n\n\n# обработчик блоков\n\nвы можете использовать обработчики блоков для создания информации каждыи раз, когда новыи блок прикрепляется к цепочке substrate, например номер блока. для достижения этои цели, определенныи blockhandler будет вызываться один раз для каждого блока.\n\nimport {substrateblock} from "@subql/types";\n\nexport async function handleblock(block: substrateblock): promise<void> {\n    // create a new starterentity with the block hash as it\'s id\n    const record = new starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nsubstrateblock является расширенным интерфеисом типа signedblock, но также включает в себя specversion и timestamp.\n\n\n# обработчик событии\n\nвы можете использовать обработчики событии для сбора информации, когда определенные события включены в новыи блок. события, входящие в стандартное время выполнения substrate, и блок могут содержать несколько событии.\n\nво время обработки события в качестве аргумента с напечатанными входами и выходами, обработчик событии будет получать подстрочное событие. любои тип события запустит сопоставление, позволяя активность с источником данных для захвата. вы должны использовать mapping filters в вашем манифесте для фильтрации событии, чтобы сократить время, необходимое для индексирования данных и улучшения производительности сопоставления.\n\nимпортировать {substrateevent} из "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // получение записи по ее id\n    const запись = new starterentity(event). xtrinsic.block.block.header.hash.tostring());\n    record.field2 = account. ostring();\n    record.field3 = (баланс как баланс).tobigint();\n    ожидание record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nsubstrateevent является расширенным интерфеисом типа eventrecord. помимо данных события, он также включает в себя id (блок к которому принадлежит это событие) и дополнительным внутри этого блока.\n\n\n# обработчик вызовов\n\nобработчики вызовов используются, когда вы хотите запечатлеть информацию о некоторых substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nsubstrateextrinsic расширяет genericextrinsic. назначенныи id (блок, к которому принадлежит), и предоставляет дополнительное своиство, которое расширяет события среди этого блока. кроме того, он регистрирует успешныи статус этои надбавки.\n\n\n# состояния запроса\n\nнаша цель - охватить все источники данных для пользователеи для сопоставления обработчиков (более чем три типа событии интерфеиса выше). поэтому мы выставили некоторые из интерфеисов @polkadot/api для увеличения возможностеи.\n\nэто интерфеисы, которые мы поддерживаем в настоящее время:\n\n * api.query.<module>.<method>() будет запрашивать current блок.\n * api.query.<module>.<method>.multi() сделает несколько запросов типа same в текущем блоке.\n * api.querymulti() сделает несколько запросов разных типов в текущем блоке.\n\nэто интерфеисы, которые мы не поддерживаем сеичас:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nсмотрите пример использования этого api в нашем validator-threshold варианте использования.\n\n\n# rpc-вызовы\n\nмы также поддерживаем некоторые методы api rpc, которые являются удаленными вызовами, которые позволяют функции сопоставления взаимодеиствовать с реальным узлом, запросом и отправкои. основнои предпосылкои подзапроса является то, что он детерминирует и, следовательно, держать последовательные результаты мы разрешаем только исторические rpc-вызовы.\n\nдокументы в json-rpc предоставляют некоторые методы, которые используют blockhash в качестве входного параметра (e. . в?: blockhash), которые теперь разрешены. мы также изменили эти методы, чтобы получить по умолчанию хэш текущего блока индексации.\n\n// скажем, мы сеичас индексируем блок с этим хэшем номером\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// оригинальныи метод имеет необязательныи входнои блок хэш\nconst b1 = ожидание api. pc.chain.getblock(blockhash);\n\n// он будет использовать текущии блок по умолчанию так:\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * для custom substrate chains rpc звонки смотрите usage.\n\n\n# модули и библиотеки\n\nдля улучшения возможностеи обработки данных subquery, мы разрешили некоторые встроенные модули nodejs для запущенных функции сопоставления в песочнице, и разрешили пользователям звонить в сторонние библиотеки.\n\nпожалуиста, обратите внимание, что это экспериментальная функция и вы можете столкнуться с ошибками или проблемами, которые могут негативно повлиять на ваши функции сопоставления. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from "ethers/lib/utils"; //good way\nimport {utils} from "ethers" //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api.query.kitties.nextkittyid();\n    // return the kitty type, input parameters types are accountid and kittyindex\n    const allkitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`next kitty id ${nextkittyid}`)\n    //custom rpc, set undefined to blockhash\n    const kittyprice = await api.rpc.kitties.getkittyprice(undefined,nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cyrillic:!0,cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Часто задаваемые вопросы",frontmatter:{summary:"Часто задаваемые вопросы Что такое SubQuery? SubQuery - это проект с открытым исходным кодом, который позволяет разработчикам индексировать, преобразовывать и запрашивать данные це",meta:[{property:"og:url",content:"/ru/faqs/faqs.html"},{property:"og:title",content:"Часто задаваемые вопросы"},{property:"og:description",content:"Часто задаваемые вопросы Что такое SubQuery? SubQuery - это проект с открытым исходным кодом, который позволяет разработчикам индексировать, преобразовывать и запрашивать данные це"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/faqs/faqs.html",relativePath:"ru/faqs/faqs.md",key:"v-249ce353",path:"/ru/faqs/faqs/",headers:[{level:2,title:"Что такое SubQuery?",slug:"что-такое-subquery",normalizedTitle:"что такое subquery?",charIndex:31},{level:2,title:"Какой лучший способ начать работу с SubQuery?",slug:"какои-лучшии-способ-начать-работу-с-subquery",normalizedTitle:"какои лучшии способ начать работу с subquery?",charIndex:472},{level:2,title:"Как я могу внести свой вклад или оставить отзыв для SubQuery?",slug:"как-я-могу-внести-свои-вклад-или-оставить-отзыв-для-subquery",normalizedTitle:"как я могу внести свои вклад или оставить отзыв для subquery?",charIndex:801},{level:2,title:"Сколько стоит разместить мой проект в SubQuery?",slug:"сколько-стоит-разместить-мои-проект-в-subquery",normalizedTitle:"сколько стоит разместить мои проект в subquery?",charIndex:1248},{level:2,title:"Что такое слоты развертывания?",slug:"что-такое-слоты-развертывания",normalizedTitle:"что такое слоты развертывания?",charIndex:1538},{level:2,title:"В чем преимущество промежуточного слота?",slug:"в-чем-преимущество-промежуточного-слота",normalizedTitle:"в чем преимущество промежуточного слота?",charIndex:2225},{level:2,title:"Что такое надстройки?",slug:"что-такое-надстроики",normalizedTitle:"что такое надстроики?",charIndex:2752}],readingTime:{minutes:.22,words:66},headersStr:"Что такое SubQuery? Какой лучший способ начать работу с SubQuery? Как я могу внести свой вклад или оставить отзыв для SubQuery? Сколько стоит разместить мой проект в SubQuery? Что такое слоты развертывания? В чем преимущество промежуточного слота? Что такое надстройки?",content:'# Часто задаваемые вопросы\n\n\n# Что такое SubQuery?\n\nSubQuery - это проект с открытым исходным кодом, который позволяет разработчикам индексировать, преобразовывать и запрашивать данные цепи Substrate для питания своих приложений.\n\nSubQuery также предоставляет бесплатный хостинг проектов по производству для разработчиков, позволяя им снять ответственность за построение инфраструктуры, и также позволяет разработчикам делать то, что они делают лучше всего - строить.\n\n\n# Какой лучший способ начать работу с SubQuery?\n\nЛучший способ начать работу с SubQuery - попробовать наш Урок «Приветствуем мир». Это простая 5-минутная прогулка по загрузке начального шаблона, построению проекта, а затем с помощью использования Docker для запуска узла на вашем локальном хосте и выполнения простого запроса.\n\n\n# Как я могу внести свой вклад или оставить отзыв для SubQuery?\n\nНам нравится вклад и отзывы сообщества. Чтобы внести свой код, форкните интересующее вас хранилище и внесите свои изменения. Затем отправьте PR или Pull Request. Ах, не забудь еще и протестировать! Также ознакомьтесь с нашими рекомендациями внесению дополнений (скоро).\n\nЧтобы оставить отзыв, свяжитесь с нами по адресу hello@subquery.network или перейдите на наш discord channel\n\n\n# Сколько стоит разместить мой проект в SubQuery?\n\nРазмещение вашего проекта в SubQuery Projects абсолютно бесплатно - это наш способ отблагодарить сообщество. Чтобы научиться каким образом размещать ваш проект у нас, пожалуйста ознакомьтесь с руководством Hello World (SubQuery hosted).\n\n\n# Что такое слоты развертывания?\n\nСлоты развертывания - это функция в SubQuery Projects, которая является эквивалентом среды разработки. Например, в любой организации занимающейся программным обеспечением обычно есть как минимум среда разработки и производственная среда (без учета localhost). Обычно дополнительные условия, такие как постановка и пре-продакшен или даже QA, включаются в зависимости от потребностей организации и их разработки.\n\nSubQuery в настоящее время имеет два доступных слота. Промежуточный слот и производственный слот. Это позволяет разработчикам установить свой SubQuery в промежуточную среду и если все хорошо, "продвинуть в производство" щелчком по кнопке.\n\n\n# В чем преимущество промежуточного слота?\n\nОсновное преимущество использования промежуточного слота состоит в том, что он позволяет вам подготовить новую версию вашего проекта SubQuery, не раскрывая ее публично. Вы можете подождать, пока промежуточный слот переиндексирует все данные, не затрагивая рабочие приложения.\n\nПромежуточный слот не отображается публично в Explorer и имеет уникальный URL, который видим только вам. И, конечно же, отдельная среда позволяет вам тестировать новый код, не ущерба вашему производству.\n\n\n# Что такое надстройки?\n\nЕсли вы уже знакомы с понятиями блокчейна, вы можете подумать о дополнительных функциях, сопоставимых с транзакциями. Однако более формально надстройками является часть информации, которая поступает извне цепи и включена в блок. Есть три категории надстроек. Они являются неотъемлемыми элементами, подписанными транзакциями и неподписанными транзакциями.\n\nInherent Extrinsics - это части информации, которые не подписаны и вставляются в блок автором блока.\n\nВнешние подписанные транзакции - это транзакции, которые содержат подпись учетной записи, выданного транзакцией. Они должны заплатить комиссию за включение транзакции в цепочку.\n\nНеподписанные транзакции – это транзакции, которые не содержат подписи счета, который выдает транзакцию. Неподписанные транзакции должны использоваться с осторожностью, потому что никто не платит комиссию, так как она подписана. Из-за этого в очереди транзакций отсутствует экономическая логика для предотвращения спама.\n\nДля получения дополнительной информации нажмите here.',normalizedContent:'# часто задаваемые вопросы\n\n\n# что такое subquery?\n\nsubquery - это проект с открытым исходным кодом, которыи позволяет разработчикам индексировать, преобразовывать и запрашивать данные цепи substrate для питания своих приложении.\n\nsubquery также предоставляет бесплатныи хостинг проектов по производству для разработчиков, позволяя им снять ответственность за построение инфраструктуры, и также позволяет разработчикам делать то, что они делают лучше всего - строить.\n\n\n# какои лучшии способ начать работу с subquery?\n\nлучшии способ начать работу с subquery - попробовать наш урок «приветствуем мир». это простая 5-минутная прогулка по загрузке начального шаблона, построению проекта, а затем с помощью использования docker для запуска узла на вашем локальном хосте и выполнения простого запроса.\n\n\n# как я могу внести свои вклад или оставить отзыв для subquery?\n\nнам нравится вклад и отзывы сообщества. чтобы внести свои код, форкните интересующее вас хранилище и внесите свои изменения. затем отправьте pr или pull request. ах, не забудь еще и протестировать! также ознакомьтесь с нашими рекомендациями внесению дополнении (скоро).\n\nчтобы оставить отзыв, свяжитесь с нами по адресу hello@subquery.network или переидите на наш discord channel\n\n\n# сколько стоит разместить мои проект в subquery?\n\nразмещение вашего проекта в subquery projects абсолютно бесплатно - это наш способ отблагодарить сообщество. чтобы научиться каким образом размещать ваш проект у нас, пожалуиста ознакомьтесь с руководством hello world (subquery hosted).\n\n\n# что такое слоты развертывания?\n\nслоты развертывания - это функция в subquery projects, которая является эквивалентом среды разработки. например, в любои организации занимающеися программным обеспечением обычно есть как минимум среда разработки и производственная среда (без учета localhost). обычно дополнительные условия, такие как постановка и пре-продакшен или даже qa, включаются в зависимости от потребностеи организации и их разработки.\n\nsubquery в настоящее время имеет два доступных слота. промежуточныи слот и производственныи слот. это позволяет разработчикам установить свои subquery в промежуточную среду и если все хорошо, "продвинуть в производство" щелчком по кнопке.\n\n\n# в чем преимущество промежуточного слота?\n\nосновное преимущество использования промежуточного слота состоит в том, что он позволяет вам подготовить новую версию вашего проекта subquery, не раскрывая ее публично. вы можете подождать, пока промежуточныи слот переиндексирует все данные, не затрагивая рабочие приложения.\n\nпромежуточныи слот не отображается публично в explorer и имеет уникальныи url, которыи видим только вам. и, конечно же, отдельная среда позволяет вам тестировать новыи код, не ущерба вашему производству.\n\n\n# что такое надстроики?\n\nесли вы уже знакомы с понятиями блокчеина, вы можете подумать о дополнительных функциях, сопоставимых с транзакциями. однако более формально надстроиками является часть информации, которая поступает извне цепи и включена в блок. есть три категории надстроек. они являются неотъемлемыми элементами, подписанными транзакциями и неподписанными транзакциями.\n\ninherent extrinsics - это части информации, которые не подписаны и вставляются в блок автором блока.\n\nвнешние подписанные транзакции - это транзакции, которые содержат подпись учетнои записи, выданного транзакциеи. они должны заплатить комиссию за включение транзакции в цепочку.\n\nнеподписанные транзакции – это транзакции, которые не содержат подписи счета, которыи выдает транзакцию. неподписанные транзакции должны использоваться с осторожностью, потому что никто не платит комиссию, так как она подписана. из-за этого в очереди транзакции отсутствует экономическая логика для предотвращения спама.\n\nдля получения дополнительнои информации нажмите here.',charsets:{cyrillic:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/ru/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/install/install.html",relativePath:"ru/install/install.md",key:"v-60abd363",path:"/ru/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Амбассадорская программа",frontmatter:{summary:"Амбассадорская программа Мы понимаем, что одна из наших самых сильных сторон - это наше сообщество, и с вашей помощью мы хотим расти и создавать локальных амбассадоров в сообщества",meta:[{property:"og:url",content:"/ru/miscellaneous/ambassadors.html"},{property:"og:title",content:"Амбассадорская программа"},{property:"og:description",content:"Амбассадорская программа Мы понимаем, что одна из наших самых сильных сторон - это наше сообщество, и с вашей помощью мы хотим расти и создавать локальных амбассадоров в сообщества"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/miscellaneous/ambassadors.html",relativePath:"ru/miscellaneous/ambassadors.md",key:"v-4a7311a2",path:"/ru/miscellaneous/ambassadors/",headers:[{level:2,title:"Во что мы верим",slug:"во-что-мы-верим",normalizedTitle:"во что мы верим",charIndex:228},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1434},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1770},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2962},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3877}],readingTime:{minutes:2.45,words:734},headersStr:"Во что мы верим Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Амбассадорская программа\n\n\n\nМы понимаем, что одна из наших самых сильных сторон - это наше сообщество, и с вашей помощью мы хотим расти и создавать локальных амбассадоров в сообществах по всему миру.\n\nПодай заявку сейчас!\n\n\n# Во что мы верим\n\nНаша команда собралась вместе, разделяя общие взгляды на создание основ гибкой и всеобъемлющей базы данных для экосистемы Polkadot.\n\nСоздано разработчиками, для разработчиков: SubQuery - растущее сообщество, фокусирующееся на предоставлении лучших продуктов и услуг для наших разработчиков, и разработчиков работающих в нашей экосистеме. SubQuery будет успешно функционировать только в том случае, если экосистема Polkadot будет успешно функционировать, поэтому все, что мы делаем, мы делаем с учетом интересов наших клиентов.\n\nЦелостность и подотчетность: У нас есть члены команды в Окленде, Шанхае и Сиднее, поэтому для нас важна удаленная работа. Мы надеемся, что наша сможет работать автономна для достижения наших совместных целей. Ключевым требованием для нашей команды является принятие ответственности за свои действия и за их добросовестность.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# амбассадорская программа\n\n\n\nмы понимаем, что одна из наших самых сильных сторон - это наше сообщество, и с вашеи помощью мы хотим расти и создавать локальных амбассадоров в сообществах по всему миру.\n\nподаи заявку сеичас!\n\n\n# во что мы верим\n\nнаша команда собралась вместе, разделяя общие взгляды на создание основ гибкои и всеобъемлющеи базы данных для экосистемы polkadot.\n\nсоздано разработчиками, для разработчиков: subquery - растущее сообщество, фокусирующееся на предоставлении лучших продуктов и услуг для наших разработчиков, и разработчиков работающих в нашеи экосистеме. subquery будет успешно функционировать только в том случае, если экосистема polkadot будет успешно функционировать, поэтому все, что мы делаем, мы делаем с учетом интересов наших клиентов.\n\nцелостность и подотчетность: у нас есть члены команды в окленде, шанхае и сиднее, поэтому для нас важна удаленная работа. мы надеемся, что наша сможет работать автономна для достижения наших совместных целеи. ключевым требованием для нашеи команды является принятие ответственности за свои деиствия и за их добросовестность.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{cyrillic:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/ru/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/miscellaneous/branding.html",relativePath:"ru/miscellaneous/branding.md",key:"v-7ce7626d",path:"/ru/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/ru/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/miscellaneous/contributing.html",relativePath:"ru/miscellaneous/contributing.md",key:"v-0258bce6",path:"/ru/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/ru/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/miscellaneous/social_media.html",relativePath:"ru/miscellaneous/social_media.md",key:"v-d647e6e6",path:"/ru/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/ru/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/publish/connect.html",relativePath:"ru/publish/connect.md",key:"v-720d45dd",path:"/ru/publish/connect/",readingTime:{minutes:.61,words:182},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/ru/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/publish/publish.html",relativePath:"ru/publish/publish.md",key:"v-605e5d93",path:"/ru/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1133},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. *We're almost there! We just need to deploy a new version of it. *\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. *we're almost there! we just need to deploy a new version of it. *\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/ru/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/publish/upgrade.html",relativePath:"ru/publish/upgrade.md",key:"v-1f0ac379",path:"/ru/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/ru/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/query/graphql.html",relativePath:"ru/query/graphql.md",key:"v-50fd6d6d",path:"/ru/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/ru/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/query/query.html",relativePath:"ru/query/query.md",key:"v-0ffdfaaf",path:"/ru/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/ru/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/quickstart/helloworld-hosted.html",relativePath:"ru/quickstart/helloworld-hosted.md",key:"v-38af4ead",path:"/ru/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/ru/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/quickstart/helloworld-localhost.html",relativePath:"ru/quickstart/helloworld-localhost.md",key:"v-953a799e",path:"/ru/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"Step 1: Initialise project",slug:"step-1-initialise-project",normalizedTitle:"step 1: initialise project",charIndex:1455},{level:2,title:"Step 2: Install dependencies",slug:"step-2-install-dependencies",normalizedTitle:"step 2: install dependencies",charIndex:2035},{level:2,title:"Step 3: Generate code",slug:"step-3-generate-code",normalizedTitle:"step 3: generate code",charIndex:2477},{level:2,title:"Step 4: Build code",slug:"step-4-build-code",normalizedTitle:"step 4: build code",charIndex:3087},{level:2,title:"Step 5: Run Docker",slug:"step-5-run-docker",normalizedTitle:"step 5: run docker",charIndex:3319},{level:2,title:"Step 6: Browse playground",slug:"step-6-browse-playground",normalizedTitle:"step 6: browse playground",charIndex:4586},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:5027}],readingTime:{minutes:2.85,words:855},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Initialise project Step 2: Install dependencies Step 3: Generate code Step 4: Build code Step 5: Run Docker Step 6: Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Step 5: Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Step 6: Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# step 5: run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# step 6: browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/ru/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/quickstart/quickstart.html",relativePath:"ru/quickstart/quickstart.md",key:"v-0133a45a",path:"/ru/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2566},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3009},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3388},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3628},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3981},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4548},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5235}],readingTime:{minutes:3.22,words:967},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/ru/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/quickstart/understanding-helloworld.html",relativePath:"ru/quickstart/understanding-helloworld.md",key:"v-05c24d2b",path:"/ru/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/ru/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/run/run.html",relativePath:"ru/run/run.md",key:"v-0df44aba",path:"/ru/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3940},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4183}],readingTime:{minutes:2.57,words:772},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/ru/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/run/sandbox.html",relativePath:"ru/run/sandbox.md",key:"v-3ba014ab",path:"/ru/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/ru/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/tutorials_examples/howto.html",relativePath:"ru/tutorials_examples/howto.md",key:"v-11f6eb4d",path:"/ru/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri",meta:[{property:"og:url",content:"/ru/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/tutorials_examples/introduction.html",relativePath:"ru/tutorials_examples/introduction.md",key:"v-b42dc576",path:"/ru/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:155}],readingTime:{minutes:.77,words:231},headersStr:"SubQuery Examples",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# SubQuery Examples\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# subquery examples\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/ru/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/tutorials_examples/terminology.html",relativePath:"ru/tutorials_examples/terminology.md",key:"v-48f9c38d",path:"/ru/tutorials_examples/terminology/",headers:[{level:2,title:"Terminology",slug:"terminology",normalizedTitle:"terminology",charIndex:2}],readingTime:{minutes:.49,words:147},headersStr:"Terminology",content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/run/run.html",relativePath:"run/run.md",key:"v-09dfd14d",path:"/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:6013},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:6256}],readingTime:{minutes:3.54,words:1063},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:'# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don\'t want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won\'t need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you\'ll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Use a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we\'ve seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\nRead more about how a SubQuery Dictionary works.\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Run in local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n# Check your node health\n\nThere are 2 endpoints that you can use to check and monitor the health of a running SubQuery node.\n\n * Health check endpoint that returns a simple 200 response\n * Metadata endpoint that includes additional analytics of your running SubQuery node\n\nAppend this to the base URL of your SubQuery node. Eg http://localhost:3000/meta will return:\n\n{\n    "currentProcessingHeight": 1000699,\n    "currentProcessingTimestamp": 1631517883547,\n    "targetHeight": 6807295,\n    "bestHeight": 6807298,\n    "indexerNodeVersion": "0.19.1",\n    "lastProcessedHeight": 1000699,\n    "lastProcessedTimestamp": 1631517883555,\n    "uptime": 41.151789063,\n    "polkadotSdkVersion": "5.4.1",\n    "apiConnected": true,\n    "injectedApiConnected": true,\n    "usingDictionary": false,\n    "chain": "Polkadot",\n    "specName": "polkadot",\n    "genesisHash": "0x91b171bb158e2d3848fa23a9f1c25182fb8e20313b2c1eb49219da7a70ce90c3",\n    "blockTime": 6000\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nhttp://localhost:3000/health will return HTTP 200 if successful.\n\nA 500 error will be returned if the indexer is not healthy. This can often be seen when the node is booting up.\n\n{\n    "status": 500,\n    "error": "Indexer is not healthy"\n}\n\n\n1\n2\n3\n4\n\n\nIf an incorrect URL is used, a 404 not found error will be returned.\n\n{\n"statusCode": 404,\n"message": "Cannot GET /healthy",\n"error": "Not Found"\n}\n\n\n1\n2\n3\n4\n5\n\n\n# Debug your project\n\nUse the node inspector to run the following command.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nFor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\nThen open up the Chrome dev tools, go to Source > Filesystem and add your project to the workspace and start debugging. For more information, check out How to debug a SubQuery project\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\nexport DB_HOST=localhost\nsubql-query --name <project_name> --playground\n\n\n1\n2\n\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.',normalizedContent:'# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don\'t want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won\'t need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you\'ll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# use a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we\'ve seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\nread more about how a subquery dictionary works.\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# run in local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n# check your node health\n\nthere are 2 endpoints that you can use to check and monitor the health of a running subquery node.\n\n * health check endpoint that returns a simple 200 response\n * metadata endpoint that includes additional analytics of your running subquery node\n\nappend this to the base url of your subquery node. eg http://localhost:3000/meta will return:\n\n{\n    "currentprocessingheight": 1000699,\n    "currentprocessingtimestamp": 1631517883547,\n    "targetheight": 6807295,\n    "bestheight": 6807298,\n    "indexernodeversion": "0.19.1",\n    "lastprocessedheight": 1000699,\n    "lastprocessedtimestamp": 1631517883555,\n    "uptime": 41.151789063,\n    "polkadotsdkversion": "5.4.1",\n    "apiconnected": true,\n    "injectedapiconnected": true,\n    "usingdictionary": false,\n    "chain": "polkadot",\n    "specname": "polkadot",\n    "genesishash": "0x91b171bb158e2d3848fa23a9f1c25182fb8e20313b2c1eb49219da7a70ce90c3",\n    "blocktime": 6000\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nhttp://localhost:3000/health will return http 200 if successful.\n\na 500 error will be returned if the indexer is not healthy. this can often be seen when the node is booting up.\n\n{\n    "status": 500,\n    "error": "indexer is not healthy"\n}\n\n\n1\n2\n3\n4\n\n\nif an incorrect url is used, a 404 not found error will be returned.\n\n{\n"statuscode": 404,\n"message": "cannot get /healthy",\n"error": "not found"\n}\n\n\n1\n2\n3\n4\n5\n\n\n# debug your project\n\nuse the node inspector to run the following command.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nfor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\nthen open up the chrome dev tools, go to source > filesystem and add your project to the workspace and start debugging. for more information, check out how to debug a subquery project\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\nexport db_host=localhost\nsubql-query --name <project_name> --playground\n\n\n1\n2\n\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/run/sandbox.html",relativePath:"run/sandbox.md",key:"v-07cf064d",path:"/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"How to change the blockchain fetching batch size?",frontmatter:{summary:"How to change the blockchain fetching batch size? Video guide Introduction The default batch size is 100, but this can be changed by using the extra command --batch-size=xx. You ne",meta:[{property:"og:url",content:"/tutorials_examples/batch-size.html"},{property:"og:title",content:"How to change the blockchain fetching batch size?"},{property:"og:description",content:"How to change the blockchain fetching batch size? Video guide Introduction The default batch size is 100, but this can be changed by using the extra command --batch-size=xx. You ne"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tutorials_examples/batch-size.html",relativePath:"tutorials_examples/batch-size.md",key:"v-685a2e6d",path:"/tutorials_examples/batch-size/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:56},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:72},{level:2,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:744}],readingTime:{minutes:.47,words:141},headersStr:"Video guide Introduction Why change the batch size?",content:'# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive.',normalizedContent:'# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"How to start at a different block height?",frontmatter:{summary:"How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from b",meta:[{property:"og:url",content:"/tutorials_examples/block-height.html"},{property:"og:title",content:"How to start at a different block height?"},{property:"og:description",content:"How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from b"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tutorials_examples/block-height.html",relativePath:"tutorials_examples/block-height.md",key:"v-295c5866",path:"/tutorials_examples/block-height/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:48},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:64},{level:2,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:952},{level:2,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1259},{level:2,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1439},{level:2,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1633}],readingTime:{minutes:1.02,words:307},headersStr:"Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen?",content:'# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.',normalizedContent:'# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"How to debug a SubQuery project?",frontmatter:{summary:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will",meta:[{property:"og:url",content:"/tutorials_examples/debug-projects.html"},{property:"og:title",content:"How to debug a SubQuery project?"},{property:"og:description",content:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tutorials_examples/debug-projects.html",relativePath:"tutorials_examples/debug-projects.md",key:"v-1bc67126",path:"/tutorials_examples/debug-projects/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:39},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:55},{level:2,title:"Node inspector",slug:"node-inspector",normalizedTitle:"node inspector",charIndex:272},{level:2,title:"Chrome devtools",slug:"chrome-devtools",normalizedTitle:"chrome devtools",charIndex:683}],readingTime:{minutes:.65,words:196},headersStr:"Video guide Introduction Node inspector Chrome devtools",content:"# How to debug a SubQuery project?\n\n\n# Video guide\n\n\n# Introduction\n\nIn order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a Node.js inspector in conjunction with Chrome developer tools.\n\n\n# Node inspector\n\nRun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nFor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# Chrome devtools\n\nOpen up Chrome DevTools and navigate to the Sources tab. Note that clicking on the green icon will open up a new window.\n\n\n\nNavigate to Filesystem and add your project folder to the workspace. Then open the dist > mappings folder and select the code you wish to debug. Then step through the code as with any standard debugging tool.\n\n",normalizedContent:"# how to debug a subquery project?\n\n\n# video guide\n\n\n# introduction\n\nin order to debug subquery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a node.js inspector in conjunction with chrome developer tools.\n\n\n# node inspector\n\nrun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nfor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# chrome devtools\n\nopen up chrome devtools and navigate to the sources tab. note that clicking on the green icon will open up a new window.\n\n\n\nnavigate to filesystem and add your project folder to the workspace. then open the dist > mappings folder and select the code you wish to debug. then step through the code as with any standard debugging tool.\n\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"How does a SubQuery dictionary work?",frontmatter:{summary:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod",meta:[{property:"og:url",content:"/tutorials_examples/dictionary.html"},{property:"og:title",content:"How does a SubQuery dictionary work?"},{property:"og:description",content:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tutorials_examples/dictionary.html",relativePath:"tutorials_examples/dictionary.md",key:"v-1f91922d",path:"/tutorials_examples/dictionary/",headers:[{level:2,title:"How to incorporate a dictionary into your project?",slug:"how-to-incorporate-a-dictionary-into-your-project",normalizedTitle:"how to incorporate a dictionary into your project?",charIndex:1024},{level:2,title:"What happens when a dictionary IS NOT used?",slug:"what-happens-when-a-dictionary-is-not-used",normalizedTitle:"what happens when a dictionary is not used?",charIndex:1350},{level:2,title:"What happens when a dictionary IS used?",slug:"what-happens-when-a-dictionary-is-used",normalizedTitle:"what happens when a dictionary is used?",charIndex:1772},{level:2,title:"When is a dictionary NOT useful?",slug:"when-is-a-dictionary-not-useful",normalizedTitle:"when is a dictionary not useful?",charIndex:2849}],readingTime:{minutes:2,words:601},headersStr:"How to incorporate a dictionary into your project? What happens when a dictionary IS NOT used? What happens when a dictionary IS used? When is a dictionary NOT useful?",content:"# How does a SubQuery dictionary work?\n\nThe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. Another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nThe network.dictionary endpoint is an optional parameter that if present, the SDK will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\nTaking the SubQuery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specVersion. These 3 entities contain 6, 4, and 2 fields respectively. When this project is run, these fields are reflected in the database tables.\n\n\n\nData from the blockchain is then stored in these tables and indexed for performance. The project is then hosted in SubQuery Projects and the API endpoint is available to be added to the manifest file.\n\n\n# How to incorporate a dictionary into your project?\n\nAdd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. Eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# What happens when a dictionary IS NOT used?\n\nWhen a dictionary is NOT used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. Later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# What happens when a dictionary IS used?\n\nWhen a dictionary IS used, the indexer will first take the call and event filters as parameters and merge this into a GraphQL query. It then uses the dictionary's API to obtain a list of relevant block heights only that contains the specific events and extrinsics. Often this is substantially less than 100 if the default is used.\n\nFor example, imagine a situation where you're indexing transfer events. Not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nThe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. This is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nThis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. But compared to the traditional method, it adds an additional step to get data from the dictionary’s API.\n\n\n# When is a dictionary NOT useful?\n\nWhen block handlers are used to grab data from a chain, every block needs to be processed. Therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nAlso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",normalizedContent:"# how does a subquery dictionary work?\n\nthe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nthe network.dictionary endpoint is an optional parameter that if present, the sdk will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\ntaking the subquery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specversion. these 3 entities contain 6, 4, and 2 fields respectively. when this project is run, these fields are reflected in the database tables.\n\n\n\ndata from the blockchain is then stored in these tables and indexed for performance. the project is then hosted in subquery projects and the api endpoint is available to be added to the manifest file.\n\n\n# how to incorporate a dictionary into your project?\n\nadd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# what happens when a dictionary is not used?\n\nwhen a dictionary is not used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# what happens when a dictionary is used?\n\nwhen a dictionary is used, the indexer will first take the call and event filters as parameters and merge this into a graphql query. it then uses the dictionary's api to obtain a list of relevant block heights only that contains the specific events and extrinsics. often this is substantially less than 100 if the default is used.\n\nfor example, imagine a situation where you're indexing transfer events. not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nthe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. this is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nthis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. but compared to the traditional method, it adds an additional step to get data from the dictionary’s api.\n\n\n# when is a dictionary not useful?\n\nwhen block handlers are used to grab data from a chain, every block needs to be processed. therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nalso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. Tutorials SubQuery Example Proje",meta:[{property:"og:url",content:"/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. Tutorials SubQuery Example Proje"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tutorials_examples/introduction.html",relativePath:"tutorials_examples/introduction.md",key:"v-65affcad",path:"/tutorials_examples/introduction/",headers:[{level:2,title:"Tutorials",slug:"tutorials",normalizedTitle:"tutorials",charIndex:2},{level:2,title:"SubQuery Example Projects",slug:"subquery-example-projects",normalizedTitle:"subquery example projects",charIndex:169}],readingTime:{minutes:.88,words:265},headersStr:"Tutorials SubQuery Example Projects",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# Tutorials\n\n\n# SubQuery Example Projects\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash.       The simplest example with a block handler function.\nblock-timestamp             Indexes timestamp of each finalized block.                     Another simple call handler function.\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data.\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block.                                            relationship.\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling.\n                            calls.\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain.\nsubquery-dictionary         Pre-indexes extrinsics and events for up to 10x performance    Block handlers, event handlers and call handlers, with data\n                            improvements.                                                  indexed from Polkadot mainnet.",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# tutorials\n\n\n# subquery example projects\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash.       the simplest example with a block handler function.\nblock-timestamp             indexes timestamp of each finalized block.                     another simple call handler function.\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data.\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block.                                            relationship.\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling.\n                            calls.\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain.\nsubquery-dictionary         pre-indexes extrinsics and events for up to 10x performance    block handlers, event handlers and call handlers, with data\n                            improvements.                                                  indexed from polkadot mainnet.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"How to run an indexer node?",frontmatter:{summary:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r",meta:[{property:"og:url",content:"/tutorials_examples/run-indexer.html"},{property:"og:title",content:"How to run an indexer node?"},{property:"og:description",content:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tutorials_examples/run-indexer.html",relativePath:"tutorials_examples/run-indexer.md",key:"v-4e5b9057",path:"/tutorials_examples/run-indexer/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:34},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:50},{level:2,title:"Postgres",slug:"postgres",normalizedTitle:"postgres",charIndex:300},{level:2,title:"Install subql/node",slug:"install-subql-node",normalizedTitle:"install subql/node",charIndex:484},{level:2,title:"Setting DB configs",slug:"setting-db-configs",normalizedTitle:"setting db configs",charIndex:802},{level:2,title:"Indexing a project",slug:"indexing-a-project",normalizedTitle:"indexing a project",charIndex:1380},{level:2,title:"Inspecting Postgres",slug:"inspecting-postgres",normalizedTitle:"inspecting postgres",charIndex:1687}],readingTime:{minutes:1.18,words:353},headersStr:"Video guide Introduction Postgres Install subql/node Setting DB configs Indexing a project Inspecting Postgres",content:"# How to run an indexer node?\n\n\n# Video guide\n\n\n# Introduction\n\nRunning an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It requires more time and effort but will enhance your understanding of how SubQuery works under the covers.\n\n\n# Postgres\n\nRunning an indexer node on your infrastructure will require the setup of a Postgres database. You can install Postgres from here and ensure the version is 12 or greater.\n\n\n# Install subql/node\n\nThen to run a SubQuery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nThe -g flag means to install it globally which means on OSX, the location will be /usr/local/lib/node_modules.\n\nOnce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# Setting DB configs\n\nNext, you need to set the following environmental variables:\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\n\n\n1\n2\n3\n4\n5\n\n\nOf course, if you have different values for the above keys, please adjust accordingly. Note that the env command will display the current environment variables and that this process only sets these values temporarily. That is, they are only valid for the duration of the terminal session. To set them permanently, store them in your ~/bash_profile instead.\n\n\n# Indexing a project\n\nTo start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nIf you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. You should see the indexer node kick into life and start indexing blocks.\n\n\n# Inspecting Postgres\n\nIf you navigate to Postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. The starter_entities table contains the indexes. To view the data, run select (*) from subquery_1.starter_entities.",normalizedContent:"# how to run an indexer node?\n\n\n# video guide\n\n\n# introduction\n\nrunning an indexer node is another option outside of using docker or having a project hosted for you at subquery projects. it requires more time and effort but will enhance your understanding of how subquery works under the covers.\n\n\n# postgres\n\nrunning an indexer node on your infrastructure will require the setup of a postgres database. you can install postgres from here and ensure the version is 12 or greater.\n\n\n# install subql/node\n\nthen to run a subquery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nthe -g flag means to install it globally which means on osx, the location will be /usr/local/lib/node_modules.\n\nonce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# setting db configs\n\nnext, you need to set the following environmental variables:\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\n\n\n1\n2\n3\n4\n5\n\n\nof course, if you have different values for the above keys, please adjust accordingly. note that the env command will display the current environment variables and that this process only sets these values temporarily. that is, they are only valid for the duration of the terminal session. to set them permanently, store them in your ~/bash_profile instead.\n\n\n# indexing a project\n\nto start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nif you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. you should see the indexer node kick into life and start indexing blocks.\n\n\n# inspecting postgres\n\nif you navigate to postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. the starter_entities table contains the indexes. to view the data, run select (*) from subquery_1.starter_entities.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tutorials_examples/terminology.html",relativePath:"tutorials_examples/terminology.md",key:"v-05bf836b",path:"/tutorials_examples/terminology/",readingTime:{minutes:.49,words:147},headersStr:null,content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{frontmatter:{summary:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello",meta:[{property:"og:url",content:"/uk/"},{property:"og:description",content:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/",relativePath:"uk/README.md",key:"v-5dda9d1e",path:"/uk/",readingTime:{minutes:3.03,words:910},headersStr:null,content:"Welcome to SubQuery’s Docs\n\nExplore and transform your chain data to build intuitive dApps faster!\n\n\nQuick Start Guide\n\nUnderstand SubQuery by getting hands on with a traditional Hello World example. Using a template project within a Docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * The SubQuery Network\n   \n   SubQuery’s decentralised future. Read more about how indexers and consumers are rewarded.\n\n\nFAQ\n\n * What is SubQuery?\n   \n   SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n   \n   READ MORE\n * What is the best way to get started with SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n * How can I contribute or give feedback to SubQuery?\n   \n   We love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guidelines (coming soon).\n   \n   READ MORE\n * How much does it cost to host my project in SubQuery Projects?\n   \n   Hosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nIntegrating with your Custom Chain?\n\nWhether you're building a new parachain or an entirely new blockchain on Substrate - SubQuery can help you index and troubleshoot your chain's data. SubQuery is designed to easily integrate with a custom Substrate based chain.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nSupport and Contribute\n\nHave a question or interested to know more or how you can contribute? We’d love to hear from you. Please contact us via email or social media from the links below. Need technical expertise? Join our Discord community and receive support from our passionate community members.\n\nJOIN THE CONVERSATION ON DISCORD\nContact us hello@subquery.network\nFollow us on social\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"welcome to subquery’s docs\n\nexplore and transform your chain data to build intuitive dapps faster!\n\n\nquick start guide\n\nunderstand subquery by getting hands on with a traditional hello world example. using a template project within a docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * the subquery network\n   \n   subquery’s decentralised future. read more about how indexers and consumers are rewarded.\n\n\nfaq\n\n * what is subquery?\n   \n   subquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n   \n   read more\n * what is the best way to get started with subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n * how can i contribute or give feedback to subquery?\n   \n   we love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guidelines (coming soon).\n   \n   read more\n * how much does it cost to host my project in subquery projects?\n   \n   hosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nintegrating with your custom chain?\n\nwhether you're building a new parachain or an entirely new blockchain on substrate - subquery can help you index and troubleshoot your chain's data. subquery is designed to easily integrate with a custom substrate based chain.\n\nlearn how to integrate with your chain\n\nsupport and contribute\n\nhave a question or interested to know more or how you can contribute? we’d love to hear from you. please contact us via email or social media from the links below. need technical expertise? join our discord community and receive support from our passionate community members.\n\njoin the conversation on discord\ncontact us hello@subquery.network\nfollow us on social\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"GraphQL Schema",frontmatter:{summary:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict",meta:[{property:"og:url",content:"/uk/create/graphql.html"},{property:"og:title",content:"GraphQL Schema"},{property:"og:description",content:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/create/graphql.html",relativePath:"uk/create/graphql.md",key:"v-6dcc960d",path:"/uk/create/graphql/",headers:[{level:2,title:"Defining Entities",slug:"defining-entities",normalizedTitle:"defining entities",charIndex:21},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:30},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:931},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1282},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1186},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3290},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3759},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:4063},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5097},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1268},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6446},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7146}],readingTime:{minutes:3.9,words:1170},headersStr:"Defining Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL Schema\n\n\n# Defining Entities\n\nThe schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates the shape of your data from SubQuery. To learn more about how to write in GraphQL schema language, we recommend checking out Schemas and Types.\n\nImportant: When you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# Entities\n\nEach entity must define its required fields id with the type of ID!. It is used as the primary key and unique among all entities of the same type.\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field \n}\n\ntype Title @entity {\n  id: ID!  \n  name: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nWhen code generation is run, this will automatically create a getByName under the User model, and the foreign key field title will create a getByTitleId method, which both can directly be accessed in the mapping function.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from \"../types/models/User\"\nimport {Title} from \"../types/models/Title\"\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account] \n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID! \n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactCard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# graphql schema\n\n\n# defining entities\n\nthe schema.graphql file defines the various graphql schemas. due to the way that the graphql query language works, the schema file essentially dictates the shape of your data from subquery. to learn more about how to write in graphql schema language, we recommend checking out schemas and types.\n\nimportant: when you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# entities\n\neach entity must define its required fields id with the type of id!. it is used as the primary key and unique among all entities of the same type.\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field \n}\n\ntype title @entity {\n  id: id!  \n  name: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nwhen code generation is run, this will automatically create a getbyname under the user model, and the foreign key field title will create a getbytitleid method, which both can directly be accessed in the mapping function.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from \"../types/models/user\"\nimport {title} from \"../types/models/title\"\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account] \n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id! \n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactcard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/uk/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/create/introduction.html",relativePath:"uk/create/introduction.md",key:"v-67670071",path:"/uk/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2327}],readingTime:{minutes:1.76,words:527},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/uk/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/create/mapping.html",relativePath:"uk/create/mapping.md",key:"v-237fd8ed",path:"/uk/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3141},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4151},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5111},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5541},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6209},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5061},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6926},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10271},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11506},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11728}],readingTime:{minutes:6.93,words:2080},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from "@subql/types";\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n    // Create a new StarterEntity with the block hash as it\'s ID\n    const record = new starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from "ethers/lib/utils"; //Good way\nimport {utils} from "ethers" //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api.query.kitties.nextKittyId();\n    // return the Kitty type, input parameters types are AccountId and KittyIndex\n    const allKitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`Next kitty id ${nextKittyId}`)\n    //Custom rpc, set undefined to blockhash\n    const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined,nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from "@subql/types";\n\nexport async function handleblock(block: substrateblock): promise<void> {\n    // create a new starterentity with the block hash as it\'s id\n    const record = new starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from "ethers/lib/utils"; //good way\nimport {utils} from "ethers" //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api.query.kitties.nextkittyid();\n    // return the kitty type, input parameters types are accountid and kittyindex\n    const allkitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`next kitty id ${nextkittyid}`)\n    //custom rpc, set undefined to blockhash\n    const kittyprice = await api.rpc.kitties.getkittyprice(undefined,nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/uk/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/create/manifest.html",relativePath:"uk/create/manifest.md",key:"v-3a2d0547",path:"/uk/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:1998},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3223},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4540}],readingTime:{minutes:2.51,words:752},headersStr:"Network Filters Mapping Filters Custom Chains",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - see Running an Indexer\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - see running an indexer\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/uk/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/faqs/faqs.html",relativePath:"uk/faqs/faqs.md",key:"v-6e8c87ed",path:"/uk/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/uk/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/install/install.html",relativePath:"uk/install/install.md",key:"v-30ad7ebd",path:"/uk/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/uk/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/miscellaneous/ambassadors.html",relativePath:"uk/miscellaneous/ambassadors.md",key:"v-0841246e",path:"/uk/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/uk/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/miscellaneous/branding.html",relativePath:"uk/miscellaneous/branding.md",key:"v-daa61166",path:"/uk/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/uk/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/miscellaneous/contributing.html",relativePath:"uk/miscellaneous/contributing.md",key:"v-392eb7ed",path:"/uk/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/uk/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/miscellaneous/social_media.html",relativePath:"uk/miscellaneous/social_media.md",key:"v-6191ba26",path:"/uk/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/uk/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/publish/connect.html",relativePath:"uk/publish/connect.md",key:"v-420ef137",path:"/uk/publish/connect/",readingTime:{minutes:.61,words:182},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/uk/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/publish/publish.html",relativePath:"uk/publish/publish.md",key:"v-306008ed",path:"/uk/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1133},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. *We're almost there! We just need to deploy a new version of it. *\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. *we're almost there! we just need to deploy a new version of it. *\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/uk/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/publish/upgrade.html",relativePath:"uk/publish/upgrade.md",key:"v-21e7225a",path:"/uk/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/uk/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/query/query.html",relativePath:"uk/query/query.md",key:"v-7bc99189",path:"/uk/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/uk/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/query/graphql.html",relativePath:"uk/query/graphql.md",key:"v-ada9f2f2",path:"/uk/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/uk/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/quickstart/helloworld-hosted.html",relativePath:"uk/quickstart/helloworld-hosted.md",key:"v-01b4cdcd",path:"/uk/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/uk/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/quickstart/quickstart.html",relativePath:"uk/quickstart/quickstart.md",key:"v-77c86fed",path:"/uk/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2566},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3009},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3388},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3628},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3981},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4548},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5235}],readingTime:{minutes:3.22,words:967},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/uk/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/quickstart/helloworld-localhost.html",relativePath:"uk/quickstart/helloworld-localhost.md",key:"v-9ea17eea",path:"/uk/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"Step 1: Initialise project",slug:"step-1-initialise-project",normalizedTitle:"step 1: initialise project",charIndex:1455},{level:2,title:"Step 2: Install dependencies",slug:"step-2-install-dependencies",normalizedTitle:"step 2: install dependencies",charIndex:2035},{level:2,title:"Step 3: Generate code",slug:"step-3-generate-code",normalizedTitle:"step 3: generate code",charIndex:2477},{level:2,title:"Step 4: Build code",slug:"step-4-build-code",normalizedTitle:"step 4: build code",charIndex:3087},{level:2,title:"Step 5: Run Docker",slug:"step-5-run-docker",normalizedTitle:"step 5: run docker",charIndex:3319},{level:2,title:"Step 6: Browse playground",slug:"step-6-browse-playground",normalizedTitle:"step 6: browse playground",charIndex:4586},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:5027}],readingTime:{minutes:2.85,words:855},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Initialise project Step 2: Install dependencies Step 3: Generate code Step 4: Build code Step 5: Run Docker Step 6: Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Step 5: Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Step 6: Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# step 5: run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# step 6: browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/uk/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/quickstart/understanding-helloworld.html",relativePath:"uk/quickstart/understanding-helloworld.md",key:"v-7943c1f6",path:"/uk/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/uk/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/run/run.html",relativePath:"uk/run/run.md",key:"v-47b39cfd",path:"/uk/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3940},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4183}],readingTime:{minutes:2.57,words:772},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/uk/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/run/sandbox.html",relativePath:"uk/run/sandbox.md",key:"v-b128a8f6",path:"/uk/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/uk/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/tutorials_examples/howto.html",relativePath:"uk/tutorials_examples/howto.md",key:"v-2ca3ee26",path:"/uk/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri",meta:[{property:"og:url",content:"/uk/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/tutorials_examples/introduction.html",relativePath:"uk/tutorials_examples/introduction.md",key:"v-bd94cac2",path:"/uk/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:155}],readingTime:{minutes:.77,words:231},headersStr:"SubQuery Examples",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# SubQuery Examples\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# subquery examples\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/uk/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/tutorials_examples/terminology.html",relativePath:"uk/tutorials_examples/terminology.md",key:"v-3b041b6d",path:"/uk/tutorials_examples/terminology/",headers:[{level:2,title:"Terminology",slug:"terminology",normalizedTitle:"terminology",charIndex:2}],readingTime:{minutes:.49,words:147},headersStr:"Terminology",content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{frontmatter:{summary:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello",meta:[{property:"og:url",content:"/vi/"},{property:"og:description",content:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/",relativePath:"vi/README.md",key:"v-e894ac04",path:"/vi/",readingTime:{minutes:3.03,words:910},headersStr:null,content:"Welcome to SubQuery’s Docs\n\nExplore and transform your chain data to build intuitive dApps faster!\n\n\nQuick Start Guide\n\nUnderstand SubQuery by getting hands on with a traditional Hello World example. Using a template project within a Docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * The SubQuery Network\n   \n   SubQuery’s decentralised future. Read more about how indexers and consumers are rewarded.\n\n\nFAQ\n\n * What is SubQuery?\n   \n   SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n   \n   READ MORE\n * What is the best way to get started with SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n * How can I contribute or give feedback to SubQuery?\n   \n   We love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guidelines (coming soon).\n   \n   READ MORE\n * How much does it cost to host my project in SubQuery Projects?\n   \n   Hosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nIntegrating with your Custom Chain?\n\nWhether you're building a new parachain or an entirely new blockchain on Substrate - SubQuery can help you index and troubleshoot your chain's data. SubQuery is designed to easily integrate with a custom Substrate based chain.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nSupport and Contribute\n\nHave a question or interested to know more or how you can contribute? We’d love to hear from you. Please contact us via email or social media from the links below. Need technical expertise? Join our Discord community and receive support from our passionate community members.\n\nJOIN THE CONVERSATION ON DISCORD\nContact us hello@subquery.network\nFollow us on social\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"welcome to subquery’s docs\n\nexplore and transform your chain data to build intuitive dapps faster!\n\n\nquick start guide\n\nunderstand subquery by getting hands on with a traditional hello world example. using a template project within a docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * the subquery network\n   \n   subquery’s decentralised future. read more about how indexers and consumers are rewarded.\n\n\nfaq\n\n * what is subquery?\n   \n   subquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n   \n   read more\n * what is the best way to get started with subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n * how can i contribute or give feedback to subquery?\n   \n   we love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guidelines (coming soon).\n   \n   read more\n * how much does it cost to host my project in subquery projects?\n   \n   hosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nintegrating with your custom chain?\n\nwhether you're building a new parachain or an entirely new blockchain on substrate - subquery can help you index and troubleshoot your chain's data. subquery is designed to easily integrate with a custom substrate based chain.\n\nlearn how to integrate with your chain\n\nsupport and contribute\n\nhave a question or interested to know more or how you can contribute? we’d love to hear from you. please contact us via email or social media from the links below. need technical expertise? join our discord community and receive support from our passionate community members.\n\njoin the conversation on discord\ncontact us hello@subquery.network\nfollow us on social\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"GraphQL Schema",frontmatter:{summary:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict",meta:[{property:"og:url",content:"/vi/create/graphql.html"},{property:"og:title",content:"GraphQL Schema"},{property:"og:description",content:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/create/graphql.html",relativePath:"vi/create/graphql.md",key:"v-9cd12ba6",path:"/vi/create/graphql/",headers:[{level:2,title:"Defining Entities",slug:"defining-entities",normalizedTitle:"defining entities",charIndex:21},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:30},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:931},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1282},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1186},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3290},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3759},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:4063},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5097},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1268},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6446},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7146}],readingTime:{minutes:3.9,words:1170},headersStr:"Defining Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL Schema\n\n\n# Defining Entities\n\nThe schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates the shape of your data from SubQuery. To learn more about how to write in GraphQL schema language, we recommend checking out Schemas and Types.\n\nImportant: When you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# Entities\n\nEach entity must define its required fields id with the type of ID!. It is used as the primary key and unique among all entities of the same type.\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field \n}\n\ntype Title @entity {\n  id: ID!  \n  name: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nWhen code generation is run, this will automatically create a getByName under the User model, and the foreign key field title will create a getByTitleId method, which both can directly be accessed in the mapping function.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from \"../types/models/User\"\nimport {Title} from \"../types/models/Title\"\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account] \n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID! \n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactCard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# graphql schema\n\n\n# defining entities\n\nthe schema.graphql file defines the various graphql schemas. due to the way that the graphql query language works, the schema file essentially dictates the shape of your data from subquery. to learn more about how to write in graphql schema language, we recommend checking out schemas and types.\n\nimportant: when you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# entities\n\neach entity must define its required fields id with the type of id!. it is used as the primary key and unique among all entities of the same type.\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field \n}\n\ntype title @entity {\n  id: id!  \n  name: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nwhen code generation is run, this will automatically create a getbyname under the user model, and the foreign key field title will create a getbytitleid method, which both can directly be accessed in the mapping function.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from \"../types/models/user\"\nimport {title} from \"../types/models/title\"\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account] \n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id! \n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactcard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/vi/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/create/introduction.html",relativePath:"vi/create/introduction.md",key:"v-62e23092",path:"/vi/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2327}],readingTime:{minutes:1.76,words:527},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/vi/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/create/manifest.html",relativePath:"vi/create/manifest.md",key:"v-e7c9cde6",path:"/vi/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:1998},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3223},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4540}],readingTime:{minutes:2.51,words:752},headersStr:"Network Filters Mapping Filters Custom Chains",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - see Running an Indexer\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - see running an indexer\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/vi/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/create/mapping.html",relativePath:"vi/create/mapping.md",key:"v-674aad0d",path:"/vi/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3141},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4151},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5111},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5541},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6209},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5061},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6926},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10271},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11506},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11728}],readingTime:{minutes:6.93,words:2080},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from "@subql/types";\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n    // Create a new StarterEntity with the block hash as it\'s ID\n    const record = new starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from "ethers/lib/utils"; //Good way\nimport {utils} from "ethers" //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api.query.kitties.nextKittyId();\n    // return the Kitty type, input parameters types are AccountId and KittyIndex\n    const allKitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`Next kitty id ${nextKittyId}`)\n    //Custom rpc, set undefined to blockhash\n    const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined,nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from "@subql/types";\n\nexport async function handleblock(block: substrateblock): promise<void> {\n    // create a new starterentity with the block hash as it\'s id\n    const record = new starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from "ethers/lib/utils"; //good way\nimport {utils} from "ethers" //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api.query.kitties.nextkittyid();\n    // return the kitty type, input parameters types are accountid and kittyindex\n    const allkitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`next kitty id ${nextkittyid}`)\n    //custom rpc, set undefined to blockhash\n    const kittyprice = await api.rpc.kitties.getkittyprice(undefined,nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/vi/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/faqs/faqs.html",relativePath:"vi/faqs/faqs.md",key:"v-6989e673",path:"/vi/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/vi/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/install/install.html",relativePath:"vi/install/install.md",key:"v-fac8dafa",path:"/vi/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/vi/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/miscellaneous/ambassadors.html",relativePath:"vi/miscellaneous/ambassadors.md",key:"v-8b57cb62",path:"/vi/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/vi/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/miscellaneous/branding.html",relativePath:"vi/miscellaneous/branding.md",key:"v-3795786d",path:"/vi/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/vi/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/miscellaneous/social_media.html",relativePath:"vi/miscellaneous/social_media.md",key:"v-1809da8d",path:"/vi/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/vi/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/miscellaneous/contributing.html",relativePath:"vi/miscellaneous/contributing.md",key:"v-fbfd20e6",path:"/vi/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/vi/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/publish/connect.html",relativePath:"vi/publish/connect.md",key:"v-d805f606",path:"/vi/publish/connect/",readingTime:{minutes:.61,words:182},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/vi/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/publish/publish.html",relativePath:"vi/publish/publish.md",key:"v-fb63c69a",path:"/vi/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1133},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. *We're almost there! We just need to deploy a new version of it. *\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. *we're almost there! we just need to deploy a new version of it. *\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/vi/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/publish/upgrade.html",relativePath:"vi/publish/upgrade.md",key:"v-40fa8299",path:"/vi/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/vi/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/query/graphql.html",relativePath:"vi/query/graphql.md",key:"v-7636cee6",path:"/vi/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/vi/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/query/query.html",relativePath:"vi/query/query.md",key:"v-290cdc62",path:"/vi/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/vi/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/quickstart/helloworld-hosted.html",relativePath:"vi/quickstart/helloworld-hosted.md",key:"v-19ad78ad",path:"/vi/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/vi/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/quickstart/helloworld-localhost.html",relativePath:"vi/quickstart/helloworld-localhost.md",key:"v-33ab2251",path:"/vi/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"Step 1: Initialise project",slug:"step-1-initialise-project",normalizedTitle:"step 1: initialise project",charIndex:1455},{level:2,title:"Step 2: Install dependencies",slug:"step-2-install-dependencies",normalizedTitle:"step 2: install dependencies",charIndex:2035},{level:2,title:"Step 3: Generate code",slug:"step-3-generate-code",normalizedTitle:"step 3: generate code",charIndex:2477},{level:2,title:"Step 4: Build code",slug:"step-4-build-code",normalizedTitle:"step 4: build code",charIndex:3087},{level:2,title:"Step 5: Run Docker",slug:"step-5-run-docker",normalizedTitle:"step 5: run docker",charIndex:3319},{level:2,title:"Step 6: Browse playground",slug:"step-6-browse-playground",normalizedTitle:"step 6: browse playground",charIndex:4586},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:5027}],readingTime:{minutes:2.85,words:855},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Initialise project Step 2: Install dependencies Step 3: Generate code Step 4: Build code Step 5: Run Docker Step 6: Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Step 5: Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Step 6: Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# step 5: run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# step 6: browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/vi/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/quickstart/quickstart.html",relativePath:"vi/quickstart/quickstart.md",key:"v-3ac4ae1a",path:"/vi/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2566},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3009},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3388},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3628},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3981},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4548},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5235}],readingTime:{minutes:3.22,words:967},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/vi/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/quickstart/understanding-helloworld.html",relativePath:"vi/quickstart/understanding-helloworld.md",key:"v-7c7a576a",path:"/vi/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/vi/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/run/run.html",relativePath:"vi/run/run.md",key:"v-258149c3",path:"/vi/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3940},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4183}],readingTime:{minutes:2.57,words:772},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/vi/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/run/sandbox.html",relativePath:"vi/run/sandbox.md",key:"v-171babcb",path:"/vi/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/vi/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/tutorials_examples/howto.html",relativePath:"vi/tutorials_examples/howto.md",key:"v-131f5d4d",path:"/vi/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri",meta:[{property:"og:url",content:"/vi/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/tutorials_examples/introduction.html",relativePath:"vi/tutorials_examples/introduction.md",key:"v-24317c65",path:"/vi/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:155}],readingTime:{minutes:.77,words:231},headersStr:"SubQuery Examples",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# SubQuery Examples\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# subquery examples\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/vi/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/tutorials_examples/terminology.html",relativePath:"vi/tutorials_examples/terminology.md",key:"v-73d3498d",path:"/vi/tutorials_examples/terminology/",headers:[{level:2,title:"Terminology",slug:"terminology",normalizedTitle:"terminology",charIndex:2}],readingTime:{minutes:.49,words:147},headersStr:"Terminology",content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{frontmatter:{summary:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello",meta:[{property:"og:url",content:"/zh/"},{property:"og:description",content:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/",relativePath:"zh/README.md",key:"v-8fbc73c4",path:"/zh/",readingTime:{minutes:3.03,words:910},headersStr:null,content:"Welcome to SubQuery’s Docs\n\nExplore and transform your chain data to build intuitive dApps faster!\n\n\nQuick Start Guide\n\nUnderstand SubQuery by getting hands on with a traditional Hello World example. Using a template project within a Docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * The SubQuery Network\n   \n   SubQuery’s decentralised future. Read more about how indexers and consumers are rewarded.\n\n\nFAQ\n\n * What is SubQuery?\n   \n   SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n   \n   READ MORE\n * What is the best way to get started with SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n * How can I contribute or give feedback to SubQuery?\n   \n   We love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guidelines (coming soon).\n   \n   READ MORE\n * How much does it cost to host my project in SubQuery Projects?\n   \n   Hosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nIntegrating with your Custom Chain?\n\nWhether you're building a new parachain or an entirely new blockchain on Substrate - SubQuery can help you index and troubleshoot your chain's data. SubQuery is designed to easily integrate with a custom Substrate based chain.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nSupport and Contribute\n\nHave a question or interested to know more or how you can contribute? We’d love to hear from you. Please contact us via email or social media from the links below. Need technical expertise? Join our Discord community and receive support from our passionate community members.\n\nJOIN THE CONVERSATION ON DISCORD\nContact us hello@subquery.network\nFollow us on social\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"welcome to subquery’s docs\n\nexplore and transform your chain data to build intuitive dapps faster!\n\n\nquick start guide\n\nunderstand subquery by getting hands on with a traditional hello world example. using a template project within a docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * the subquery network\n   \n   subquery’s decentralised future. read more about how indexers and consumers are rewarded.\n\n\nfaq\n\n * what is subquery?\n   \n   subquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n   \n   read more\n * what is the best way to get started with subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n * how can i contribute or give feedback to subquery?\n   \n   we love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guidelines (coming soon).\n   \n   read more\n * how much does it cost to host my project in subquery projects?\n   \n   hosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nintegrating with your custom chain?\n\nwhether you're building a new parachain or an entirely new blockchain on substrate - subquery can help you index and troubleshoot your chain's data. subquery is designed to easily integrate with a custom substrate based chain.\n\nlearn how to integrate with your chain\n\nsupport and contribute\n\nhave a question or interested to know more or how you can contribute? we’d love to hear from you. please contact us via email or social media from the links below. need technical expertise? join our discord community and receive support from our passionate community members.\n\njoin the conversation on discord\ncontact us hello@subquery.network\nfollow us on social\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"GraphQL方案",frontmatter:{summary:"GraphQL方案 Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates ",meta:[{property:"og:url",content:"/zh/create/graphql.html"},{property:"og:title",content:"GraphQL方案"},{property:"og:description",content:"GraphQL方案 Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/create/graphql.html",relativePath:"zh/create/graphql.md",key:"v-4cb5e50d",path:"/zh/create/graphql/",headers:[{level:2,title:"Defining Entities",slug:"defining-entities",normalizedTitle:"defining entities",charIndex:16},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:25},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:926},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1277},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1181},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3285},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3754},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:4058},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5092},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1263},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6441},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7141}],readingTime:{minutes:3.9,words:1171},headersStr:"Defining Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL方案\n\n\n# Defining Entities\n\nThe schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates the shape of your data from SubQuery. To learn more about how to write in GraphQL schema language, we recommend checking out Schemas and Types.\n\nImportant: When you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# Entities\n\nEach entity must define its required fields id with the type of ID!. It is used as the primary key and unique among all entities of the same type.\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field \n}\n\ntype Title @entity {\n  id: ID!  \n  name: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nWhen code generation is run, this will automatically create a getByName under the User model, and the foreign key field title will create a getByTitleId method, which both can directly be accessed in the mapping function.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from \"../types/models/User\"\nimport {Title} from \"../types/models/Title\"\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account] \n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID! \n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactCard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# graphql方案\n\n\n# defining entities\n\nthe schema.graphql file defines the various graphql schemas. due to the way that the graphql query language works, the schema file essentially dictates the shape of your data from subquery. to learn more about how to write in graphql schema language, we recommend checking out schemas and types.\n\nimportant: when you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# entities\n\neach entity must define its required fields id with the type of id!. it is used as the primary key and unique among all entities of the same type.\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field \n}\n\ntype title @entity {\n  id: id!  \n  name: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nwhen code generation is run, this will automatically create a getbyname under the user model, and the foreign key field title will create a getbytitleid method, which both can directly be accessed in the mapping function.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from \"../types/models/user\"\nimport {title} from \"../types/models/title\"\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account] \n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id! \n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactcard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/zh/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/create/introduction.html",relativePath:"zh/create/introduction.md",key:"v-8de7f97e",path:"/zh/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2327}],readingTime:{minutes:1.76,words:527},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/zh/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/create/manifest.html",relativePath:"zh/create/manifest.md",key:"v-541b37d2",path:"/zh/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:1998},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3223},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4540}],readingTime:{minutes:2.51,words:752},headersStr:"Network Filters Mapping Filters Custom Chains",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - see Running an Indexer\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - see running an indexer\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/zh/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/create/mapping.html",relativePath:"zh/create/mapping.md",key:"v-026927ed",path:"/zh/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3141},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4151},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5111},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5541},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6209},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5061},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6926},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10271},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11506},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11728}],readingTime:{minutes:6.93,words:2080},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from "@subql/types";\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n    // Create a new StarterEntity with the block hash as it\'s ID\n    const record = new starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from "ethers/lib/utils"; //Good way\nimport {utils} from "ethers" //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api.query.kitties.nextKittyId();\n    // return the Kitty type, input parameters types are AccountId and KittyIndex\n    const allKitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`Next kitty id ${nextKittyId}`)\n    //Custom rpc, set undefined to blockhash\n    const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined,nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from "@subql/types";\n\nexport async function handleblock(block: substrateblock): promise<void> {\n    // create a new starterentity with the block hash as it\'s id\n    const record = new starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from "ethers/lib/utils"; //good way\nimport {utils} from "ethers" //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api.query.kitties.nextkittyid();\n    // return the kitty type, input parameters types are accountid and kittyindex\n    const allkitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`next kitty id ${nextkittyid}`)\n    //custom rpc, set undefined to blockhash\n    const kittyprice = await api.rpc.kitties.getkittyprice(undefined,nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/zh/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/faqs/faqs.html",relativePath:"zh/faqs/faqs.md",key:"v-39ce30bd",path:"/zh/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/zh/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/install/install.html",relativePath:"zh/install/install.md",key:"v-671a44e6",path:"/zh/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/zh/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/miscellaneous/ambassadors.html",relativePath:"zh/miscellaneous/ambassadors.md",key:"v-3bc0b2ce",path:"/zh/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/zh/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/miscellaneous/branding.html",relativePath:"zh/miscellaneous/branding.md",key:"v-723b4366",path:"/zh/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/zh/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/miscellaneous/contributing.html",relativePath:"zh/miscellaneous/contributing.md",key:"v-0501aa26",path:"/zh/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/zh/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/miscellaneous/social_media.html",relativePath:"zh/miscellaneous/social_media.md",key:"v-d8f0d426",path:"/zh/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/zh/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/publish/connect.html",relativePath:"zh/publish/connect.md",key:"v-44575ff2",path:"/zh/publish/connect/",readingTime:{minutes:.61,words:182},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/zh/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/publish/publish.html",relativePath:"zh/publish/publish.md",key:"v-67b53086",path:"/zh/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1133},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. *We're almost there! We just need to deploy a new version of it. *\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. *we're almost there! we just need to deploy a new version of it. *\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/zh/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/publish/upgrade.html",relativePath:"zh/publish/upgrade.md",key:"v-ea5c64ba",path:"/zh/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/zh/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/query/graphql.html",relativePath:"zh/query/graphql.md",key:"v-29ed5952",path:"/zh/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/zh/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/query/query.html",relativePath:"zh/query/query.md",key:"v-37f14c59",path:"/zh/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/zh/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/quickstart/helloworld-hosted.html",relativePath:"zh/quickstart/helloworld-hosted.md",key:"v-50bff266",path:"/zh/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/zh/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/quickstart/helloworld-localhost.html",relativePath:"zh/quickstart/helloworld-localhost.md",key:"v-9101a14a",path:"/zh/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"Step 1: Initialise project",slug:"step-1-initialise-project",normalizedTitle:"step 1: initialise project",charIndex:1455},{level:2,title:"Step 2: Install dependencies",slug:"step-2-install-dependencies",normalizedTitle:"step 2: install dependencies",charIndex:2035},{level:2,title:"Step 3: Generate code",slug:"step-3-generate-code",normalizedTitle:"step 3: generate code",charIndex:2477},{level:2,title:"Step 4: Build code",slug:"step-4-build-code",normalizedTitle:"step 4: build code",charIndex:3087},{level:2,title:"Step 5: Run Docker",slug:"step-5-run-docker",normalizedTitle:"step 5: run docker",charIndex:3319},{level:2,title:"Step 6: Browse playground",slug:"step-6-browse-playground",normalizedTitle:"step 6: browse playground",charIndex:4586},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:5027}],readingTime:{minutes:2.85,words:855},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Initialise project Step 2: Install dependencies Step 3: Generate code Step 4: Build code Step 5: Run Docker Step 6: Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Step 5: Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Step 6: Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# step 5: run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# step 6: browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/zh/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/quickstart/quickstart.html",relativePath:"zh/quickstart/quickstart.md",key:"v-2c2604bd",path:"/zh/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2566},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3009},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3388},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3628},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3981},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4548},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5235}],readingTime:{minutes:3.22,words:967},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/zh/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/quickstart/understanding-helloworld.html",relativePath:"zh/quickstart/understanding-helloworld.md",key:"v-31d49c56",path:"/zh/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/zh/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/run/sandbox.html",relativePath:"zh/run/sandbox.md",key:"v-63936655",path:"/zh/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/zh/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/run/run.html",relativePath:"zh/run/run.md",key:"v-5f7fb3cd",path:"/zh/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3940},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4183}],readingTime:{minutes:2.57,words:772},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/zh/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/tutorials_examples/howto.html",relativePath:"zh/tutorials_examples/howto.md",key:"v-58f735ed",path:"/zh/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/zh/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/tutorials_examples/terminology.html",relativePath:"zh/tutorials_examples/terminology.md",key:"v-cc84cb26",path:"/zh/tutorials_examples/terminology/",headers:[{level:2,title:"Terminology",slug:"terminology",normalizedTitle:"terminology",charIndex:2}],readingTime:{minutes:.49,words:147},headersStr:"Terminology",content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri",meta:[{property:"og:url",content:"/zh/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/tutorials_examples/introduction.html",relativePath:"zh/tutorials_examples/introduction.md",key:"v-aff4ed22",path:"/zh/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:155}],readingTime:{minutes:.77,words:231},headersStr:"SubQuery Examples",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# SubQuery Examples\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# subquery examples\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{frontmatter:{summary:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello",meta:[{property:"og:url",content:"/ja/"},{property:"og:description",content:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/",relativePath:"ja/README.md",key:"v-2a03c37e",path:"/ja/",readingTime:{minutes:3.03,words:910},headersStr:null,content:"Welcome to SubQuery’s Docs\n\nExplore and transform your chain data to build intuitive dApps faster!\n\n\nQuick Start Guide\n\nUnderstand SubQuery by getting hands on with a traditional Hello World example. Using a template project within a Docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * The SubQuery Network\n   \n   SubQuery’s decentralised future. Read more about how indexers and consumers are rewarded.\n\n\nFAQ\n\n * What is SubQuery?\n   \n   SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n   \n   READ MORE\n * What is the best way to get started with SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n * How can I contribute or give feedback to SubQuery?\n   \n   We love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guidelines (coming soon).\n   \n   READ MORE\n * How much does it cost to host my project in SubQuery Projects?\n   \n   Hosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nIntegrating with your Custom Chain?\n\nWhether you're building a new parachain or an entirely new blockchain on Substrate - SubQuery can help you index and troubleshoot your chain's data. SubQuery is designed to easily integrate with a custom Substrate based chain.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nSupport and Contribute\n\nHave a question or interested to know more or how you can contribute? We’d love to hear from you. Please contact us via email or social media from the links below. Need technical expertise? Join our Discord community and receive support from our passionate community members.\n\nJOIN THE CONVERSATION ON DISCORD\nContact us hello@subquery.network\nFollow us on social\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"welcome to subquery’s docs\n\nexplore and transform your chain data to build intuitive dapps faster!\n\n\nquick start guide\n\nunderstand subquery by getting hands on with a traditional hello world example. using a template project within a docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * the subquery network\n   \n   subquery’s decentralised future. read more about how indexers and consumers are rewarded.\n\n\nfaq\n\n * what is subquery?\n   \n   subquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n   \n   read more\n * what is the best way to get started with subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n * how can i contribute or give feedback to subquery?\n   \n   we love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guidelines (coming soon).\n   \n   read more\n * how much does it cost to host my project in subquery projects?\n   \n   hosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nintegrating with your custom chain?\n\nwhether you're building a new parachain or an entirely new blockchain on substrate - subquery can help you index and troubleshoot your chain's data. subquery is designed to easily integrate with a custom substrate based chain.\n\nlearn how to integrate with your chain\n\nsupport and contribute\n\nhave a question or interested to know more or how you can contribute? we’d love to hear from you. please contact us via email or social media from the links below. need technical expertise? join our discord community and receive support from our passionate community members.\n\njoin the conversation on discord\ncontact us hello@subquery.network\nfollow us on social\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{title:"GraphQL Schema",frontmatter:{summary:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict",meta:[{property:"og:url",content:"/ja/create/graphql.html"},{property:"og:title",content:"GraphQL Schema"},{property:"og:description",content:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/create/graphql.html",relativePath:"ja/create/graphql.md",key:"v-045024ad",path:"/ja/create/graphql/",headers:[{level:2,title:"Defining Entities",slug:"defining-entities",normalizedTitle:"defining entities",charIndex:21},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:30},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:931},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1282},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1186},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3290},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3759},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:4063},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5097},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1268},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6446},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7146}],readingTime:{minutes:3.9,words:1170},headersStr:"Defining Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL Schema\n\n\n# Defining Entities\n\nThe schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates the shape of your data from SubQuery. To learn more about how to write in GraphQL schema language, we recommend checking out Schemas and Types.\n\nImportant: When you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# Entities\n\nEach entity must define its required fields id with the type of ID!. It is used as the primary key and unique among all entities of the same type.\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field \n}\n\ntype Title @entity {\n  id: ID!  \n  name: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nWhen code generation is run, this will automatically create a getByName under the User model, and the foreign key field title will create a getByTitleId method, which both can directly be accessed in the mapping function.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from \"../types/models/User\"\nimport {Title} from \"../types/models/Title\"\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account] \n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID! \n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactCard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# graphql schema\n\n\n# defining entities\n\nthe schema.graphql file defines the various graphql schemas. due to the way that the graphql query language works, the schema file essentially dictates the shape of your data from subquery. to learn more about how to write in graphql schema language, we recommend checking out schemas and types.\n\nimportant: when you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# entities\n\neach entity must define its required fields id with the type of id!. it is used as the primary key and unique among all entities of the same type.\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field \n}\n\ntype title @entity {\n  id: id!  \n  name: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nwhen code generation is run, this will automatically create a getbyname under the user model, and the foreign key field title will create a getbytitleid method, which both can directly be accessed in the mapping function.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from \"../types/models/user\"\nimport {title} from \"../types/models/title\"\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account] \n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id! \n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactcard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{},updateTime:"September 23, 2021 02:20",updateTimeStamp:1632363655e3,createTime:"September 23, 2021 02:20",createTimeStamp:1632363655e3,contributors:[]},{frontmatter:{layout:"Blog",summary:"",meta:[{property:"og:url",content:"/article/"},{property:"og:type",content:"website"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/article/",key:"v-6453f364",path:"/article/",readingTime:{minutes:0,words:0},headersStr:null,content:"",normalizedContent:"",charsets:{}},{frontmatter:{layout:"Blog",summary:"",meta:[{property:"og:url",content:"/star/"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/star/",key:"v-4340f7e8",path:"/star/",readingTime:{minutes:0,words:0},headersStr:null,content:"",normalizedContent:"",charsets:{}},{frontmatter:{layout:"Blog",summary:"",meta:[{property:"og:url",content:"/encrypt/"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/encrypt/",key:"v-7d484ebf",path:"/encrypt/",readingTime:{minutes:0,words:0},headersStr:null,content:"",normalizedContent:"",charsets:{}},{frontmatter:{layout:"Blog",summary:"",meta:[{property:"og:url",content:"/slide/"},{property:"og:type",content:"article"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/slide/",key:"v-2470be33",path:"/slide/",readingTime:{minutes:0,words:0},headersStr:null,content:"",normalizedContent:"",charsets:{}},{frontmatter:{layout:"Blog",summary:"",meta:[{property:"og:url",content:"/timeline/"},{property:"og:type",content:"website"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/timeline/",key:"v-6319eb4e",path:"/timeline/",readingTime:{minutes:0,words:0},headersStr:null,content:"",normalizedContent:"",charsets:{}},{frontmatter:{layout:"Blog",title:"Tag",summary:"",meta:[{property:"og:url",content:"/tag/"},{property:"og:type",content:"website"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tag/",key:"v-b1564aac",path:"/tag/",readingTime:{minutes:0,words:0},headersStr:null,content:"",normalizedContent:"",charsets:{}},{frontmatter:{layout:"Blog",title:"Category",summary:"",meta:[{property:"og:url",content:"/category/"},{property:"og:type",content:"website"},{property:"og:locale",content:"English"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/category/",key:"v-28e6393c",path:"/category/",readingTime:{minutes:0,words:0},headersStr:null,content:"",normalizedContent:"",charsets:{}}],themeConfig:{logo:"/assets/img/logo.png",logoLink:"https://subquery.network",lastUpdated:!0,nav:[{text:"Explorer",link:"https://explorer.subquery.network/",target:"_blank",rel:""},{text:"Projects",link:"https://project.subquery.network/",target:"_blank",rel:""},{text:"Documentation",link:"/"},{text:"GitHub",link:"https://github.com/subquery/subql",target:"_blank",rel:""}],sidebarDepth:2,themeColor:!1,sidebar:[{title:"Welcome to SubQuery",path:"/",collapsable:!0},{title:"Quick Start Guide",path:"/quickstart/quickstart",collapsable:!0,children:["/quickstart/quickstart.md","/quickstart/helloworld-localhost.md","/quickstart/understanding-helloworld.md","/quickstart/helloworld-hosted.md"]},{title:"Installation",path:"/install/install",collapsable:!0,children:["/install/install.md"]},{title:"Create a Project",path:"/create/introduction",collapsable:!0,children:["/create/introduction.md","/create/manifest.md","/create/graphql.md","/create/mapping.md"]},{title:"Run a Project",path:"/run/run",collapsable:!0,children:["/run/run.md","/run/sandbox.md"]},{title:"Publish a Project",path:"/publish/publish",collapsable:!0,children:["/publish/publish.md","/publish/upgrade.md","/publish/connect.md"]},{title:"Query your Data",path:"/query/query",collapsable:!0,children:["/query/query.md","/query/graphql.md"]},{title:"Tutorials & Examples",path:"/tutorials_examples/introduction",collapsable:!0,children:["/tutorials_examples/introduction","/tutorials_examples/block-height.md","/tutorials_examples/batch-size.md","/tutorials_examples/run-indexer.md","/tutorials_examples/dictionary.md","/tutorials_examples/debug-projects.md","/tutorials_examples/terminology.md"]},{title:"FAQs",path:"/faqs/faqs.md",collapsable:!0,children:[]},{title:"Miscellaneous",path:"/miscellaneous/contributing",collapsable:!0,children:["/miscellaneous/contributing.md","/miscellaneous/social_media.md","/miscellaneous/branding.md","/miscellaneous/ambassadors.md"]},{title:"References",path:"/references/references",collapsable:!0,children:["/references/references.md"]}],locales:{"/":{lang:"en-US",selectText:"Language",label:"English",ariaLabel:"Select language",meta:{contributor:"Contributors",editLink:"Edit this page",updateTime:"Last update"},themeColor:{themeColor:"Theme Color",themeMode:"Theme Mode"},encrypt:{title:"Please enter password",errorHint:"Please enter the corrent password!"},error404:{hint:["There’s nothing here.","How did we get here?","That’s a Four-Oh-Four.","Looks like we've got some broken links."],back:"Go back",home:"Take me home"},blog:{article:"Articles",articleList:"Article List",category:"Category",tag:"Tags",timeline:"Timeline",timelineText:"Yesterday Once More!",allText:"All",intro:"Personal Intro",star:"Star",slides:"Slides",encrypt:"Encrypted"}}}},locales:{"/":{lang:"English",title:"SubQuery Docs",description:"Explore and transform your chain data to build intuitive dApps faster!.",path:"/"}}};t(161);const Nn={"/zh/":{backToTop:"返回顶部",pagination:{prev:"上一页",next:"下一页",navigate:"跳转到",button:"前往",errorText:"请输入 1 到 $page 之前的页码！"}},"/en/":{backToTop:"Back to top",pagination:{prev:"Prev",next:"Next",navigate:"Jump to",button:"Go",errorText:"Please enter a number between 1 and $page !"}},"/de/":{backToTop:"Zurück nach oben.",pagination:{prev:"Vorheriges",next:"Nächstes",navigate:"Springe zu",button:"Los",errorText:"Bitte gib eine Nummer zwischen 1 und $page ein!"}},"/vi/":{backToTop:"Trở lại đầu trang",pagination:{prev:"Bài kế",next:"Bài trước",navigate:"Đi đến",button:"Đi",errorText:"Xin hãy nhập 1 số từ 1 đến $page !"}},"/":{backToTop:"Back to top",pagination:{prev:"Prev",next:"Next",navigate:"Jump to",button:"Go",errorText:"Please enter a number between 1 and $page !"}}};let Rn;var Mn=o.a.extend({name:"BackToTop",props:{threshold:{type:Number,default:300}},data:()=>({scrollTop:0}),computed:{thresholdDistance(){return"number"==typeof this.$themeConfig.backToTop?this.$themeConfig.backToTop:this.threshold},isDisplay(){const e=!1!==this.$themeConfig.backToTop,n=this.$page.frontmatter.backToTop;return(n||e&&!1!==n)&&this.scrollTop>this.thresholdDistance},hint(){return Nn[this.$localePath||"/"].backToTop}},mounted(){this.scrollTop=this.getScrollTop(),Rn=Tn()(()=>{this.scrollTop=this.getScrollTop()},100),window.addEventListener("scroll",Rn)},beforeDestroy(){window.removeEventListener("scroll",Rn)},methods:{getScrollTop:()=>window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,scrollToTop(){window.scrollTo({top:0,behavior:"smooth"}),this.scrollTop=0}}}),Wn=(t(162),Object(Hn.a)(Mn,(function(){var e=this.$createElement,n=this._self._c||e;return n("transition",{attrs:{name:"fade"}},[this.isDisplay?n("button",{staticClass:"back-to-top",attrs:{"aria-label":this.hint,"data-balloon-pos":"left"},on:{click:this.scrollToTop}},[n("svg",{attrs:{viewBox:"0 0 1024 1024",xmlns:"http://www.w3.org/2000/svg"}},[n("path",{attrs:{d:"M512 0C229.517 0 0 229.517 0 512s227.752 512 512 512c282.483 0 512-227.752 512-512C1024 229.517 794.483\n      0 512 0zM351.338 271.89h305.434c14.125 0 26.483 12.358 26.483 26.482s-12.358 26.483-26.483\n      26.483H351.338c-14.124 0-26.483-12.358-26.483-26.483 0-15.89 12.359-26.482 26.483-26.482z\n      m331.917 303.669c-12.358 12.358-33.545 12.358-45.903 0L531.42 471.393v270.124c0 14.124-12.359\n      26.483-26.483 26.483s-26.483-12.359-26.483-26.483v-271.89l-105.93 104.166c-12.36 12.359-33.546 12.359-45.904\n      0-12.359-12.359-12.359-31.78 0-45.903l155.365-151.835c7.062-7.062 14.124-8.827 22.952-8.827s15.89 3.53 22.952\n      8.827L683.255 527.89c12.359 15.89 12.359 35.31 0 47.669z",fill:"currentColor"}})])]):this._e()])}),[],!1,null,null,null).exports),Bn=o.a.extend({name:"Badge",functional:!0,props:{type:{type:String,default:"tip"},text:{type:String,default:""},vertical:{type:String,default:"top"},color:{type:String,default:""}},render(e,{props:n,slots:t}){const o={class:["badge",n.type],style:{verticalAlign:n.vertical}};return n.color&&(o.class.push("diy"),o.style.backgroundColor=n.color,o["data-color"]=n.color),e("span",o,n.text||t().default)}}),Fn=(t(163),Object(Hn.a)(Bn,void 0,void 0,!1,null,"7b453e57",null).exports),Un=o.a.extend({name:"BreadCrumb",computed:{enable(){const e=!1!==this.$themeConfig.breadcrumb,n=this.$page.frontmatter.breadcrumb;return(e&&!1!==n||!0===n)&&this.config.length>1},iconEnable(){const e=!1!==this.$themeConfig.breadcrumbIcon,n=this.$page.frontmatter.breadcrumbIcon;return this.enable&&(e&&!1!==n||!0===n)},iconPrefix(){const{iconPrefix:e}=this.$themeConfig;return""===e?"":e||"icon-"},config(){const e=[],{pages:n}=this.$site,t=this.getLinks(this.$route);for(let o=1;o<t.length;o++)for(let r=0;r<n.length;r++){const a=n[r];if(a.path===t[o]){e.push({title:a.title,icon:a.frontmatter.icon,url:a.path});break}}return e}},methods:{getLinks(e){const n=e.path.split("/"),t=[];let o="";return n.forEach((e,r)=>{r!==n.length-1?(o+=e+"/",t.push(o)):""!==e&&(o+=e,t.push(o))}),t}}}),Yn=(t(164),Object(Hn.a)(Un,(function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("nav",{staticClass:"breadcrumb",class:{disable:!e.enable}},[e.enable?t("ol",{attrs:{vocab:"https://schema.org/",typeof:"BreadcrumbList"}},e._l(e.config,(function(n,o){return t("li",{key:n.url,class:{"is-active":e.config.length-1===o},attrs:{property:"itemListElement",typeof:"ListItem"}},[t("RouterLink",{attrs:{to:n.url,property:"item",typeof:"WebPage"}},[n.icon&&e.iconEnable?t("i",{class:"iconfont "+e.iconPrefix+n.icon}):e._e(),e._v(" "),t("span",{attrs:{property:"name"}},[e._v(e._s(n.title))])]),e._v(" "),t("meta",{attrs:{property:"position",content:o+1}})],1)})),0):e._e()])}),[],!1,null,null,null).exports),Vn=o.a.extend({name:"CodeGroup",data:()=>({codeTabs:[],activeTabIndex:-1}),watch:{activeTabIndex(e){this.activateCodeTab(e)}},mounted(){this.loadTabs()},methods:{loadTabs(){this.codeTabs=(this.$slots.default||[]).filter(e=>Boolean(e.componentOptions)).map((e,n)=>{const t=e.componentOptions.propsData;return t.active&&(this.activeTabIndex=n),{title:t.title,element:e.elm}}),-1===this.activeTabIndex&&this.codeTabs.length>0&&(this.activeTabIndex=0),this.activateCodeTab(0)},changeCodeTab(e){this.activeTabIndex=e},keyDownHandler(e,n){" "===e.key||"Enter"===e.key?(e.preventDefault(),this.activeTabIndex=n):"ArrowRight"===e.key?(e.preventDefault(),n+1<this.codeTabs.length&&(this.activeTabIndex=n+1,this.$refs.tab[n+1].focus())):"ArrowLeft"===e.key&&(e.preventDefault(),n-1>=0&&(this.activeTabIndex=n-1,this.$refs.tab[n-1].focus()))},activateCodeTab(e){this.codeTabs.forEach((n,t)=>{const{element:o}=n;o&&(e===t?o.classList.add("active"):o.classList.remove("active"))})}}}),Jn=(t(165),Object(Hn.a)(Vn,(function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("ClientOnly",[t("div",{staticClass:"code-group"},[t("div",{staticClass:"code-group-nav",attrs:{"v:if":"codeTabs.length"}},e._l(e.codeTabs,(function(n,o){return t("button",{key:n.title,ref:"tab",refInFor:!0,staticClass:"code-group-nav-tab",class:{active:o===e.activeTabIndex},attrs:{"aria-pressed":o===e.activeTabIndex,"aria-expanded":o===e.activeTabIndex},domProps:{textContent:e._s(n.title)},on:{click:function(n){return e.changeCodeTab(o)},keydown:function(n){return e.keyDownHandler(n,o)}}})})),0),e._v(" "),e._t("default"),e._v(" "),e.codeTabs.length?e._e():t("pre",{staticClass:"hints",domProps:{textContent:e._s("// Make sure to add code blocks to your code group")}})],2)])}),[],!1,null,null,null).exports),$n=o.a.extend({name:"CodeGroupItem",props:{title:{type:String,required:!0},active:{type:Boolean,required:!1,default:!1}},mounted(){this.$parent&&this.$parent.loadTabs&&this.$parent.loadTabs()}}),Kn=(t(166),Object(Hn.a)($n,(function(){var e=this.$createElement;return(this._self._c||e)("div",{staticClass:"code-group-item",class:{active:this.active},attrs:{"aria-selected":this.active}},[this._t("default")],2)}),[],!1,null,null,null).exports),Zn=o.a.extend({name:"Pagination",model:{prop:"currentPage",event:"change"},props:{total:{type:Number,default:10},perPage:{type:Number,default:10},currentPage:{type:Number,default:1}},data:()=>({input:""}),computed:{totalPages(){return Math.ceil(this.total/this.perPage)},enable(){return Boolean(this.totalPages)&&1!==this.totalPages},displayLeftEllipsis(){return!(this.totalPages<7)&&this.currentPage>4},displayRightEllipsis(){return!(this.totalPages<7)&&this.currentPage<this.totalPages-3},indexs(){const{currentPage:e,totalPages:n}=this;let t=1,o=n;const r=[];n>=7&&(e<=4&&e<n-3?(t=1,o=5):e>4&&e>=n-3?(o=n,t=n-4):n>7&&(t=e-2,o=e+2));for(let e=t;e<=o;e++)r.push(e);return r},i18n(){return Nn[this.$localePath||"/"].pagination}},mounted(){const{index:e}=this.$route.query;this.navigate(e?Number(e):1)},methods:{navigate(e){const n=Object.assign({},this.$route.query);n.page===e.toString()||1===e&&!n.page||(this.$emit("change",e),1===e?delete n.page:n.page=e.toString(),this.$router.push({path:this.$route.path,query:n}))},jumpPage(e){const n=parseInt(e);n<=this.totalPages&&n>0?this.navigate(n):alert(this.i18n.errorText.replace(/\$page/g,this.totalPages.toString()))}}}),Xn=(t(167),Object(Hn.a)(Zn,(function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("div",{staticClass:"pagination-wrapper"},[e.enable?t("div",{staticClass:"pagination-list"},[t("div",{staticClass:"btn-group"},[e.currentPage>1?t("div",{staticClass:"prev",attrs:{role:"navigation",unselectable:"on"},on:{click:function(n){return e.navigate(e.currentPage-1)}}},[e._v("\n        "+e._s(e.i18n.prev)+"\n      ")]):e._e(),e._v(" "),e.displayLeftEllipsis?t("div",{attrs:{role:"navigation"},on:{click:function(n){return e.navigate(1)}}},[e._v("\n        1\n      ")]):e._e(),e._v(" "),e.displayLeftEllipsis?t("div",{staticClass:"ellipsis"},[e._v("...")]):e._e(),e._v(" "),e._l(e.indexs,(function(n){return t("div",{key:n,class:{active:e.currentPage===n},attrs:{role:"navigation"},on:{click:function(t){return e.navigate(n)}}},[e._v("\n        "+e._s(n)+"\n      ")])})),e._v(" "),e.displayRightEllipsis?t("div",{staticClass:"ellipsis"},[e._v("...")]):e._e(),e._v(" "),e.displayRightEllipsis?t("div",{attrs:{role:"navigation"},on:{click:function(n){return e.navigate(e.totalPages)}}},[e._v("\n        "+e._s(e.totalPages)+"\n      ")]):e._e(),e._v(" "),e.currentPage<e.totalPages?t("div",{staticClass:"next",attrs:{role:"navigation"},on:{click:function(n){return e.navigate(e.currentPage+1)}}},[e._v("\n        "+e._s(e.i18n.next)+"\n      ")]):e._e()],2),e._v(" "),t("div",{staticClass:"navigate-wrapper"},[t("label",{attrs:{for:"navigation-text"}},[e._v(e._s(e.i18n.navigate)+": ")]),e._v(" "),t("input",{directives:[{name:"model",rawName:"v-model",value:e.input,expression:"input"}],attrs:{id:"navigation-text",type:"text"},domProps:{value:e.input},on:{keypress:function(n){return!n.type.indexOf("key")&&e._k(n.keyCode,"enter",13,n.key,"Enter")?null:e.jumpPage(e.input)},input:function(n){n.target.composing||(e.input=n.target.value)}}}),e._v(" "),t("button",{staticClass:"navigate",attrs:{role:"navigation",title:e.i18n.button},on:{click:function(n){return e.jumpPage(e.input)}}},[e._v("\n        "+e._s(e.i18n.button)+"\n      ")])])]):e._e()])}),[],!1,null,null,null).exports),et=t(8),nt=o.a.extend({name:"ScreenFull",data:()=>({canFullscreen:!1,isFullscreen:!1}),mounted(){this.canFullscreen=et.isEnabled&&!1!==this.$themeConfig.fullscreen},methods:{click(){et.isEnabled&&et.toggle().then(()=>{this.isFullscreen=et.isFullscreen})}}}),tt=(t(168),Object(Hn.a)(nt,(function(){var e=this.$createElement,n=this._self._c||e;return this.canFullscreen?n("button",{class:this.isFullscreen?"cancel-full-screen":"full-screen",attrs:{"aria-pressed":this.isFullscreen},on:{click:this.click}},[n("svg",{attrs:{viewBox:"0 0 1024 1024",xmlns:"http://www.w3.org/2000/svg"}},[this.isFullscreen?n("path",{attrs:{d:"M778.46755555 78.62044445H247.92177778c-102.51377778 0-186.02666667 83.51288889-186.02666667 186.02666666v530.432c0 102.51377778 83.51288889 186.02666667 186.02666667 186.02666667h530.432c102.51377778 0 186.70933333-83.51288889 186.02666667-186.02666667V264.64711111c0.11377778-102.62755555-83.39911111-186.02666667-185.9128889-186.02666666zM250.88 574.35022222h171.12177778c23.32444445 0 43.12177778 19.11466667 43.80444444 43.80444445v171.12177778c0 24.00711111-19.11466667 43.12177778-43.12177777 43.12177777-12.06044445 0-22.64177778-5.00622222-30.37866667-12.74311111s-12.74311111-19.11466667-12.74311111-30.37866666v-66.44622223L224.59733333 877.90933333c-16.95288889 16.95288889-44.60088889 16.95288889-61.55377778 0-16.95288889-16.95288889-16.95288889-44.60088889 0-61.55377778l154.96533334-154.96533333h-66.44622222c-24.00711111 0-43.12177778-19.11466667-43.12177778-43.12177777 0-24.12088889 18.432-43.91822222 42.43911111-43.91822223z m521.89866667-98.87288889H601.65688889c-23.32444445 0-43.12177778-19.11466667-43.80444444-43.80444444V260.55111111c0-24.00711111 19.11466667-43.12177778 43.12177777-43.12177778 12.06044445 0 22.64177778 5.00622222 30.37866667 12.74311112s12.74311111 19.11466667 12.74311111 30.37866666v66.44622222l154.96533333-154.96533333c16.95288889-16.95288889 44.60088889-16.95288889 61.55377778 0 16.95288889 16.95288889 16.95288889 44.60088889 0 61.55377778L705.536 388.55111111h66.44622222c24.00711111 0 43.12177778 19.11466667 43.12177778 43.12177778 0.11377778 24.00711111-18.31822222 43.80444445-42.32533333 43.80444444z"}}):n("path",{attrs:{d:"M762.77333333 90.24H265.49333333c-96.10666667 0-174.4 78.29333333-174.4 174.4v497.28c0 96.10666667 78.29333333 174.4 174.4 174.4h497.28c96.10666667 0 175.04-78.29333333 174.4-174.4V264.64c0-96.21333333-78.18666667-174.4-174.4-174.4z m-387.2 761.17333333H215.04c-21.86666667 0-40.42666667-17.92-41.06666667-41.06666666V649.92c0-22.50666667 17.92-40.42666667 40.42666667-40.42666667 11.30666667 0 21.22666667 4.69333333 28.48 11.94666667 7.25333333 7.25333333 11.94666667 17.92 11.94666667 28.48v62.29333333l145.28-145.28c15.89333333-15.89333333 41.81333333-15.89333333 57.70666666 0 15.89333333 15.89333333 15.89333333 41.81333333 0 57.70666667L312.53333333 769.92h62.29333334c22.50666667 0 40.42666667 17.92 40.42666666 40.42666667s-17.17333333 41.06666667-39.68 41.06666666z m274.66666667-685.65333333H810.66666667c21.86666667 0 40.42666667 17.92 41.06666666 41.06666667v160.42666666c0 22.50666667-17.92 40.42666667-40.42666666 40.42666667-11.30666667 0-21.22666667-4.69333333-28.48-11.94666667-7.25333333-7.25333333-11.94666667-17.92-11.94666667-28.48V305.06666667L625.6 450.34666667c-15.89333333 15.89333333-41.81333333 15.89333333-57.70666667 0-15.89333333-15.89333333-15.89333333-41.81333333 0-57.70666667l145.28-145.28h-62.29333333c-22.50666667 0-40.42666667-17.92-40.42666667-40.42666667s17.17333333-41.17333333 39.78666667-41.17333333z"}})])]):this._e()}),[],!1,null,null,null).exports);var ot=({Vue:e})=>{e.component("BackToTop",Wn),e.component("Badge",Fn),e.component("BreadCrumb",Yn),e.component("CodeGroup",Jn),e.component("CodeGroupItem",Kn),e.component("Pagination",Xn),e.component("ScreenFull",tt)};class rt{constructor(e){this.registration=e}update(){return this.registration.update()}skipWaiting(){const e=this.registration.waiting;return e?(console.log("[PWA]: Execute worker.skipWaiting()."),new Promise((n,t)=>{const o=new MessageChannel;o.port1.onmessage=e=>{console.log("[PWA]: Finish worker.skipWaiting()."),e.data.error?t(e.data.error):n(e.data)},e.postMessage({type:"skip-waiting"},[o.port2])})):Promise.resolve()}}var at=Object(Hn.a)({},(function(){var e=this.$createElement,n=this._self._c||e;return n("svg",{staticClass:"icon icon-arrow-left",attrs:{xmlns:"http://www.w3.org/2000/svg",viewBox:"0 0 512 512"}},[n("path",{attrs:{d:"M401.4 224h-214l83-79.4c11.9-12.5 11.9-32.7 0-45.2s-31.2-12.5-43.2 0L89 233.4c-6 5.8-9 13.7-9 22.4v.4c0 8.7 3 16.6 9 22.4l138.1 134c12 12.5 31.3 12.5 43.2 0 11.9-12.5 11.9-32.7 0-45.2l-83-79.4h214c16.9 0 30.6-14.3 30.6-32 .1-18-13.6-32-30.5-32z"}})])}),[],!1,null,null,null).exports,it=Object(Hn.a)({},(function(){var e=this.$createElement,n=this._self._c||e;return n("svg",{staticClass:"icon icon-arrow-right",attrs:{xmlns:"http://www.w3.org/2000/svg",viewBox:"0 0 512 512"}},[n("path",{attrs:{d:"M284.9 412.6l138.1-134c6-5.8 9-13.7 9-22.4v-.4c0-8.7-3-16.6-9-22.4l-138.1-134c-12-12.5-31.3-12.5-43.2 0-11.9 12.5-11.9 32.7 0 45.2l83 79.4h-214c-17 0-30.7 14.3-30.7 32 0 18 13.7 32 30.6 32h214l-83 79.4c-11.9 12.5-11.9 32.7 0 45.2 12 12.5 31.3 12.5 43.3 0z"}})])}),[],!1,null,null,null).exports,st=Object(Hn.a)({},(function(){var e=this.$createElement,n=this._self._c||e;return n("svg",{staticClass:"icon close-icon",attrs:{width:"23",height:"22",xmlns:"http://www.w3.org/2000/svg"}},[n("path",{attrs:{"fill-rule":"evenodd","clip-rule":"evenodd",d:"M1.12.358a1.224 1.224 0 011.729 0l8.92 8.914L20.686.358a1.224 1.224 0 011.73 1.728L13.497 11l8.92 8.913a1.222 1.222 0 11-1.73 1.729l-8.919-8.913-8.92 8.913a1.224 1.224 0 01-1.729-1.729L10.04 11l-8.92-8.914a1.222 1.222 0 010-1.728z",fill:"currentColor"}})])}),[],!1,null,null,null).exports;const lt={"/zh/":{install:"安装",iOSInstall:"点击分享按钮然后点击“添加到主屏幕”",cancel:"取消",close:"关闭",prevImage:"上一张图片",nextImage:"下一张图片",desc:"详情",feature:"主要特色",explain:"该应用可以安装在您的 PC 或移动设备上。这将使该 Web 应用程序外观和行为与其他应用程序相同。它将在出现在应用程序列表中，并可以固定到主屏幕，开始菜单或任务栏。此 Web 应用程序还将能够与其他应用程序和您的操作系统安全地进行交互。",update:"发现新内容可用"},"/en/":{install:"Install",iOSInstall:"Tap the share button and then 'Add to Homescreen'",cancel:"Cancel",close:"Close",prevImage:"Previous Image",nextImage:"Next Image",desc:"Description",feature:"Key Features",explain:"This app can be installed on your PC or mobile device.  This will allow this web app to look and behave like any other installed app.  You will find it in your app lists and be able to pin it to your home screen, start menus or task bars.  This installed web app will also be able to safely interact with other apps and your operating system. ",update:"New content is available."},"/de/":{install:"Installieren",iOSInstall:"Drucke den Share-Button und dan 'zu Homescreen hinzufügen'",cancel:"Abbrechen",close:"Schließen",prevImage:"Vorheriges Bild",nextImage:"Nächstes Bild",desc:"Berschreibung",feature:"Features",explain:"Diese App kann auf Ihrem PC oder Mobilgerät installiert werden.  Dadurch sieht diese Web-App aus und verhält sich wie jede andere installierte App.  Sie finden sie in Ihren App-Listen und können sie an den Startbildschirm, die Startmenüs oder die Taskleisten anheften.  Diese installierte Web-App kann auch sicher mit anderen Apps und Ihrem Betriebssystem interagieren.",update:"Neue Inhalte sind verfügbar."},"/vi/":{install:"Tải về",iOSInstall:"Nhấn vào nút chia sẻ và sau đó 'Thêm vào Màn hình chính'",cancel:"Huỷ bỏ",close:"Đóng",prevImage:"Hình ảnh trước đó",nextImage:"Hình ảnh tiếp theo",desc:"Sự miêu tả",feature:"Các tính năng chính",explain:"Ứng dụng này có thể được cài đặt trên PC hoặc thiết bị di động của bạn. Điều này sẽ cho phép ứng dụng web này trông và hoạt động giống như bất kỳ ứng dụng đã cài đặt nào khác. Bạn sẽ tìm thấy nó trong danh sách ứng dụng của mình và có thể ghim nó vào màn hình chính, menu bắt đầu hoặc thanh tác vụ. Ứng dụng web đã cài đặt này cũng sẽ có thể tương tác an toàn với các ứng dụng khác và hệ điều hành của bạn.",update:"Đã có nội dung mới"},"/":{install:"Install",iOSInstall:"Tap the share button and then 'Add to Homescreen'",cancel:"Cancel",close:"Close",prevImage:"Previous Image",nextImage:"Next Image",desc:"Description",feature:"Key Features",explain:"This app can be installed on your PC or mobile device.  This will allow this web app to look and behave like any other installed app.  You will find it in your app lists and be able to pin it to your home screen, start menus or task bars.  This installed web app will also be able to safely interact with other apps and your operating system. ",update:"New content is available."}};let ut,ct;var dt=o.a.extend({name:"PWAInstallModal",components:{ArrowLeftIcon:at,ArrowRightIcon:it,CloseIcon:st},props:{useHint:{type:Boolean,default:!1}},data:()=>({manifest:{},isIOS:!1,deferredprompt:null}),computed:{i18n(){return lt[this.$localePath||"/"]}},mounted(){window.hasOwnProperty("BeforeInstallPromptEvent")&&(ct=e=>{this.deferredprompt=e,this.$emit("can-install",!0),e.preventDefault()},window.addEventListener("beforeinstallprompt",ct),this.getManifest(),ut=e=>{"Escape"===e.key&&this.$emit("toogle",!1)},document.addEventListener("keyup",ut))},beforeDestroy(){window.hasOwnProperty("BeforeInstallPromptEvent")&&document.removeEventListener("beforeinstallprompt",ct),document.removeEventListener("keyup",ut)},methods:{async getManifest(){const e=localStorage.getItem("manifest");if(e)this.manifest=JSON.parse(e);else try{const e=await fetch("/manifest.webmanifest"),n=await e.json();this.manifest=n,localStorage.setItem("manifest",JSON.stringify(n))}catch(e){console.error("Error getting manifest, check that you have a valid web manifest or network connection")}},scrollToLeft(){const e=document.querySelector(".screenshot");e&&e.scrollBy({left:-e.clientWidth,top:0,behavior:"smooth"})},scrollToRight(){const e=document.querySelector(".screenshot");e&&e.scrollBy({left:e.clientWidth,top:0,behavior:"smooth"})},async install(){if(this.deferredprompt){this.deferredprompt.prompt(),document.dispatchEvent(new CustomEvent("show"));if("accepted"===(await this.deferredprompt.userChoice).outcome)return console.info("PWA has been installed"),this.$emit("toogle",!1),this.$emit("can-install",!1),!0;console.info("You choose to not install PWA"),this.$emit("toogle",!1),this.$emit("can-install",!1)}return!1},hint(){console.info("You accepted the install hint"),this.$emit("hint")}}}),ht=(t(169),Object(Hn.a)(dt,(function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("div",{attrs:{id:"install-modal-wrapper"}},[t("div",{staticClass:"background",on:{click:function(n){return e.$emit("toogle",!1)}}}),e._v(" "),t("div",{staticClass:"install-modal"},[t("div",{staticClass:"header"},[t("button",{staticClass:"close-button",attrs:{"aria-label":e.i18n.close},on:{click:function(n){return e.$emit("toogle",!1)}}},[t("CloseIcon")],1),e._v(" "),t("div",{staticClass:"logo"},[e.manifest.icons?t("img",{attrs:{src:e.manifest.icons[0].src,alt:"App Logo"}}):e._e(),e._v(" "),t("div",{staticClass:"title"},[t("h1",[e._v(e._s(e.manifest.short_name||e.manifest.name))]),e._v(" "),t("p",{staticClass:"desc"},[e._v(e._s(e.i18n.explain))])])])]),e._v(" "),t("div",{staticClass:"content"},[t("div",{staticClass:"highlight"},[e.manifest.features?t("div",{staticClass:"feature-wrapper"},[t("h3",[e._v(e._s(e.i18n.feature))]),e._v(" "),e.manifest.features?t("ul",e._l(e.manifest.features,(function(n){return t("li",{key:n,domProps:{textContent:e._s(n)}})})),0):e._e()]):e._e(),e._v(" "),e.manifest.screenshots?t("div",{staticClass:"screenshot-wrapper"},[t("button",{attrs:{"aria-label":e.i18n.prevImage},on:{click:e.scrollToLeft}},[t("ArrowLeftIcon")],1),e._v(" "),t("section",{staticClass:"screenshot"},e._l(e.manifest.screenshots,(function(e){return t("div",{key:e.src},[t("img",{attrs:{alt:"App Screenshot",src:e.src}})])})),0),e._v(" "),t("button",{attrs:{"aria-label":e.i18n.nextImage},on:{click:e.scrollToRight}},[t("ArrowRightIcon")],1)]):e._e()]),e._v(" "),t("div",{staticClass:"description"},[t("h3",{domProps:{textContent:e._s(e.i18n.desc)}}),e._v(" "),t("p",{domProps:{textContent:e._s(e.manifest.description)}})])]),e._v(" "),e.useHint?t("div",{staticClass:"ios-text",on:{click:e.hint}},[t("p",[e._v(e._s(e.i18n.iOSInstall))]),e._v(" "),t("button",{staticClass:"success"},[e._v("Got it!")])]):t("div",{staticClass:"button-wrapper"},[t("button",{staticClass:"install-button",on:{click:e.install}},[e._v("\n        "+e._s(e.i18n.install)+" "),t("span",[e._v(e._s(e.manifest.short_name))])]),e._v(" "),t("button",{staticClass:"cancel-button",on:{click:function(n){return e.$emit("toogle",!1)}}},[e._v("\n        "+e._s(e.i18n.cancel)+"\n      ")])])])])}),[],!1,null,null,null).exports),pt=o.a.extend({name:"PWAInstall",components:{PWAInstallModal:ht},data:()=>({canInstall:!1,hasRelatedApps:!1,isOpen:!1,isIOS:!1,isSafari:!1,hinted:!1}),computed:{install(){return lt[this.$localePath||"/"].install},useHint(){return this.isIOS&&this.isSafari&&!1===this.hinted},showInstall(){return this.hasRelatedApps&&this.canInstall||this.useHint}},mounted(){if(this.getInstalledStatus()){const{userAgent:e}=navigator;this.isIOS=e.includes("iPhone")||e.includes("iPad")||Boolean(e.includes("Macintosh")&&navigator.maxTouchPoints&&navigator.maxTouchPoints>2),this.isSafari=navigator.userAgent.includes("Safari")&&!e.includes("Chrome"),this.hinted=Boolean(localStorage.getItem("iOS-pwa-hint"))}"getInstalledRelatedApps"in navigator&&navigator.getInstalledRelatedApps().then(e=>{this.hasRelatedApps=e.length>0})},methods:{getInstalledStatus:()=>navigator.standalone?navigator.standalone:matchMedia("(display-mode: standalone)").matches,hint(){this.isOpen=!1,this.hinted=!0,localStorage.setItem("iOS-pwa-hint","hinted")}}}),yt=(t(170),Object(Hn.a)(pt,(function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("div",{attrs:{id:"pwa-install"}},[e.showInstall?t("button",{staticClass:"modal-button",attrs:{"use-hint":e.useHint},domProps:{textContent:e._s(e.install)},on:{click:function(n){e.isOpen=!0}}}):e._e(),e._v(" "),t("PWAInstallModal",{directives:[{name:"show",rawName:"v-show",value:e.isOpen,expression:"isOpen"}],on:{"can-install":function(n){e.canInstall=n},hint:e.hint,toogle:function(n){e.isOpen=n}}})],1)}),[],!1,null,null,null).exports);const mt=new o.a;var gt=o.a.extend({name:"SWUpdatePopup",data:()=>({updateEvent:null}),computed:{enabled(){return Boolean(this.updateEvent)},message(){return lt[this.$localePath||"/"].update}},created(){mt.$on("sw-updated",this.onSWUpdated.bind(this))},methods:{onSWUpdated(e){this.updateEvent=e},reload(){this.updateEvent&&this.updateEvent.skipWaiting().then(()=>{location.reload(!0),this.updateEvent=null})}}}),bt=(t(171),Object(Hn.a)(gt,(function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("transition",{attrs:{name:"sw-update-popup"}},[e._t("default",(function(){return[e.enabled?t("div",{staticClass:"sw-update-popup",attrs:{role:"button",tabindex:"0"},on:{click:e.reload}},[e._v("\n      "+e._s(e.message)+"\n      "),t("span",{staticClass:"refresh"},[t("svg",{attrs:{viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg",width:"84",height:"84"}},[t("path",{attrs:{d:"M949.948959 146.249899l0 255.82655c0 21.980617-13.988596 35.969213-35.969213 35.969213l-255.82655\n            0c-13.988596 0-25.982768-7.992021-33.972742-21.980617-5.997598-13.988596-4.001127-27.977191\n            7.990998-39.97034l79.941704-77.945233c-55.954383-51.973722-121.917724-77.955466-199.862957-77.955466-37.974893 0-75.949786 8.002254-113.924679 21.99085-37.974893 15.984043-67.947532 37.974893-91.933829\n            63.956637-25.981744 23.986297-47.972595 53.958936-63.956637 91.933829-29.982872 73.954339-29.982872\n            153.895019 0 227.849358 15.984043 37.975916 37.974893 67.947532 63.956637 91.933829 23.986297 25.982768\n            53.958936 47.973618 91.933829 63.956637 37.974893 13.988596 75.949786 21.99085 113.924679 21.99085\n            45.966914 0 87.941911-9.997702 127.913275-29.981848 41.97602-17.989723 75.950809-45.966914\n            101.930507-83.942831 7.993045-4.001127 11.994172-5.995551 13.988596-5.995551 5.997598 0 9.998725\n            1.994424 13.988596 5.995551l77.957513 77.945233c3.988848 4.001127 5.986341 7.993045 5.986341\n            11.994172 0 1.994424-1.99647 5.995551-3.990894 11.994172-43.972491 51.962465-93.940532\n            91.933829-151.898549 117.91455-53.958936 25.982768-115.921149 39.971363-185.874361\n            39.971363-61.96119 0-119.921253-11.983939-169.889295-33.972742C284.40084 889.74325 236.438479\n            857.764931 202.464713\n            821.785485c-35.979446-33.972742-67.957765-81.936127-93.939509-139.897214-45.966914-101.930507-45.966914-237.846036 0-339.777567 25.981744-57.960063 57.960063-105.922425 93.939509-139.89619\n            33.973766-35.979446 81.936127-67.957765 139.89619-93.939509 49.968042-21.99085\n            107.928105-33.973766 169.889295-33.973766 55.963593 0 109.923552 9.987468 161.886017\n            29.972639 53.969169 21.99085 101.932554 51.963489 139.907447 89.938382l73.954339-73.944106c9.987468-9.997702 23.987321-13.988596 39.971363-8.002254C941.956937 120.268154 949.948959 132.261303\n            949.948959 146.249899z"}})])])]):e._e()]}),{reload:e.reload,enabled:e.enabled,message:e.message})],2)}),[],!1,null,null,null).exports);var ft=async({Vue:e,router:n,isServer:o})=>{if(e.component("PWAInstall",yt),e.component("SWUpdatePopup",bt),!o){const{register:e}=await t.e(60).then(t.bind(null,476));n.onReady(()=>{e("/service-worker.js",{registrationOptions:{},ready(){console.log("[PWA]: Service worker is active"),mt.$emit("sw-ready")},cached(e){console.log("[PWA]: Content has been cached for offline usage"),mt.$emit("sw-cached",new rt(e))},updated(e){console.log("[PWA]: Content has been updated");const n="service-worker-version",t=Number(localStorage.getItem(n)||0);localStorage.setItem(n,(t+1).toString()),localStorage.removeItem("manifest"),mt.$emit("sw-updated",new rt(e))},offline(){console.log("[PWA]: No internet connection，APP runs in offline mode"),mt.$emit("sw-offline")},error(e){console.error("[PWA]: Register Service Worker error:",e),mt.$emit("sw-error",e)}})})}};t(172);const wt=e=>{const n=document.documentElement.getBoundingClientRect(),t=e.getBoundingClientRect();return{x:t.left-n.left,y:t.top-n.top}};var vt=({Vue:e,router:n})=>{n.options.scrollBehavior=(n,t,o)=>{o?window.scrollTo({top:o.y,behavior:"smooth"}):n.hash?e.$vuepress.$get("disableScrollBehavior")||setTimeout(()=>{const e=decodeURI(n.hash.slice(1)),t=document.getElementById(e)||document.querySelector(`[name='${e}']`);t&&window.scrollTo({top:wt(t).y,behavior:"smooth"})},500):window.scrollTo({top:0,behavior:"smooth"})}},kt={tag:{},category:{}};class qt{constructor(e,n){this._metaMap=Object.assign({},e),Object.keys(this._metaMap).forEach(e=>{const{pageKeys:t}=this._metaMap[e];this._metaMap[e].pages=t.map(e=>function(e,n){for(let t=0;t<e.length;t++){const o=e[t];if(o.key===n)return o}return{path:"",frontmatter:{}}}(n,e))})}get length(){return Object.keys(this._metaMap).length}get map(){return this._metaMap}get pages(){return this.list}get list(){return this.toArray()}toArray(){const e=[];return Object.keys(this._metaMap).forEach(n=>{const{pages:t,path:o}=this._metaMap[n];e.push({name:n,pages:t,path:o})}),e}getItemByName(e){return this._metaMap[e]}}var xt=t(61);const jt=t.n(xt)()("plugin-blog:pagination");class St{constructor(e,n,t){jt("pagination",e);const{pages:o,prevText:r,nextText:a}=e,{path:i}=t;this._prevText=r,this._nextText=a;for(let e=0,n=o.length;e<n;e++){if(o[e].path===i){this.paginationIndex=e;break}}this.paginationIndex||(this.paginationIndex=0),this._paginationPages=o,this._currentPage=o[this.paginationIndex],this._matchedPages=n.filter(n=>e.filter(n,e.id,e.pid)).sort(e.sorter)}setIndexPage(e){this._indexPage=e}get length(){return this._paginationPages.length}get pages(){const[e,n]=this._currentPage.interval;return this._matchedPages.slice(e,n+1)}get hasPrev(){return 0!==this.paginationIndex}get prevLink(){return this.hasPrev?this.paginationIndex-1==0&&this._indexPage?this._indexPage:this._paginationPages[this.paginationIndex-1].path:null}get hasNext(){return this.paginationIndex!==this.length-1}get nextLink(){return this.hasNext?this._paginationPages[this.paginationIndex+1].path:null}get prevText(){return this._prevText}get nextText(){return this._nextText}getSpecificPageLink(e){return this._paginationPages[e].path}}const Tt=new class{constructor(e){this.paginations=e}get pages(){return o.a.$vuepress.$get("siteData").pages}getPagination(e,n,t){jt("id",n),jt("pid",e);const o=this.paginations.filter(t=>t.id===n&&t.pid===e)[0];return new St(o,this.pages,t)}}([]);var Qt={comment:{enabled:!1,service:""},email:{enabled:!1},feed:{rss:!1,atom:!1,json:!1}};t(175),t(16),t(176);var It=({Vue:e})=>{};let Pt;const zt={"/zh/":{close:"关闭",fullsreen:"切换全屏",share:"分享",zoom:"缩放",prev:"上一个 (左箭头)",next:"下一个 (右箭头)",buttons:[{id:"qq",label:"分享到 QQ",url:"https://connect.qq.com/widget/shareqq/iframe_index.html?url={{url}}&title={{text}}&pics={{image_url}}"},{id:"qzone",label:"分享到 Qzone",url:"https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url={{url}}&title={{text}}&pics={{image_url}}"},{id:"weibo",label:"分享到 Weibo",url:"http://service.weibo.com/share/share.php?url={{url}}&title={{text}}&content=utf8&pic={{image_url}}"},{id:"download",label:"下载图片",url:"{{raw_image_url}}",download:!0}]},"/en/":{close:"Close",fullsreen:"Vollbild umschalten",share:"Teilen",zoom:"Zoom in/out",prev:"Prev (Arrow Left)",next:"Next (Arrow Right)",buttons:[{id:"facebook",label:"Share on Facebook",url:"https://www.facebook.com/sharer/sharer.php?u={{url}}"},{id:"twitter",label:"Tweet",url:"https://twitter.com/intent/tweet?text={{text}}&url={{url}}"},{id:"pinterest",label:"Pin it",url:"http://www.pinterest.com/pin/create/button/?url={{url}}&media={{image_url}}&description={{text}}"},{id:"download",label:"Download image",url:"{{raw_image_url}}",download:!0}]},"/de/":{close:"Schließen",fullsreen:"Toggle fullscreen",share:"Teilen",zoom:"Rein / rauszoomen",prev:"Zurück (Pfeil links)",next:"Weiter (Pfeil rechts)",buttons:[{id:"facebook",label:"Teilen auf Facebook",url:"https://www.facebook.com/sharer/sharer.php?u={{url}}"},{id:"twitter",label:"Tweet",url:"https://twitter.com/intent/tweet?text={{text}}&url={{url}}"},{id:"pinterest",label:"Pin it",url:"http://www.pinterest.com/pin/create/button/?url={{url}}&media={{image_url}}&description={{text}}"},{id:"download",label:"Bild herunterladen",url:"{{raw_image_url}}",download:!0}]},"/vi/":{close:"Đóng",fullsreen:"Bật chế độ toàn màn hình",share:"Chia sẻ",zoom:"Phóng to / thu nhỏ",prev:"Trước (Mũi tên trái)",next:"Tiếp theo (Mũi tên Phải)",buttons:[{id:"facebook",label:"Share on Facebook",url:"https://www.facebook.com/sharer/sharer.php?u={{url}}"},{id:"twitter",label:"Tweet",url:"https://twitter.com/intent/tweet?text={{text}}&url={{url}}"},{id:"pinterest",label:"Pin it",url:"http://www.pinterest.com/pin/create/button/?url={{url}}&media={{image_url}}&description={{text}}"},{id:"download",label:"Download image",url:"{{raw_image_url}}",download:!0}]},"/":{close:"Close",fullsreen:"Vollbild umschalten",share:"Teilen",zoom:"Zoom in/out",prev:"Prev (Arrow Left)",next:"Next (Arrow Right)",buttons:[{id:"facebook",label:"Share on Facebook",url:"https://www.facebook.com/sharer/sharer.php?u={{url}}"},{id:"twitter",label:"Tweet",url:"https://twitter.com/intent/tweet?text={{text}}&url={{url}}"},{id:"pinterest",label:"Pin it",url:"http://www.pinterest.com/pin/create/button/?url={{url}}&media={{image_url}}&description={{text}}"},{id:"download",label:"Download image",url:"{{raw_image_url}}",download:!0}]}};var Ct=o.a.extend({name:"PhotoSwipeUI",data:()=>({i18n:zt}),watch:{$route(){const e=setInterval(()=>{document.querySelector(".theme-default-content")&&(this.photoswipe(),clearInterval(e))},200)}},mounted(){const e=setInterval(()=>{document.querySelector(".theme-default-content")&&(this.photoswipe(),clearInterval(e))},200)},methods:{photoswipe(){const e=document.querySelector(".pswp");Promise.all([t.e(59).then(t.t.bind(null,477,7)),t.e(59).then(t.t.bind(null,478,7))]).then(([n,t])=>{this.getImages().then(o=>{Pt.forEach((r,a)=>{r.onclick=()=>{new n.default(e,t.default,o,Object.assign(Object.assign({shareButtons:zt[this.$localePath||"/"].buttons},{}),{index:a})).init()}})})})},getImageInfo:e=>({src:e.src,w:e.naturalWidth,h:e.naturalHeight,title:e.alt}),getImages(){const e=[];return Pt=document.querySelectorAll(".theme-default-content :not(a) > img"),Pt.forEach((n,t)=>{e[t]=new Promise((e,t)=>{n.complete?e(this.getImageInfo(n)):(n.onload=()=>e(this.getImageInfo(n)),n.onerror=e=>t(e))})}),Promise.all(e)}}}),_t=(t(177),Object(Hn.a)(Ct,(function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("div",{staticClass:"pswp",attrs:{tabindex:"-1",role:"dialog","aria-hidden":"true"}},[t("div",{staticClass:"pswp__bg"}),e._v(" "),t("div",{staticClass:"pswp__scroll-wrap"},[e._m(0),e._v(" "),t("div",{staticClass:"pswp__ui pswp__ui--hidden"},[t("div",{staticClass:"pswp__top-bar"},[t("div",{staticClass:"pswp__counter"}),e._v(" "),t("button",{staticClass:"pswp__button pswp__button--close",attrs:{title:e.i18n.close,"aria-label":e.i18n.close}}),e._v(" "),t("button",{staticClass:"pswp__button pswp__button--share",attrs:{title:e.i18n.share,"aria-label":e.i18n.share}}),e._v(" "),t("button",{staticClass:"pswp__button pswp__button--fs",attrs:{title:e.i18n.fullscreen,"aria-label":e.i18n.fullscreen}}),e._v(" "),t("button",{staticClass:"pswp__button pswp__button--zoom",attrs:{title:e.i18n.zoom,"aria-label":e.i18n.zoom}}),e._v(" "),e._m(1)]),e._v(" "),e._m(2),e._v(" "),t("button",{staticClass:"pswp__button pswp__button--arrow--left",attrs:{title:e.i18n.prev,"aria-label":e.i18n.prev}}),e._v(" "),t("button",{staticClass:"pswp__button pswp__button--arrow--right",attrs:{title:e.i18n.next,"aria-label":e.i18n.next}}),e._v(" "),e._m(3)])])])}),[function(){var e=this.$createElement,n=this._self._c||e;return n("div",{staticClass:"pswp__container"},[n("div",{staticClass:"pswp__item"}),this._v(" "),n("div",{staticClass:"pswp__item"}),this._v(" "),n("div",{staticClass:"pswp__item"})])},function(){var e=this.$createElement,n=this._self._c||e;return n("div",{staticClass:"pswp__preloader"},[n("div",{staticClass:"pswp__preloader__icn"},[n("div",{staticClass:"pswp__preloader__cut"},[n("div",{staticClass:"pswp__preloader__donut"})])])])},function(){var e=this.$createElement,n=this._self._c||e;return n("div",{staticClass:"pswp__share-modal pswp__share-modal--hidden pswp__single-tap"},[n("div",{staticClass:"pswp__share-tooltip"})])},function(){var e=this.$createElement,n=this._self._c||e;return n("div",{staticClass:"pswp__caption"},[n("div",{staticClass:"pswp__caption__center"})])}],!1,null,null,null).exports);var At=[{},({Vue:e})=>{e.mixin({computed:{$dataBlock(){return this.$options.__data__block__}}})},{},ot,ft,vt,({Vue:e})=>{const n=Object.keys(kt).map(e=>{const n=kt[e],t="$"+e;return{[t](){const{pages:e}=this.$site;return new qt(n,e)},["$current"+(e.charAt(0).toUpperCase()+e.slice(1))](){const e=this.$route.meta.id;return this[t].getItemByName(e)}}}).reduce((e,n)=>(Object.assign(e,n),e),{});n.$frontmatterKey=function(){const e=this["$"+this.$route.meta.id];return e||null},e.mixin({computed:n})},({Vue:e})=>{e.mixin({computed:{$pagination(){return this.$route.meta.pid&&this.$route.meta.id?this.$getPagination(this.$route.meta.pid,this.$route.meta.id):null}},methods:{$getPagination(e,n){return n=n||e,Tt.getPagination(e,n,this.$route)}}})},({Vue:e})=>{const n={$service:()=>Qt};e.mixin({computed:n})},{},It,({Vue:e})=>{e.component("PhotoSwipeUI",_t)},({router:e})=>{0}],Et=["BackToTop","SWUpdatePopup","PWAInstall","PhotoSwipeUI"];class Lt extends class{constructor(){this.store=new o.a({data:{state:{}}})}$get(e){return this.store.state[e]}$set(e,n){o.a.set(this.store.state,e,n)}$emit(...e){this.store.$emit(...e)}$on(...e){this.store.$on(...e)}}{}Object.assign(Lt.prototype,{getPageAsyncComponent:un,getLayoutAsyncComponent:cn,getAsyncComponent:dn,getVueComponent:hn});var Ht={install(e){const n=new Lt;e.$vuepress=n,e.prototype.$vuepress=n}};function Ot(e,n){const t=n.toLowerCase();return e.options.routes.some(e=>e.path.toLowerCase()===t)}var Dt={props:{pageKey:String,slotKey:{type:String,default:"default"}},render(e){const n=this.pageKey||this.$parent.$page.key;return yn("pageKey",n),o.a.component(n)||o.a.component(n,un(n)),o.a.component(n)?e(n):e("")}},Gt={functional:!0,props:{slotKey:String,required:!0},render:(e,{props:n,slots:t})=>e("div",{class:["content__"+n.slotKey]},t()[n.slotKey])},Nt={computed:{openInNewWindowTitle(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Rt=(t(178),t(179),Object(Hn.a)(Nt,(function(){var e=this.$createElement,n=this._self._c||e;return n("span",[n("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[n("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),n("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),n("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports),Mt={functional:!0,render(e,{parent:n,children:t}){if(n._isMounted)return t;n.$once("hook:mounted",()=>{n.$forceUpdate()})}};o.a.config.productionTip=!1,o.a.use(Ye),o.a.use(Ht),o.a.mixin(function(e,n,t=o.a){!function(e){e.locales&&Object.keys(e.locales).forEach(n=>{e.locales[n].path=n});Object.freeze(e)}(n),t.$vuepress.$set("siteData",n);const r=new(e(t.$vuepress.$get("siteData"))),a=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(r)),i={};return Object.keys(a).reduce((e,n)=>(n.startsWith("$")&&(e[n]=a[n].get),e),i),{computed:i}}(e=>class{setPage(e){this.__page=e}get $site(){return e}get $themeConfig(){return this.$site.themeConfig}get $frontmatter(){return this.$page.frontmatter}get $localeConfig(){const{locales:e={}}=this.$site;let n,t;for(const o in e)"/"===o?t=e[o]:0===this.$page.path.indexOf(o)&&(n=e[o]);return n||t||{}}get $siteTitle(){return this.$localeConfig.title||this.$site.title||""}get $canonicalUrl(){const{canonicalUrl:e}=this.$page.frontmatter;return"string"==typeof e&&e}get $title(){const e=this.$page,{metaTitle:n}=this.$page.frontmatter;if("string"==typeof n)return n;const t=this.$siteTitle,o=e.frontmatter.home?null:e.frontmatter.title||e.title;return t?o?o+" | "+t:t:o||"VuePress"}get $description(){const e=function(e){if(e){const n=e.filter(e=>"description"===e.name)[0];if(n)return n.content}}(this.$page.frontmatter.meta);return e||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}get $lang(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}get $localePath(){return this.$localeConfig.path||"/"}get $themeLocaleConfig(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}get $page(){return this.__page?this.__page:function(e,n){for(let t=0;t<e.length;t++){const o=e[t];if(o.path.toLowerCase()===n.toLowerCase())return o}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}},Gn)),o.a.component("Content",Dt),o.a.component("ContentSlotsDistributor",Gt),o.a.component("OutboundLink",Rt),o.a.component("ClientOnly",Mt),o.a.component("Layout",cn("Layout")),o.a.component("NotFound",cn("NotFound")),o.a.prototype.$withBase=function(e){const n=this.$site.base;return"/"===e.charAt(0)?n+e.slice(1):e},window.__VUEPRESS__={version:"1.8.2",hash:"89dc942"},async function(e){const n="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:Gn.routerBase||Gn.base,t=new Ye({base:n,mode:"history",fallback:!1,routes:Dn,scrollBehavior:(e,n,t)=>t||(e.hash?!o.a.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(e.hash)}:{x:0,y:0})});!function(e){e.beforeEach((n,t,o)=>{if(Ot(e,n.path))o();else if(/(\/|\.html)$/.test(n.path))if(/\/$/.test(n.path)){const t=n.path.replace(/\/$/,"")+".html";Ot(e,t)?o(t):o()}else o();else{const t=n.path+"/",r=n.path+".html";Ot(e,r)?o(r):Ot(e,t)?o(t):o()}})}(t);const r={};try{await Promise.all(At.filter(e=>"function"==typeof e).map(n=>n({Vue:o.a,options:r,router:t,siteData:Gn,isServer:e})))}catch(e){console.error(e)}return{app:new o.a(Object.assign(r,{router:t,render:e=>e("div",{attrs:{id:"app"}},[e("RouterView",{ref:"layout"}),e("div",{class:"global-ui"},Et.map(n=>e(n)))])})),router:t}}(!1).then(({app:e,router:n})=>{n.onReady(()=>{e.$mount("#app")})})}]);