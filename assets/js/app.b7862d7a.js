(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(e){function n(n){for(var a,i,s=n[0],l=n[1],u=n[2],d=0,h=[];d<s.length;d++)i=s[d],Object.prototype.hasOwnProperty.call(o,i)&&o[i]&&h.push(o[i][0]),o[i]=0;for(a in l)Object.prototype.hasOwnProperty.call(l,a)&&(e[a]=l[a]);for(c&&c(n);h.length;)h.shift()();return r.push.apply(r,u||[]),t()}function t(){for(var e,n=0;n<r.length;n++){for(var t=r[n],a=!0,s=1;s<t.length;s++){var l=t[s];0!==o[l]&&(a=!1)}a&&(r.splice(n--,1),e=i(i.s=t[0]))}return e}var a={},o={3:0},r=[];function i(n){if(a[n])return a[n].exports;var t=a[n]={i:n,l:!1,exports:{}};return e[n].call(t.exports,t,t.exports,i),t.l=!0,t.exports}i.e=function(e){var n=[],t=o[e];if(0!==t)if(t)n.push(t[2]);else{var a=new Promise((function(n,a){t=o[e]=[n,a]}));n.push(t[2]=a);var r,s=document.createElement("script");s.charset="utf-8",s.timeout=120,i.nc&&s.setAttribute("nonce",i.nc),s.src=function(e){return i.p+"assets/js/"+({1:"vendors~layout-Blog~layout-Layout~layout-NotFound~layout-Slide",2:"vendors~layout-Blog~layout-Layout~layout-NotFound",4:"layout-Blog",5:"layout-Layout",6:"layout-NotFound",7:"layout-Slide",8:"page--1397d61e",9:"page--14d51344",10:"page--188a7204",11:"page--1d6eb7c4",12:"page--2a03c37e",13:"page--3bb71ffe",14:"page--47639a6e",15:"page--4806233e",16:"page--560420fe",17:"page--5dda9d1e",18:"page--6eb67c5e",19:"page--8fbc73c4",20:"page--e894ac04",21:"page-AmbassadorProgram",22:"page-BagaimanacarakerjakamusSubQuery",23:"page-Bagaimanacaramen-debugproyekSubQuery",24:"page-Bagaimanacaramengubahukuranblockchainfetchingbatch",25:"page-Bagaimanacaramenjalankannodepengindeks",26:"page-Bagaimanacaramulaiditinggiblockberbeda",27:"page-BerkontribusiUntukSubQuery",28:"page-BildirimDosyası",29:"page-Blockchaingetirmetopluişboyutunasıldeğiştirilir",30:"page-BrandingMaterials",31:"page-BuatkueriProyekAndadiSubQueryExplorer",32:"page-ChươngtrìnhĐạisứSubQuery",33:"page-ChạySubQuerytrênmôitrườnglocal",34:"page-CommandLineFlags",35:"page-ConnecttoyourNewProject",36:"page-Connecttoyournewproject",37:"page-ContributingToSubQuery",38:"page-CrearunproyectodeSubquery",39:"page-CreatingaSubQueryProject",40:"page-CàiđặtSubQuery",41:"page-Cáccâuhỏithườnggặp",42:"page-DeployaNewVersionofyourSubQueryProject",43:"page-DeployanewversionofyourSubQueryproject",44:"page-Deployโปรเจ็กต์SubQueryเวอร์ชั่นใหม่ของคุณ",45:"page-ErstellungeinesSubQuery-Projekts",46:"page-Eşleme",47:"page-Farklıbirblokyüksekliğindenasılbaşlarılır",48:"page-FileManifest",49:"page-FrequentlyAskedQuestions",50:"page-GiảithíchHelloWorld",51:"page-GraphQL-Schema",52:"page-GraphQLSchema",53:"page-GraphQL方案",54:"page-GraphQŞema",55:"page-HaloDunia",56:"page-HelloWorld(SubQueryBarındırılan)",57:"page-HelloWorld(SubQueryhosted)",58:"page-HelloWorld(SubQuery호스팅)",59:"page-HelloWorld(hostingSubQuery)",60:"page-HelloWorld(localhost+Docker)",61:"page-HelloWorld(đượclưutrữtrênSubQuery)",62:"page-HelloWorld(локальныйхост+докер)",63:"page-HelloWorld(โฮสต์บนSubQuery)",64:"page-HelloWorld(由SubQuery托管)",65:"page-HelloWorldAçıklandı",66:"page-HelloWorldExplained",67:"page-HelloWorld설명",68:"page-HowdoesaSubQuerydictionarywork",69:"page-Howtochangetheblockchainfetchingbatchsize",70:"page-HowtodebugaSubQueryproject",71:"page-Howtorunanindexernode",72:"page-Howtostartatadifferentblockheight",73:"page-HubungkankeProyekBaruAnda",74:"page-HızlıBaşlangıçKılavuzu",75:"page-Hướngdẫn",76:"page-HướngdẫnVídụ",77:"page-Hướngdẫnnhanh",78:"page-InstallingSubQuery",79:"page-KếtnốiđếnDựÁnMớicủabạn",80:"page-LearnmoreaboutGraphQL",81:"page-Liênkếttruyềnthôngxãhội",82:"page-Làmcáchnàođểthayđổikíchthướclôtìmnạpblockchain",83:"page-Làmthếnàođểbắtđầuởmộtblockheightkhác",84:"page-Làmthếnàođểchạymộtnútchỉmục",85:"page-LàmthếnàođểgỡlỗimộtdựánSubQuery",86:"page-LượcđồGraphQL",87:"page-Lậpbảnđồ",88:"page-Manifest-Datei",89:"page-ManifestFile",90:"page-Manifest파일",91:"page-Mapping",92:"page-MateriMerek",93:"page-MemasangSubQuery",94:"page-MembuatProyekSubQuery",95:"page-MenjalankanSubQuerySecaraLokal",96:"page-PanduanMemulaiCepat",97:"page-PelajarilebihlanjuttentangGraphQL",98:"page-Pemetaan",99:"page-Pertanyaanyangseringdiajukan",100:"page-ProgramDutaBesar",101:"page-PublikasikanProyekSubQueryAnda",102:"page-PublishyourSubQueryProject",103:"page-PublishyourSubQueryproject",104:"page-QueryDựÁncủabạntrongSubQueryExplorer",105:"page-QueryyourProjectinSubQueryExplorer",106:"page-QuickStartGuide",107:"page-RunningSubQueryLocally",108:"page-Sandbox",109:"page-SkemaGraphQL",110:"page-SocialMediaLinks",111:"page-SubQuery사전은어떻게작동하나요",112:"page-SubQuery프로젝트를어떻게디버그할수있을까요",113:"page-SıkçaSorulanSorular",114:"page-TautanMediaSosial",115:"page-TerapkanVersiBaruProyekSubQueryAnda",116:"page-Terminologi",117:"page-Terminology",118:"page-Terminoloji",119:"page-TheSandbox",120:"page-Thuậtngữ",121:"page-TriểnKhaiPhiênBảnMớichoDựÁnSubQuerycủabạn",122:"page-Tutorial",123:"page-TutorialContoh",124:"page-Tutorials",125:"page-TutorialsExamples",126:"page-TìmhiểuthêmvềGraphQL",127:"page-TạomộtdựánSubQuery",128:"page-TừđiểnSubQueryhoạtđộngnhưthếnào",129:"page-Vậtliệuxâydựngthươnghiệu",130:"page-XuấtbảnDựÁnSubQuerycủabạn",131:"page-YenibirSubQueryProjesiOluşturma",132:"page-Zuordnung",133:"page-¿Cómocambiareltamañodellotedelabúsquedaencadenadebloques",134:"page-¿CómodepurarunproyectoSubQuery",135:"page-¿Cómoejecutarunnodoindexador",136:"page-¿Cómoempezaraunaalturadebloquediferente",137:"page-¿CómofuncionaundiccionarioSubQuery",138:"page-ÖğreticilerÖrnekler",139:"page-ĐónggópchoSubQuery",140:"page-Амбассадорскаяпрограмма",141:"page-Брендинговыематериалы",142:"page-ВкладвSubQuery",143:"page-ЗапускSubQueryлокально",144:"page-Какзапуститьузелиндексатора",145:"page-Какизменитьразмерпакетнойвыборкиблокчейна",146:"page-Какначатьсдругойвысотыблока",147:"page-КакотлаживатьпроектSubQuery",148:"page-КакработаетсловарьSubQuery",149:"page-Краткоеруководствопользователя",150:"page-ОбучениеПримеры",151:"page-ОпубликоватьвашпроектSubQuery",152:"page-Подключитеськвашемуновомупроекту",153:"page-Сопоставление",154:"page-Ссылкивсоциальныхсетях",155:"page-Терминология",156:"page-УзнайбольшеоGraphQL",157:"page-УстановкаSubQuery",158:"page-Файлманифеста",159:"page-Частозадаваемыевопросы",160:"page-การติดตั้งSubQuery",161:"page-คำถามที่พบบ่อย",162:"page-คำศัพท์",163:"page-จะdebugโปรเจ็กต์SubQueryได้อย่างไร",164:"page-จะเปลี่ยนbatchsizeการfetchบล็อคเชนได้อย่างไร",165:"page-จะเริ่มต้นที่blockheightที่ต่างกันได้อย่างไร",166:"page-วัตถุดิบแบรนด์ดิ้ง",167:"page-วิธีการรันindexernode",168:"page-สืบค้นโปรเจ็กต์ของคุณในSubQueryExplorer",169:"page-เชื่อมต่อกับโปรเจ็กต์ใหม่ของคุณ",170:"page-เผยแพร่โครงการSubQueryของคุณ",171:"page-เรียนรู้เพิ่มเติมเกี่ยวกับGraphQL",172:"page-โปรแกรมแอมบาสเดอร์",173:"page-创建子查询项目",174:"page-快速入门指南",175:"page-教程",176:"page-术语",177:"page-部署您的SubQuery项目的新版本",178:"page-다른블록의높이부터시작하려면어떻게해야하죠",179:"page-로컬에서하위쿼리실행",180:"page-블록체인의설치뱃지크기를변경하려면어떻게해야합니까",181:"page-빠른시작가이드",182:"page-샌드박스",183:"page-술어",184:"page-인덱서노드를실행하는방법은무엇인가요",185:"page-튜토리얼예",186:"vendors~layout-Layout",187:"vendors~photo-swipe"}[e]||e)+"."+{1:"9352c3ab",2:"14c09c19",4:"3563f886",5:"f3e9cb51",6:"1d8fa5a1",7:"ba37b1c1",8:"40671dc8",9:"70fadad6",10:"f3f61e31",11:"5a32372d",12:"02d2e401",13:"b4573307",14:"98ffc145",15:"0ef2170d",16:"e73d1585",17:"67fe61e9",18:"a9bedeee",19:"7b874a39",20:"81493888",21:"10aef526",22:"665acf84",23:"9524db81",24:"56647e62",25:"edc7d035",26:"6e91514e",27:"318a5119",28:"62b43628",29:"8b9b35a0",30:"2eac579c",31:"5ffe151d",32:"7f4b6d32",33:"15a55624",34:"3a692f35",35:"948d5d8f",36:"01e0db66",37:"09c97737",38:"5a1352ac",39:"35e69ff6",40:"98d31757",41:"70aa44c0",42:"addfe999",43:"b85e337b",44:"1e7146df",45:"c96129af",46:"ec9c9f11",47:"7c57f154",48:"957f9893",49:"b2d0652a",50:"85f3896f",51:"d07cb8cf",52:"4d6bf362",53:"825791b0",54:"d10ba35b",55:"a460a307",56:"90c3b872",57:"a1b08817",58:"a9a05245",59:"c4c0c719",60:"d3a3685e",61:"f19a6336",62:"4e8b4c0a",63:"38cff7b7",64:"d53910da",65:"c3a2a44f",66:"e13c6550",67:"aa329783",68:"74ec54b4",69:"6bb9f4fd",70:"583b9420",71:"7ab58f00",72:"6c65792f",73:"0d8a6bc6",74:"ead1bc8e",75:"64241c48",76:"fb28e4c7",77:"9bd28c88",78:"2ed3349e",79:"2df8b570",80:"a2f3b0c0",81:"08dc9165",82:"8dd579ad",83:"a1c675c4",84:"9b4be17d",85:"5c3953e7",86:"bf631bb4",87:"ac659014",88:"3e07b4da",89:"f9c7a8e2",90:"bf2c5f6b",91:"c7fad726",92:"921ba43b",93:"df4a3c38",94:"73169385",95:"f9738d79",96:"0d00b5fc",97:"5dcee8c6",98:"addb9ec0",99:"c6eeffc5",100:"9fae3ca8",101:"5d693a70",102:"6cb0977a",103:"79d3df30",104:"bbe4cacb",105:"07b8a812",106:"ff3c1a1f",107:"2182ab51",108:"8a0beaea",109:"df44d9f4",110:"4dbca4ec",111:"71dbe0e6",112:"547e41cf",113:"6b184afa",114:"9dead354",115:"fedd366f",116:"f522d01b",117:"f42c9b93",118:"eb3246ff",119:"31b90271",120:"6511aa25",121:"3a788545",122:"8dec6fdf",123:"4c3e0e28",124:"0640f545",125:"61b8b55e",126:"b316ee80",127:"f9b79d75",128:"623cfa5c",129:"b465b6bf",130:"8dc2da2f",131:"11f52e4f",132:"636e9ec1",133:"5561e44b",134:"7b4efd05",135:"0fe403a0",136:"39e42866",137:"2c262a8b",138:"09d8b388",139:"ef0d58c4",140:"27359971",141:"713ff866",142:"7ef3688a",143:"ab6b04d7",144:"6c384ddb",145:"77fb0485",146:"ad7c7045",147:"d0924fbf",148:"a5ce7765",149:"e6918d1f",150:"82cb6fa8",151:"da19e2cf",152:"02eca677",153:"a0cc3b6d",154:"676c3fab",155:"1d42fe2c",156:"2d0b89ea",157:"77583d68",158:"e9105a1c",159:"0e086d4f",160:"e98a43aa",161:"c08b4579",162:"8e6f8860",163:"45b429b3",164:"284adfd4",165:"bd5d8c33",166:"9f7a37be",167:"de23b4b7",168:"8366a469",169:"9211b2e4",170:"47b615d1",171:"0e9ff5a7",172:"da827b2f",173:"139e0ecb",174:"2664d0c9",175:"53a9b9d3",176:"31f39eef",177:"c7cfc9f8",178:"3b20cfb9",179:"60a2e224",180:"814904b8",181:"117066d8",182:"76cb2b39",183:"0a8a9181",184:"37afce91",185:"bdabfa06",186:"5e2d6038",187:"d119c1b6",188:"a2dce9de"}[e]+".js"}(e);var l=new Error;r=function(n){s.onerror=s.onload=null,clearTimeout(u);var t=o[e];if(0!==t){if(t){var a=n&&("load"===n.type?"missing":n.type),r=n&&n.target&&n.target.src;l.message="Loading chunk "+e+" failed.\n("+a+": "+r+")",l.name="ChunkLoadError",l.type=a,l.request=r,t[1](l)}o[e]=void 0}};var u=setTimeout((function(){r({type:"timeout",target:s})}),12e4);s.onerror=s.onload=r,document.head.appendChild(s)}return Promise.all(n)},i.m=e,i.c=a,i.d=function(e,n,t){i.o(e,n)||Object.defineProperty(e,n,{enumerable:!0,get:t})},i.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},i.t=function(e,n){if(1&n&&(e=i(e)),8&n)return e;if(4&n&&"object"==typeof e&&e&&e.__esModule)return e;var t=Object.create(null);if(i.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:e}),2&n&&"string"!=typeof e)for(var a in e)i.d(t,a,function(n){return e[n]}.bind(null,a));return t},i.n=function(e){var n=e&&e.__esModule?function(){return e.default}:function(){return e};return i.d(n,"a",n),n},i.o=function(e,n){return Object.prototype.hasOwnProperty.call(e,n)},i.p="/",i.oe=function(e){throw console.error(e),e};var s=window.webpackJsonp=window.webpackJsonp||[],l=s.push.bind(s);s.push=n,s=s.slice();for(var u=0;u<s.length;u++)n(s[u]);var c=l;r.push([63,0]),t()}([function(e,n,t){"use strict";
/*!
 * Vue.js v2.6.14
 * (c) 2014-2021 Evan You
 * Released under the MIT License.
 */var a=Object.freeze({});function o(e){return null==e}function r(e){return null!=e}function i(e){return!0===e}function s(e){return"string"==typeof e||"number"==typeof e||"symbol"==typeof e||"boolean"==typeof e}function l(e){return null!==e&&"object"==typeof e}var u=Object.prototype.toString;function c(e){return"[object Object]"===u.call(e)}function d(e){return"[object RegExp]"===u.call(e)}function h(e){var n=parseFloat(String(e));return n>=0&&Math.floor(n)===n&&isFinite(e)}function p(e){return r(e)&&"function"==typeof e.then&&"function"==typeof e.catch}function m(e){return null==e?"":Array.isArray(e)||c(e)&&e.toString===u?JSON.stringify(e,null,2):String(e)}function y(e){var n=parseFloat(e);return isNaN(n)?e:n}function g(e,n){for(var t=Object.create(null),a=e.split(","),o=0;o<a.length;o++)t[a[o]]=!0;return n?function(e){return t[e.toLowerCase()]}:function(e){return t[e]}}g("slot,component",!0);var b=g("key,ref,slot,slot-scope,is");function k(e,n){if(e.length){var t=e.indexOf(n);if(t>-1)return e.splice(t,1)}}var f=Object.prototype.hasOwnProperty;function w(e,n){return f.call(e,n)}function v(e){var n=Object.create(null);return function(t){return n[t]||(n[t]=e(t))}}var q=/-(\w)/g,x=v((function(e){return e.replace(q,(function(e,n){return n?n.toUpperCase():""}))})),j=v((function(e){return e.charAt(0).toUpperCase()+e.slice(1)})),S=/\B([A-Z])/g,T=v((function(e){return e.replace(S,"-$1").toLowerCase()}));var z=Function.prototype.bind?function(e,n){return e.bind(n)}:function(e,n){function t(t){var a=arguments.length;return a?a>1?e.apply(n,arguments):e.call(n,t):e.call(n)}return t._length=e.length,t};function Q(e,n){n=n||0;for(var t=e.length-n,a=new Array(t);t--;)a[t]=e[t+n];return a}function I(e,n){for(var t in n)e[t]=n[t];return e}function P(e){for(var n={},t=0;t<e.length;t++)e[t]&&I(n,e[t]);return n}function _(e,n,t){}var C=function(e,n,t){return!1},A=function(e){return e};function O(e,n){if(e===n)return!0;var t=l(e),a=l(n);if(!t||!a)return!t&&!a&&String(e)===String(n);try{var o=Array.isArray(e),r=Array.isArray(n);if(o&&r)return e.length===n.length&&e.every((function(e,t){return O(e,n[t])}));if(e instanceof Date&&n instanceof Date)return e.getTime()===n.getTime();if(o||r)return!1;var i=Object.keys(e),s=Object.keys(n);return i.length===s.length&&i.every((function(t){return O(e[t],n[t])}))}catch(e){return!1}}function H(e,n){for(var t=0;t<e.length;t++)if(O(e[t],n))return t;return-1}function L(e){var n=!1;return function(){n||(n=!0,e.apply(this,arguments))}}var D=["component","directive","filter"],E=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch"],B={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:C,isReservedAttr:C,isUnknownElement:C,getTagNamespace:_,parsePlatformTagName:A,mustUseProp:C,async:!0,_lifecycleHooks:E},G=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function N(e,n,t,a){Object.defineProperty(e,n,{value:t,enumerable:!!a,writable:!0,configurable:!0})}var M=new RegExp("[^"+G.source+".$_\\d]");var R,W="__proto__"in{},U="undefined"!=typeof window,F="undefined"!=typeof WXEnvironment&&!!WXEnvironment.platform,K=F&&WXEnvironment.platform.toLowerCase(),V=U&&window.navigator.userAgent.toLowerCase(),Y=V&&/msie|trident/.test(V),J=V&&V.indexOf("msie 9.0")>0,$=V&&V.indexOf("edge/")>0,Z=(V&&V.indexOf("android"),V&&/iphone|ipad|ipod|ios/.test(V)||"ios"===K),X=(V&&/chrome\/\d+/.test(V),V&&/phantomjs/.test(V),V&&V.match(/firefox\/(\d+)/)),ee={}.watch,ne=!1;if(U)try{var te={};Object.defineProperty(te,"passive",{get:function(){ne=!0}}),window.addEventListener("test-passive",null,te)}catch(e){}var ae=function(){return void 0===R&&(R=!U&&!F&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),R},oe=U&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function re(e){return"function"==typeof e&&/native code/.test(e.toString())}var ie,se="undefined"!=typeof Symbol&&re(Symbol)&&"undefined"!=typeof Reflect&&re(Reflect.ownKeys);ie="undefined"!=typeof Set&&re(Set)?Set:function(){function e(){this.set=Object.create(null)}return e.prototype.has=function(e){return!0===this.set[e]},e.prototype.add=function(e){this.set[e]=!0},e.prototype.clear=function(){this.set=Object.create(null)},e}();var le=_,ue=0,ce=function(){this.id=ue++,this.subs=[]};ce.prototype.addSub=function(e){this.subs.push(e)},ce.prototype.removeSub=function(e){k(this.subs,e)},ce.prototype.depend=function(){ce.target&&ce.target.addDep(this)},ce.prototype.notify=function(){var e=this.subs.slice();for(var n=0,t=e.length;n<t;n++)e[n].update()},ce.target=null;var de=[];function he(e){de.push(e),ce.target=e}function pe(){de.pop(),ce.target=de[de.length-1]}var me=function(e,n,t,a,o,r,i,s){this.tag=e,this.data=n,this.children=t,this.text=a,this.elm=o,this.ns=void 0,this.context=r,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=n&&n.key,this.componentOptions=i,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=s,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1},ye={child:{configurable:!0}};ye.child.get=function(){return this.componentInstance},Object.defineProperties(me.prototype,ye);var ge=function(e){void 0===e&&(e="");var n=new me;return n.text=e,n.isComment=!0,n};function be(e){return new me(void 0,void 0,void 0,String(e))}function ke(e){var n=new me(e.tag,e.data,e.children&&e.children.slice(),e.text,e.elm,e.context,e.componentOptions,e.asyncFactory);return n.ns=e.ns,n.isStatic=e.isStatic,n.key=e.key,n.isComment=e.isComment,n.fnContext=e.fnContext,n.fnOptions=e.fnOptions,n.fnScopeId=e.fnScopeId,n.asyncMeta=e.asyncMeta,n.isCloned=!0,n}var fe=Array.prototype,we=Object.create(fe);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(e){var n=fe[e];N(we,e,(function(){for(var t=[],a=arguments.length;a--;)t[a]=arguments[a];var o,r=n.apply(this,t),i=this.__ob__;switch(e){case"push":case"unshift":o=t;break;case"splice":o=t.slice(2)}return o&&i.observeArray(o),i.dep.notify(),r}))}));var ve=Object.getOwnPropertyNames(we),qe=!0;function xe(e){qe=e}var je=function(e){this.value=e,this.dep=new ce,this.vmCount=0,N(e,"__ob__",this),Array.isArray(e)?(W?function(e,n){e.__proto__=n}(e,we):function(e,n,t){for(var a=0,o=t.length;a<o;a++){var r=t[a];N(e,r,n[r])}}(e,we,ve),this.observeArray(e)):this.walk(e)};function Se(e,n){var t;if(l(e)&&!(e instanceof me))return w(e,"__ob__")&&e.__ob__ instanceof je?t=e.__ob__:qe&&!ae()&&(Array.isArray(e)||c(e))&&Object.isExtensible(e)&&!e._isVue&&(t=new je(e)),n&&t&&t.vmCount++,t}function Te(e,n,t,a,o){var r=new ce,i=Object.getOwnPropertyDescriptor(e,n);if(!i||!1!==i.configurable){var s=i&&i.get,l=i&&i.set;s&&!l||2!==arguments.length||(t=e[n]);var u=!o&&Se(t);Object.defineProperty(e,n,{enumerable:!0,configurable:!0,get:function(){var n=s?s.call(e):t;return ce.target&&(r.depend(),u&&(u.dep.depend(),Array.isArray(n)&&Ie(n))),n},set:function(n){var a=s?s.call(e):t;n===a||n!=n&&a!=a||s&&!l||(l?l.call(e,n):t=n,u=!o&&Se(n),r.notify())}})}}function ze(e,n,t){if(Array.isArray(e)&&h(n))return e.length=Math.max(e.length,n),e.splice(n,1,t),t;if(n in e&&!(n in Object.prototype))return e[n]=t,t;var a=e.__ob__;return e._isVue||a&&a.vmCount?t:a?(Te(a.value,n,t),a.dep.notify(),t):(e[n]=t,t)}function Qe(e,n){if(Array.isArray(e)&&h(n))e.splice(n,1);else{var t=e.__ob__;e._isVue||t&&t.vmCount||w(e,n)&&(delete e[n],t&&t.dep.notify())}}function Ie(e){for(var n=void 0,t=0,a=e.length;t<a;t++)(n=e[t])&&n.__ob__&&n.__ob__.dep.depend(),Array.isArray(n)&&Ie(n)}je.prototype.walk=function(e){for(var n=Object.keys(e),t=0;t<n.length;t++)Te(e,n[t])},je.prototype.observeArray=function(e){for(var n=0,t=e.length;n<t;n++)Se(e[n])};var Pe=B.optionMergeStrategies;function _e(e,n){if(!n)return e;for(var t,a,o,r=se?Reflect.ownKeys(n):Object.keys(n),i=0;i<r.length;i++)"__ob__"!==(t=r[i])&&(a=e[t],o=n[t],w(e,t)?a!==o&&c(a)&&c(o)&&_e(a,o):ze(e,t,o));return e}function Ce(e,n,t){return t?function(){var a="function"==typeof n?n.call(t,t):n,o="function"==typeof e?e.call(t,t):e;return a?_e(a,o):o}:n?e?function(){return _e("function"==typeof n?n.call(this,this):n,"function"==typeof e?e.call(this,this):e)}:n:e}function Ae(e,n){var t=n?e?e.concat(n):Array.isArray(n)?n:[n]:e;return t?function(e){for(var n=[],t=0;t<e.length;t++)-1===n.indexOf(e[t])&&n.push(e[t]);return n}(t):t}function Oe(e,n,t,a){var o=Object.create(e||null);return n?I(o,n):o}Pe.data=function(e,n,t){return t?Ce(e,n,t):n&&"function"!=typeof n?e:Ce(e,n)},E.forEach((function(e){Pe[e]=Ae})),D.forEach((function(e){Pe[e+"s"]=Oe})),Pe.watch=function(e,n,t,a){if(e===ee&&(e=void 0),n===ee&&(n=void 0),!n)return Object.create(e||null);if(!e)return n;var o={};for(var r in I(o,e),n){var i=o[r],s=n[r];i&&!Array.isArray(i)&&(i=[i]),o[r]=i?i.concat(s):Array.isArray(s)?s:[s]}return o},Pe.props=Pe.methods=Pe.inject=Pe.computed=function(e,n,t,a){if(!e)return n;var o=Object.create(null);return I(o,e),n&&I(o,n),o},Pe.provide=Ce;var He=function(e,n){return void 0===n?e:n};function Le(e,n,t){if("function"==typeof n&&(n=n.options),function(e,n){var t=e.props;if(t){var a,o,r={};if(Array.isArray(t))for(a=t.length;a--;)"string"==typeof(o=t[a])&&(r[x(o)]={type:null});else if(c(t))for(var i in t)o=t[i],r[x(i)]=c(o)?o:{type:o};else 0;e.props=r}}(n),function(e,n){var t=e.inject;if(t){var a=e.inject={};if(Array.isArray(t))for(var o=0;o<t.length;o++)a[t[o]]={from:t[o]};else if(c(t))for(var r in t){var i=t[r];a[r]=c(i)?I({from:r},i):{from:i}}else 0}}(n),function(e){var n=e.directives;if(n)for(var t in n){var a=n[t];"function"==typeof a&&(n[t]={bind:a,update:a})}}(n),!n._base&&(n.extends&&(e=Le(e,n.extends,t)),n.mixins))for(var a=0,o=n.mixins.length;a<o;a++)e=Le(e,n.mixins[a],t);var r,i={};for(r in e)s(r);for(r in n)w(e,r)||s(r);function s(a){var o=Pe[a]||He;i[a]=o(e[a],n[a],t,a)}return i}function De(e,n,t,a){if("string"==typeof t){var o=e[n];if(w(o,t))return o[t];var r=x(t);if(w(o,r))return o[r];var i=j(r);return w(o,i)?o[i]:o[t]||o[r]||o[i]}}function Ee(e,n,t,a){var o=n[e],r=!w(t,e),i=t[e],s=Me(Boolean,o.type);if(s>-1)if(r&&!w(o,"default"))i=!1;else if(""===i||i===T(e)){var l=Me(String,o.type);(l<0||s<l)&&(i=!0)}if(void 0===i){i=function(e,n,t){if(!w(n,"default"))return;var a=n.default;0;if(e&&e.$options.propsData&&void 0===e.$options.propsData[t]&&void 0!==e._props[t])return e._props[t];return"function"==typeof a&&"Function"!==Ge(n.type)?a.call(e):a}(a,o,e);var u=qe;xe(!0),Se(i),xe(u)}return i}var Be=/^\s*function (\w+)/;function Ge(e){var n=e&&e.toString().match(Be);return n?n[1]:""}function Ne(e,n){return Ge(e)===Ge(n)}function Me(e,n){if(!Array.isArray(n))return Ne(n,e)?0:-1;for(var t=0,a=n.length;t<a;t++)if(Ne(n[t],e))return t;return-1}function Re(e,n,t){he();try{if(n)for(var a=n;a=a.$parent;){var o=a.$options.errorCaptured;if(o)for(var r=0;r<o.length;r++)try{if(!1===o[r].call(a,e,n,t))return}catch(e){Ue(e,a,"errorCaptured hook")}}Ue(e,n,t)}finally{pe()}}function We(e,n,t,a,o){var r;try{(r=t?e.apply(n,t):e.call(n))&&!r._isVue&&p(r)&&!r._handled&&(r.catch((function(e){return Re(e,a,o+" (Promise/async)")})),r._handled=!0)}catch(e){Re(e,a,o)}return r}function Ue(e,n,t){if(B.errorHandler)try{return B.errorHandler.call(null,e,n,t)}catch(n){n!==e&&Fe(n,null,"config.errorHandler")}Fe(e,n,t)}function Fe(e,n,t){if(!U&&!F||"undefined"==typeof console)throw e;console.error(e)}var Ke,Ve=!1,Ye=[],Je=!1;function $e(){Je=!1;var e=Ye.slice(0);Ye.length=0;for(var n=0;n<e.length;n++)e[n]()}if("undefined"!=typeof Promise&&re(Promise)){var Ze=Promise.resolve();Ke=function(){Ze.then($e),Z&&setTimeout(_)},Ve=!0}else if(Y||"undefined"==typeof MutationObserver||!re(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())Ke="undefined"!=typeof setImmediate&&re(setImmediate)?function(){setImmediate($e)}:function(){setTimeout($e,0)};else{var Xe=1,en=new MutationObserver($e),nn=document.createTextNode(String(Xe));en.observe(nn,{characterData:!0}),Ke=function(){Xe=(Xe+1)%2,nn.data=String(Xe)},Ve=!0}function tn(e,n){var t;if(Ye.push((function(){if(e)try{e.call(n)}catch(e){Re(e,n,"nextTick")}else t&&t(n)})),Je||(Je=!0,Ke()),!e&&"undefined"!=typeof Promise)return new Promise((function(e){t=e}))}var an=new ie;function on(e){!function e(n,t){var a,o,r=Array.isArray(n);if(!r&&!l(n)||Object.isFrozen(n)||n instanceof me)return;if(n.__ob__){var i=n.__ob__.dep.id;if(t.has(i))return;t.add(i)}if(r)for(a=n.length;a--;)e(n[a],t);else for(o=Object.keys(n),a=o.length;a--;)e(n[o[a]],t)}(e,an),an.clear()}var rn=v((function(e){var n="&"===e.charAt(0),t="~"===(e=n?e.slice(1):e).charAt(0),a="!"===(e=t?e.slice(1):e).charAt(0);return{name:e=a?e.slice(1):e,once:t,capture:a,passive:n}}));function sn(e,n){function t(){var e=arguments,a=t.fns;if(!Array.isArray(a))return We(a,null,arguments,n,"v-on handler");for(var o=a.slice(),r=0;r<o.length;r++)We(o[r],null,e,n,"v-on handler")}return t.fns=e,t}function ln(e,n,t,a,r,s){var l,u,c,d;for(l in e)u=e[l],c=n[l],d=rn(l),o(u)||(o(c)?(o(u.fns)&&(u=e[l]=sn(u,s)),i(d.once)&&(u=e[l]=r(d.name,u,d.capture)),t(d.name,u,d.capture,d.passive,d.params)):u!==c&&(c.fns=u,e[l]=c));for(l in n)o(e[l])&&a((d=rn(l)).name,n[l],d.capture)}function un(e,n,t){var a;e instanceof me&&(e=e.data.hook||(e.data.hook={}));var s=e[n];function l(){t.apply(this,arguments),k(a.fns,l)}o(s)?a=sn([l]):r(s.fns)&&i(s.merged)?(a=s).fns.push(l):a=sn([s,l]),a.merged=!0,e[n]=a}function cn(e,n,t,a,o){if(r(n)){if(w(n,t))return e[t]=n[t],o||delete n[t],!0;if(w(n,a))return e[t]=n[a],o||delete n[a],!0}return!1}function dn(e){return s(e)?[be(e)]:Array.isArray(e)?function e(n,t){var a,l,u,c,d=[];for(a=0;a<n.length;a++)o(l=n[a])||"boolean"==typeof l||(u=d.length-1,c=d[u],Array.isArray(l)?l.length>0&&(hn((l=e(l,(t||"")+"_"+a))[0])&&hn(c)&&(d[u]=be(c.text+l[0].text),l.shift()),d.push.apply(d,l)):s(l)?hn(c)?d[u]=be(c.text+l):""!==l&&d.push(be(l)):hn(l)&&hn(c)?d[u]=be(c.text+l.text):(i(n._isVList)&&r(l.tag)&&o(l.key)&&r(t)&&(l.key="__vlist"+t+"_"+a+"__"),d.push(l)));return d}(e):void 0}function hn(e){return r(e)&&r(e.text)&&!1===e.isComment}function pn(e,n){if(e){for(var t=Object.create(null),a=se?Reflect.ownKeys(e):Object.keys(e),o=0;o<a.length;o++){var r=a[o];if("__ob__"!==r){for(var i=e[r].from,s=n;s;){if(s._provided&&w(s._provided,i)){t[r]=s._provided[i];break}s=s.$parent}if(!s)if("default"in e[r]){var l=e[r].default;t[r]="function"==typeof l?l.call(n):l}else 0}}return t}}function mn(e,n){if(!e||!e.length)return{};for(var t={},a=0,o=e.length;a<o;a++){var r=e[a],i=r.data;if(i&&i.attrs&&i.attrs.slot&&delete i.attrs.slot,r.context!==n&&r.fnContext!==n||!i||null==i.slot)(t.default||(t.default=[])).push(r);else{var s=i.slot,l=t[s]||(t[s]=[]);"template"===r.tag?l.push.apply(l,r.children||[]):l.push(r)}}for(var u in t)t[u].every(yn)&&delete t[u];return t}function yn(e){return e.isComment&&!e.asyncFactory||" "===e.text}function gn(e){return e.isComment&&e.asyncFactory}function bn(e,n,t){var o,r=Object.keys(n).length>0,i=e?!!e.$stable:!r,s=e&&e.$key;if(e){if(e._normalized)return e._normalized;if(i&&t&&t!==a&&s===t.$key&&!r&&!t.$hasNormal)return t;for(var l in o={},e)e[l]&&"$"!==l[0]&&(o[l]=kn(n,l,e[l]))}else o={};for(var u in n)u in o||(o[u]=fn(n,u));return e&&Object.isExtensible(e)&&(e._normalized=o),N(o,"$stable",i),N(o,"$key",s),N(o,"$hasNormal",r),o}function kn(e,n,t){var a=function(){var e=arguments.length?t.apply(null,arguments):t({}),n=(e=e&&"object"==typeof e&&!Array.isArray(e)?[e]:dn(e))&&e[0];return e&&(!n||1===e.length&&n.isComment&&!gn(n))?void 0:e};return t.proxy&&Object.defineProperty(e,n,{get:a,enumerable:!0,configurable:!0}),a}function fn(e,n){return function(){return e[n]}}function wn(e,n){var t,a,o,i,s;if(Array.isArray(e)||"string"==typeof e)for(t=new Array(e.length),a=0,o=e.length;a<o;a++)t[a]=n(e[a],a);else if("number"==typeof e)for(t=new Array(e),a=0;a<e;a++)t[a]=n(a+1,a);else if(l(e))if(se&&e[Symbol.iterator]){t=[];for(var u=e[Symbol.iterator](),c=u.next();!c.done;)t.push(n(c.value,t.length)),c=u.next()}else for(i=Object.keys(e),t=new Array(i.length),a=0,o=i.length;a<o;a++)s=i[a],t[a]=n(e[s],s,a);return r(t)||(t=[]),t._isVList=!0,t}function vn(e,n,t,a){var o,r=this.$scopedSlots[e];r?(t=t||{},a&&(t=I(I({},a),t)),o=r(t)||("function"==typeof n?n():n)):o=this.$slots[e]||("function"==typeof n?n():n);var i=t&&t.slot;return i?this.$createElement("template",{slot:i},o):o}function qn(e){return De(this.$options,"filters",e)||A}function xn(e,n){return Array.isArray(e)?-1===e.indexOf(n):e!==n}function jn(e,n,t,a,o){var r=B.keyCodes[n]||t;return o&&a&&!B.keyCodes[n]?xn(o,a):r?xn(r,e):a?T(a)!==n:void 0===e}function Sn(e,n,t,a,o){if(t)if(l(t)){var r;Array.isArray(t)&&(t=P(t));var i=function(i){if("class"===i||"style"===i||b(i))r=e;else{var s=e.attrs&&e.attrs.type;r=a||B.mustUseProp(n,s,i)?e.domProps||(e.domProps={}):e.attrs||(e.attrs={})}var l=x(i),u=T(i);l in r||u in r||(r[i]=t[i],o&&((e.on||(e.on={}))["update:"+i]=function(e){t[i]=e}))};for(var s in t)i(s)}else;return e}function Tn(e,n){var t=this._staticTrees||(this._staticTrees=[]),a=t[e];return a&&!n||Qn(a=t[e]=this.$options.staticRenderFns[e].call(this._renderProxy,null,this),"__static__"+e,!1),a}function zn(e,n,t){return Qn(e,"__once__"+n+(t?"_"+t:""),!0),e}function Qn(e,n,t){if(Array.isArray(e))for(var a=0;a<e.length;a++)e[a]&&"string"!=typeof e[a]&&In(e[a],n+"_"+a,t);else In(e,n,t)}function In(e,n,t){e.isStatic=!0,e.key=n,e.isOnce=t}function Pn(e,n){if(n)if(c(n)){var t=e.on=e.on?I({},e.on):{};for(var a in n){var o=t[a],r=n[a];t[a]=o?[].concat(o,r):r}}else;return e}function _n(e,n,t,a){n=n||{$stable:!t};for(var o=0;o<e.length;o++){var r=e[o];Array.isArray(r)?_n(r,n,t):r&&(r.proxy&&(r.fn.proxy=!0),n[r.key]=r.fn)}return a&&(n.$key=a),n}function Cn(e,n){for(var t=0;t<n.length;t+=2){var a=n[t];"string"==typeof a&&a&&(e[n[t]]=n[t+1])}return e}function An(e,n){return"string"==typeof e?n+e:e}function On(e){e._o=zn,e._n=y,e._s=m,e._l=wn,e._t=vn,e._q=O,e._i=H,e._m=Tn,e._f=qn,e._k=jn,e._b=Sn,e._v=be,e._e=ge,e._u=_n,e._g=Pn,e._d=Cn,e._p=An}function Hn(e,n,t,o,r){var s,l=this,u=r.options;w(o,"_uid")?(s=Object.create(o))._original=o:(s=o,o=o._original);var c=i(u._compiled),d=!c;this.data=e,this.props=n,this.children=t,this.parent=o,this.listeners=e.on||a,this.injections=pn(u.inject,o),this.slots=function(){return l.$slots||bn(e.scopedSlots,l.$slots=mn(t,o)),l.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return bn(e.scopedSlots,this.slots())}}),c&&(this.$options=u,this.$slots=this.slots(),this.$scopedSlots=bn(e.scopedSlots,this.$slots)),u._scopeId?this._c=function(e,n,t,a){var r=Mn(s,e,n,t,a,d);return r&&!Array.isArray(r)&&(r.fnScopeId=u._scopeId,r.fnContext=o),r}:this._c=function(e,n,t,a){return Mn(s,e,n,t,a,d)}}function Ln(e,n,t,a,o){var r=ke(e);return r.fnContext=t,r.fnOptions=a,n.slot&&((r.data||(r.data={})).slot=n.slot),r}function Dn(e,n){for(var t in n)e[x(t)]=n[t]}On(Hn.prototype);var En={init:function(e,n){if(e.componentInstance&&!e.componentInstance._isDestroyed&&e.data.keepAlive){var t=e;En.prepatch(t,t)}else{(e.componentInstance=function(e,n){var t={_isComponent:!0,_parentVnode:e,parent:n},a=e.data.inlineTemplate;r(a)&&(t.render=a.render,t.staticRenderFns=a.staticRenderFns);return new e.componentOptions.Ctor(t)}(e,$n)).$mount(n?e.elm:void 0,n)}},prepatch:function(e,n){var t=n.componentOptions;!function(e,n,t,o,r){0;var i=o.data.scopedSlots,s=e.$scopedSlots,l=!!(i&&!i.$stable||s!==a&&!s.$stable||i&&e.$scopedSlots.$key!==i.$key||!i&&e.$scopedSlots.$key),u=!!(r||e.$options._renderChildren||l);e.$options._parentVnode=o,e.$vnode=o,e._vnode&&(e._vnode.parent=o);if(e.$options._renderChildren=r,e.$attrs=o.data.attrs||a,e.$listeners=t||a,n&&e.$options.props){xe(!1);for(var c=e._props,d=e.$options._propKeys||[],h=0;h<d.length;h++){var p=d[h],m=e.$options.props;c[p]=Ee(p,m,n,e)}xe(!0),e.$options.propsData=n}t=t||a;var y=e.$options._parentListeners;e.$options._parentListeners=t,Jn(e,t,y),u&&(e.$slots=mn(r,o.context),e.$forceUpdate());0}(n.componentInstance=e.componentInstance,t.propsData,t.listeners,n,t.children)},insert:function(e){var n,t=e.context,a=e.componentInstance;a._isMounted||(a._isMounted=!0,nt(a,"mounted")),e.data.keepAlive&&(t._isMounted?((n=a)._inactive=!1,at.push(n)):et(a,!0))},destroy:function(e){var n=e.componentInstance;n._isDestroyed||(e.data.keepAlive?function e(n,t){if(t&&(n._directInactive=!0,Xn(n)))return;if(!n._inactive){n._inactive=!0;for(var a=0;a<n.$children.length;a++)e(n.$children[a]);nt(n,"deactivated")}}(n,!0):n.$destroy())}},Bn=Object.keys(En);function Gn(e,n,t,s,u){if(!o(e)){var c=t.$options._base;if(l(e)&&(e=c.extend(e)),"function"==typeof e){var d;if(o(e.cid)&&void 0===(e=function(e,n){if(i(e.error)&&r(e.errorComp))return e.errorComp;if(r(e.resolved))return e.resolved;var t=Wn;t&&r(e.owners)&&-1===e.owners.indexOf(t)&&e.owners.push(t);if(i(e.loading)&&r(e.loadingComp))return e.loadingComp;if(t&&!r(e.owners)){var a=e.owners=[t],s=!0,u=null,c=null;t.$on("hook:destroyed",(function(){return k(a,t)}));var d=function(e){for(var n=0,t=a.length;n<t;n++)a[n].$forceUpdate();e&&(a.length=0,null!==u&&(clearTimeout(u),u=null),null!==c&&(clearTimeout(c),c=null))},h=L((function(t){e.resolved=Un(t,n),s?a.length=0:d(!0)})),m=L((function(n){r(e.errorComp)&&(e.error=!0,d(!0))})),y=e(h,m);return l(y)&&(p(y)?o(e.resolved)&&y.then(h,m):p(y.component)&&(y.component.then(h,m),r(y.error)&&(e.errorComp=Un(y.error,n)),r(y.loading)&&(e.loadingComp=Un(y.loading,n),0===y.delay?e.loading=!0:u=setTimeout((function(){u=null,o(e.resolved)&&o(e.error)&&(e.loading=!0,d(!1))}),y.delay||200)),r(y.timeout)&&(c=setTimeout((function(){c=null,o(e.resolved)&&m(null)}),y.timeout)))),s=!1,e.loading?e.loadingComp:e.resolved}}(d=e,c)))return function(e,n,t,a,o){var r=ge();return r.asyncFactory=e,r.asyncMeta={data:n,context:t,children:a,tag:o},r}(d,n,t,s,u);n=n||{},xt(e),r(n.model)&&function(e,n){var t=e.model&&e.model.prop||"value",a=e.model&&e.model.event||"input";(n.attrs||(n.attrs={}))[t]=n.model.value;var o=n.on||(n.on={}),i=o[a],s=n.model.callback;r(i)?(Array.isArray(i)?-1===i.indexOf(s):i!==s)&&(o[a]=[s].concat(i)):o[a]=s}(e.options,n);var h=function(e,n,t){var a=n.options.props;if(!o(a)){var i={},s=e.attrs,l=e.props;if(r(s)||r(l))for(var u in a){var c=T(u);cn(i,l,u,c,!0)||cn(i,s,u,c,!1)}return i}}(n,e);if(i(e.options.functional))return function(e,n,t,o,i){var s=e.options,l={},u=s.props;if(r(u))for(var c in u)l[c]=Ee(c,u,n||a);else r(t.attrs)&&Dn(l,t.attrs),r(t.props)&&Dn(l,t.props);var d=new Hn(t,l,i,o,e),h=s.render.call(null,d._c,d);if(h instanceof me)return Ln(h,t,d.parent,s,d);if(Array.isArray(h)){for(var p=dn(h)||[],m=new Array(p.length),y=0;y<p.length;y++)m[y]=Ln(p[y],t,d.parent,s,d);return m}}(e,h,n,t,s);var m=n.on;if(n.on=n.nativeOn,i(e.options.abstract)){var y=n.slot;n={},y&&(n.slot=y)}!function(e){for(var n=e.hook||(e.hook={}),t=0;t<Bn.length;t++){var a=Bn[t],o=n[a],r=En[a];o===r||o&&o._merged||(n[a]=o?Nn(r,o):r)}}(n);var g=e.options.name||u;return new me("vue-component-"+e.cid+(g?"-"+g:""),n,void 0,void 0,void 0,t,{Ctor:e,propsData:h,listeners:m,tag:u,children:s},d)}}}function Nn(e,n){var t=function(t,a){e(t,a),n(t,a)};return t._merged=!0,t}function Mn(e,n,t,a,u,c){return(Array.isArray(t)||s(t))&&(u=a,a=t,t=void 0),i(c)&&(u=2),function(e,n,t,a,s){if(r(t)&&r(t.__ob__))return ge();r(t)&&r(t.is)&&(n=t.is);if(!n)return ge();0;Array.isArray(a)&&"function"==typeof a[0]&&((t=t||{}).scopedSlots={default:a[0]},a.length=0);2===s?a=dn(a):1===s&&(a=function(e){for(var n=0;n<e.length;n++)if(Array.isArray(e[n]))return Array.prototype.concat.apply([],e);return e}(a));var u,c;if("string"==typeof n){var d;c=e.$vnode&&e.$vnode.ns||B.getTagNamespace(n),u=B.isReservedTag(n)?new me(B.parsePlatformTagName(n),t,a,void 0,void 0,e):t&&t.pre||!r(d=De(e.$options,"components",n))?new me(n,t,a,void 0,void 0,e):Gn(d,t,e,a,n)}else u=Gn(n,t,e,a);return Array.isArray(u)?u:r(u)?(r(c)&&function e(n,t,a){n.ns=t,"foreignObject"===n.tag&&(t=void 0,a=!0);if(r(n.children))for(var s=0,l=n.children.length;s<l;s++){var u=n.children[s];r(u.tag)&&(o(u.ns)||i(a)&&"svg"!==u.tag)&&e(u,t,a)}}(u,c),r(t)&&function(e){l(e.style)&&on(e.style);l(e.class)&&on(e.class)}(t),u):ge()}(e,n,t,a,u)}var Rn,Wn=null;function Un(e,n){return(e.__esModule||se&&"Module"===e[Symbol.toStringTag])&&(e=e.default),l(e)?n.extend(e):e}function Fn(e){if(Array.isArray(e))for(var n=0;n<e.length;n++){var t=e[n];if(r(t)&&(r(t.componentOptions)||gn(t)))return t}}function Kn(e,n){Rn.$on(e,n)}function Vn(e,n){Rn.$off(e,n)}function Yn(e,n){var t=Rn;return function a(){var o=n.apply(null,arguments);null!==o&&t.$off(e,a)}}function Jn(e,n,t){Rn=e,ln(n,t||{},Kn,Vn,Yn,e),Rn=void 0}var $n=null;function Zn(e){var n=$n;return $n=e,function(){$n=n}}function Xn(e){for(;e&&(e=e.$parent);)if(e._inactive)return!0;return!1}function et(e,n){if(n){if(e._directInactive=!1,Xn(e))return}else if(e._directInactive)return;if(e._inactive||null===e._inactive){e._inactive=!1;for(var t=0;t<e.$children.length;t++)et(e.$children[t]);nt(e,"activated")}}function nt(e,n){he();var t=e.$options[n],a=n+" hook";if(t)for(var o=0,r=t.length;o<r;o++)We(t[o],e,null,e,a);e._hasHookEvent&&e.$emit("hook:"+n),pe()}var tt=[],at=[],ot={},rt=!1,it=!1,st=0;var lt=0,ut=Date.now;if(U&&!Y){var ct=window.performance;ct&&"function"==typeof ct.now&&ut()>document.createEvent("Event").timeStamp&&(ut=function(){return ct.now()})}function dt(){var e,n;for(lt=ut(),it=!0,tt.sort((function(e,n){return e.id-n.id})),st=0;st<tt.length;st++)(e=tt[st]).before&&e.before(),n=e.id,ot[n]=null,e.run();var t=at.slice(),a=tt.slice();st=tt.length=at.length=0,ot={},rt=it=!1,function(e){for(var n=0;n<e.length;n++)e[n]._inactive=!0,et(e[n],!0)}(t),function(e){var n=e.length;for(;n--;){var t=e[n],a=t.vm;a._watcher===t&&a._isMounted&&!a._isDestroyed&&nt(a,"updated")}}(a),oe&&B.devtools&&oe.emit("flush")}var ht=0,pt=function(e,n,t,a,o){this.vm=e,o&&(e._watcher=this),e._watchers.push(this),a?(this.deep=!!a.deep,this.user=!!a.user,this.lazy=!!a.lazy,this.sync=!!a.sync,this.before=a.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++ht,this.active=!0,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new ie,this.newDepIds=new ie,this.expression="","function"==typeof n?this.getter=n:(this.getter=function(e){if(!M.test(e)){var n=e.split(".");return function(e){for(var t=0;t<n.length;t++){if(!e)return;e=e[n[t]]}return e}}}(n),this.getter||(this.getter=_)),this.value=this.lazy?void 0:this.get()};pt.prototype.get=function(){var e;he(this);var n=this.vm;try{e=this.getter.call(n,n)}catch(e){if(!this.user)throw e;Re(e,n,'getter for watcher "'+this.expression+'"')}finally{this.deep&&on(e),pe(),this.cleanupDeps()}return e},pt.prototype.addDep=function(e){var n=e.id;this.newDepIds.has(n)||(this.newDepIds.add(n),this.newDeps.push(e),this.depIds.has(n)||e.addSub(this))},pt.prototype.cleanupDeps=function(){for(var e=this.deps.length;e--;){var n=this.deps[e];this.newDepIds.has(n.id)||n.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},pt.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():function(e){var n=e.id;if(null==ot[n]){if(ot[n]=!0,it){for(var t=tt.length-1;t>st&&tt[t].id>e.id;)t--;tt.splice(t+1,0,e)}else tt.push(e);rt||(rt=!0,tn(dt))}}(this)},pt.prototype.run=function(){if(this.active){var e=this.get();if(e!==this.value||l(e)||this.deep){var n=this.value;if(this.value=e,this.user){var t='callback for watcher "'+this.expression+'"';We(this.cb,this.vm,[e,n],this.vm,t)}else this.cb.call(this.vm,e,n)}}},pt.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},pt.prototype.depend=function(){for(var e=this.deps.length;e--;)this.deps[e].depend()},pt.prototype.teardown=function(){if(this.active){this.vm._isBeingDestroyed||k(this.vm._watchers,this);for(var e=this.deps.length;e--;)this.deps[e].removeSub(this);this.active=!1}};var mt={enumerable:!0,configurable:!0,get:_,set:_};function yt(e,n,t){mt.get=function(){return this[n][t]},mt.set=function(e){this[n][t]=e},Object.defineProperty(e,t,mt)}function gt(e){e._watchers=[];var n=e.$options;n.props&&function(e,n){var t=e.$options.propsData||{},a=e._props={},o=e.$options._propKeys=[];e.$parent&&xe(!1);var r=function(r){o.push(r);var i=Ee(r,n,t,e);Te(a,r,i),r in e||yt(e,"_props",r)};for(var i in n)r(i);xe(!0)}(e,n.props),n.methods&&function(e,n){e.$options.props;for(var t in n)e[t]="function"!=typeof n[t]?_:z(n[t],e)}(e,n.methods),n.data?function(e){var n=e.$options.data;c(n=e._data="function"==typeof n?function(e,n){he();try{return e.call(n,n)}catch(e){return Re(e,n,"data()"),{}}finally{pe()}}(n,e):n||{})||(n={});var t=Object.keys(n),a=e.$options.props,o=(e.$options.methods,t.length);for(;o--;){var r=t[o];0,a&&w(a,r)||(i=void 0,36!==(i=(r+"").charCodeAt(0))&&95!==i&&yt(e,"_data",r))}var i;Se(n,!0)}(e):Se(e._data={},!0),n.computed&&function(e,n){var t=e._computedWatchers=Object.create(null),a=ae();for(var o in n){var r=n[o],i="function"==typeof r?r:r.get;0,a||(t[o]=new pt(e,i||_,_,bt)),o in e||kt(e,o,r)}}(e,n.computed),n.watch&&n.watch!==ee&&function(e,n){for(var t in n){var a=n[t];if(Array.isArray(a))for(var o=0;o<a.length;o++)vt(e,t,a[o]);else vt(e,t,a)}}(e,n.watch)}var bt={lazy:!0};function kt(e,n,t){var a=!ae();"function"==typeof t?(mt.get=a?ft(n):wt(t),mt.set=_):(mt.get=t.get?a&&!1!==t.cache?ft(n):wt(t.get):_,mt.set=t.set||_),Object.defineProperty(e,n,mt)}function ft(e){return function(){var n=this._computedWatchers&&this._computedWatchers[e];if(n)return n.dirty&&n.evaluate(),ce.target&&n.depend(),n.value}}function wt(e){return function(){return e.call(this,this)}}function vt(e,n,t,a){return c(t)&&(a=t,t=t.handler),"string"==typeof t&&(t=e[t]),e.$watch(n,t,a)}var qt=0;function xt(e){var n=e.options;if(e.super){var t=xt(e.super);if(t!==e.superOptions){e.superOptions=t;var a=function(e){var n,t=e.options,a=e.sealedOptions;for(var o in t)t[o]!==a[o]&&(n||(n={}),n[o]=t[o]);return n}(e);a&&I(e.extendOptions,a),(n=e.options=Le(t,e.extendOptions)).name&&(n.components[n.name]=e)}}return n}function jt(e){this._init(e)}function St(e){e.cid=0;var n=1;e.extend=function(e){e=e||{};var t=this,a=t.cid,o=e._Ctor||(e._Ctor={});if(o[a])return o[a];var r=e.name||t.options.name;var i=function(e){this._init(e)};return(i.prototype=Object.create(t.prototype)).constructor=i,i.cid=n++,i.options=Le(t.options,e),i.super=t,i.options.props&&function(e){var n=e.options.props;for(var t in n)yt(e.prototype,"_props",t)}(i),i.options.computed&&function(e){var n=e.options.computed;for(var t in n)kt(e.prototype,t,n[t])}(i),i.extend=t.extend,i.mixin=t.mixin,i.use=t.use,D.forEach((function(e){i[e]=t[e]})),r&&(i.options.components[r]=i),i.superOptions=t.options,i.extendOptions=e,i.sealedOptions=I({},i.options),o[a]=i,i}}function Tt(e){return e&&(e.Ctor.options.name||e.tag)}function zt(e,n){return Array.isArray(e)?e.indexOf(n)>-1:"string"==typeof e?e.split(",").indexOf(n)>-1:!!d(e)&&e.test(n)}function Qt(e,n){var t=e.cache,a=e.keys,o=e._vnode;for(var r in t){var i=t[r];if(i){var s=i.name;s&&!n(s)&&It(t,r,a,o)}}}function It(e,n,t,a){var o=e[n];!o||a&&o.tag===a.tag||o.componentInstance.$destroy(),e[n]=null,k(t,n)}!function(e){e.prototype._init=function(e){var n=this;n._uid=qt++,n._isVue=!0,e&&e._isComponent?function(e,n){var t=e.$options=Object.create(e.constructor.options),a=n._parentVnode;t.parent=n.parent,t._parentVnode=a;var o=a.componentOptions;t.propsData=o.propsData,t._parentListeners=o.listeners,t._renderChildren=o.children,t._componentTag=o.tag,n.render&&(t.render=n.render,t.staticRenderFns=n.staticRenderFns)}(n,e):n.$options=Le(xt(n.constructor),e||{},n),n._renderProxy=n,n._self=n,function(e){var n=e.$options,t=n.parent;if(t&&!n.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(e)}e.$parent=t,e.$root=t?t.$root:e,e.$children=[],e.$refs={},e._watcher=null,e._inactive=null,e._directInactive=!1,e._isMounted=!1,e._isDestroyed=!1,e._isBeingDestroyed=!1}(n),function(e){e._events=Object.create(null),e._hasHookEvent=!1;var n=e.$options._parentListeners;n&&Jn(e,n)}(n),function(e){e._vnode=null,e._staticTrees=null;var n=e.$options,t=e.$vnode=n._parentVnode,o=t&&t.context;e.$slots=mn(n._renderChildren,o),e.$scopedSlots=a,e._c=function(n,t,a,o){return Mn(e,n,t,a,o,!1)},e.$createElement=function(n,t,a,o){return Mn(e,n,t,a,o,!0)};var r=t&&t.data;Te(e,"$attrs",r&&r.attrs||a,null,!0),Te(e,"$listeners",n._parentListeners||a,null,!0)}(n),nt(n,"beforeCreate"),function(e){var n=pn(e.$options.inject,e);n&&(xe(!1),Object.keys(n).forEach((function(t){Te(e,t,n[t])})),xe(!0))}(n),gt(n),function(e){var n=e.$options.provide;n&&(e._provided="function"==typeof n?n.call(e):n)}(n),nt(n,"created"),n.$options.el&&n.$mount(n.$options.el)}}(jt),function(e){var n={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(e.prototype,"$data",n),Object.defineProperty(e.prototype,"$props",t),e.prototype.$set=ze,e.prototype.$delete=Qe,e.prototype.$watch=function(e,n,t){if(c(n))return vt(this,e,n,t);(t=t||{}).user=!0;var a=new pt(this,e,n,t);if(t.immediate){var o='callback for immediate watcher "'+a.expression+'"';he(),We(n,this,[a.value],this,o),pe()}return function(){a.teardown()}}}(jt),function(e){var n=/^hook:/;e.prototype.$on=function(e,t){var a=this;if(Array.isArray(e))for(var o=0,r=e.length;o<r;o++)a.$on(e[o],t);else(a._events[e]||(a._events[e]=[])).push(t),n.test(e)&&(a._hasHookEvent=!0);return a},e.prototype.$once=function(e,n){var t=this;function a(){t.$off(e,a),n.apply(t,arguments)}return a.fn=n,t.$on(e,a),t},e.prototype.$off=function(e,n){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(Array.isArray(e)){for(var a=0,o=e.length;a<o;a++)t.$off(e[a],n);return t}var r,i=t._events[e];if(!i)return t;if(!n)return t._events[e]=null,t;for(var s=i.length;s--;)if((r=i[s])===n||r.fn===n){i.splice(s,1);break}return t},e.prototype.$emit=function(e){var n=this,t=n._events[e];if(t){t=t.length>1?Q(t):t;for(var a=Q(arguments,1),o='event handler for "'+e+'"',r=0,i=t.length;r<i;r++)We(t[r],n,a,n,o)}return n}}(jt),function(e){e.prototype._update=function(e,n){var t=this,a=t.$el,o=t._vnode,r=Zn(t);t._vnode=e,t.$el=o?t.__patch__(o,e):t.__patch__(t.$el,e,n,!1),r(),a&&(a.__vue__=null),t.$el&&(t.$el.__vue__=t),t.$vnode&&t.$parent&&t.$vnode===t.$parent._vnode&&(t.$parent.$el=t.$el)},e.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},e.prototype.$destroy=function(){var e=this;if(!e._isBeingDestroyed){nt(e,"beforeDestroy"),e._isBeingDestroyed=!0;var n=e.$parent;!n||n._isBeingDestroyed||e.$options.abstract||k(n.$children,e),e._watcher&&e._watcher.teardown();for(var t=e._watchers.length;t--;)e._watchers[t].teardown();e._data.__ob__&&e._data.__ob__.vmCount--,e._isDestroyed=!0,e.__patch__(e._vnode,null),nt(e,"destroyed"),e.$off(),e.$el&&(e.$el.__vue__=null),e.$vnode&&(e.$vnode.parent=null)}}}(jt),function(e){On(e.prototype),e.prototype.$nextTick=function(e){return tn(e,this)},e.prototype._render=function(){var e,n=this,t=n.$options,a=t.render,o=t._parentVnode;o&&(n.$scopedSlots=bn(o.data.scopedSlots,n.$slots,n.$scopedSlots)),n.$vnode=o;try{Wn=n,e=a.call(n._renderProxy,n.$createElement)}catch(t){Re(t,n,"render"),e=n._vnode}finally{Wn=null}return Array.isArray(e)&&1===e.length&&(e=e[0]),e instanceof me||(e=ge()),e.parent=o,e}}(jt);var Pt=[String,RegExp,Array],_t={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:Pt,exclude:Pt,max:[String,Number]},methods:{cacheVNode:function(){var e=this.cache,n=this.keys,t=this.vnodeToCache,a=this.keyToCache;if(t){var o=t.tag,r=t.componentInstance,i=t.componentOptions;e[a]={name:Tt(i),tag:o,componentInstance:r},n.push(a),this.max&&n.length>parseInt(this.max)&&It(e,n[0],n,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var e in this.cache)It(this.cache,e,this.keys)},mounted:function(){var e=this;this.cacheVNode(),this.$watch("include",(function(n){Qt(e,(function(e){return zt(n,e)}))})),this.$watch("exclude",(function(n){Qt(e,(function(e){return!zt(n,e)}))}))},updated:function(){this.cacheVNode()},render:function(){var e=this.$slots.default,n=Fn(e),t=n&&n.componentOptions;if(t){var a=Tt(t),o=this.include,r=this.exclude;if(o&&(!a||!zt(o,a))||r&&a&&zt(r,a))return n;var i=this.cache,s=this.keys,l=null==n.key?t.Ctor.cid+(t.tag?"::"+t.tag:""):n.key;i[l]?(n.componentInstance=i[l].componentInstance,k(s,l),s.push(l)):(this.vnodeToCache=n,this.keyToCache=l),n.data.keepAlive=!0}return n||e&&e[0]}}};!function(e){var n={get:function(){return B}};Object.defineProperty(e,"config",n),e.util={warn:le,extend:I,mergeOptions:Le,defineReactive:Te},e.set=ze,e.delete=Qe,e.nextTick=tn,e.observable=function(e){return Se(e),e},e.options=Object.create(null),D.forEach((function(n){e.options[n+"s"]=Object.create(null)})),e.options._base=e,I(e.options.components,_t),function(e){e.use=function(e){var n=this._installedPlugins||(this._installedPlugins=[]);if(n.indexOf(e)>-1)return this;var t=Q(arguments,1);return t.unshift(this),"function"==typeof e.install?e.install.apply(e,t):"function"==typeof e&&e.apply(null,t),n.push(e),this}}(e),function(e){e.mixin=function(e){return this.options=Le(this.options,e),this}}(e),St(e),function(e){D.forEach((function(n){e[n]=function(e,t){return t?("component"===n&&c(t)&&(t.name=t.name||e,t=this.options._base.extend(t)),"directive"===n&&"function"==typeof t&&(t={bind:t,update:t}),this.options[n+"s"][e]=t,t):this.options[n+"s"][e]}}))}(e)}(jt),Object.defineProperty(jt.prototype,"$isServer",{get:ae}),Object.defineProperty(jt.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(jt,"FunctionalRenderContext",{value:Hn}),jt.version="2.6.14";var Ct=g("style,class"),At=g("input,textarea,option,select,progress"),Ot=g("contenteditable,draggable,spellcheck"),Ht=g("events,caret,typing,plaintext-only"),Lt=g("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),Dt="http://www.w3.org/1999/xlink",Et=function(e){return":"===e.charAt(5)&&"xlink"===e.slice(0,5)},Bt=function(e){return Et(e)?e.slice(6,e.length):""},Gt=function(e){return null==e||!1===e};function Nt(e){for(var n=e.data,t=e,a=e;r(a.componentInstance);)(a=a.componentInstance._vnode)&&a.data&&(n=Mt(a.data,n));for(;r(t=t.parent);)t&&t.data&&(n=Mt(n,t.data));return function(e,n){if(r(e)||r(n))return Rt(e,Wt(n));return""}(n.staticClass,n.class)}function Mt(e,n){return{staticClass:Rt(e.staticClass,n.staticClass),class:r(e.class)?[e.class,n.class]:n.class}}function Rt(e,n){return e?n?e+" "+n:e:n||""}function Wt(e){return Array.isArray(e)?function(e){for(var n,t="",a=0,o=e.length;a<o;a++)r(n=Wt(e[a]))&&""!==n&&(t&&(t+=" "),t+=n);return t}(e):l(e)?function(e){var n="";for(var t in e)e[t]&&(n&&(n+=" "),n+=t);return n}(e):"string"==typeof e?e:""}var Ut={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},Ft=g("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),Kt=g("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),Vt=function(e){return Ft(e)||Kt(e)};var Yt=Object.create(null);var Jt=g("text,number,password,search,email,tel,url");var $t=Object.freeze({createElement:function(e,n){var t=document.createElement(e);return"select"!==e||n.data&&n.data.attrs&&void 0!==n.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(e,n){return document.createElementNS(Ut[e],n)},createTextNode:function(e){return document.createTextNode(e)},createComment:function(e){return document.createComment(e)},insertBefore:function(e,n,t){e.insertBefore(n,t)},removeChild:function(e,n){e.removeChild(n)},appendChild:function(e,n){e.appendChild(n)},parentNode:function(e){return e.parentNode},nextSibling:function(e){return e.nextSibling},tagName:function(e){return e.tagName},setTextContent:function(e,n){e.textContent=n},setStyleScope:function(e,n){e.setAttribute(n,"")}}),Zt={create:function(e,n){Xt(n)},update:function(e,n){e.data.ref!==n.data.ref&&(Xt(e,!0),Xt(n))},destroy:function(e){Xt(e,!0)}};function Xt(e,n){var t=e.data.ref;if(r(t)){var a=e.context,o=e.componentInstance||e.elm,i=a.$refs;n?Array.isArray(i[t])?k(i[t],o):i[t]===o&&(i[t]=void 0):e.data.refInFor?Array.isArray(i[t])?i[t].indexOf(o)<0&&i[t].push(o):i[t]=[o]:i[t]=o}}var ea=new me("",{},[]),na=["create","activate","update","remove","destroy"];function ta(e,n){return e.key===n.key&&e.asyncFactory===n.asyncFactory&&(e.tag===n.tag&&e.isComment===n.isComment&&r(e.data)===r(n.data)&&function(e,n){if("input"!==e.tag)return!0;var t,a=r(t=e.data)&&r(t=t.attrs)&&t.type,o=r(t=n.data)&&r(t=t.attrs)&&t.type;return a===o||Jt(a)&&Jt(o)}(e,n)||i(e.isAsyncPlaceholder)&&o(n.asyncFactory.error))}function aa(e,n,t){var a,o,i={};for(a=n;a<=t;++a)r(o=e[a].key)&&(i[o]=a);return i}var oa={create:ra,update:ra,destroy:function(e){ra(e,ea)}};function ra(e,n){(e.data.directives||n.data.directives)&&function(e,n){var t,a,o,r=e===ea,i=n===ea,s=sa(e.data.directives,e.context),l=sa(n.data.directives,n.context),u=[],c=[];for(t in l)a=s[t],o=l[t],a?(o.oldValue=a.value,o.oldArg=a.arg,ua(o,"update",n,e),o.def&&o.def.componentUpdated&&c.push(o)):(ua(o,"bind",n,e),o.def&&o.def.inserted&&u.push(o));if(u.length){var d=function(){for(var t=0;t<u.length;t++)ua(u[t],"inserted",n,e)};r?un(n,"insert",d):d()}c.length&&un(n,"postpatch",(function(){for(var t=0;t<c.length;t++)ua(c[t],"componentUpdated",n,e)}));if(!r)for(t in s)l[t]||ua(s[t],"unbind",e,e,i)}(e,n)}var ia=Object.create(null);function sa(e,n){var t,a,o=Object.create(null);if(!e)return o;for(t=0;t<e.length;t++)(a=e[t]).modifiers||(a.modifiers=ia),o[la(a)]=a,a.def=De(n.$options,"directives",a.name);return o}function la(e){return e.rawName||e.name+"."+Object.keys(e.modifiers||{}).join(".")}function ua(e,n,t,a,o){var r=e.def&&e.def[n];if(r)try{r(t.elm,e,t,a,o)}catch(a){Re(a,t.context,"directive "+e.name+" "+n+" hook")}}var ca=[Zt,oa];function da(e,n){var t=n.componentOptions;if(!(r(t)&&!1===t.Ctor.options.inheritAttrs||o(e.data.attrs)&&o(n.data.attrs))){var a,i,s=n.elm,l=e.data.attrs||{},u=n.data.attrs||{};for(a in r(u.__ob__)&&(u=n.data.attrs=I({},u)),u)i=u[a],l[a]!==i&&ha(s,a,i,n.data.pre);for(a in(Y||$)&&u.value!==l.value&&ha(s,"value",u.value),l)o(u[a])&&(Et(a)?s.removeAttributeNS(Dt,Bt(a)):Ot(a)||s.removeAttribute(a))}}function ha(e,n,t,a){a||e.tagName.indexOf("-")>-1?pa(e,n,t):Lt(n)?Gt(t)?e.removeAttribute(n):(t="allowfullscreen"===n&&"EMBED"===e.tagName?"true":n,e.setAttribute(n,t)):Ot(n)?e.setAttribute(n,function(e,n){return Gt(n)||"false"===n?"false":"contenteditable"===e&&Ht(n)?n:"true"}(n,t)):Et(n)?Gt(t)?e.removeAttributeNS(Dt,Bt(n)):e.setAttributeNS(Dt,n,t):pa(e,n,t)}function pa(e,n,t){if(Gt(t))e.removeAttribute(n);else{if(Y&&!J&&"TEXTAREA"===e.tagName&&"placeholder"===n&&""!==t&&!e.__ieph){var a=function(n){n.stopImmediatePropagation(),e.removeEventListener("input",a)};e.addEventListener("input",a),e.__ieph=!0}e.setAttribute(n,t)}}var ma={create:da,update:da};function ya(e,n){var t=n.elm,a=n.data,i=e.data;if(!(o(a.staticClass)&&o(a.class)&&(o(i)||o(i.staticClass)&&o(i.class)))){var s=Nt(n),l=t._transitionClasses;r(l)&&(s=Rt(s,Wt(l))),s!==t._prevClass&&(t.setAttribute("class",s),t._prevClass=s)}}var ga,ba={create:ya,update:ya};function ka(e,n,t){var a=ga;return function o(){var r=n.apply(null,arguments);null!==r&&va(e,o,t,a)}}var fa=Ve&&!(X&&Number(X[1])<=53);function wa(e,n,t,a){if(fa){var o=lt,r=n;n=r._wrapper=function(e){if(e.target===e.currentTarget||e.timeStamp>=o||e.timeStamp<=0||e.target.ownerDocument!==document)return r.apply(this,arguments)}}ga.addEventListener(e,n,ne?{capture:t,passive:a}:t)}function va(e,n,t,a){(a||ga).removeEventListener(e,n._wrapper||n,t)}function qa(e,n){if(!o(e.data.on)||!o(n.data.on)){var t=n.data.on||{},a=e.data.on||{};ga=n.elm,function(e){if(r(e.__r)){var n=Y?"change":"input";e[n]=[].concat(e.__r,e[n]||[]),delete e.__r}r(e.__c)&&(e.change=[].concat(e.__c,e.change||[]),delete e.__c)}(t),ln(t,a,wa,va,ka,n.context),ga=void 0}}var xa,ja={create:qa,update:qa};function Sa(e,n){if(!o(e.data.domProps)||!o(n.data.domProps)){var t,a,i=n.elm,s=e.data.domProps||{},l=n.data.domProps||{};for(t in r(l.__ob__)&&(l=n.data.domProps=I({},l)),s)t in l||(i[t]="");for(t in l){if(a=l[t],"textContent"===t||"innerHTML"===t){if(n.children&&(n.children.length=0),a===s[t])continue;1===i.childNodes.length&&i.removeChild(i.childNodes[0])}if("value"===t&&"PROGRESS"!==i.tagName){i._value=a;var u=o(a)?"":String(a);Ta(i,u)&&(i.value=u)}else if("innerHTML"===t&&Kt(i.tagName)&&o(i.innerHTML)){(xa=xa||document.createElement("div")).innerHTML="<svg>"+a+"</svg>";for(var c=xa.firstChild;i.firstChild;)i.removeChild(i.firstChild);for(;c.firstChild;)i.appendChild(c.firstChild)}else if(a!==s[t])try{i[t]=a}catch(e){}}}}function Ta(e,n){return!e.composing&&("OPTION"===e.tagName||function(e,n){var t=!0;try{t=document.activeElement!==e}catch(e){}return t&&e.value!==n}(e,n)||function(e,n){var t=e.value,a=e._vModifiers;if(r(a)){if(a.number)return y(t)!==y(n);if(a.trim)return t.trim()!==n.trim()}return t!==n}(e,n))}var za={create:Sa,update:Sa},Qa=v((function(e){var n={},t=/:(.+)/;return e.split(/;(?![^(]*\))/g).forEach((function(e){if(e){var a=e.split(t);a.length>1&&(n[a[0].trim()]=a[1].trim())}})),n}));function Ia(e){var n=Pa(e.style);return e.staticStyle?I(e.staticStyle,n):n}function Pa(e){return Array.isArray(e)?P(e):"string"==typeof e?Qa(e):e}var _a,Ca=/^--/,Aa=/\s*!important$/,Oa=function(e,n,t){if(Ca.test(n))e.style.setProperty(n,t);else if(Aa.test(t))e.style.setProperty(T(n),t.replace(Aa,""),"important");else{var a=La(n);if(Array.isArray(t))for(var o=0,r=t.length;o<r;o++)e.style[a]=t[o];else e.style[a]=t}},Ha=["Webkit","Moz","ms"],La=v((function(e){if(_a=_a||document.createElement("div").style,"filter"!==(e=x(e))&&e in _a)return e;for(var n=e.charAt(0).toUpperCase()+e.slice(1),t=0;t<Ha.length;t++){var a=Ha[t]+n;if(a in _a)return a}}));function Da(e,n){var t=n.data,a=e.data;if(!(o(t.staticStyle)&&o(t.style)&&o(a.staticStyle)&&o(a.style))){var i,s,l=n.elm,u=a.staticStyle,c=a.normalizedStyle||a.style||{},d=u||c,h=Pa(n.data.style)||{};n.data.normalizedStyle=r(h.__ob__)?I({},h):h;var p=function(e,n){var t,a={};if(n)for(var o=e;o.componentInstance;)(o=o.componentInstance._vnode)&&o.data&&(t=Ia(o.data))&&I(a,t);(t=Ia(e.data))&&I(a,t);for(var r=e;r=r.parent;)r.data&&(t=Ia(r.data))&&I(a,t);return a}(n,!0);for(s in d)o(p[s])&&Oa(l,s,"");for(s in p)(i=p[s])!==d[s]&&Oa(l,s,null==i?"":i)}}var Ea={create:Da,update:Da},Ba=/\s+/;function Ga(e,n){if(n&&(n=n.trim()))if(e.classList)n.indexOf(" ")>-1?n.split(Ba).forEach((function(n){return e.classList.add(n)})):e.classList.add(n);else{var t=" "+(e.getAttribute("class")||"")+" ";t.indexOf(" "+n+" ")<0&&e.setAttribute("class",(t+n).trim())}}function Na(e,n){if(n&&(n=n.trim()))if(e.classList)n.indexOf(" ")>-1?n.split(Ba).forEach((function(n){return e.classList.remove(n)})):e.classList.remove(n),e.classList.length||e.removeAttribute("class");else{for(var t=" "+(e.getAttribute("class")||"")+" ",a=" "+n+" ";t.indexOf(a)>=0;)t=t.replace(a," ");(t=t.trim())?e.setAttribute("class",t):e.removeAttribute("class")}}function Ma(e){if(e){if("object"==typeof e){var n={};return!1!==e.css&&I(n,Ra(e.name||"v")),I(n,e),n}return"string"==typeof e?Ra(e):void 0}}var Ra=v((function(e){return{enterClass:e+"-enter",enterToClass:e+"-enter-to",enterActiveClass:e+"-enter-active",leaveClass:e+"-leave",leaveToClass:e+"-leave-to",leaveActiveClass:e+"-leave-active"}})),Wa=U&&!J,Ua="transition",Fa="transitionend",Ka="animation",Va="animationend";Wa&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(Ua="WebkitTransition",Fa="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(Ka="WebkitAnimation",Va="webkitAnimationEnd"));var Ya=U?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(e){return e()};function Ja(e){Ya((function(){Ya(e)}))}function $a(e,n){var t=e._transitionClasses||(e._transitionClasses=[]);t.indexOf(n)<0&&(t.push(n),Ga(e,n))}function Za(e,n){e._transitionClasses&&k(e._transitionClasses,n),Na(e,n)}function Xa(e,n,t){var a=no(e,n),o=a.type,r=a.timeout,i=a.propCount;if(!o)return t();var s="transition"===o?Fa:Va,l=0,u=function(){e.removeEventListener(s,c),t()},c=function(n){n.target===e&&++l>=i&&u()};setTimeout((function(){l<i&&u()}),r+1),e.addEventListener(s,c)}var eo=/\b(transform|all)(,|$)/;function no(e,n){var t,a=window.getComputedStyle(e),o=(a[Ua+"Delay"]||"").split(", "),r=(a[Ua+"Duration"]||"").split(", "),i=to(o,r),s=(a[Ka+"Delay"]||"").split(", "),l=(a[Ka+"Duration"]||"").split(", "),u=to(s,l),c=0,d=0;return"transition"===n?i>0&&(t="transition",c=i,d=r.length):"animation"===n?u>0&&(t="animation",c=u,d=l.length):d=(t=(c=Math.max(i,u))>0?i>u?"transition":"animation":null)?"transition"===t?r.length:l.length:0,{type:t,timeout:c,propCount:d,hasTransform:"transition"===t&&eo.test(a[Ua+"Property"])}}function to(e,n){for(;e.length<n.length;)e=e.concat(e);return Math.max.apply(null,n.map((function(n,t){return ao(n)+ao(e[t])})))}function ao(e){return 1e3*Number(e.slice(0,-1).replace(",","."))}function oo(e,n){var t=e.elm;r(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var a=Ma(e.data.transition);if(!o(a)&&!r(t._enterCb)&&1===t.nodeType){for(var i=a.css,s=a.type,u=a.enterClass,c=a.enterToClass,d=a.enterActiveClass,h=a.appearClass,p=a.appearToClass,m=a.appearActiveClass,g=a.beforeEnter,b=a.enter,k=a.afterEnter,f=a.enterCancelled,w=a.beforeAppear,v=a.appear,q=a.afterAppear,x=a.appearCancelled,j=a.duration,S=$n,T=$n.$vnode;T&&T.parent;)S=T.context,T=T.parent;var z=!S._isMounted||!e.isRootInsert;if(!z||v||""===v){var Q=z&&h?h:u,I=z&&m?m:d,P=z&&p?p:c,_=z&&w||g,C=z&&"function"==typeof v?v:b,A=z&&q||k,O=z&&x||f,H=y(l(j)?j.enter:j);0;var D=!1!==i&&!J,E=so(C),B=t._enterCb=L((function(){D&&(Za(t,P),Za(t,I)),B.cancelled?(D&&Za(t,Q),O&&O(t)):A&&A(t),t._enterCb=null}));e.data.show||un(e,"insert",(function(){var n=t.parentNode,a=n&&n._pending&&n._pending[e.key];a&&a.tag===e.tag&&a.elm._leaveCb&&a.elm._leaveCb(),C&&C(t,B)})),_&&_(t),D&&($a(t,Q),$a(t,I),Ja((function(){Za(t,Q),B.cancelled||($a(t,P),E||(io(H)?setTimeout(B,H):Xa(t,s,B)))}))),e.data.show&&(n&&n(),C&&C(t,B)),D||E||B()}}}function ro(e,n){var t=e.elm;r(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var a=Ma(e.data.transition);if(o(a)||1!==t.nodeType)return n();if(!r(t._leaveCb)){var i=a.css,s=a.type,u=a.leaveClass,c=a.leaveToClass,d=a.leaveActiveClass,h=a.beforeLeave,p=a.leave,m=a.afterLeave,g=a.leaveCancelled,b=a.delayLeave,k=a.duration,f=!1!==i&&!J,w=so(p),v=y(l(k)?k.leave:k);0;var q=t._leaveCb=L((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[e.key]=null),f&&(Za(t,c),Za(t,d)),q.cancelled?(f&&Za(t,u),g&&g(t)):(n(),m&&m(t)),t._leaveCb=null}));b?b(x):x()}function x(){q.cancelled||(!e.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[e.key]=e),h&&h(t),f&&($a(t,u),$a(t,d),Ja((function(){Za(t,u),q.cancelled||($a(t,c),w||(io(v)?setTimeout(q,v):Xa(t,s,q)))}))),p&&p(t,q),f||w||q())}}function io(e){return"number"==typeof e&&!isNaN(e)}function so(e){if(o(e))return!1;var n=e.fns;return r(n)?so(Array.isArray(n)?n[0]:n):(e._length||e.length)>1}function lo(e,n){!0!==n.data.show&&oo(n)}var uo=function(e){var n,t,a={},l=e.modules,u=e.nodeOps;for(n=0;n<na.length;++n)for(a[na[n]]=[],t=0;t<l.length;++t)r(l[t][na[n]])&&a[na[n]].push(l[t][na[n]]);function c(e){var n=u.parentNode(e);r(n)&&u.removeChild(n,e)}function d(e,n,t,o,s,l,c){if(r(e.elm)&&r(l)&&(e=l[c]=ke(e)),e.isRootInsert=!s,!function(e,n,t,o){var s=e.data;if(r(s)){var l=r(e.componentInstance)&&s.keepAlive;if(r(s=s.hook)&&r(s=s.init)&&s(e,!1),r(e.componentInstance))return h(e,n),p(t,e.elm,o),i(l)&&function(e,n,t,o){var i,s=e;for(;s.componentInstance;)if(s=s.componentInstance._vnode,r(i=s.data)&&r(i=i.transition)){for(i=0;i<a.activate.length;++i)a.activate[i](ea,s);n.push(s);break}p(t,e.elm,o)}(e,n,t,o),!0}}(e,n,t,o)){var d=e.data,y=e.children,g=e.tag;r(g)?(e.elm=e.ns?u.createElementNS(e.ns,g):u.createElement(g,e),k(e),m(e,y,n),r(d)&&b(e,n),p(t,e.elm,o)):i(e.isComment)?(e.elm=u.createComment(e.text),p(t,e.elm,o)):(e.elm=u.createTextNode(e.text),p(t,e.elm,o))}}function h(e,n){r(e.data.pendingInsert)&&(n.push.apply(n,e.data.pendingInsert),e.data.pendingInsert=null),e.elm=e.componentInstance.$el,y(e)?(b(e,n),k(e)):(Xt(e),n.push(e))}function p(e,n,t){r(e)&&(r(t)?u.parentNode(t)===e&&u.insertBefore(e,n,t):u.appendChild(e,n))}function m(e,n,t){if(Array.isArray(n)){0;for(var a=0;a<n.length;++a)d(n[a],t,e.elm,null,!0,n,a)}else s(e.text)&&u.appendChild(e.elm,u.createTextNode(String(e.text)))}function y(e){for(;e.componentInstance;)e=e.componentInstance._vnode;return r(e.tag)}function b(e,t){for(var o=0;o<a.create.length;++o)a.create[o](ea,e);r(n=e.data.hook)&&(r(n.create)&&n.create(ea,e),r(n.insert)&&t.push(e))}function k(e){var n;if(r(n=e.fnScopeId))u.setStyleScope(e.elm,n);else for(var t=e;t;)r(n=t.context)&&r(n=n.$options._scopeId)&&u.setStyleScope(e.elm,n),t=t.parent;r(n=$n)&&n!==e.context&&n!==e.fnContext&&r(n=n.$options._scopeId)&&u.setStyleScope(e.elm,n)}function f(e,n,t,a,o,r){for(;a<=o;++a)d(t[a],r,e,n,!1,t,a)}function w(e){var n,t,o=e.data;if(r(o))for(r(n=o.hook)&&r(n=n.destroy)&&n(e),n=0;n<a.destroy.length;++n)a.destroy[n](e);if(r(n=e.children))for(t=0;t<e.children.length;++t)w(e.children[t])}function v(e,n,t){for(;n<=t;++n){var a=e[n];r(a)&&(r(a.tag)?(q(a),w(a)):c(a.elm))}}function q(e,n){if(r(n)||r(e.data)){var t,o=a.remove.length+1;for(r(n)?n.listeners+=o:n=function(e,n){function t(){0==--t.listeners&&c(e)}return t.listeners=n,t}(e.elm,o),r(t=e.componentInstance)&&r(t=t._vnode)&&r(t.data)&&q(t,n),t=0;t<a.remove.length;++t)a.remove[t](e,n);r(t=e.data.hook)&&r(t=t.remove)?t(e,n):n()}else c(e.elm)}function x(e,n,t,a){for(var o=t;o<a;o++){var i=n[o];if(r(i)&&ta(e,i))return o}}function j(e,n,t,s,l,c){if(e!==n){r(n.elm)&&r(s)&&(n=s[l]=ke(n));var h=n.elm=e.elm;if(i(e.isAsyncPlaceholder))r(n.asyncFactory.resolved)?z(e.elm,n,t):n.isAsyncPlaceholder=!0;else if(i(n.isStatic)&&i(e.isStatic)&&n.key===e.key&&(i(n.isCloned)||i(n.isOnce)))n.componentInstance=e.componentInstance;else{var p,m=n.data;r(m)&&r(p=m.hook)&&r(p=p.prepatch)&&p(e,n);var g=e.children,b=n.children;if(r(m)&&y(n)){for(p=0;p<a.update.length;++p)a.update[p](e,n);r(p=m.hook)&&r(p=p.update)&&p(e,n)}o(n.text)?r(g)&&r(b)?g!==b&&function(e,n,t,a,i){var s,l,c,h=0,p=0,m=n.length-1,y=n[0],g=n[m],b=t.length-1,k=t[0],w=t[b],q=!i;for(0;h<=m&&p<=b;)o(y)?y=n[++h]:o(g)?g=n[--m]:ta(y,k)?(j(y,k,a,t,p),y=n[++h],k=t[++p]):ta(g,w)?(j(g,w,a,t,b),g=n[--m],w=t[--b]):ta(y,w)?(j(y,w,a,t,b),q&&u.insertBefore(e,y.elm,u.nextSibling(g.elm)),y=n[++h],w=t[--b]):ta(g,k)?(j(g,k,a,t,p),q&&u.insertBefore(e,g.elm,y.elm),g=n[--m],k=t[++p]):(o(s)&&(s=aa(n,h,m)),o(l=r(k.key)?s[k.key]:x(k,n,h,m))?d(k,a,e,y.elm,!1,t,p):ta(c=n[l],k)?(j(c,k,a,t,p),n[l]=void 0,q&&u.insertBefore(e,c.elm,y.elm)):d(k,a,e,y.elm,!1,t,p),k=t[++p]);h>m?f(e,o(t[b+1])?null:t[b+1].elm,t,p,b,a):p>b&&v(n,h,m)}(h,g,b,t,c):r(b)?(r(e.text)&&u.setTextContent(h,""),f(h,null,b,0,b.length-1,t)):r(g)?v(g,0,g.length-1):r(e.text)&&u.setTextContent(h,""):e.text!==n.text&&u.setTextContent(h,n.text),r(m)&&r(p=m.hook)&&r(p=p.postpatch)&&p(e,n)}}}function S(e,n,t){if(i(t)&&r(e.parent))e.parent.data.pendingInsert=n;else for(var a=0;a<n.length;++a)n[a].data.hook.insert(n[a])}var T=g("attrs,class,staticClass,staticStyle,key");function z(e,n,t,a){var o,s=n.tag,l=n.data,u=n.children;if(a=a||l&&l.pre,n.elm=e,i(n.isComment)&&r(n.asyncFactory))return n.isAsyncPlaceholder=!0,!0;if(r(l)&&(r(o=l.hook)&&r(o=o.init)&&o(n,!0),r(o=n.componentInstance)))return h(n,t),!0;if(r(s)){if(r(u))if(e.hasChildNodes())if(r(o=l)&&r(o=o.domProps)&&r(o=o.innerHTML)){if(o!==e.innerHTML)return!1}else{for(var c=!0,d=e.firstChild,p=0;p<u.length;p++){if(!d||!z(d,u[p],t,a)){c=!1;break}d=d.nextSibling}if(!c||d)return!1}else m(n,u,t);if(r(l)){var y=!1;for(var g in l)if(!T(g)){y=!0,b(n,t);break}!y&&l.class&&on(l.class)}}else e.data!==n.text&&(e.data=n.text);return!0}return function(e,n,t,s){if(!o(n)){var l,c=!1,h=[];if(o(e))c=!0,d(n,h);else{var p=r(e.nodeType);if(!p&&ta(e,n))j(e,n,h,null,null,s);else{if(p){if(1===e.nodeType&&e.hasAttribute("data-server-rendered")&&(e.removeAttribute("data-server-rendered"),t=!0),i(t)&&z(e,n,h))return S(n,h,!0),e;l=e,e=new me(u.tagName(l).toLowerCase(),{},[],void 0,l)}var m=e.elm,g=u.parentNode(m);if(d(n,h,m._leaveCb?null:g,u.nextSibling(m)),r(n.parent))for(var b=n.parent,k=y(n);b;){for(var f=0;f<a.destroy.length;++f)a.destroy[f](b);if(b.elm=n.elm,k){for(var q=0;q<a.create.length;++q)a.create[q](ea,b);var x=b.data.hook.insert;if(x.merged)for(var T=1;T<x.fns.length;T++)x.fns[T]()}else Xt(b);b=b.parent}r(g)?v([e],0,0):r(e.tag)&&w(e)}}return S(n,h,c),n.elm}r(e)&&w(e)}}({nodeOps:$t,modules:[ma,ba,ja,za,Ea,U?{create:lo,activate:lo,remove:function(e,n){!0!==e.data.show?ro(e,n):n()}}:{}].concat(ca)});J&&document.addEventListener("selectionchange",(function(){var e=document.activeElement;e&&e.vmodel&&ko(e,"input")}));var co={inserted:function(e,n,t,a){"select"===t.tag?(a.elm&&!a.elm._vOptions?un(t,"postpatch",(function(){co.componentUpdated(e,n,t)})):ho(e,n,t.context),e._vOptions=[].map.call(e.options,yo)):("textarea"===t.tag||Jt(e.type))&&(e._vModifiers=n.modifiers,n.modifiers.lazy||(e.addEventListener("compositionstart",go),e.addEventListener("compositionend",bo),e.addEventListener("change",bo),J&&(e.vmodel=!0)))},componentUpdated:function(e,n,t){if("select"===t.tag){ho(e,n,t.context);var a=e._vOptions,o=e._vOptions=[].map.call(e.options,yo);if(o.some((function(e,n){return!O(e,a[n])})))(e.multiple?n.value.some((function(e){return mo(e,o)})):n.value!==n.oldValue&&mo(n.value,o))&&ko(e,"change")}}};function ho(e,n,t){po(e,n,t),(Y||$)&&setTimeout((function(){po(e,n,t)}),0)}function po(e,n,t){var a=n.value,o=e.multiple;if(!o||Array.isArray(a)){for(var r,i,s=0,l=e.options.length;s<l;s++)if(i=e.options[s],o)r=H(a,yo(i))>-1,i.selected!==r&&(i.selected=r);else if(O(yo(i),a))return void(e.selectedIndex!==s&&(e.selectedIndex=s));o||(e.selectedIndex=-1)}}function mo(e,n){return n.every((function(n){return!O(n,e)}))}function yo(e){return"_value"in e?e._value:e.value}function go(e){e.target.composing=!0}function bo(e){e.target.composing&&(e.target.composing=!1,ko(e.target,"input"))}function ko(e,n){var t=document.createEvent("HTMLEvents");t.initEvent(n,!0,!0),e.dispatchEvent(t)}function fo(e){return!e.componentInstance||e.data&&e.data.transition?e:fo(e.componentInstance._vnode)}var wo={model:co,show:{bind:function(e,n,t){var a=n.value,o=(t=fo(t)).data&&t.data.transition,r=e.__vOriginalDisplay="none"===e.style.display?"":e.style.display;a&&o?(t.data.show=!0,oo(t,(function(){e.style.display=r}))):e.style.display=a?r:"none"},update:function(e,n,t){var a=n.value;!a!=!n.oldValue&&((t=fo(t)).data&&t.data.transition?(t.data.show=!0,a?oo(t,(function(){e.style.display=e.__vOriginalDisplay})):ro(t,(function(){e.style.display="none"}))):e.style.display=a?e.__vOriginalDisplay:"none")},unbind:function(e,n,t,a,o){o||(e.style.display=e.__vOriginalDisplay)}}},vo={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function qo(e){var n=e&&e.componentOptions;return n&&n.Ctor.options.abstract?qo(Fn(n.children)):e}function xo(e){var n={},t=e.$options;for(var a in t.propsData)n[a]=e[a];var o=t._parentListeners;for(var r in o)n[x(r)]=o[r];return n}function jo(e,n){if(/\d-keep-alive$/.test(n.tag))return e("keep-alive",{props:n.componentOptions.propsData})}var So=function(e){return e.tag||gn(e)},To=function(e){return"show"===e.name},zo={name:"transition",props:vo,abstract:!0,render:function(e){var n=this,t=this.$slots.default;if(t&&(t=t.filter(So)).length){0;var a=this.mode;0;var o=t[0];if(function(e){for(;e=e.parent;)if(e.data.transition)return!0}(this.$vnode))return o;var r=qo(o);if(!r)return o;if(this._leaving)return jo(e,o);var i="__transition-"+this._uid+"-";r.key=null==r.key?r.isComment?i+"comment":i+r.tag:s(r.key)?0===String(r.key).indexOf(i)?r.key:i+r.key:r.key;var l=(r.data||(r.data={})).transition=xo(this),u=this._vnode,c=qo(u);if(r.data.directives&&r.data.directives.some(To)&&(r.data.show=!0),c&&c.data&&!function(e,n){return n.key===e.key&&n.tag===e.tag}(r,c)&&!gn(c)&&(!c.componentInstance||!c.componentInstance._vnode.isComment)){var d=c.data.transition=I({},l);if("out-in"===a)return this._leaving=!0,un(d,"afterLeave",(function(){n._leaving=!1,n.$forceUpdate()})),jo(e,o);if("in-out"===a){if(gn(r))return u;var h,p=function(){h()};un(l,"afterEnter",p),un(l,"enterCancelled",p),un(d,"delayLeave",(function(e){h=e}))}}return o}}},Qo=I({tag:String,moveClass:String},vo);function Io(e){e.elm._moveCb&&e.elm._moveCb(),e.elm._enterCb&&e.elm._enterCb()}function Po(e){e.data.newPos=e.elm.getBoundingClientRect()}function _o(e){var n=e.data.pos,t=e.data.newPos,a=n.left-t.left,o=n.top-t.top;if(a||o){e.data.moved=!0;var r=e.elm.style;r.transform=r.WebkitTransform="translate("+a+"px,"+o+"px)",r.transitionDuration="0s"}}delete Qo.mode;var Co={Transition:zo,TransitionGroup:{props:Qo,beforeMount:function(){var e=this,n=this._update;this._update=function(t,a){var o=Zn(e);e.__patch__(e._vnode,e.kept,!1,!0),e._vnode=e.kept,o(),n.call(e,t,a)}},render:function(e){for(var n=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),a=this.prevChildren=this.children,o=this.$slots.default||[],r=this.children=[],i=xo(this),s=0;s<o.length;s++){var l=o[s];if(l.tag)if(null!=l.key&&0!==String(l.key).indexOf("__vlist"))r.push(l),t[l.key]=l,(l.data||(l.data={})).transition=i;else;}if(a){for(var u=[],c=[],d=0;d<a.length;d++){var h=a[d];h.data.transition=i,h.data.pos=h.elm.getBoundingClientRect(),t[h.key]?u.push(h):c.push(h)}this.kept=e(n,null,u),this.removed=c}return e(n,null,r)},updated:function(){var e=this.prevChildren,n=this.moveClass||(this.name||"v")+"-move";e.length&&this.hasMove(e[0].elm,n)&&(e.forEach(Io),e.forEach(Po),e.forEach(_o),this._reflow=document.body.offsetHeight,e.forEach((function(e){if(e.data.moved){var t=e.elm,a=t.style;$a(t,n),a.transform=a.WebkitTransform=a.transitionDuration="",t.addEventListener(Fa,t._moveCb=function e(a){a&&a.target!==t||a&&!/transform$/.test(a.propertyName)||(t.removeEventListener(Fa,e),t._moveCb=null,Za(t,n))})}})))},methods:{hasMove:function(e,n){if(!Wa)return!1;if(this._hasMove)return this._hasMove;var t=e.cloneNode();e._transitionClasses&&e._transitionClasses.forEach((function(e){Na(t,e)})),Ga(t,n),t.style.display="none",this.$el.appendChild(t);var a=no(t);return this.$el.removeChild(t),this._hasMove=a.hasTransform}}}};jt.config.mustUseProp=function(e,n,t){return"value"===t&&At(e)&&"button"!==n||"selected"===t&&"option"===e||"checked"===t&&"input"===e||"muted"===t&&"video"===e},jt.config.isReservedTag=Vt,jt.config.isReservedAttr=Ct,jt.config.getTagNamespace=function(e){return Kt(e)?"svg":"math"===e?"math":void 0},jt.config.isUnknownElement=function(e){if(!U)return!0;if(Vt(e))return!1;if(e=e.toLowerCase(),null!=Yt[e])return Yt[e];var n=document.createElement(e);return e.indexOf("-")>-1?Yt[e]=n.constructor===window.HTMLUnknownElement||n.constructor===window.HTMLElement:Yt[e]=/HTMLUnknownElement/.test(n.toString())},I(jt.options.directives,wo),I(jt.options.components,Co),jt.prototype.__patch__=U?uo:_,jt.prototype.$mount=function(e,n){return function(e,n,t){var a;return e.$el=n,e.$options.render||(e.$options.render=ge),nt(e,"beforeMount"),a=function(){e._update(e._render(),t)},new pt(e,a,_,{before:function(){e._isMounted&&!e._isDestroyed&&nt(e,"beforeUpdate")}},!0),t=!1,null==e.$vnode&&(e._isMounted=!0,nt(e,"mounted")),e}(this,e=e&&U?function(e){if("string"==typeof e){var n=document.querySelector(e);return n||document.createElement("div")}return e}(e):void 0,n)},U&&setTimeout((function(){B.devtools&&oe&&oe.emit("init",jt)}),0),n.a=jt},function(e,n,t){"use strict";function a(e,n,t,a,o,r,i,s){var l,u="function"==typeof e?e.options:e;if(n&&(u.render=n,u.staticRenderFns=t,u._compiled=!0),a&&(u.functional=!0),r&&(u._scopeId="data-v-"+r),i?(l=function(e){(e=e||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(e=__VUE_SSR_CONTEXT__),o&&o.call(this,e),e&&e._registeredComponents&&e._registeredComponents.add(i)},u._ssrRegister=l):o&&(l=s?function(){o.call(this,(u.functional?this.parent:this).$root.$options.shadowRoot)}:o),l)if(u.functional){u._injectStyles=l;var c=u.render;u.render=function(e,n){return l.call(n),c(e,n)}}else{var d=u.beforeCreate;u.beforeCreate=d?[].concat(d,l):[l]}return{exports:e,options:u}}t.d(n,"a",(function(){return a}))},function(e,n,t){var a=t(28),o="object"==typeof self&&self&&self.Object===Object&&self,r=a||o||Function("return this")();e.exports=r},function(e,n){var t=Array.isArray;e.exports=t},function(e,n,t){var a=t(82),o=t(85);e.exports=function(e,n){var t=o(e,n);return a(t)?t:void 0}},function(e,n){e.exports=function(e){return null!=e&&"object"==typeof e}},function(e,n,t){var a=t(2).Symbol;e.exports=a},function(e,n,t){var a=t(6),o=t(67),r=t(68),i=a?a.toStringTag:void 0;e.exports=function(e){return null==e?void 0===e?"[object Undefined]":"[object Null]":i&&i in Object(e)?o(e):r(e)}},function(e,n,t){
/*!
* screenfull
* v5.1.0 - 2020-12-24
* (c) Sindre Sorhus; MIT License
*/
!function(){"use strict";var n="undefined"!=typeof window&&void 0!==window.document?window.document:{},t=e.exports,a=function(){for(var e,t=[["requestFullscreen","exitFullscreen","fullscreenElement","fullscreenEnabled","fullscreenchange","fullscreenerror"],["webkitRequestFullscreen","webkitExitFullscreen","webkitFullscreenElement","webkitFullscreenEnabled","webkitfullscreenchange","webkitfullscreenerror"],["webkitRequestFullScreen","webkitCancelFullScreen","webkitCurrentFullScreenElement","webkitCancelFullScreen","webkitfullscreenchange","webkitfullscreenerror"],["mozRequestFullScreen","mozCancelFullScreen","mozFullScreenElement","mozFullScreenEnabled","mozfullscreenchange","mozfullscreenerror"],["msRequestFullscreen","msExitFullscreen","msFullscreenElement","msFullscreenEnabled","MSFullscreenChange","MSFullscreenError"]],a=0,o=t.length,r={};a<o;a++)if((e=t[a])&&e[1]in n){for(a=0;a<e.length;a++)r[t[0][a]]=e[a];return r}return!1}(),o={change:a.fullscreenchange,error:a.fullscreenerror},r={request:function(e,t){return new Promise(function(o,r){var i=function(){this.off("change",i),o()}.bind(this);this.on("change",i);var s=(e=e||n.documentElement)[a.requestFullscreen](t);s instanceof Promise&&s.then(i).catch(r)}.bind(this))},exit:function(){return new Promise(function(e,t){if(this.isFullscreen){var o=function(){this.off("change",o),e()}.bind(this);this.on("change",o);var r=n[a.exitFullscreen]();r instanceof Promise&&r.then(o).catch(t)}else e()}.bind(this))},toggle:function(e,n){return this.isFullscreen?this.exit():this.request(e,n)},onchange:function(e){this.on("change",e)},onerror:function(e){this.on("error",e)},on:function(e,t){var a=o[e];a&&n.addEventListener(a,t,!1)},off:function(e,t){var a=o[e];a&&n.removeEventListener(a,t,!1)},raw:a};a?(Object.defineProperties(r,{isFullscreen:{get:function(){return Boolean(n[a.fullscreenElement])}},element:{enumerable:!0,get:function(){return n[a.fullscreenElement]}},isEnabled:{enumerable:!0,get:function(){return Boolean(n[a.fullscreenEnabled])}}}),t?e.exports=r:window.screenfull=r):t?e.exports={isEnabled:!1}:window.screenfull={isEnabled:!1}}()},function(e,n,t){var a=t(72),o=t(73),r=t(74),i=t(75),s=t(76);function l(e){var n=-1,t=null==e?0:e.length;for(this.clear();++n<t;){var a=e[n];this.set(a[0],a[1])}}l.prototype.clear=a,l.prototype.delete=o,l.prototype.get=r,l.prototype.has=i,l.prototype.set=s,e.exports=l},function(e,n,t){var a=t(30);e.exports=function(e,n){for(var t=e.length;t--;)if(a(e[t][0],n))return t;return-1}},function(e,n,t){var a=t(4)(Object,"create");e.exports=a},function(e,n,t){var a=t(94);e.exports=function(e,n){var t=e.__data__;return a(n)?t["string"==typeof n?"string":"hash"]:t.map}},function(e,n,t){var a=t(24);e.exports=function(e){if("string"==typeof e||a(e))return e;var n=e+"";return"0"==n&&1/e==-1/0?"-0":n}},function(e,n){var t=/^\s+|\s+$/g,a=/^[-+]0x[0-9a-f]+$/i,o=/^0b[01]+$/i,r=/^0o[0-7]+$/i,i=parseInt,s="object"==typeof global&&global&&global.Object===Object&&global,l="object"==typeof self&&self&&self.Object===Object&&self,u=s||l||Function("return this")(),c=Object.prototype.toString,d=Math.max,h=Math.min,p=function(){return u.Date.now()};function m(e){var n=typeof e;return!!e&&("object"==n||"function"==n)}function y(e){if("number"==typeof e)return e;if(function(e){return"symbol"==typeof e||function(e){return!!e&&"object"==typeof e}(e)&&"[object Symbol]"==c.call(e)}(e))return NaN;if(m(e)){var n="function"==typeof e.valueOf?e.valueOf():e;e=m(n)?n+"":n}if("string"!=typeof e)return 0===e?e:+e;e=e.replace(t,"");var s=o.test(e);return s||r.test(e)?i(e.slice(2),s?2:8):a.test(e)?NaN:+e}e.exports=function(e,n,t){var a,o,r,i,s,l,u=0,c=!1,g=!1,b=!0;if("function"!=typeof e)throw new TypeError("Expected a function");function k(n){var t=a,r=o;return a=o=void 0,u=n,i=e.apply(r,t)}function f(e){return u=e,s=setTimeout(v,n),c?k(e):i}function w(e){var t=e-l;return void 0===l||t>=n||t<0||g&&e-u>=r}function v(){var e=p();if(w(e))return q(e);s=setTimeout(v,function(e){var t=n-(e-l);return g?h(t,r-(e-u)):t}(e))}function q(e){return s=void 0,b&&a?k(e):(a=o=void 0,i)}function x(){var e=p(),t=w(e);if(a=arguments,o=this,l=e,t){if(void 0===s)return f(l);if(g)return s=setTimeout(v,n),k(l)}return void 0===s&&(s=setTimeout(v,n)),i}return n=y(n)||0,m(t)&&(c=!!t.leading,r=(g="maxWait"in t)?d(y(t.maxWait)||0,n):r,b="trailing"in t?!!t.trailing:b),x.cancel=function(){void 0!==s&&clearTimeout(s),u=0,a=l=o=s=void 0},x.flush=function(){return void 0===s?i:q(p())},x}},function(e,n,t){var a,o;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(o="function"==typeof(a=function(){var e,n,t={version:"0.2.0"},a=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function o(e,n,t){return e<n?n:e>t?t:e}function r(e){return 100*(-1+e)}t.configure=function(e){var n,t;for(n in e)void 0!==(t=e[n])&&e.hasOwnProperty(n)&&(a[n]=t);return this},t.status=null,t.set=function(e){var n=t.isStarted();e=o(e,a.minimum,1),t.status=1===e?null:e;var l=t.render(!n),u=l.querySelector(a.barSelector),c=a.speed,d=a.easing;return l.offsetWidth,i((function(n){""===a.positionUsing&&(a.positionUsing=t.getPositioningCSS()),s(u,function(e,n,t){var o;return(o="translate3d"===a.positionUsing?{transform:"translate3d("+r(e)+"%,0,0)"}:"translate"===a.positionUsing?{transform:"translate("+r(e)+"%,0)"}:{"margin-left":r(e)+"%"}).transition="all "+n+"ms "+t,o}(e,c,d)),1===e?(s(l,{transition:"none",opacity:1}),l.offsetWidth,setTimeout((function(){s(l,{transition:"all "+c+"ms linear",opacity:0}),setTimeout((function(){t.remove(),n()}),c)}),c)):setTimeout(n,c)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var e=function(){setTimeout((function(){t.status&&(t.trickle(),e())}),a.trickleSpeed)};return a.trickle&&e(),this},t.done=function(e){return e||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(e){var n=t.status;return n?("number"!=typeof e&&(e=(1-n)*o(Math.random()*n,.1,.95)),n=o(n+e,0,.994),t.set(n)):t.start()},t.trickle=function(){return t.inc(Math.random()*a.trickleRate)},e=0,n=0,t.promise=function(a){return a&&"resolved"!==a.state()?(0===n&&t.start(),e++,n++,a.always((function(){0==--n?(e=0,t.done()):t.set((e-n)/e)})),this):this},t.render=function(e){if(t.isRendered())return document.getElementById("nprogress");u(document.documentElement,"nprogress-busy");var n=document.createElement("div");n.id="nprogress",n.innerHTML=a.template;var o,i=n.querySelector(a.barSelector),l=e?"-100":r(t.status||0),c=document.querySelector(a.parent);return s(i,{transition:"all 0 linear",transform:"translate3d("+l+"%,0,0)"}),a.showSpinner||(o=n.querySelector(a.spinnerSelector))&&h(o),c!=document.body&&u(c,"nprogress-custom-parent"),c.appendChild(n),n},t.remove=function(){c(document.documentElement,"nprogress-busy"),c(document.querySelector(a.parent),"nprogress-custom-parent");var e=document.getElementById("nprogress");e&&h(e)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var e=document.body.style,n="WebkitTransform"in e?"Webkit":"MozTransform"in e?"Moz":"msTransform"in e?"ms":"OTransform"in e?"O":"";return n+"Perspective"in e?"translate3d":n+"Transform"in e?"translate":"margin"};var i=function(){var e=[];function n(){var t=e.shift();t&&t(n)}return function(t){e.push(t),1==e.length&&n()}}(),s=function(){var e=["Webkit","O","Moz","ms"],n={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(e,n){return n.toUpperCase()})),n[t]||(n[t]=function(n){var t=document.body.style;if(n in t)return n;for(var a,o=e.length,r=n.charAt(0).toUpperCase()+n.slice(1);o--;)if((a=e[o]+r)in t)return a;return n}(t))}function a(e,n,a){n=t(n),e.style[n]=a}return function(e,n){var t,o,r=arguments;if(2==r.length)for(t in n)void 0!==(o=n[t])&&n.hasOwnProperty(t)&&a(e,t,o);else a(e,r[1],r[2])}}();function l(e,n){return("string"==typeof e?e:d(e)).indexOf(" "+n+" ")>=0}function u(e,n){var t=d(e),a=t+n;l(t,n)||(e.className=a.substring(1))}function c(e,n){var t,a=d(e);l(e,n)&&(t=a.replace(" "+n+" "," "),e.className=t.substring(1,t.length-1))}function d(e){return(" "+(e.className||"")+" ").replace(/\s+/gi," ")}function h(e){e&&e.parentNode&&e.parentNode.removeChild(e)}return t})?a.call(n,t,n,e):a)||(e.exports=o)},function(e,n,t){"use strict";n.a={render:()=>null}},function(e,n,t){var a=t(66),o=t(5),r=Object.prototype,i=r.hasOwnProperty,s=r.propertyIsEnumerable,l=a(function(){return arguments}())?a:function(e){return o(e)&&i.call(e,"callee")&&!s.call(e,"callee")};e.exports=l},function(e,n,t){var a=t(4)(t(2),"Map");e.exports=a},function(e,n){e.exports=function(e){var n=typeof e;return null!=e&&("object"==n||"function"==n)}},function(e,n,t){var a=t(86),o=t(93),r=t(95),i=t(96),s=t(97);function l(e){var n=-1,t=null==e?0:e.length;for(this.clear();++n<t;){var a=e[n];this.set(a[0],a[1])}}l.prototype.clear=a,l.prototype.delete=o,l.prototype.get=r,l.prototype.has=i,l.prototype.set=s,e.exports=l},function(e,n){e.exports=function(e){var n=-1,t=Array(e.size);return e.forEach((function(e){t[++n]=e})),t}},function(e,n){e.exports=function(e){return"number"==typeof e&&e>-1&&e%1==0&&e<=9007199254740991}},function(e,n,t){var a=t(3),o=t(24),r=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,i=/^\w*$/;e.exports=function(e,n){if(a(e))return!1;var t=typeof e;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=e&&!o(e))||(i.test(e)||!r.test(e)||null!=n&&e in Object(n))}},function(e,n,t){var a=t(7),o=t(5);e.exports=function(e){return"symbol"==typeof e||o(e)&&"[object Symbol]"==a(e)}},function(e,n){e.exports=function(e){return e}},function(e,n){e.exports=function(e){return e.webpackPolyfill||(e.deprecate=function(){},e.paths=[],e.children||(e.children=[]),Object.defineProperty(e,"loaded",{enumerable:!0,get:function(){return e.l}}),Object.defineProperty(e,"id",{enumerable:!0,get:function(){return e.i}}),e.webpackPolyfill=1),e}},function(e,n){e.exports=function(e,n){for(var t=-1,a=n.length,o=e.length;++t<a;)e[o+t]=n[t];return e}},function(e,n){var t="object"==typeof global&&global&&global.Object===Object&&global;e.exports=t},function(e,n,t){var a=t(9),o=t(77),r=t(78),i=t(79),s=t(80),l=t(81);function u(e){var n=this.__data__=new a(e);this.size=n.size}u.prototype.clear=o,u.prototype.delete=r,u.prototype.get=i,u.prototype.has=s,u.prototype.set=l,e.exports=u},function(e,n){e.exports=function(e,n){return e===n||e!=e&&n!=n}},function(e,n,t){var a=t(7),o=t(19);e.exports=function(e){if(!o(e))return!1;var n=a(e);return"[object Function]"==n||"[object GeneratorFunction]"==n||"[object AsyncFunction]"==n||"[object Proxy]"==n}},function(e,n){var t=Function.prototype.toString;e.exports=function(e){if(null!=e){try{return t.call(e)}catch(e){}try{return e+""}catch(e){}}return""}},function(e,n,t){var a=t(98),o=t(5);e.exports=function e(n,t,r,i,s){return n===t||(null==n||null==t||!o(n)&&!o(t)?n!=n&&t!=t:a(n,t,r,i,e,s))}},function(e,n,t){var a=t(35),o=t(101),r=t(36);e.exports=function(e,n,t,i,s,l){var u=1&t,c=e.length,d=n.length;if(c!=d&&!(u&&d>c))return!1;var h=l.get(e),p=l.get(n);if(h&&p)return h==n&&p==e;var m=-1,y=!0,g=2&t?new a:void 0;for(l.set(e,n),l.set(n,e);++m<c;){var b=e[m],k=n[m];if(i)var f=u?i(k,b,m,n,e,l):i(b,k,m,e,n,l);if(void 0!==f){if(f)continue;y=!1;break}if(g){if(!o(n,(function(e,n){if(!r(g,n)&&(b===e||s(b,e,t,i,l)))return g.push(n)}))){y=!1;break}}else if(b!==k&&!s(b,k,t,i,l)){y=!1;break}}return l.delete(e),l.delete(n),y}},function(e,n,t){var a=t(20),o=t(99),r=t(100);function i(e){var n=-1,t=null==e?0:e.length;for(this.__data__=new a;++n<t;)this.add(e[n])}i.prototype.add=i.prototype.push=o,i.prototype.has=r,e.exports=i},function(e,n){e.exports=function(e,n){return e.has(n)}},function(e,n,t){var a=t(111),o=t(117),r=t(41);e.exports=function(e){return r(e)?a(e):o(e)}},function(e,n,t){(function(e){var a=t(2),o=t(113),r=n&&!n.nodeType&&n,i=r&&"object"==typeof e&&e&&!e.nodeType&&e,s=i&&i.exports===r?a.Buffer:void 0,l=(s?s.isBuffer:void 0)||o;e.exports=l}).call(this,t(26)(e))},function(e,n){var t=/^(?:0|[1-9]\d*)$/;e.exports=function(e,n){var a=typeof e;return!!(n=null==n?9007199254740991:n)&&("number"==a||"symbol"!=a&&t.test(e))&&e>-1&&e%1==0&&e<n}},function(e,n,t){var a=t(114),o=t(115),r=t(116),i=r&&r.isTypedArray,s=i?o(i):a;e.exports=s},function(e,n,t){var a=t(31),o=t(22);e.exports=function(e){return null!=e&&o(e.length)&&!a(e)}},function(e,n,t){var a=t(4)(t(2),"Set");e.exports=a},function(e,n,t){var a=t(19);e.exports=function(e){return e==e&&!a(e)}},function(e,n){e.exports=function(e,n){return function(t){return null!=t&&(t[e]===n&&(void 0!==n||e in Object(t)))}}},function(e,n,t){var a=t(46),o=t(13);e.exports=function(e,n){for(var t=0,r=(n=a(n,e)).length;null!=e&&t<r;)e=e[o(n[t++])];return t&&t==r?e:void 0}},function(e,n,t){var a=t(3),o=t(23),r=t(128),i=t(131);e.exports=function(e,n){return a(e)?e:o(e,n)?[e]:r(i(e))}},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){var a=t(64),o=t(69),r=t(140),i=t(148),s=t(157),l=t(158),u=r((function(e){var n=l(e);return s(n)&&(n=void 0),i(a(e,1,s,!0),o(n,2))}));e.exports=u},function(e,n,t){n.formatArgs=function(n){if(n[0]=(this.useColors?"%c":"")+this.namespace+(this.useColors?" %c":" ")+n[0]+(this.useColors?"%c ":" ")+"+"+e.exports.humanize(this.diff),!this.useColors)return;const t="color: "+this.color;n.splice(1,0,t,"color: inherit");let a=0,o=0;n[0].replace(/%[a-zA-Z%]/g,e=>{"%%"!==e&&(a++,"%c"===e&&(o=a))}),n.splice(o,0,t)},n.save=function(e){try{e?n.storage.setItem("debug",e):n.storage.removeItem("debug")}catch(e){}},n.load=function(){let e;try{e=n.storage.getItem("debug")}catch(e){}!e&&"undefined"!=typeof process&&"env"in process&&(e=process.env.DEBUG);return e},n.useColors=function(){if("undefined"!=typeof window&&window.process&&("renderer"===window.process.type||window.process.__nwjs))return!0;if("undefined"!=typeof navigator&&navigator.userAgent&&navigator.userAgent.toLowerCase().match(/(edge|trident)\/(\d+)/))return!1;return"undefined"!=typeof document&&document.documentElement&&document.documentElement.style&&document.documentElement.style.WebkitAppearance||"undefined"!=typeof window&&window.console&&(window.console.firebug||window.console.exception&&window.console.table)||"undefined"!=typeof navigator&&navigator.userAgent&&navigator.userAgent.toLowerCase().match(/firefox\/(\d+)/)&&parseInt(RegExp.$1,10)>=31||"undefined"!=typeof navigator&&navigator.userAgent&&navigator.userAgent.toLowerCase().match(/applewebkit\/(\d+)/)},n.storage=function(){try{return localStorage}catch(e){}}(),n.destroy=(()=>{let e=!1;return()=>{e||(e=!0,console.warn("Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`."))}})(),n.colors=["#0000CC","#0000FF","#0033CC","#0033FF","#0066CC","#0066FF","#0099CC","#0099FF","#00CC00","#00CC33","#00CC66","#00CC99","#00CCCC","#00CCFF","#3300CC","#3300FF","#3333CC","#3333FF","#3366CC","#3366FF","#3399CC","#3399FF","#33CC00","#33CC33","#33CC66","#33CC99","#33CCCC","#33CCFF","#6600CC","#6600FF","#6633CC","#6633FF","#66CC00","#66CC33","#9900CC","#9900FF","#9933CC","#9933FF","#99CC00","#99CC33","#CC0000","#CC0033","#CC0066","#CC0099","#CC00CC","#CC00FF","#CC3300","#CC3333","#CC3366","#CC3399","#CC33CC","#CC33FF","#CC6600","#CC6633","#CC9900","#CC9933","#CCCC00","#CCCC33","#FF0000","#FF0033","#FF0066","#FF0099","#FF00CC","#FF00FF","#FF3300","#FF3333","#FF3366","#FF3399","#FF33CC","#FF33FF","#FF6600","#FF6633","#FF9900","#FF9933","#FFCC00","#FFCC33"],n.log=console.debug||console.log||(()=>{}),e.exports=t(173)(n);const{formatters:a}=e.exports;a.j=function(e){try{return JSON.stringify(e)}catch(e){return"[UnexpectedJSONParseError]: "+e.message}}},function(e,n,t){},function(e,n,t){e.exports=t(180)},function(e,n,t){var a=t(27),o=t(65);e.exports=function e(n,t,r,i,s){var l=-1,u=n.length;for(r||(r=o),s||(s=[]);++l<u;){var c=n[l];t>0&&r(c)?t>1?e(c,t-1,r,i,s):a(s,c):i||(s[s.length]=c)}return s}},function(e,n,t){var a=t(6),o=t(17),r=t(3),i=a?a.isConcatSpreadable:void 0;e.exports=function(e){return r(e)||o(e)||!!(i&&e&&e[i])}},function(e,n,t){var a=t(7),o=t(5);e.exports=function(e){return o(e)&&"[object Arguments]"==a(e)}},function(e,n,t){var a=t(6),o=Object.prototype,r=o.hasOwnProperty,i=o.toString,s=a?a.toStringTag:void 0;e.exports=function(e){var n=r.call(e,s),t=e[s];try{e[s]=void 0;var a=!0}catch(e){}var o=i.call(e);return a&&(n?e[s]=t:delete e[s]),o}},function(e,n){var t=Object.prototype.toString;e.exports=function(e){return t.call(e)}},function(e,n,t){var a=t(70),o=t(126),r=t(25),i=t(3),s=t(137);e.exports=function(e){return"function"==typeof e?e:null==e?r:"object"==typeof e?i(e)?o(e[0],e[1]):a(e):s(e)}},function(e,n,t){var a=t(71),o=t(125),r=t(44);e.exports=function(e){var n=o(e);return 1==n.length&&n[0][2]?r(n[0][0],n[0][1]):function(t){return t===e||a(t,e,n)}}},function(e,n,t){var a=t(29),o=t(33);e.exports=function(e,n,t,r){var i=t.length,s=i,l=!r;if(null==e)return!s;for(e=Object(e);i--;){var u=t[i];if(l&&u[2]?u[1]!==e[u[0]]:!(u[0]in e))return!1}for(;++i<s;){var c=(u=t[i])[0],d=e[c],h=u[1];if(l&&u[2]){if(void 0===d&&!(c in e))return!1}else{var p=new a;if(r)var m=r(d,h,c,e,n,p);if(!(void 0===m?o(h,d,3,r,p):m))return!1}}return!0}},function(e,n){e.exports=function(){this.__data__=[],this.size=0}},function(e,n,t){var a=t(10),o=Array.prototype.splice;e.exports=function(e){var n=this.__data__,t=a(n,e);return!(t<0)&&(t==n.length-1?n.pop():o.call(n,t,1),--this.size,!0)}},function(e,n,t){var a=t(10);e.exports=function(e){var n=this.__data__,t=a(n,e);return t<0?void 0:n[t][1]}},function(e,n,t){var a=t(10);e.exports=function(e){return a(this.__data__,e)>-1}},function(e,n,t){var a=t(10);e.exports=function(e,n){var t=this.__data__,o=a(t,e);return o<0?(++this.size,t.push([e,n])):t[o][1]=n,this}},function(e,n,t){var a=t(9);e.exports=function(){this.__data__=new a,this.size=0}},function(e,n){e.exports=function(e){var n=this.__data__,t=n.delete(e);return this.size=n.size,t}},function(e,n){e.exports=function(e){return this.__data__.get(e)}},function(e,n){e.exports=function(e){return this.__data__.has(e)}},function(e,n,t){var a=t(9),o=t(18),r=t(20);e.exports=function(e,n){var t=this.__data__;if(t instanceof a){var i=t.__data__;if(!o||i.length<199)return i.push([e,n]),this.size=++t.size,this;t=this.__data__=new r(i)}return t.set(e,n),this.size=t.size,this}},function(e,n,t){var a=t(31),o=t(83),r=t(19),i=t(32),s=/^\[object .+?Constructor\]$/,l=Function.prototype,u=Object.prototype,c=l.toString,d=u.hasOwnProperty,h=RegExp("^"+c.call(d).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");e.exports=function(e){return!(!r(e)||o(e))&&(a(e)?h:s).test(i(e))}},function(e,n,t){var a,o=t(84),r=(a=/[^.]+$/.exec(o&&o.keys&&o.keys.IE_PROTO||""))?"Symbol(src)_1."+a:"";e.exports=function(e){return!!r&&r in e}},function(e,n,t){var a=t(2)["__core-js_shared__"];e.exports=a},function(e,n){e.exports=function(e,n){return null==e?void 0:e[n]}},function(e,n,t){var a=t(87),o=t(9),r=t(18);e.exports=function(){this.size=0,this.__data__={hash:new a,map:new(r||o),string:new a}}},function(e,n,t){var a=t(88),o=t(89),r=t(90),i=t(91),s=t(92);function l(e){var n=-1,t=null==e?0:e.length;for(this.clear();++n<t;){var a=e[n];this.set(a[0],a[1])}}l.prototype.clear=a,l.prototype.delete=o,l.prototype.get=r,l.prototype.has=i,l.prototype.set=s,e.exports=l},function(e,n,t){var a=t(11);e.exports=function(){this.__data__=a?a(null):{},this.size=0}},function(e,n){e.exports=function(e){var n=this.has(e)&&delete this.__data__[e];return this.size-=n?1:0,n}},function(e,n,t){var a=t(11),o=Object.prototype.hasOwnProperty;e.exports=function(e){var n=this.__data__;if(a){var t=n[e];return"__lodash_hash_undefined__"===t?void 0:t}return o.call(n,e)?n[e]:void 0}},function(e,n,t){var a=t(11),o=Object.prototype.hasOwnProperty;e.exports=function(e){var n=this.__data__;return a?void 0!==n[e]:o.call(n,e)}},function(e,n,t){var a=t(11);e.exports=function(e,n){var t=this.__data__;return this.size+=this.has(e)?0:1,t[e]=a&&void 0===n?"__lodash_hash_undefined__":n,this}},function(e,n,t){var a=t(12);e.exports=function(e){var n=a(this,e).delete(e);return this.size-=n?1:0,n}},function(e,n){e.exports=function(e){var n=typeof e;return"string"==n||"number"==n||"symbol"==n||"boolean"==n?"__proto__"!==e:null===e}},function(e,n,t){var a=t(12);e.exports=function(e){return a(this,e).get(e)}},function(e,n,t){var a=t(12);e.exports=function(e){return a(this,e).has(e)}},function(e,n,t){var a=t(12);e.exports=function(e,n){var t=a(this,e),o=t.size;return t.set(e,n),this.size+=t.size==o?0:1,this}},function(e,n,t){var a=t(29),o=t(34),r=t(102),i=t(105),s=t(121),l=t(3),u=t(38),c=t(40),d="[object Object]",h=Object.prototype.hasOwnProperty;e.exports=function(e,n,t,p,m,y){var g=l(e),b=l(n),k=g?"[object Array]":s(e),f=b?"[object Array]":s(n),w=(k="[object Arguments]"==k?d:k)==d,v=(f="[object Arguments]"==f?d:f)==d,q=k==f;if(q&&u(e)){if(!u(n))return!1;g=!0,w=!1}if(q&&!w)return y||(y=new a),g||c(e)?o(e,n,t,p,m,y):r(e,n,k,t,p,m,y);if(!(1&t)){var x=w&&h.call(e,"__wrapped__"),j=v&&h.call(n,"__wrapped__");if(x||j){var S=x?e.value():e,T=j?n.value():n;return y||(y=new a),m(S,T,t,p,y)}}return!!q&&(y||(y=new a),i(e,n,t,p,m,y))}},function(e,n){e.exports=function(e){return this.__data__.set(e,"__lodash_hash_undefined__"),this}},function(e,n){e.exports=function(e){return this.__data__.has(e)}},function(e,n){e.exports=function(e,n){for(var t=-1,a=null==e?0:e.length;++t<a;)if(n(e[t],t,e))return!0;return!1}},function(e,n,t){var a=t(6),o=t(103),r=t(30),i=t(34),s=t(104),l=t(21),u=a?a.prototype:void 0,c=u?u.valueOf:void 0;e.exports=function(e,n,t,a,u,d,h){switch(t){case"[object DataView]":if(e.byteLength!=n.byteLength||e.byteOffset!=n.byteOffset)return!1;e=e.buffer,n=n.buffer;case"[object ArrayBuffer]":return!(e.byteLength!=n.byteLength||!d(new o(e),new o(n)));case"[object Boolean]":case"[object Date]":case"[object Number]":return r(+e,+n);case"[object Error]":return e.name==n.name&&e.message==n.message;case"[object RegExp]":case"[object String]":return e==n+"";case"[object Map]":var p=s;case"[object Set]":var m=1&a;if(p||(p=l),e.size!=n.size&&!m)return!1;var y=h.get(e);if(y)return y==n;a|=2,h.set(e,n);var g=i(p(e),p(n),a,u,d,h);return h.delete(e),g;case"[object Symbol]":if(c)return c.call(e)==c.call(n)}return!1}},function(e,n,t){var a=t(2).Uint8Array;e.exports=a},function(e,n){e.exports=function(e){var n=-1,t=Array(e.size);return e.forEach((function(e,a){t[++n]=[a,e]})),t}},function(e,n,t){var a=t(106),o=Object.prototype.hasOwnProperty;e.exports=function(e,n,t,r,i,s){var l=1&t,u=a(e),c=u.length;if(c!=a(n).length&&!l)return!1;for(var d=c;d--;){var h=u[d];if(!(l?h in n:o.call(n,h)))return!1}var p=s.get(e),m=s.get(n);if(p&&m)return p==n&&m==e;var y=!0;s.set(e,n),s.set(n,e);for(var g=l;++d<c;){var b=e[h=u[d]],k=n[h];if(r)var f=l?r(k,b,h,n,e,s):r(b,k,h,e,n,s);if(!(void 0===f?b===k||i(b,k,t,r,s):f)){y=!1;break}g||(g="constructor"==h)}if(y&&!g){var w=e.constructor,v=n.constructor;w==v||!("constructor"in e)||!("constructor"in n)||"function"==typeof w&&w instanceof w&&"function"==typeof v&&v instanceof v||(y=!1)}return s.delete(e),s.delete(n),y}},function(e,n,t){var a=t(107),o=t(108),r=t(37);e.exports=function(e){return a(e,r,o)}},function(e,n,t){var a=t(27),o=t(3);e.exports=function(e,n,t){var r=n(e);return o(e)?r:a(r,t(e))}},function(e,n,t){var a=t(109),o=t(110),r=Object.prototype.propertyIsEnumerable,i=Object.getOwnPropertySymbols,s=i?function(e){return null==e?[]:(e=Object(e),a(i(e),(function(n){return r.call(e,n)})))}:o;e.exports=s},function(e,n){e.exports=function(e,n){for(var t=-1,a=null==e?0:e.length,o=0,r=[];++t<a;){var i=e[t];n(i,t,e)&&(r[o++]=i)}return r}},function(e,n){e.exports=function(){return[]}},function(e,n,t){var a=t(112),o=t(17),r=t(3),i=t(38),s=t(39),l=t(40),u=Object.prototype.hasOwnProperty;e.exports=function(e,n){var t=r(e),c=!t&&o(e),d=!t&&!c&&i(e),h=!t&&!c&&!d&&l(e),p=t||c||d||h,m=p?a(e.length,String):[],y=m.length;for(var g in e)!n&&!u.call(e,g)||p&&("length"==g||d&&("offset"==g||"parent"==g)||h&&("buffer"==g||"byteLength"==g||"byteOffset"==g)||s(g,y))||m.push(g);return m}},function(e,n){e.exports=function(e,n){for(var t=-1,a=Array(e);++t<e;)a[t]=n(t);return a}},function(e,n){e.exports=function(){return!1}},function(e,n,t){var a=t(7),o=t(22),r=t(5),i={};i["[object Float32Array]"]=i["[object Float64Array]"]=i["[object Int8Array]"]=i["[object Int16Array]"]=i["[object Int32Array]"]=i["[object Uint8Array]"]=i["[object Uint8ClampedArray]"]=i["[object Uint16Array]"]=i["[object Uint32Array]"]=!0,i["[object Arguments]"]=i["[object Array]"]=i["[object ArrayBuffer]"]=i["[object Boolean]"]=i["[object DataView]"]=i["[object Date]"]=i["[object Error]"]=i["[object Function]"]=i["[object Map]"]=i["[object Number]"]=i["[object Object]"]=i["[object RegExp]"]=i["[object Set]"]=i["[object String]"]=i["[object WeakMap]"]=!1,e.exports=function(e){return r(e)&&o(e.length)&&!!i[a(e)]}},function(e,n){e.exports=function(e){return function(n){return e(n)}}},function(e,n,t){(function(e){var a=t(28),o=n&&!n.nodeType&&n,r=o&&"object"==typeof e&&e&&!e.nodeType&&e,i=r&&r.exports===o&&a.process,s=function(){try{var e=r&&r.require&&r.require("util").types;return e||i&&i.binding&&i.binding("util")}catch(e){}}();e.exports=s}).call(this,t(26)(e))},function(e,n,t){var a=t(118),o=t(119),r=Object.prototype.hasOwnProperty;e.exports=function(e){if(!a(e))return o(e);var n=[];for(var t in Object(e))r.call(e,t)&&"constructor"!=t&&n.push(t);return n}},function(e,n){var t=Object.prototype;e.exports=function(e){var n=e&&e.constructor;return e===("function"==typeof n&&n.prototype||t)}},function(e,n,t){var a=t(120)(Object.keys,Object);e.exports=a},function(e,n){e.exports=function(e,n){return function(t){return e(n(t))}}},function(e,n,t){var a=t(122),o=t(18),r=t(123),i=t(42),s=t(124),l=t(7),u=t(32),c=u(a),d=u(o),h=u(r),p=u(i),m=u(s),y=l;(a&&"[object DataView]"!=y(new a(new ArrayBuffer(1)))||o&&"[object Map]"!=y(new o)||r&&"[object Promise]"!=y(r.resolve())||i&&"[object Set]"!=y(new i)||s&&"[object WeakMap]"!=y(new s))&&(y=function(e){var n=l(e),t="[object Object]"==n?e.constructor:void 0,a=t?u(t):"";if(a)switch(a){case c:return"[object DataView]";case d:return"[object Map]";case h:return"[object Promise]";case p:return"[object Set]";case m:return"[object WeakMap]"}return n}),e.exports=y},function(e,n,t){var a=t(4)(t(2),"DataView");e.exports=a},function(e,n,t){var a=t(4)(t(2),"Promise");e.exports=a},function(e,n,t){var a=t(4)(t(2),"WeakMap");e.exports=a},function(e,n,t){var a=t(43),o=t(37);e.exports=function(e){for(var n=o(e),t=n.length;t--;){var r=n[t],i=e[r];n[t]=[r,i,a(i)]}return n}},function(e,n,t){var a=t(33),o=t(127),r=t(134),i=t(23),s=t(43),l=t(44),u=t(13);e.exports=function(e,n){return i(e)&&s(n)?l(u(e),n):function(t){var i=o(t,e);return void 0===i&&i===n?r(t,e):a(n,i,3)}}},function(e,n,t){var a=t(45);e.exports=function(e,n,t){var o=null==e?void 0:a(e,n);return void 0===o?t:o}},function(e,n,t){var a=t(129),o=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,r=/\\(\\)?/g,i=a((function(e){var n=[];return 46===e.charCodeAt(0)&&n.push(""),e.replace(o,(function(e,t,a,o){n.push(a?o.replace(r,"$1"):t||e)})),n}));e.exports=i},function(e,n,t){var a=t(130);e.exports=function(e){var n=a(e,(function(e){return 500===t.size&&t.clear(),e})),t=n.cache;return n}},function(e,n,t){var a=t(20);function o(e,n){if("function"!=typeof e||null!=n&&"function"!=typeof n)throw new TypeError("Expected a function");var t=function(){var a=arguments,o=n?n.apply(this,a):a[0],r=t.cache;if(r.has(o))return r.get(o);var i=e.apply(this,a);return t.cache=r.set(o,i)||r,i};return t.cache=new(o.Cache||a),t}o.Cache=a,e.exports=o},function(e,n,t){var a=t(132);e.exports=function(e){return null==e?"":a(e)}},function(e,n,t){var a=t(6),o=t(133),r=t(3),i=t(24),s=a?a.prototype:void 0,l=s?s.toString:void 0;e.exports=function e(n){if("string"==typeof n)return n;if(r(n))return o(n,e)+"";if(i(n))return l?l.call(n):"";var t=n+"";return"0"==t&&1/n==-1/0?"-0":t}},function(e,n){e.exports=function(e,n){for(var t=-1,a=null==e?0:e.length,o=Array(a);++t<a;)o[t]=n(e[t],t,e);return o}},function(e,n,t){var a=t(135),o=t(136);e.exports=function(e,n){return null!=e&&o(e,n,a)}},function(e,n){e.exports=function(e,n){return null!=e&&n in Object(e)}},function(e,n,t){var a=t(46),o=t(17),r=t(3),i=t(39),s=t(22),l=t(13);e.exports=function(e,n,t){for(var u=-1,c=(n=a(n,e)).length,d=!1;++u<c;){var h=l(n[u]);if(!(d=null!=e&&t(e,h)))break;e=e[h]}return d||++u!=c?d:!!(c=null==e?0:e.length)&&s(c)&&i(h,c)&&(r(e)||o(e))}},function(e,n,t){var a=t(138),o=t(139),r=t(23),i=t(13);e.exports=function(e){return r(e)?a(i(e)):o(e)}},function(e,n){e.exports=function(e){return function(n){return null==n?void 0:n[e]}}},function(e,n,t){var a=t(45);e.exports=function(e){return function(n){return a(n,e)}}},function(e,n,t){var a=t(25),o=t(141),r=t(143);e.exports=function(e,n){return r(o(e,n,a),e+"")}},function(e,n,t){var a=t(142),o=Math.max;e.exports=function(e,n,t){return n=o(void 0===n?e.length-1:n,0),function(){for(var r=arguments,i=-1,s=o(r.length-n,0),l=Array(s);++i<s;)l[i]=r[n+i];i=-1;for(var u=Array(n+1);++i<n;)u[i]=r[i];return u[n]=t(l),a(e,this,u)}}},function(e,n){e.exports=function(e,n,t){switch(t.length){case 0:return e.call(n);case 1:return e.call(n,t[0]);case 2:return e.call(n,t[0],t[1]);case 3:return e.call(n,t[0],t[1],t[2])}return e.apply(n,t)}},function(e,n,t){var a=t(144),o=t(147)(a);e.exports=o},function(e,n,t){var a=t(145),o=t(146),r=t(25),i=o?function(e,n){return o(e,"toString",{configurable:!0,enumerable:!1,value:a(n),writable:!0})}:r;e.exports=i},function(e,n){e.exports=function(e){return function(){return e}}},function(e,n,t){var a=t(4),o=function(){try{var e=a(Object,"defineProperty");return e({},"",{}),e}catch(e){}}();e.exports=o},function(e,n){var t=Date.now;e.exports=function(e){var n=0,a=0;return function(){var o=t(),r=16-(o-a);if(a=o,r>0){if(++n>=800)return arguments[0]}else n=0;return e.apply(void 0,arguments)}}},function(e,n,t){var a=t(35),o=t(149),r=t(154),i=t(36),s=t(155),l=t(21);e.exports=function(e,n,t){var u=-1,c=o,d=e.length,h=!0,p=[],m=p;if(t)h=!1,c=r;else if(d>=200){var y=n?null:s(e);if(y)return l(y);h=!1,c=i,m=new a}else m=n?[]:p;e:for(;++u<d;){var g=e[u],b=n?n(g):g;if(g=t||0!==g?g:0,h&&b==b){for(var k=m.length;k--;)if(m[k]===b)continue e;n&&m.push(b),p.push(g)}else c(m,b,t)||(m!==p&&m.push(b),p.push(g))}return p}},function(e,n,t){var a=t(150);e.exports=function(e,n){return!!(null==e?0:e.length)&&a(e,n,0)>-1}},function(e,n,t){var a=t(151),o=t(152),r=t(153);e.exports=function(e,n,t){return n==n?r(e,n,t):a(e,o,t)}},function(e,n){e.exports=function(e,n,t,a){for(var o=e.length,r=t+(a?1:-1);a?r--:++r<o;)if(n(e[r],r,e))return r;return-1}},function(e,n){e.exports=function(e){return e!=e}},function(e,n){e.exports=function(e,n,t){for(var a=t-1,o=e.length;++a<o;)if(e[a]===n)return a;return-1}},function(e,n){e.exports=function(e,n,t){for(var a=-1,o=null==e?0:e.length;++a<o;)if(t(n,e[a]))return!0;return!1}},function(e,n,t){var a=t(42),o=t(156),r=t(21),i=a&&1/r(new a([,-0]))[1]==1/0?function(e){return new a(e)}:o;e.exports=i},function(e,n){e.exports=function(){}},function(e,n,t){var a=t(41),o=t(5);e.exports=function(e){return o(e)&&a(e)}},function(e,n){e.exports=function(e){var n=null==e?0:e.length;return n?e[n-1]:void 0}},function(e,n,t){},function(e,n,t){},function(e,n,t){},function(e,n,t){"use strict";t(47)},function(e,n,t){"use strict";t(48)},function(e,n,t){"use strict";t(49)},function(e,n,t){"use strict";t(50)},function(e,n,t){"use strict";t(51)},function(e,n,t){"use strict";t(52)},function(e,n,t){"use strict";t(53)},function(e,n,t){"use strict";t(54)},function(e,n,t){"use strict";t(55)},function(e,n,t){"use strict";t(56)},function(e,n,t){},function(e,n,t){e.exports=function(e){function n(e){let t,o,r,i=null;function s(...e){if(!s.enabled)return;const a=s,o=Number(new Date),r=o-(t||o);a.diff=r,a.prev=t,a.curr=o,t=o,e[0]=n.coerce(e[0]),"string"!=typeof e[0]&&e.unshift("%O");let i=0;e[0]=e[0].replace(/%([a-zA-Z%])/g,(t,o)=>{if("%%"===t)return"%";i++;const r=n.formatters[o];if("function"==typeof r){const n=e[i];t=r.call(a,n),e.splice(i,1),i--}return t}),n.formatArgs.call(a,e);(a.log||n.log).apply(a,e)}return s.namespace=e,s.useColors=n.useColors(),s.color=n.selectColor(e),s.extend=a,s.destroy=n.destroy,Object.defineProperty(s,"enabled",{enumerable:!0,configurable:!1,get:()=>null!==i?i:(o!==n.namespaces&&(o=n.namespaces,r=n.enabled(e)),r),set:e=>{i=e}}),"function"==typeof n.init&&n.init(s),s}function a(e,t){const a=n(this.namespace+(void 0===t?":":t)+e);return a.log=this.log,a}function o(e){return e.toString().substring(2,e.toString().length-2).replace(/\.\*\?$/,"*")}return n.debug=n,n.default=n,n.coerce=function(e){if(e instanceof Error)return e.stack||e.message;return e},n.disable=function(){const e=[...n.names.map(o),...n.skips.map(o).map(e=>"-"+e)].join(",");return n.enable(""),e},n.enable=function(e){let t;n.save(e),n.namespaces=e,n.names=[],n.skips=[];const a=("string"==typeof e?e:"").split(/[\s,]+/),o=a.length;for(t=0;t<o;t++)a[t]&&("-"===(e=a[t].replace(/\*/g,".*?"))[0]?n.skips.push(new RegExp("^"+e.substr(1)+"$")):n.names.push(new RegExp("^"+e+"$")))},n.enabled=function(e){if("*"===e[e.length-1])return!0;let t,a;for(t=0,a=n.skips.length;t<a;t++)if(n.skips[t].test(e))return!1;for(t=0,a=n.names.length;t<a;t++)if(n.names[t].test(e))return!0;return!1},n.humanize=t(174),n.destroy=function(){console.warn("Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.")},Object.keys(e).forEach(t=>{n[t]=e[t]}),n.names=[],n.skips=[],n.formatters={},n.selectColor=function(e){let t=0;for(let n=0;n<e.length;n++)t=(t<<5)-t+e.charCodeAt(n),t|=0;return n.colors[Math.abs(t)%n.colors.length]},n.enable(n.load()),n}},function(e,n){var t=1e3,a=6e4,o=60*a,r=24*o;function i(e,n,t){if(!(e<n))return e<1.5*n?Math.floor(e/n)+" "+t:Math.ceil(e/n)+" "+t+"s"}e.exports=function(e,n){n=n||{};var s,l=typeof e;if("string"===l&&e.length>0)return function(e){if((e=String(e)).length>100)return;var n=/^((?:\d+)?\.?\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|years?|yrs?|y)?$/i.exec(e);if(!n)return;var i=parseFloat(n[1]);switch((n[2]||"ms").toLowerCase()){case"years":case"year":case"yrs":case"yr":case"y":return 315576e5*i;case"days":case"day":case"d":return i*r;case"hours":case"hour":case"hrs":case"hr":case"h":return i*o;case"minutes":case"minute":case"mins":case"min":case"m":return i*a;case"seconds":case"second":case"secs":case"sec":case"s":return i*t;case"milliseconds":case"millisecond":case"msecs":case"msec":case"ms":return i;default:return}}(e);if("number"===l&&!1===isNaN(e))return n.long?i(s=e,r,"day")||i(s,o,"hour")||i(s,a,"minute")||i(s,t,"second")||s+" ms":function(e){if(e>=r)return Math.round(e/r)+"d";if(e>=o)return Math.round(e/o)+"h";if(e>=a)return Math.round(e/a)+"m";if(e>=t)return Math.round(e/t)+"s";return e+"ms"}(e);throw new Error("val is not a non-empty string or a valid number. val="+JSON.stringify(e))}},function(e,n,t){},function(e,n,t){},function(e,n,t){"use strict";t(57)},function(e,n,t){"use strict";t(58)},function(e,n,t){"use strict";t(59)},function(e,n,t){"use strict";t.r(n);var a=t(0);
/*!
  * vue-router v3.5.1
  * (c) 2021 Evan You
  * @license MIT
  */function o(e,n){for(var t in n)e[t]=n[t];return e}var r=/[!'()*]/g,i=function(e){return"%"+e.charCodeAt(0).toString(16)},s=/%2C/g,l=function(e){return encodeURIComponent(e).replace(r,i).replace(s,",")};function u(e){try{return decodeURIComponent(e)}catch(e){0}return e}var c=function(e){return null==e||"object"==typeof e?e:String(e)};function d(e){var n={};return(e=e.trim().replace(/^(\?|#|&)/,""))?(e.split("&").forEach((function(e){var t=e.replace(/\+/g," ").split("="),a=u(t.shift()),o=t.length>0?u(t.join("=")):null;void 0===n[a]?n[a]=o:Array.isArray(n[a])?n[a].push(o):n[a]=[n[a],o]})),n):n}function h(e){var n=e?Object.keys(e).map((function(n){var t=e[n];if(void 0===t)return"";if(null===t)return l(n);if(Array.isArray(t)){var a=[];return t.forEach((function(e){void 0!==e&&(null===e?a.push(l(n)):a.push(l(n)+"="+l(e)))})),a.join("&")}return l(n)+"="+l(t)})).filter((function(e){return e.length>0})).join("&"):null;return n?"?"+n:""}var p=/\/?$/;function m(e,n,t,a){var o=a&&a.options.stringifyQuery,r=n.query||{};try{r=y(r)}catch(e){}var i={name:n.name||e&&e.name,meta:e&&e.meta||{},path:n.path||"/",hash:n.hash||"",query:r,params:n.params||{},fullPath:k(n,o),matched:e?b(e):[]};return t&&(i.redirectedFrom=k(t,o)),Object.freeze(i)}function y(e){if(Array.isArray(e))return e.map(y);if(e&&"object"==typeof e){var n={};for(var t in e)n[t]=y(e[t]);return n}return e}var g=m(null,{path:"/"});function b(e){for(var n=[];e;)n.unshift(e),e=e.parent;return n}function k(e,n){var t=e.path,a=e.query;void 0===a&&(a={});var o=e.hash;return void 0===o&&(o=""),(t||"/")+(n||h)(a)+o}function f(e,n,t){return n===g?e===n:!!n&&(e.path&&n.path?e.path.replace(p,"")===n.path.replace(p,"")&&(t||e.hash===n.hash&&w(e.query,n.query)):!(!e.name||!n.name)&&(e.name===n.name&&(t||e.hash===n.hash&&w(e.query,n.query)&&w(e.params,n.params))))}function w(e,n){if(void 0===e&&(e={}),void 0===n&&(n={}),!e||!n)return e===n;var t=Object.keys(e).sort(),a=Object.keys(n).sort();return t.length===a.length&&t.every((function(t,o){var r=e[t];if(a[o]!==t)return!1;var i=n[t];return null==r||null==i?r===i:"object"==typeof r&&"object"==typeof i?w(r,i):String(r)===String(i)}))}function v(e){for(var n=0;n<e.matched.length;n++){var t=e.matched[n];for(var a in t.instances){var o=t.instances[a],r=t.enteredCbs[a];if(o&&r){delete t.enteredCbs[a];for(var i=0;i<r.length;i++)o._isBeingDestroyed||r[i](o)}}}}var q={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(e,n){var t=n.props,a=n.children,r=n.parent,i=n.data;i.routerView=!0;for(var s=r.$createElement,l=t.name,u=r.$route,c=r._routerViewCache||(r._routerViewCache={}),d=0,h=!1;r&&r._routerRoot!==r;){var p=r.$vnode?r.$vnode.data:{};p.routerView&&d++,p.keepAlive&&r._directInactive&&r._inactive&&(h=!0),r=r.$parent}if(i.routerViewDepth=d,h){var m=c[l],y=m&&m.component;return y?(m.configProps&&x(y,i,m.route,m.configProps),s(y,i,a)):s()}var g=u.matched[d],b=g&&g.components[l];if(!g||!b)return c[l]=null,s();c[l]={component:b},i.registerRouteInstance=function(e,n){var t=g.instances[l];(n&&t!==e||!n&&t===e)&&(g.instances[l]=n)},(i.hook||(i.hook={})).prepatch=function(e,n){g.instances[l]=n.componentInstance},i.hook.init=function(e){e.data.keepAlive&&e.componentInstance&&e.componentInstance!==g.instances[l]&&(g.instances[l]=e.componentInstance),v(u)};var k=g.props&&g.props[l];return k&&(o(c[l],{route:u,configProps:k}),x(b,i,u,k)),s(b,i,a)}};function x(e,n,t,a){var r=n.props=function(e,n){switch(typeof n){case"undefined":return;case"object":return n;case"function":return n(e);case"boolean":return n?e.params:void 0;default:0}}(t,a);if(r){r=n.props=o({},r);var i=n.attrs=n.attrs||{};for(var s in r)e.props&&s in e.props||(i[s]=r[s],delete r[s])}}function j(e,n,t){var a=e.charAt(0);if("/"===a)return e;if("?"===a||"#"===a)return n+e;var o=n.split("/");t&&o[o.length-1]||o.pop();for(var r=e.replace(/^\//,"").split("/"),i=0;i<r.length;i++){var s=r[i];".."===s?o.pop():"."!==s&&o.push(s)}return""!==o[0]&&o.unshift(""),o.join("/")}function S(e){return e.replace(/\/\//g,"/")}var T=Array.isArray||function(e){return"[object Array]"==Object.prototype.toString.call(e)},z=N,Q=A,I=function(e,n){return H(A(e,n),n)},P=H,_=G,C=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function A(e,n){for(var t,a=[],o=0,r=0,i="",s=n&&n.delimiter||"/";null!=(t=C.exec(e));){var l=t[0],u=t[1],c=t.index;if(i+=e.slice(r,c),r=c+l.length,u)i+=u[1];else{var d=e[r],h=t[2],p=t[3],m=t[4],y=t[5],g=t[6],b=t[7];i&&(a.push(i),i="");var k=null!=h&&null!=d&&d!==h,f="+"===g||"*"===g,w="?"===g||"*"===g,v=t[2]||s,q=m||y;a.push({name:p||o++,prefix:h||"",delimiter:v,optional:w,repeat:f,partial:k,asterisk:!!b,pattern:q?D(q):b?".*":"[^"+L(v)+"]+?"})}}return r<e.length&&(i+=e.substr(r)),i&&a.push(i),a}function O(e){return encodeURI(e).replace(/[\/?#]/g,(function(e){return"%"+e.charCodeAt(0).toString(16).toUpperCase()}))}function H(e,n){for(var t=new Array(e.length),a=0;a<e.length;a++)"object"==typeof e[a]&&(t[a]=new RegExp("^(?:"+e[a].pattern+")$",B(n)));return function(n,a){for(var o="",r=n||{},i=(a||{}).pretty?O:encodeURIComponent,s=0;s<e.length;s++){var l=e[s];if("string"!=typeof l){var u,c=r[l.name];if(null==c){if(l.optional){l.partial&&(o+=l.prefix);continue}throw new TypeError('Expected "'+l.name+'" to be defined')}if(T(c)){if(!l.repeat)throw new TypeError('Expected "'+l.name+'" to not repeat, but received `'+JSON.stringify(c)+"`");if(0===c.length){if(l.optional)continue;throw new TypeError('Expected "'+l.name+'" to not be empty')}for(var d=0;d<c.length;d++){if(u=i(c[d]),!t[s].test(u))throw new TypeError('Expected all "'+l.name+'" to match "'+l.pattern+'", but received `'+JSON.stringify(u)+"`");o+=(0===d?l.prefix:l.delimiter)+u}}else{if(u=l.asterisk?encodeURI(c).replace(/[?#]/g,(function(e){return"%"+e.charCodeAt(0).toString(16).toUpperCase()})):i(c),!t[s].test(u))throw new TypeError('Expected "'+l.name+'" to match "'+l.pattern+'", but received "'+u+'"');o+=l.prefix+u}}else o+=l}return o}}function L(e){return e.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function D(e){return e.replace(/([=!:$\/()])/g,"\\$1")}function E(e,n){return e.keys=n,e}function B(e){return e&&e.sensitive?"":"i"}function G(e,n,t){T(n)||(t=n||t,n=[]);for(var a=(t=t||{}).strict,o=!1!==t.end,r="",i=0;i<e.length;i++){var s=e[i];if("string"==typeof s)r+=L(s);else{var l=L(s.prefix),u="(?:"+s.pattern+")";n.push(s),s.repeat&&(u+="(?:"+l+u+")*"),r+=u=s.optional?s.partial?l+"("+u+")?":"(?:"+l+"("+u+"))?":l+"("+u+")"}}var c=L(t.delimiter||"/"),d=r.slice(-c.length)===c;return a||(r=(d?r.slice(0,-c.length):r)+"(?:"+c+"(?=$))?"),r+=o?"$":a&&d?"":"(?="+c+"|$)",E(new RegExp("^"+r,B(t)),n)}function N(e,n,t){return T(n)||(t=n||t,n=[]),t=t||{},e instanceof RegExp?function(e,n){var t=e.source.match(/\((?!\?)/g);if(t)for(var a=0;a<t.length;a++)n.push({name:a,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return E(e,n)}(e,n):T(e)?function(e,n,t){for(var a=[],o=0;o<e.length;o++)a.push(N(e[o],n,t).source);return E(new RegExp("(?:"+a.join("|")+")",B(t)),n)}(e,n,t):function(e,n,t){return G(A(e,t),n,t)}(e,n,t)}z.parse=Q,z.compile=I,z.tokensToFunction=P,z.tokensToRegExp=_;var M=Object.create(null);function R(e,n,t){n=n||{};try{var a=M[e]||(M[e]=z.compile(e));return"string"==typeof n.pathMatch&&(n[0]=n.pathMatch),a(n,{pretty:!0})}catch(e){return""}finally{delete n[0]}}function W(e,n,t,a){var r="string"==typeof e?{path:e}:e;if(r._normalized)return r;if(r.name){var i=(r=o({},e)).params;return i&&"object"==typeof i&&(r.params=o({},i)),r}if(!r.path&&r.params&&n){(r=o({},r))._normalized=!0;var s=o(o({},n.params),r.params);if(n.name)r.name=n.name,r.params=s;else if(n.matched.length){var l=n.matched[n.matched.length-1].path;r.path=R(l,s,n.path)}else 0;return r}var u=function(e){var n="",t="",a=e.indexOf("#");a>=0&&(n=e.slice(a),e=e.slice(0,a));var o=e.indexOf("?");return o>=0&&(t=e.slice(o+1),e=e.slice(0,o)),{path:e,query:t,hash:n}}(r.path||""),h=n&&n.path||"/",p=u.path?j(u.path,h,t||r.append):h,m=function(e,n,t){void 0===n&&(n={});var a,o=t||d;try{a=o(e||"")}catch(e){a={}}for(var r in n){var i=n[r];a[r]=Array.isArray(i)?i.map(c):c(i)}return a}(u.query,r.query,a&&a.options.parseQuery),y=r.hash||u.hash;return y&&"#"!==y.charAt(0)&&(y="#"+y),{_normalized:!0,path:p,query:m,hash:y}}var U,F=function(){},K={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(e){var n=this,t=this.$router,a=this.$route,r=t.resolve(this.to,a,this.append),i=r.location,s=r.route,l=r.href,u={},c=t.options.linkActiveClass,d=t.options.linkExactActiveClass,h=null==c?"router-link-active":c,y=null==d?"router-link-exact-active":d,g=null==this.activeClass?h:this.activeClass,b=null==this.exactActiveClass?y:this.exactActiveClass,k=s.redirectedFrom?m(null,W(s.redirectedFrom),null,t):s;u[b]=f(a,k,this.exactPath),u[g]=this.exact||this.exactPath?u[b]:function(e,n){return 0===e.path.replace(p,"/").indexOf(n.path.replace(p,"/"))&&(!n.hash||e.hash===n.hash)&&function(e,n){for(var t in n)if(!(t in e))return!1;return!0}(e.query,n.query)}(a,k);var w=u[b]?this.ariaCurrentValue:null,v=function(e){V(e)&&(n.replace?t.replace(i,F):t.push(i,F))},q={click:V};Array.isArray(this.event)?this.event.forEach((function(e){q[e]=v})):q[this.event]=v;var x={class:u},j=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:l,route:s,navigate:v,isActive:u[g],isExactActive:u[b]});if(j){if(1===j.length)return j[0];if(j.length>1||!j.length)return 0===j.length?e():e("span",{},j)}if("a"===this.tag)x.on=q,x.attrs={href:l,"aria-current":w};else{var S=function e(n){var t;if(n)for(var a=0;a<n.length;a++){if("a"===(t=n[a]).tag)return t;if(t.children&&(t=e(t.children)))return t}}(this.$slots.default);if(S){S.isStatic=!1;var T=S.data=o({},S.data);for(var z in T.on=T.on||{},T.on){var Q=T.on[z];z in q&&(T.on[z]=Array.isArray(Q)?Q:[Q])}for(var I in q)I in T.on?T.on[I].push(q[I]):T.on[I]=v;var P=S.data.attrs=o({},S.data.attrs);P.href=l,P["aria-current"]=w}else x.on=q}return e(this.tag,x,this.$slots.default)}};function V(e){if(!(e.metaKey||e.altKey||e.ctrlKey||e.shiftKey||e.defaultPrevented||void 0!==e.button&&0!==e.button)){if(e.currentTarget&&e.currentTarget.getAttribute){var n=e.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(n))return}return e.preventDefault&&e.preventDefault(),!0}}var Y="undefined"!=typeof window;function J(e,n,t,a,o){var r=n||[],i=t||Object.create(null),s=a||Object.create(null);e.forEach((function(e){!function e(n,t,a,o,r,i){var s=o.path,l=o.name;0;var u=o.pathToRegexpOptions||{},c=function(e,n,t){t||(e=e.replace(/\/$/,""));if("/"===e[0])return e;if(null==n)return e;return S(n.path+"/"+e)}(s,r,u.strict);"boolean"==typeof o.caseSensitive&&(u.sensitive=o.caseSensitive);var d={path:c,regex:$(c,u),components:o.components||{default:o.component},alias:o.alias?"string"==typeof o.alias?[o.alias]:o.alias:[],instances:{},enteredCbs:{},name:l,parent:r,matchAs:i,redirect:o.redirect,beforeEnter:o.beforeEnter,meta:o.meta||{},props:null==o.props?{}:o.components?o.props:{default:o.props}};o.children&&o.children.forEach((function(o){var r=i?S(i+"/"+o.path):void 0;e(n,t,a,o,d,r)}));t[d.path]||(n.push(d.path),t[d.path]=d);if(void 0!==o.alias)for(var h=Array.isArray(o.alias)?o.alias:[o.alias],p=0;p<h.length;++p){0;var m={path:h[p],children:o.children};e(n,t,a,m,r,d.path||"/")}l&&(a[l]||(a[l]=d))}(r,i,s,e,o)}));for(var l=0,u=r.length;l<u;l++)"*"===r[l]&&(r.push(r.splice(l,1)[0]),u--,l--);return{pathList:r,pathMap:i,nameMap:s}}function $(e,n){return z(e,[],n)}function Z(e,n){var t=J(e),a=t.pathList,o=t.pathMap,r=t.nameMap;function i(e,t,i){var s=W(e,t,!1,n),u=s.name;if(u){var c=r[u];if(!c)return l(null,s);var d=c.regex.keys.filter((function(e){return!e.optional})).map((function(e){return e.name}));if("object"!=typeof s.params&&(s.params={}),t&&"object"==typeof t.params)for(var h in t.params)!(h in s.params)&&d.indexOf(h)>-1&&(s.params[h]=t.params[h]);return s.path=R(c.path,s.params),l(c,s,i)}if(s.path){s.params={};for(var p=0;p<a.length;p++){var m=a[p],y=o[m];if(X(y.regex,s.path,s.params))return l(y,s,i)}}return l(null,s)}function s(e,t){var a=e.redirect,o="function"==typeof a?a(m(e,t,null,n)):a;if("string"==typeof o&&(o={path:o}),!o||"object"!=typeof o)return l(null,t);var s=o,u=s.name,c=s.path,d=t.query,h=t.hash,p=t.params;if(d=s.hasOwnProperty("query")?s.query:d,h=s.hasOwnProperty("hash")?s.hash:h,p=s.hasOwnProperty("params")?s.params:p,u){r[u];return i({_normalized:!0,name:u,query:d,hash:h,params:p},void 0,t)}if(c){var y=function(e,n){return j(e,n.parent?n.parent.path:"/",!0)}(c,e);return i({_normalized:!0,path:R(y,p),query:d,hash:h},void 0,t)}return l(null,t)}function l(e,t,a){return e&&e.redirect?s(e,a||t):e&&e.matchAs?function(e,n,t){var a=i({_normalized:!0,path:R(t,n.params)});if(a){var o=a.matched,r=o[o.length-1];return n.params=a.params,l(r,n)}return l(null,n)}(0,t,e.matchAs):m(e,t,a,n)}return{match:i,addRoute:function(e,n){var t="object"!=typeof e?r[e]:void 0;J([n||e],a,o,r,t),t&&J(t.alias.map((function(e){return{path:e,children:[n]}})),a,o,r,t)},getRoutes:function(){return a.map((function(e){return o[e]}))},addRoutes:function(e){J(e,a,o,r)}}}function X(e,n,t){var a=n.match(e);if(!a)return!1;if(!t)return!0;for(var o=1,r=a.length;o<r;++o){var i=e.keys[o-1];i&&(t[i.name||"pathMatch"]="string"==typeof a[o]?u(a[o]):a[o])}return!0}var ee=Y&&window.performance&&window.performance.now?window.performance:Date;function ne(){return ee.now().toFixed(3)}var te=ne();function ae(){return te}function oe(e){return te=e}var re=Object.create(null);function ie(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var e=window.location.protocol+"//"+window.location.host,n=window.location.href.replace(e,""),t=o({},window.history.state);return t.key=ae(),window.history.replaceState(t,"",n),window.addEventListener("popstate",ue),function(){window.removeEventListener("popstate",ue)}}function se(e,n,t,a){if(e.app){var o=e.options.scrollBehavior;o&&e.app.$nextTick((function(){var r=function(){var e=ae();if(e)return re[e]}(),i=o.call(e,n,t,a?r:null);i&&("function"==typeof i.then?i.then((function(e){me(e,r)})).catch((function(e){0})):me(i,r))}))}}function le(){var e=ae();e&&(re[e]={x:window.pageXOffset,y:window.pageYOffset})}function ue(e){le(),e.state&&e.state.key&&oe(e.state.key)}function ce(e){return he(e.x)||he(e.y)}function de(e){return{x:he(e.x)?e.x:window.pageXOffset,y:he(e.y)?e.y:window.pageYOffset}}function he(e){return"number"==typeof e}var pe=/^#\d/;function me(e,n){var t,a="object"==typeof e;if(a&&"string"==typeof e.selector){var o=pe.test(e.selector)?document.getElementById(e.selector.slice(1)):document.querySelector(e.selector);if(o){var r=e.offset&&"object"==typeof e.offset?e.offset:{};n=function(e,n){var t=document.documentElement.getBoundingClientRect(),a=e.getBoundingClientRect();return{x:a.left-t.left-n.x,y:a.top-t.top-n.y}}(o,r={x:he((t=r).x)?t.x:0,y:he(t.y)?t.y:0})}else ce(e)&&(n=de(e))}else a&&ce(e)&&(n=de(e));n&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:n.x,top:n.y,behavior:e.behavior}):window.scrollTo(n.x,n.y))}var ye,ge=Y&&((-1===(ye=window.navigator.userAgent).indexOf("Android 2.")&&-1===ye.indexOf("Android 4.0")||-1===ye.indexOf("Mobile Safari")||-1!==ye.indexOf("Chrome")||-1!==ye.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function be(e,n){le();var t=window.history;try{if(n){var a=o({},t.state);a.key=ae(),t.replaceState(a,"",e)}else t.pushState({key:oe(ne())},"",e)}catch(t){window.location[n?"replace":"assign"](e)}}function ke(e){be(e,!0)}function fe(e,n,t){var a=function(o){o>=e.length?t():e[o]?n(e[o],(function(){a(o+1)})):a(o+1)};a(0)}var we={redirected:2,aborted:4,cancelled:8,duplicated:16};function ve(e,n){return xe(e,n,we.redirected,'Redirected when going from "'+e.fullPath+'" to "'+function(e){if("string"==typeof e)return e;if("path"in e)return e.path;var n={};return je.forEach((function(t){t in e&&(n[t]=e[t])})),JSON.stringify(n,null,2)}(n)+'" via a navigation guard.')}function qe(e,n){return xe(e,n,we.cancelled,'Navigation cancelled from "'+e.fullPath+'" to "'+n.fullPath+'" with a new navigation.')}function xe(e,n,t,a){var o=new Error(a);return o._isRouter=!0,o.from=e,o.to=n,o.type=t,o}var je=["params","query","hash"];function Se(e){return Object.prototype.toString.call(e).indexOf("Error")>-1}function Te(e,n){return Se(e)&&e._isRouter&&(null==n||e.type===n)}function ze(e){return function(n,t,a){var o=!1,r=0,i=null;Qe(e,(function(e,n,t,s){if("function"==typeof e&&void 0===e.cid){o=!0,r++;var l,u=_e((function(n){var o;((o=n).__esModule||Pe&&"Module"===o[Symbol.toStringTag])&&(n=n.default),e.resolved="function"==typeof n?n:U.extend(n),t.components[s]=n,--r<=0&&a()})),c=_e((function(e){var n="Failed to resolve async component "+s+": "+e;i||(i=Se(e)?e:new Error(n),a(i))}));try{l=e(u,c)}catch(e){c(e)}if(l)if("function"==typeof l.then)l.then(u,c);else{var d=l.component;d&&"function"==typeof d.then&&d.then(u,c)}}})),o||a()}}function Qe(e,n){return Ie(e.map((function(e){return Object.keys(e.components).map((function(t){return n(e.components[t],e.instances[t],e,t)}))})))}function Ie(e){return Array.prototype.concat.apply([],e)}var Pe="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function _e(e){var n=!1;return function(){for(var t=[],a=arguments.length;a--;)t[a]=arguments[a];if(!n)return n=!0,e.apply(this,t)}}var Ce=function(e,n){this.router=e,this.base=function(e){if(!e)if(Y){var n=document.querySelector("base");e=(e=n&&n.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else e="/";"/"!==e.charAt(0)&&(e="/"+e);return e.replace(/\/$/,"")}(n),this.current=g,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function Ae(e,n,t,a){var o=Qe(e,(function(e,a,o,r){var i=function(e,n){"function"!=typeof e&&(e=U.extend(e));return e.options[n]}(e,n);if(i)return Array.isArray(i)?i.map((function(e){return t(e,a,o,r)})):t(i,a,o,r)}));return Ie(a?o.reverse():o)}function Oe(e,n){if(n)return function(){return e.apply(n,arguments)}}Ce.prototype.listen=function(e){this.cb=e},Ce.prototype.onReady=function(e,n){this.ready?e():(this.readyCbs.push(e),n&&this.readyErrorCbs.push(n))},Ce.prototype.onError=function(e){this.errorCbs.push(e)},Ce.prototype.transitionTo=function(e,n,t){var a,o=this;try{a=this.router.match(e,this.current)}catch(e){throw this.errorCbs.forEach((function(n){n(e)})),e}var r=this.current;this.confirmTransition(a,(function(){o.updateRoute(a),n&&n(a),o.ensureURL(),o.router.afterHooks.forEach((function(e){e&&e(a,r)})),o.ready||(o.ready=!0,o.readyCbs.forEach((function(e){e(a)})))}),(function(e){t&&t(e),e&&!o.ready&&(Te(e,we.redirected)&&r===g||(o.ready=!0,o.readyErrorCbs.forEach((function(n){n(e)}))))}))},Ce.prototype.confirmTransition=function(e,n,t){var a=this,o=this.current;this.pending=e;var r,i,s=function(e){!Te(e)&&Se(e)&&(a.errorCbs.length?a.errorCbs.forEach((function(n){n(e)})):console.error(e)),t&&t(e)},l=e.matched.length-1,u=o.matched.length-1;if(f(e,o)&&l===u&&e.matched[l]===o.matched[u])return this.ensureURL(),s(((i=xe(r=o,e,we.duplicated,'Avoided redundant navigation to current location: "'+r.fullPath+'".')).name="NavigationDuplicated",i));var c=function(e,n){var t,a=Math.max(e.length,n.length);for(t=0;t<a&&e[t]===n[t];t++);return{updated:n.slice(0,t),activated:n.slice(t),deactivated:e.slice(t)}}(this.current.matched,e.matched),d=c.updated,h=c.deactivated,p=c.activated,m=[].concat(function(e){return Ae(e,"beforeRouteLeave",Oe,!0)}(h),this.router.beforeHooks,function(e){return Ae(e,"beforeRouteUpdate",Oe)}(d),p.map((function(e){return e.beforeEnter})),ze(p)),y=function(n,t){if(a.pending!==e)return s(qe(o,e));try{n(e,o,(function(n){!1===n?(a.ensureURL(!0),s(function(e,n){return xe(e,n,we.aborted,'Navigation aborted from "'+e.fullPath+'" to "'+n.fullPath+'" via a navigation guard.')}(o,e))):Se(n)?(a.ensureURL(!0),s(n)):"string"==typeof n||"object"==typeof n&&("string"==typeof n.path||"string"==typeof n.name)?(s(ve(o,e)),"object"==typeof n&&n.replace?a.replace(n):a.push(n)):t(n)}))}catch(e){s(e)}};fe(m,y,(function(){fe(function(e){return Ae(e,"beforeRouteEnter",(function(e,n,t,a){return function(e,n,t){return function(a,o,r){return e(a,o,(function(e){"function"==typeof e&&(n.enteredCbs[t]||(n.enteredCbs[t]=[]),n.enteredCbs[t].push(e)),r(e)}))}}(e,t,a)}))}(p).concat(a.router.resolveHooks),y,(function(){if(a.pending!==e)return s(qe(o,e));a.pending=null,n(e),a.router.app&&a.router.app.$nextTick((function(){v(e)}))}))}))},Ce.prototype.updateRoute=function(e){this.current=e,this.cb&&this.cb(e)},Ce.prototype.setupListeners=function(){},Ce.prototype.teardown=function(){this.listeners.forEach((function(e){e()})),this.listeners=[],this.current=g,this.pending=null};var He=function(e){function n(n,t){e.call(this,n,t),this._startLocation=Le(this.base)}return e&&(n.__proto__=e),n.prototype=Object.create(e&&e.prototype),n.prototype.constructor=n,n.prototype.setupListeners=function(){var e=this;if(!(this.listeners.length>0)){var n=this.router,t=n.options.scrollBehavior,a=ge&&t;a&&this.listeners.push(ie());var o=function(){var t=e.current,o=Le(e.base);e.current===g&&o===e._startLocation||e.transitionTo(o,(function(e){a&&se(n,e,t,!0)}))};window.addEventListener("popstate",o),this.listeners.push((function(){window.removeEventListener("popstate",o)}))}},n.prototype.go=function(e){window.history.go(e)},n.prototype.push=function(e,n,t){var a=this,o=this.current;this.transitionTo(e,(function(e){be(S(a.base+e.fullPath)),se(a.router,e,o,!1),n&&n(e)}),t)},n.prototype.replace=function(e,n,t){var a=this,o=this.current;this.transitionTo(e,(function(e){ke(S(a.base+e.fullPath)),se(a.router,e,o,!1),n&&n(e)}),t)},n.prototype.ensureURL=function(e){if(Le(this.base)!==this.current.fullPath){var n=S(this.base+this.current.fullPath);e?be(n):ke(n)}},n.prototype.getCurrentLocation=function(){return Le(this.base)},n}(Ce);function Le(e){var n=window.location.pathname;return e&&0===n.toLowerCase().indexOf(e.toLowerCase())&&(n=n.slice(e.length)),(n||"/")+window.location.search+window.location.hash}var De=function(e){function n(n,t,a){e.call(this,n,t),a&&function(e){var n=Le(e);if(!/^\/#/.test(n))return window.location.replace(S(e+"/#"+n)),!0}(this.base)||Ee()}return e&&(n.__proto__=e),n.prototype=Object.create(e&&e.prototype),n.prototype.constructor=n,n.prototype.setupListeners=function(){var e=this;if(!(this.listeners.length>0)){var n=this.router.options.scrollBehavior,t=ge&&n;t&&this.listeners.push(ie());var a=function(){var n=e.current;Ee()&&e.transitionTo(Be(),(function(a){t&&se(e.router,a,n,!0),ge||Me(a.fullPath)}))},o=ge?"popstate":"hashchange";window.addEventListener(o,a),this.listeners.push((function(){window.removeEventListener(o,a)}))}},n.prototype.push=function(e,n,t){var a=this,o=this.current;this.transitionTo(e,(function(e){Ne(e.fullPath),se(a.router,e,o,!1),n&&n(e)}),t)},n.prototype.replace=function(e,n,t){var a=this,o=this.current;this.transitionTo(e,(function(e){Me(e.fullPath),se(a.router,e,o,!1),n&&n(e)}),t)},n.prototype.go=function(e){window.history.go(e)},n.prototype.ensureURL=function(e){var n=this.current.fullPath;Be()!==n&&(e?Ne(n):Me(n))},n.prototype.getCurrentLocation=function(){return Be()},n}(Ce);function Ee(){var e=Be();return"/"===e.charAt(0)||(Me("/"+e),!1)}function Be(){var e=window.location.href,n=e.indexOf("#");return n<0?"":e=e.slice(n+1)}function Ge(e){var n=window.location.href,t=n.indexOf("#");return(t>=0?n.slice(0,t):n)+"#"+e}function Ne(e){ge?be(Ge(e)):window.location.hash=e}function Me(e){ge?ke(Ge(e)):window.location.replace(Ge(e))}var Re=function(e){function n(n,t){e.call(this,n,t),this.stack=[],this.index=-1}return e&&(n.__proto__=e),n.prototype=Object.create(e&&e.prototype),n.prototype.constructor=n,n.prototype.push=function(e,n,t){var a=this;this.transitionTo(e,(function(e){a.stack=a.stack.slice(0,a.index+1).concat(e),a.index++,n&&n(e)}),t)},n.prototype.replace=function(e,n,t){var a=this;this.transitionTo(e,(function(e){a.stack=a.stack.slice(0,a.index).concat(e),n&&n(e)}),t)},n.prototype.go=function(e){var n=this,t=this.index+e;if(!(t<0||t>=this.stack.length)){var a=this.stack[t];this.confirmTransition(a,(function(){var e=n.current;n.index=t,n.updateRoute(a),n.router.afterHooks.forEach((function(n){n&&n(a,e)}))}),(function(e){Te(e,we.duplicated)&&(n.index=t)}))}},n.prototype.getCurrentLocation=function(){var e=this.stack[this.stack.length-1];return e?e.fullPath:"/"},n.prototype.ensureURL=function(){},n}(Ce),We=function(e){void 0===e&&(e={}),this.app=null,this.apps=[],this.options=e,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Z(e.routes||[],this);var n=e.mode||"hash";switch(this.fallback="history"===n&&!ge&&!1!==e.fallback,this.fallback&&(n="hash"),Y||(n="abstract"),this.mode=n,n){case"history":this.history=new He(this,e.base);break;case"hash":this.history=new De(this,e.base,this.fallback);break;case"abstract":this.history=new Re(this,e.base);break;default:0}},Ue={currentRoute:{configurable:!0}};function Fe(e,n){return e.push(n),function(){var t=e.indexOf(n);t>-1&&e.splice(t,1)}}We.prototype.match=function(e,n,t){return this.matcher.match(e,n,t)},Ue.currentRoute.get=function(){return this.history&&this.history.current},We.prototype.init=function(e){var n=this;if(this.apps.push(e),e.$once("hook:destroyed",(function(){var t=n.apps.indexOf(e);t>-1&&n.apps.splice(t,1),n.app===e&&(n.app=n.apps[0]||null),n.app||n.history.teardown()})),!this.app){this.app=e;var t=this.history;if(t instanceof He||t instanceof De){var a=function(e){t.setupListeners(),function(e){var a=t.current,o=n.options.scrollBehavior;ge&&o&&"fullPath"in e&&se(n,e,a,!1)}(e)};t.transitionTo(t.getCurrentLocation(),a,a)}t.listen((function(e){n.apps.forEach((function(n){n._route=e}))}))}},We.prototype.beforeEach=function(e){return Fe(this.beforeHooks,e)},We.prototype.beforeResolve=function(e){return Fe(this.resolveHooks,e)},We.prototype.afterEach=function(e){return Fe(this.afterHooks,e)},We.prototype.onReady=function(e,n){this.history.onReady(e,n)},We.prototype.onError=function(e){this.history.onError(e)},We.prototype.push=function(e,n,t){var a=this;if(!n&&!t&&"undefined"!=typeof Promise)return new Promise((function(n,t){a.history.push(e,n,t)}));this.history.push(e,n,t)},We.prototype.replace=function(e,n,t){var a=this;if(!n&&!t&&"undefined"!=typeof Promise)return new Promise((function(n,t){a.history.replace(e,n,t)}));this.history.replace(e,n,t)},We.prototype.go=function(e){this.history.go(e)},We.prototype.back=function(){this.go(-1)},We.prototype.forward=function(){this.go(1)},We.prototype.getMatchedComponents=function(e){var n=e?e.matched?e:this.resolve(e).route:this.currentRoute;return n?[].concat.apply([],n.matched.map((function(e){return Object.keys(e.components).map((function(n){return e.components[n]}))}))):[]},We.prototype.resolve=function(e,n,t){var a=W(e,n=n||this.history.current,t,this),o=this.match(a,n),r=o.redirectedFrom||o.fullPath;return{location:a,route:o,href:function(e,n,t){var a="hash"===t?"#"+n:n;return e?S(e+"/"+a):a}(this.history.base,r,this.mode),normalizedTo:a,resolved:o}},We.prototype.getRoutes=function(){return this.matcher.getRoutes()},We.prototype.addRoute=function(e,n){this.matcher.addRoute(e,n),this.history.current!==g&&this.history.transitionTo(this.history.getCurrentLocation())},We.prototype.addRoutes=function(e){this.matcher.addRoutes(e),this.history.current!==g&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(We.prototype,Ue),We.install=function e(n){if(!e.installed||U!==n){e.installed=!0,U=n;var t=function(e){return void 0!==e},a=function(e,n){var a=e.$options._parentVnode;t(a)&&t(a=a.data)&&t(a=a.registerRouteInstance)&&a(e,n)};n.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),n.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,a(this,this)},destroyed:function(){a(this)}}),Object.defineProperty(n.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(n.prototype,"$route",{get:function(){return this._routerRoot._route}}),n.component("RouterView",q),n.component("RouterLink",K);var o=n.config.optionMergeStrategies;o.beforeRouteEnter=o.beforeRouteLeave=o.beforeRouteUpdate=o.created}},We.version="3.5.1",We.isNavigationFailure=Te,We.NavigationFailureType=we,We.START_LOCATION=g,Y&&window.Vue&&window.Vue.use(We);var Ke=We;var Ve={NotFound:()=>Promise.all([t.e(0),t.e(1),t.e(2),t.e(6)]).then(t.bind(null,481)),Blog:()=>Promise.all([t.e(0),t.e(1),t.e(2),t.e(4)]).then(t.bind(null,480)),Layout:()=>Promise.all([t.e(0),t.e(1),t.e(2),t.e(186),t.e(5)]).then(t.bind(null,479)),Slide:()=>Promise.all([t.e(0),t.e(1),t.e(7)]).then(t.bind(null,482))},Ye={"v-86b1f726":()=>t.e(52).then(t.bind(null,483)),"v-47639a6e":()=>t.e(14).then(t.bind(null,484)),"v-94114ee6":()=>t.e(39).then(t.bind(null,485)),"v-5d960c2d":()=>t.e(89).then(t.bind(null,486)),"v-03d2d023":()=>t.e(91).then(t.bind(null,487)),"v-4806233e":()=>t.e(15).then(t.bind(null,488)),"v-64c45226":()=>t.e(51).then(t.bind(null,489)),"v-19f3891b":()=>t.e(45).then(t.bind(null,490)),"v-4f881571":()=>t.e(88).then(t.bind(null,491)),"v-f95dcc66":()=>t.e(132).then(t.bind(null,492)),"v-3d649b57":()=>t.e(49).then(t.bind(null,493)),"v-46088ee7":()=>t.e(78).then(t.bind(null,494)),"v-4f6d6333":()=>t.e(21).then(t.bind(null,495)),"v-25b5132d":()=>t.e(30).then(t.bind(null,496)),"v-220de14d":()=>t.e(37).then(t.bind(null,497)),"v-8fd36766":()=>t.e(110).then(t.bind(null,498)),"v-576a0161":()=>t.e(35).then(t.bind(null,499)),"v-45bb1917":()=>t.e(102).then(t.bind(null,500)),"v-03e13271":()=>t.e(80).then(t.bind(null,501)),"v-04677efd":()=>t.e(42).then(t.bind(null,502)),"v-306d6933":()=>t.e(105).then(t.bind(null,503)),"v-754465ed":()=>t.e(57).then(t.bind(null,504)),"v-756db2b5":()=>t.e(60).then(t.bind(null,505)),"v-e30ce652":()=>t.e(106).then(t.bind(null,506)),"v-76f709af":()=>t.e(66).then(t.bind(null,507)),"v-bc8b07b2":()=>t.e(107).then(t.bind(null,508)),"v-5c0f832f":()=>t.e(119).then(t.bind(null,509)),"v-59012e95":()=>t.e(69).then(t.bind(null,510)),"v-6274ba2f":()=>t.e(72).then(t.bind(null,511)),"v-0bb0d095":()=>t.e(70).then(t.bind(null,512)),"v-34796e51":()=>t.e(68).then(t.bind(null,513)),"v-89f298e6":()=>t.e(124).then(t.bind(null,514)),"v-65f40cc9":()=>t.e(125).then(t.bind(null,515)),"v-68df3c0d":()=>t.e(71).then(t.bind(null,516)),"v-4162124d":()=>t.e(117).then(t.bind(null,517)),"v-1397d61e":()=>t.e(8).then(t.bind(null,518)),"v-514b550d":()=>t.e(52).then(t.bind(null,519)),"v-7c3a4841":()=>t.e(38).then(t.bind(null,520)),"v-38986917":()=>t.e(89).then(t.bind(null,521)),"v-06fe97ed":()=>t.e(91).then(t.bind(null,522)),"v-56f85486":()=>t.e(49).then(t.bind(null,523)),"v-2f18e28d":()=>t.e(78).then(t.bind(null,524)),"v-76f64b99":()=>t.e(21).then(t.bind(null,525)),"v-2e6d4e4d":()=>t.e(30).then(t.bind(null,526)),"v-29564a26":()=>t.e(37).then(t.bind(null,527)),"v-fd457426":()=>t.e(110).then(t.bind(null,528)),"v-407a5507":()=>t.e(35).then(t.bind(null,529)),"v-2ecb6cbd":()=>t.e(102).then(t.bind(null,530)),"v-25105aba":()=>t.e(42).then(t.bind(null,531)),"v-0b973857":()=>t.e(80).then(t.bind(null,532)),"v-2d2f1159":()=>t.e(105).then(t.bind(null,533)),"v-ee61d266":()=>t.e(57).then(t.bind(null,534)),"v-2f06345b":()=>t.e(60).then(t.bind(null,535)),"v-19c469bd":()=>t.e(106).then(t.bind(null,536)),"v-6ba4f6d5":()=>t.e(66).then(t.bind(null,537)),"v-ab158e66":()=>t.e(107).then(t.bind(null,538)),"v-58d12b55":()=>t.e(119).then(t.bind(null,539)),"v-a1803b0a":()=>t.e(133).then(t.bind(null,540)),"v-1c0d3bd5":()=>t.e(136).then(t.bind(null,541)),"v-5fbd0ffb":()=>t.e(134).then(t.bind(null,542)),"v-ea8fbb92":()=>t.e(137).then(t.bind(null,543)),"v-76eb85ed":()=>t.e(124).then(t.bind(null,544)),"v-1f8c8e6f":()=>t.e(125).then(t.bind(null,545)),"v-f98997a6":()=>t.e(135).then(t.bind(null,546)),"v-5bbe0a6d":()=>t.e(117).then(t.bind(null,547)),"v-1265970d":()=>t.e(49).then(t.bind(null,548)),"v-560420fe":()=>t.e(16).then(t.bind(null,549)),"v-56f909a6":()=>t.e(109).then(t.bind(null,550)),"v-6a073232":()=>t.e(94).then(t.bind(null,551)),"v-7e31bc3d":()=>t.e(48).then(t.bind(null,552)),"v-eb9283e6":()=>t.e(98).then(t.bind(null,553)),"v-47ab00ba":()=>t.e(99).then(t.bind(null,554)),"v-74b235b3":()=>t.e(93).then(t.bind(null,555)),"v-42d0237f":()=>t.e(100).then(t.bind(null,556)),"v-73371d26":()=>t.e(92).then(t.bind(null,557)),"v-932646e6":()=>t.e(27).then(t.bind(null,558)),"v-4c75478d":()=>t.e(114).then(t.bind(null,559)),"v-f3d8afa6":()=>t.e(73).then(t.bind(null,560)),"v-7464bfe3":()=>t.e(101).then(t.bind(null,561)),"v-331125c9":()=>t.e(115).then(t.bind(null,562)),"v-7981e486":()=>t.e(97).then(t.bind(null,563)),"v-5e3758ff":()=>t.e(31).then(t.bind(null,564)),"v-eabc40a6":()=>t.e(59).then(t.bind(null,565)),"v-79dd94fe":()=>t.e(60).then(t.bind(null,566)),"v-26e5d623":()=>t.e(96).then(t.bind(null,567)),"v-3977c37b":()=>t.e(55).then(t.bind(null,568)),"v-5ee434f3":()=>t.e(95).then(t.bind(null,569)),"v-ec4d1a0a":()=>t.e(108).then(t.bind(null,570)),"v-b00c343e":()=>t.e(24).then(t.bind(null,571)),"v-9fcf860a":()=>t.e(26).then(t.bind(null,572)),"v-0fc2023e":()=>t.e(23).then(t.bind(null,573)),"v-f91bb4c6":()=>t.e(22).then(t.bind(null,574)),"v-7c9e504d":()=>t.e(122).then(t.bind(null,575)),"v-98d0e0d6":()=>t.e(123).then(t.bind(null,576)),"v-23ca544d":()=>t.e(25).then(t.bind(null,577)),"v-0765aae6":()=>t.e(116).then(t.bind(null,578)),"v-2680104d":()=>t.e(78).then(t.bind(null,579)),"v-188a7204":()=>t.e(10).then(t.bind(null,580)),"v-1466252d":()=>t.e(52).then(t.bind(null,581)),"v-73c98272":()=>t.e(39).then(t.bind(null,582)),"v-1553fc1d":()=>t.e(89).then(t.bind(null,583)),"v-6bcd2fe6":()=>t.e(91).then(t.bind(null,584)),"v-784c5b83":()=>t.e(49).then(t.bind(null,585)),"v-0bd47593":()=>t.e(78).then(t.bind(null,586)),"v-a8374142":()=>t.e(21).then(t.bind(null,587)),"v-2a342b6d":()=>t.e(30).then(t.bind(null,588)),"v-36e11e8d":()=>t.e(37).then(t.bind(null,589)),"v-0b86ffc3":()=>t.e(102).then(t.bind(null,590)),"v-6b9934ae":()=>t.e(42).then(t.bind(null,591)),"v-a188fcc6":()=>t.e(80).then(t.bind(null,592)),"v-296dfe42":()=>t.e(105).then(t.bind(null,593)),"v-f39834a6":()=>t.e(57).then(t.bind(null,594)),"v-0ca4553e":()=>t.e(60).then(t.bind(null,595)),"v-475b7a03":()=>t.e(106).then(t.bind(null,596)),"v-2fc0fb5b":()=>t.e(66).then(t.bind(null,597)),"v-ec5d765a":()=>t.e(107).then(t.bind(null,598)),"v-16eb1adb":()=>t.e(119).then(t.bind(null,599)),"v-1098b9c1":()=>t.e(69).then(t.bind(null,600)),"v-3296464a":()=>t.e(72).then(t.bind(null,601)),"v-49346ac1":()=>t.e(70).then(t.bind(null,602)),"v-27de0d06":()=>t.e(68).then(t.bind(null,603)),"v-2b97a116":()=>t.e(125).then(t.bind(null,604)),"v-0f11ce4d":()=>t.e(124).then(t.bind(null,605)),"v-05571e4d":()=>t.e(71).then(t.bind(null,606)),"v-444c16e6":()=>t.e(117).then(t.bind(null,607)),"v-2a03c37e":()=>t.e(12).then(t.bind(null,608)),"v-045024ad":()=>t.e(52).then(t.bind(null,609)),"v-027260af":()=>t.e(39).then(t.bind(null,610)),"v-f2a4a7f6":()=>t.e(89).then(t.bind(null,611)),"v-8bf930e6":()=>t.e(91).then(t.bind(null,612)),"v-6d65c06b":()=>t.e(49).then(t.bind(null,613)),"v-7d2e257b":()=>t.e(78).then(t.bind(null,614)),"v-0a98e772":()=>t.e(21).then(t.bind(null,615)),"v-95e01226":()=>t.e(30).then(t.bind(null,616)),"v-1738500d":()=>t.e(37).then(t.bind(null,617)),"v-a57e89e6":()=>t.e(110).then(t.bind(null,618)),"v-e2e0d016":()=>t.e(35).then(t.bind(null,619)),"v-7ce0afab":()=>t.e(102).then(t.bind(null,620)),"v-3b8d1591":()=>t.e(42).then(t.bind(null,621)),"v-bf8e4ef6":()=>t.e(80).then(t.bind(null,622)),"v-d5d38272":()=>t.e(105).then(t.bind(null,623)),"v-02e16a2d":()=>t.e(57).then(t.bind(null,624)),"v-bab9656e":()=>t.e(60).then(t.bind(null,625)),"v-c098962a":()=>t.e(106).then(t.bind(null,626)),"v-2f10357a":()=>t.e(66).then(t.bind(null,627)),"v-6a0310bb":()=>t.e(107).then(t.bind(null,628)),"v-7e8f4e7a":()=>t.e(119).then(t.bind(null,629)),"v-c1e04eae":()=>t.e(69).then(t.bind(null,630)),"v-e0ab567a":()=>t.e(72).then(t.bind(null,631)),"v-73f708ae":()=>t.e(70).then(t.bind(null,632)),"v-7a881865":()=>t.e(68).then(t.bind(null,633)),"v-062f2666":()=>t.e(124).then(t.bind(null,634)),"v-d9acb146":()=>t.e(125).then(t.bind(null,635)),"v-2e80b5cd":()=>t.e(71).then(t.bind(null,636)),"v-07038c0d":()=>t.e(117).then(t.bind(null,637)),"v-14d51344":()=>t.e(9).then(t.bind(null,638)),"v-f004ba66":()=>t.e(80).then(t.bind(null,639)),"v-64b91fd5":()=>t.e(39).then(t.bind(null,640)),"v-6fbdffab":()=>t.e(90).then(t.bind(null,641)),"v-3db0e5ad":()=>t.e(91).then(t.bind(null,642)),"v-0484fad1":()=>t.e(49).then(t.bind(null,643)),"v-663e7921":()=>t.e(78).then(t.bind(null,644)),"v-223c74ad":()=>t.e(21).then(t.bind(null,645)),"v-846f9be6":()=>t.e(30).then(t.bind(null,646)),"v-3f016ca6":()=>t.e(37).then(t.bind(null,647)),"v-7687b4ad":()=>t.e(110).then(t.bind(null,648)),"v-65f10351":()=>t.e(102).then(t.bind(null,649)),"v-779feb9b":()=>t.e(35).then(t.bind(null,650)),"v-249d6937":()=>t.e(42).then(t.bind(null,651)),"v-b022432a":()=>t.e(80).then(t.bind(null,652)),"v-dc503226":()=>t.e(105).then(t.bind(null,653)),"v-166c1b0d":()=>t.e(58).then(t.bind(null,654)),"v-5c3bceef":()=>t.e(60).then(t.bind(null,655)),"v-2afe91d1":()=>t.e(181).then(t.bind(null,656)),"v-45b45b2e":()=>t.e(67).then(t.bind(null,657)),"v-72bdcd61":()=>t.e(179).then(t.bind(null,658)),"v-850bfe2e":()=>t.e(182).then(t.bind(null,659)),"v-1562e6e2":()=>t.e(180).then(t.bind(null,660)),"v-4942d669":()=>t.e(178).then(t.bind(null,661)),"v-1a10bb0f":()=>t.e(112).then(t.bind(null,662)),"v-5e72676a":()=>t.e(111).then(t.bind(null,663)),"v-8e6581a6":()=>t.e(124).then(t.bind(null,664)),"v-4cc22903":()=>t.e(185).then(t.bind(null,665)),"v-48dcaded":()=>t.e(184).then(t.bind(null,666)),"v-215f842d":()=>t.e(183).then(t.bind(null,667)),"v-ae40a866":()=>t.e(21).then(t.bind(null,668)),"v-a45391be":()=>t.e(30).then(t.bind(null,669)),"v-6d299e43":()=>t.e(37).then(t.bind(null,670)),"v-034044f3":()=>t.e(110).then(t.bind(null,671)),"v-b6710da6":()=>t.e(36).then(t.bind(null,672)),"v-529f2d66":()=>t.e(103).then(t.bind(null,673)),"v-5be2726d":()=>t.e(43).then(t.bind(null,674)),"v-31c257a6":()=>t.e(80).then(t.bind(null,675)),"v-ecedcbe6":()=>t.e(105).then(t.bind(null,676)),"v-562bf2a5":()=>t.e(57).then(t.bind(null,677)),"v-bc9cfe26":()=>t.e(60).then(t.bind(null,678)),"v-867568e6":()=>t.e(106).then(t.bind(null,679)),"v-d4874966":()=>t.e(66).then(t.bind(null,680)),"v-b4ffb0e6":()=>t.e(34).then(t.bind(null,681)),"v-3bb71ffe":()=>t.e(13).then(t.bind(null,682)),"v-1b3677a6":()=>t.e(156).then(t.bind(null,683)),"v-1e91fed2":()=>t.e(125).then(t.bind(null,684)),"v-6a2b59ed":()=>t.e(158).then(t.bind(null,685)),"v-afcff1e6":()=>t.e(153).then(t.bind(null,686)),"v-249ce353":()=>t.e(159).then(t.bind(null,687)),"v-60abd363":()=>t.e(157).then(t.bind(null,688)),"v-4a7311a2":()=>t.e(140).then(t.bind(null,689)),"v-7ce7626d":()=>t.e(141).then(t.bind(null,690)),"v-0258bce6":()=>t.e(142).then(t.bind(null,691)),"v-d647e6e6":()=>t.e(154).then(t.bind(null,692)),"v-720d45dd":()=>t.e(152).then(t.bind(null,693)),"v-1f0ac379":()=>t.e(42).then(t.bind(null,694)),"v-605e5d93":()=>t.e(151).then(t.bind(null,695)),"v-50fd6d6d":()=>t.e(80).then(t.bind(null,696)),"v-0ffdfaaf":()=>t.e(105).then(t.bind(null,697)),"v-38af4ead":()=>t.e(57).then(t.bind(null,698)),"v-953a799e":()=>t.e(62).then(t.bind(null,699)),"v-0133a45a":()=>t.e(149).then(t.bind(null,700)),"v-05c24d2b":()=>t.e(66).then(t.bind(null,701)),"v-0df44aba":()=>t.e(143).then(t.bind(null,702)),"v-3ba014ab":()=>t.e(119).then(t.bind(null,703)),"v-911794de":()=>t.e(145).then(t.bind(null,704)),"v-bb2c6aaa":()=>t.e(146).then(t.bind(null,705)),"v-542b4a91":()=>t.e(147).then(t.bind(null,706)),"v-da271566":()=>t.e(148).then(t.bind(null,707)),"v-11f6eb4d":()=>t.e(124).then(t.bind(null,708)),"v-b42dc576":()=>t.e(150).then(t.bind(null,709)),"v-7076ed4d":()=>t.e(144).then(t.bind(null,710)),"v-48f9c38d":()=>t.e(155).then(t.bind(null,711)),"v-09dfd14d":()=>t.e(107).then(t.bind(null,712)),"v-07cf064d":()=>t.e(119).then(t.bind(null,713)),"v-6eb67c5e":()=>t.e(18).then(t.bind(null,714)),"v-73ea2666":()=>t.e(52).then(t.bind(null,715)),"v-11c575b5":()=>t.e(39).then(t.bind(null,716)),"v-662cece6":()=>t.e(110).then(t.bind(null,717)),"v-62c494b1":()=>t.e(161).then(t.bind(null,718)),"v-6f84b701":()=>t.e(160).then(t.bind(null,719)),"v-1c946e8d":()=>t.e(172).then(t.bind(null,720)),"v-1d35e80d":()=>t.e(35).then(t.bind(null,721)),"v-5e938c0d":()=>t.e(166).then(t.bind(null,722)),"v-6837abad":()=>t.e(37).then(t.bind(null,723)),"v-037fd2a6":()=>t.e(110).then(t.bind(null,724)),"v-fe33ad0a":()=>t.e(169).then(t.bind(null,725)),"v-6f374131":()=>t.e(170).then(t.bind(null,726)),"v-2de3a717":()=>t.e(44).then(t.bind(null,727)),"v-53b2904b":()=>t.e(171).then(t.bind(null,728)),"v-1ff7e666":()=>t.e(168).then(t.bind(null,729)),"v-69c2fde6":()=>t.e(63).then(t.bind(null,730)),"v-06bb2662":()=>t.e(60).then(t.bind(null,731)),"v-52ce73b1":()=>t.e(106).then(t.bind(null,732)),"v-38028849":()=>t.e(66).then(t.bind(null,733)),"v-4c7bdb41":()=>t.e(107).then(t.bind(null,734)),"v-1ba626c9":()=>t.e(119).then(t.bind(null,735)),"v-304ac322":()=>t.e(164).then(t.bind(null,736)),"v-2cad176e":()=>t.e(165).then(t.bind(null,737)),"v-7c7ce4ef":()=>t.e(163).then(t.bind(null,738)),"v-795a43aa":()=>t.e(68).then(t.bind(null,739)),"v-25ae723a":()=>t.e(125).then(t.bind(null,740)),"v-433617ed":()=>t.e(167).then(t.bind(null,741)),"v-1bb8ee2d":()=>t.e(162).then(t.bind(null,742)),"v-1d6eb7c4":()=>t.e(11).then(t.bind(null,743)),"v-e40ed1e6":()=>t.e(54).then(t.bind(null,744)),"v-228e86be":()=>t.e(131).then(t.bind(null,745)),"v-5779a577":()=>t.e(28).then(t.bind(null,746)),"v-43abd9ed":()=>t.e(46).then(t.bind(null,747)),"v-f74c83c6":()=>t.e(113).then(t.bind(null,748)),"v-4dfa1eed":()=>t.e(78).then(t.bind(null,749)),"v-5e4113f9":()=>t.e(21).then(t.bind(null,750)),"v-7cf5604d":()=>t.e(30).then(t.bind(null,751)),"v-788054ed":()=>t.e(37).then(t.bind(null,752)),"v-0e88bfed":()=>t.e(110).then(t.bind(null,753)),"v-5f5b9167":()=>t.e(36).then(t.bind(null,754)),"v-4daca91d":()=>t.e(103).then(t.bind(null,755)),"v-0c590f03":()=>t.e(43).then(t.bind(null,756)),"v-719f4e92":()=>t.e(80).then(t.bind(null,757)),"v-282f15b9":()=>t.e(105).then(t.bind(null,758)),"v-0859c4cd":()=>t.e(56).then(t.bind(null,759)),"v-5ec450bb":()=>t.e(60).then(t.bind(null,760)),"v-71d00bc6":()=>t.e(74).then(t.bind(null,761)),"v-51f04b35":()=>t.e(65).then(t.bind(null,762)),"v-f15ff5a6":()=>t.e(107).then(t.bind(null,763)),"v-53d12fb5":()=>t.e(119).then(t.bind(null,764)),"v-ed843a4a":()=>t.e(29).then(t.bind(null,765)),"v-4bcb5835":()=>t.e(47).then(t.bind(null,766)),"v-e1ab6f4a":()=>t.e(70).then(t.bind(null,767)),"v-64b62297":()=>t.e(68).then(t.bind(null,768)),"v-4f4aaacf":()=>t.e(138).then(t.bind(null,769)),"v-102e162d":()=>t.e(71).then(t.bind(null,770)),"v-2e9e2726":()=>t.e(118).then(t.bind(null,771)),"v-295c5866":()=>t.e(72).then(t.bind(null,772)),"v-1bc67126":()=>t.e(70).then(t.bind(null,773)),"v-685a2e6d":()=>t.e(69).then(t.bind(null,774)),"v-1f91922d":()=>t.e(68).then(t.bind(null,775)),"v-65affcad":()=>t.e(125).then(t.bind(null,776)),"v-4e5b9057":()=>t.e(71).then(t.bind(null,777)),"v-05bf836b":()=>t.e(117).then(t.bind(null,778)),"v-6dcc960d":()=>t.e(52).then(t.bind(null,779)),"v-67670071":()=>t.e(39).then(t.bind(null,780)),"v-5dda9d1e":()=>t.e(17).then(t.bind(null,781)),"v-3a2d0547":()=>t.e(89).then(t.bind(null,782)),"v-237fd8ed":()=>t.e(91).then(t.bind(null,783)),"v-6e8c87ed":()=>t.e(49).then(t.bind(null,784)),"v-30ad7ebd":()=>t.e(78).then(t.bind(null,785)),"v-0841246e":()=>t.e(21).then(t.bind(null,786)),"v-daa61166":()=>t.e(30).then(t.bind(null,787)),"v-392eb7ed":()=>t.e(37).then(t.bind(null,788)),"v-6191ba26":()=>t.e(110).then(t.bind(null,789)),"v-420ef137":()=>t.e(35).then(t.bind(null,790)),"v-306008ed":()=>t.e(102).then(t.bind(null,791)),"v-21e7225a":()=>t.e(42).then(t.bind(null,792)),"v-ada9f2f2":()=>t.e(80).then(t.bind(null,793)),"v-7bc99189":()=>t.e(105).then(t.bind(null,794)),"v-01b4cdcd":()=>t.e(57).then(t.bind(null,795)),"v-9ea17eea":()=>t.e(60).then(t.bind(null,796)),"v-77c86fed":()=>t.e(106).then(t.bind(null,797)),"v-7943c1f6":()=>t.e(66).then(t.bind(null,798)),"v-47b39cfd":()=>t.e(107).then(t.bind(null,799)),"v-b128a8f6":()=>t.e(119).then(t.bind(null,800)),"v-b3a7beaa":()=>t.e(69).then(t.bind(null,801)),"v-c4936ff6":()=>t.e(72).then(t.bind(null,802)),"v-ee6b2baa":()=>t.e(70).then(t.bind(null,803)),"v-fcb73f32":()=>t.e(68).then(t.bind(null,804)),"v-2ca3ee26":()=>t.e(124).then(t.bind(null,805)),"v-bd94cac2":()=>t.e(125).then(t.bind(null,806)),"v-6281452d":()=>t.e(71).then(t.bind(null,807)),"v-e894ac04":()=>t.e(20).then(t.bind(null,808)),"v-3b041b6d":()=>t.e(117).then(t.bind(null,809)),"v-9cd12ba6":()=>t.e(86).then(t.bind(null,810)),"v-62e23092":()=>t.e(127).then(t.bind(null,811)),"v-674aad0d":()=>t.e(87).then(t.bind(null,812)),"v-e7c9cde6":()=>t.e(89).then(t.bind(null,813)),"v-fac8dafa":()=>t.e(40).then(t.bind(null,814)),"v-6989e673":()=>t.e(41).then(t.bind(null,815)),"v-8b57cb62":()=>t.e(32).then(t.bind(null,816)),"v-3795786d":()=>t.e(129).then(t.bind(null,817)),"v-fbfd20e6":()=>t.e(139).then(t.bind(null,818)),"v-1809da8d":()=>t.e(81).then(t.bind(null,819)),"v-fb63c69a":()=>t.e(130).then(t.bind(null,820)),"v-40fa8299":()=>t.e(121).then(t.bind(null,821)),"v-7636cee6":()=>t.e(126).then(t.bind(null,822)),"v-290cdc62":()=>t.e(104).then(t.bind(null,823)),"v-19ad78ad":()=>t.e(61).then(t.bind(null,824)),"v-33ab2251":()=>t.e(60).then(t.bind(null,825)),"v-3ac4ae1a":()=>t.e(77).then(t.bind(null,826)),"v-7c7a576a":()=>t.e(50).then(t.bind(null,827)),"v-258149c3":()=>t.e(33).then(t.bind(null,828)),"v-171babcb":()=>t.e(108).then(t.bind(null,829)),"v-d867fe9e":()=>t.e(82).then(t.bind(null,830)),"v-20b229cb":()=>t.e(83).then(t.bind(null,831)),"v-e87d849e":()=>t.e(85).then(t.bind(null,832)),"v-6f44406d":()=>t.e(128).then(t.bind(null,833)),"v-131f5d4d":()=>t.e(75).then(t.bind(null,834)),"v-24317c65":()=>t.e(76).then(t.bind(null,835)),"v-c95f1966":()=>t.e(84).then(t.bind(null,836)),"v-73d3498d":()=>t.e(120).then(t.bind(null,837)),"v-8fbc73c4":()=>t.e(19).then(t.bind(null,838)),"v-4cb5e50d":()=>t.e(53).then(t.bind(null,839)),"v-8de7f97e":()=>t.e(173).then(t.bind(null,840)),"v-541b37d2":()=>t.e(89).then(t.bind(null,841)),"v-026927ed":()=>t.e(91).then(t.bind(null,842)),"v-39ce30bd":()=>t.e(49).then(t.bind(null,843)),"v-671a44e6":()=>t.e(78).then(t.bind(null,844)),"v-d805f606":()=>t.e(79).then(t.bind(null,845)),"v-3bc0b2ce":()=>t.e(21).then(t.bind(null,846)),"v-0501aa26":()=>t.e(37).then(t.bind(null,847)),"v-723b4366":()=>t.e(30).then(t.bind(null,848)),"v-d8f0d426":()=>t.e(110).then(t.bind(null,849)),"v-44575ff2":()=>t.e(35).then(t.bind(null,850)),"v-67b53086":()=>t.e(102).then(t.bind(null,851)),"v-ea5c64ba":()=>t.e(177).then(t.bind(null,852)),"v-29ed5952":()=>t.e(80).then(t.bind(null,853)),"v-37f14c59":()=>t.e(105).then(t.bind(null,854)),"v-50bff266":()=>t.e(64).then(t.bind(null,855)),"v-9101a14a":()=>t.e(60).then(t.bind(null,856)),"v-2c2604bd":()=>t.e(174).then(t.bind(null,857)),"v-31d49c56":()=>t.e(66).then(t.bind(null,858)),"v-5f7fb3cd":()=>t.e(107).then(t.bind(null,859)),"v-63936655":()=>t.e(119).then(t.bind(null,860)),"v-0810fd7b":()=>t.e(69).then(t.bind(null,861)),"v-b6f39256":()=>t.e(72).then(t.bind(null,862)),"v-0b15eafb":()=>t.e(70).then(t.bind(null,863)),"v-38ed8592":()=>t.e(68).then(t.bind(null,864)),"v-58f735ed":()=>t.e(124).then(t.bind(null,865)),"v-aff4ed22":()=>t.e(175).then(t.bind(null,866)),"v-7d8a77a6":()=>t.e(71).then(t.bind(null,867)),"v-cc84cb26":()=>t.e(176).then(t.bind(null,868)),"v-79043d8b":()=>t.e(89).then(t.bind(null,869)),"v-7bbe2fad":()=>t.e(91).then(t.bind(null,870))};function Je(e){const n=Object.create(null);return function(t){return n[t]||(n[t]=e(t))}}const $e=/-(\w)/g,Ze=Je(e=>e.replace($e,(e,n)=>n?n.toUpperCase():"")),Xe=/\B([A-Z])/g,en=Je(e=>e.replace(Xe,"-$1").toLowerCase()),nn=Je(e=>e.charAt(0).toUpperCase()+e.slice(1));function tn(e,n){if(!n)return;if(e(n))return e(n);return n.includes("-")?e(nn(Ze(n))):e(nn(n))||e(en(n))}const an=Object.assign({},Ve,Ye),on=e=>an[e],rn=e=>Ye[e],sn=e=>Ve[e],ln=e=>a.a.component(e);function un(e){return tn(rn,e)}function cn(e){return tn(sn,e)}function dn(e){return tn(on,e)}function hn(e){return tn(ln,e)}function pn(...e){return Promise.all(e.filter(e=>e).map(async e=>{if(!hn(e)&&dn(e)){const n=await dn(e)();a.a.component(e,n.default)}}))}function mn(e,n){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[e]=n)}var yn=t(60),gn=t.n(yn),bn={created(){if(this.siteMeta=this.$site.headTags.filter(([e])=>"meta"===e).map(([e,n])=>n),this.$ssrContext){const n=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(e=n)?e.map(e=>{let n="<meta";return Object.keys(e).forEach(t=>{n+=` ${t}="${e[t]}"`}),n+">"}).join("\n    "):"",this.$ssrContext.canonicalLink=fn(this.$canonicalUrl)}var e},mounted(){this.currentMetaTags=[...document.querySelectorAll("meta")],this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta(){document.title=this.$title,document.documentElement.lang=this.$lang;const e=this.getMergedMetaTags();this.currentMetaTags=wn(e,this.currentMetaTags)},getMergedMetaTags(){const e=this.$page.frontmatter.meta||[];return gn()([{name:"description",content:this.$description}],e,this.siteMeta,vn)},updateCanonicalLink(){kn(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",fn(this.$canonicalUrl))}},watch:{$page(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy(){wn(null,this.currentMetaTags),kn()}};function kn(){const e=document.querySelector("link[rel='canonical']");e&&e.remove()}function fn(e=""){return e?`<link href="${e}" rel="canonical" />`:""}function wn(e,n){if(n&&[...n].filter(e=>e.parentNode===document.head).forEach(e=>document.head.removeChild(e)),e)return e.map(e=>{const n=document.createElement("meta");return Object.keys(e).forEach(t=>{n.setAttribute(t,e[t])}),document.head.appendChild(n),n})}function vn(e){for(const n of["name","property","itemprop"])if(e.hasOwnProperty(n))return e[n]+n;return JSON.stringify(e)}var qn=t(15),xn=t.n(qn),jn={mounted(){xn.a.configure({showSpinner:!1}),this.$router.beforeEach((e,n,t)=>{e.path===n.path||a.a.component(e.name)||xn.a.start(),t()}),this.$router.afterEach(()=>{xn.a.done(),this.isSidebarOpen=!1})}},Sn=t(14),Tn=t.n(Sn);let zn;var Qn=a.a.extend({mounted(){zn=Tn()(()=>{this.setActiveHash()},300),window.addEventListener("scroll",zn)},beforeDestroy(){window.removeEventListener("scroll",zn)},methods:{setActiveHash(){const e=Array.from(document.querySelectorAll(".sidebar-link")),n=Array.from(document.querySelectorAll(".header-anchor")).filter(n=>0===e.length||e.some(e=>e.hash===n.hash)),t=document.querySelector(".theme-default-content").offsetTop,a=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),o=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),r=window.innerHeight+a,i=decodeURIComponent(this.$route.hash),s=(e,t)=>{if(r===o)for(let e=t+1;e<n.length;e++)if(i===decodeURIComponent(n[e].hash))return;this.$vuepress.$set("disableScrollBehavior",!0),this.$router.replace(decodeURIComponent(e),()=>{this.$nextTick(()=>{this.$vuepress.$set("disableScrollBehavior",!1)})})};if(a-t<0&&i)s("#",-1);else for(let e=0;e<n.length;e++){const o=n[e],r=n[e+1];if(a-t>=o.parentElement.offsetTop+0&&(!r||a-t<r.parentElement.offsetTop+0)&&i!==decodeURIComponent(o.hash))return void s(o.hash,e)}}}});t(159);class In{constructor(){const e=document.getElementById("message-container");e?this.containerElement=e:(this.containerElement=document.createElement("div"),this.containerElement.id="message-container",document.body.appendChild(this.containerElement))}pop(e,n=2e3){const t=document.createElement("div");t.className="message move-in",t.innerHTML=`<svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="#06a35a"><path d="M822.812 824.618c-83.076 81.992-188.546 124.614-316.05 127.865-122.085-3.251-223.943-45.873-305.935-127.865S76.213 640.406 72.962 518.682c3.251-127.503 45.873-232.973 127.865-316.05 81.992-83.075 184.211-126.058 305.936-129.309 127.503 3.251 232.973 46.234 316.049 129.31 83.076 83.076 126.059 188.546 129.31 316.05-2.89 121.723-46.234 223.943-129.31 305.935zM432.717 684.111c3.973 3.974 8.307 5.78 13.364 6.14 5.057.362 9.753-1.444 13.365-5.417l292.57-287.515c3.974-3.973 5.78-8.307 5.78-13.364s-1.806-9.753-5.78-13.365l1.807 1.806c-3.973-3.973-8.669-5.779-14.087-6.14-5.418-.361-10.475 1.445-14.809 5.418L460.529 592.006c-3.973 3.25-8.669 4.695-14.448 4.695-5.78 0-10.836-1.445-15.531-3.973l-94.273-72.962c-4.335-3.251-9.392-4.335-14.448-3.973s-9.392 3.25-12.642 7.585l-2.89 3.973c-3.25 4.334-4.334 9.391-3.973 14.81.722 5.417 2.528 10.113 5.779 14.086L432.717 684.11z"/></svg><span>${e}</span>`,this.containerElement.appendChild(t),n>0&&setTimeout(()=>{this.close(t)},n)}close(e){e.className=e.className.replace("move-in",""),e.className+="move-out",e.addEventListener("animationend",()=>{e.remove()})}}t(160),t(62);let Pn;const _n={"/zh/":{copy:"复制成功 🎉",hint:"复制代码"},"/en/":{copy:"Copy successfully 🎉",hint:"Copy the code"},"/de/":{copy:"Kopieren erfolgreich 🎉",hint:"Kopiere den Code."},"/vi/":{copy:"Sao chép thành công 🎉",hint:"Sao chép code"},"/":{copy:"Copy successfully 🎉",hint:"Copy the code"}},Cn={},An=()=>!!navigator&&/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/iu.test(navigator.userAgent);var On=[bn,jn,Qn,a.a.extend({mounted(){Pn=new In,An()&&!Cn.showInMobile||this.genCopyButton()},updated(){An()&&!Cn.showInMobile||this.genCopyButton()},methods:{genCopyButton(){const e=Cn.selector||'.theme-default-content div[class*="language-"] pre';setTimeout(()=>{"string"==typeof e?document.querySelectorAll(e).forEach(this.insertCopyButton.bind(this)):Array.isArray(e)&&e.forEach(e=>{document.querySelectorAll(e).forEach(this.insertCopyButton.bind(this))})},1e3)},insertCopyButton(e){if(!e.hasAttribute("copy-code-registerd")){const n=document.createElement("button");n.className="copy-code-button",n.innerHTML='<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" class="icon-copy-code"><path fill="currentColor" d="M384 112v352c0 26.51-21.49 48-48 48H48c-26.51 0-48-21.49-48-48V112c0-26.51 21.49-48 48-48h80c0-35.29 28.71-64 64-64s64 28.71 64 64h80c26.51 0 48 21.49 48 48zM192 40c-13.255 0-24 10.745-24 24s10.745 24 24 24 24-10.745 24-24-10.745-24-24-24m96 114v-20a6 6 0 00-6-6H102a6 6 0 00-6 6v20a6 6 0 006 6h180a6 6 0 006-6z" /></svg>',n.addEventListener("click",()=>{this.copyToClipboard(e.innerText)}),n.setAttribute("aria-label",_n[this.$localePath||"/"].hint),n.setAttribute("data-balloon-pos","left"),e.parentElement&&e.parentElement.insertBefore(n,e),e.setAttribute("copy-code-registerd","")}},copyToClipboard(e){const n=document.getSelection(),t=!!(n&&n.rangeCount>0)&&n.getRangeAt(0),a=document.createElement("textarea");a.value=e,a.setAttribute("readonly",""),a.style.position="absolute",a.style.top="-9999px",document.body.appendChild(a),a.select(),document.execCommand("copy"),0!==Cn.duration&&Pn.pop(_n[this.$localePath||"/"].copy,Cn.duration),document.body.removeChild(a),t&&n&&(n.removeAllRanges(),n.addRange(t))}}})],Hn={name:"GlobalLayout",computed:{layout(){const e=this.getLayout();return mn("layout",e),a.a.component(e)}},methods:{getLayout(){if(this.$page.path){const e=this.$page.frontmatter.layout;return e&&(this.$vuepress.getLayoutAsyncComponent(e)||this.$vuepress.getVueComponent(e))?e:"Layout"}return"NotFound"}}},Ln=t(1),Dn=Object(Ln.a)(Hn,(function(){var e=this.$createElement;return(this._self._c||e)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(e,n,t){switch(n){case"components":e[n]||(e[n]={}),Object.assign(e[n],t);break;case"mixins":e[n]||(e[n]=[]),e[n].push(...t);break;default:throw new Error("Unknown option name.")}}(Dn,"mixins",On);const En=[{name:"v-86b1f726",path:"/create/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-86b1f726").then(t)}},{path:"/create/graphql/index.html",redirect:"/create/graphql/"},{path:"/create/graphql.html",redirect:"/create/graphql/"},{name:"v-47639a6e",path:"/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-47639a6e").then(t)}},{path:"/index.html",redirect:"/"},{name:"v-94114ee6",path:"/create/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-94114ee6").then(t)}},{path:"/create/introduction/index.html",redirect:"/create/introduction/"},{path:"/create/introduction.html",redirect:"/create/introduction/"},{name:"v-5d960c2d",path:"/create/manifest/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5d960c2d").then(t)}},{path:"/create/manifest/index.html",redirect:"/create/manifest/"},{path:"/create/manifest.html",redirect:"/create/manifest/"},{name:"v-03d2d023",path:"/create/mapping/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-03d2d023").then(t)}},{path:"/create/mapping/index.html",redirect:"/create/mapping/"},{path:"/create/mapping.html",redirect:"/create/mapping/"},{name:"v-4806233e",path:"/de/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-4806233e").then(t)}},{path:"/de/index.html",redirect:"/de/"},{name:"v-64c45226",path:"/de/create/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-64c45226").then(t)}},{path:"/de/create/graphql/index.html",redirect:"/de/create/graphql/"},{path:"/de/create/graphql.html",redirect:"/de/create/graphql/"},{name:"v-19f3891b",path:"/de/create/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-19f3891b").then(t)}},{path:"/de/create/introduction/index.html",redirect:"/de/create/introduction/"},{path:"/de/create/introduction.html",redirect:"/de/create/introduction/"},{name:"v-4f881571",path:"/de/create/manifest/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-4f881571").then(t)}},{path:"/de/create/manifest/index.html",redirect:"/de/create/manifest/"},{path:"/de/create/manifest.html",redirect:"/de/create/manifest/"},{name:"v-f95dcc66",path:"/de/create/mapping/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-f95dcc66").then(t)}},{path:"/de/create/mapping/index.html",redirect:"/de/create/mapping/"},{path:"/de/create/mapping.html",redirect:"/de/create/mapping/"},{name:"v-3d649b57",path:"/de/faqs/faqs/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-3d649b57").then(t)}},{path:"/de/faqs/faqs/index.html",redirect:"/de/faqs/faqs/"},{path:"/de/faqs/faqs.html",redirect:"/de/faqs/faqs/"},{name:"v-46088ee7",path:"/de/install/install/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-46088ee7").then(t)}},{path:"/de/install/install/index.html",redirect:"/de/install/install/"},{path:"/de/install/install.html",redirect:"/de/install/install/"},{name:"v-4f6d6333",path:"/de/miscellaneous/ambassadors/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-4f6d6333").then(t)}},{path:"/de/miscellaneous/ambassadors/index.html",redirect:"/de/miscellaneous/ambassadors/"},{path:"/de/miscellaneous/ambassadors.html",redirect:"/de/miscellaneous/ambassadors/"},{name:"v-25b5132d",path:"/de/miscellaneous/branding/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-25b5132d").then(t)}},{path:"/de/miscellaneous/branding/index.html",redirect:"/de/miscellaneous/branding/"},{path:"/de/miscellaneous/branding.html",redirect:"/de/miscellaneous/branding/"},{name:"v-220de14d",path:"/de/miscellaneous/contributing/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-220de14d").then(t)}},{path:"/de/miscellaneous/contributing/index.html",redirect:"/de/miscellaneous/contributing/"},{path:"/de/miscellaneous/contributing.html",redirect:"/de/miscellaneous/contributing/"},{name:"v-8fd36766",path:"/de/miscellaneous/social_media/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-8fd36766").then(t)}},{path:"/de/miscellaneous/social_media/index.html",redirect:"/de/miscellaneous/social_media/"},{path:"/de/miscellaneous/social_media.html",redirect:"/de/miscellaneous/social_media/"},{name:"v-576a0161",path:"/de/publish/connect/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-576a0161").then(t)}},{path:"/de/publish/connect/index.html",redirect:"/de/publish/connect/"},{path:"/de/publish/connect.html",redirect:"/de/publish/connect/"},{name:"v-45bb1917",path:"/de/publish/publish/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-45bb1917").then(t)}},{path:"/de/publish/publish/index.html",redirect:"/de/publish/publish/"},{path:"/de/publish/publish.html",redirect:"/de/publish/publish/"},{name:"v-03e13271",path:"/de/query/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-03e13271").then(t)}},{path:"/de/query/graphql/index.html",redirect:"/de/query/graphql/"},{path:"/de/query/graphql.html",redirect:"/de/query/graphql/"},{name:"v-04677efd",path:"/de/publish/upgrade/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-04677efd").then(t)}},{path:"/de/publish/upgrade/index.html",redirect:"/de/publish/upgrade/"},{path:"/de/publish/upgrade.html",redirect:"/de/publish/upgrade/"},{name:"v-306d6933",path:"/de/query/query/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-306d6933").then(t)}},{path:"/de/query/query/index.html",redirect:"/de/query/query/"},{path:"/de/query/query.html",redirect:"/de/query/query/"},{name:"v-754465ed",path:"/de/quickstart/helloworld-hosted/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-754465ed").then(t)}},{path:"/de/quickstart/helloworld-hosted/index.html",redirect:"/de/quickstart/helloworld-hosted/"},{path:"/de/quickstart/helloworld-hosted.html",redirect:"/de/quickstart/helloworld-hosted/"},{name:"v-756db2b5",path:"/de/quickstart/helloworld-localhost/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-756db2b5").then(t)}},{path:"/de/quickstart/helloworld-localhost/index.html",redirect:"/de/quickstart/helloworld-localhost/"},{path:"/de/quickstart/helloworld-localhost.html",redirect:"/de/quickstart/helloworld-localhost/"},{name:"v-e30ce652",path:"/de/quickstart/quickstart/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-e30ce652").then(t)}},{path:"/de/quickstart/quickstart/index.html",redirect:"/de/quickstart/quickstart/"},{path:"/de/quickstart/quickstart.html",redirect:"/de/quickstart/quickstart/"},{name:"v-76f709af",path:"/de/quickstart/understanding-helloworld/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-76f709af").then(t)}},{path:"/de/quickstart/understanding-helloworld/index.html",redirect:"/de/quickstart/understanding-helloworld/"},{path:"/de/quickstart/understanding-helloworld.html",redirect:"/de/quickstart/understanding-helloworld/"},{name:"v-bc8b07b2",path:"/de/run/run/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-bc8b07b2").then(t)}},{path:"/de/run/run/index.html",redirect:"/de/run/run/"},{path:"/de/run/run.html",redirect:"/de/run/run/"},{name:"v-5c0f832f",path:"/de/run/sandbox/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5c0f832f").then(t)}},{path:"/de/run/sandbox/index.html",redirect:"/de/run/sandbox/"},{path:"/de/run/sandbox.html",redirect:"/de/run/sandbox/"},{name:"v-59012e95",path:"/de/tutorials_examples/batch-size/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-59012e95").then(t)}},{path:"/de/tutorials_examples/batch-size/index.html",redirect:"/de/tutorials_examples/batch-size/"},{path:"/de/tutorials_examples/batch-size.html",redirect:"/de/tutorials_examples/batch-size/"},{name:"v-6274ba2f",path:"/de/tutorials_examples/block-height/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6274ba2f").then(t)}},{path:"/de/tutorials_examples/block-height/index.html",redirect:"/de/tutorials_examples/block-height/"},{path:"/de/tutorials_examples/block-height.html",redirect:"/de/tutorials_examples/block-height/"},{name:"v-0bb0d095",path:"/de/tutorials_examples/debug-projects/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0bb0d095").then(t)}},{path:"/de/tutorials_examples/debug-projects/index.html",redirect:"/de/tutorials_examples/debug-projects/"},{path:"/de/tutorials_examples/debug-projects.html",redirect:"/de/tutorials_examples/debug-projects/"},{name:"v-34796e51",path:"/de/tutorials_examples/dictionary/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-34796e51").then(t)}},{path:"/de/tutorials_examples/dictionary/index.html",redirect:"/de/tutorials_examples/dictionary/"},{path:"/de/tutorials_examples/dictionary.html",redirect:"/de/tutorials_examples/dictionary/"},{name:"v-89f298e6",path:"/de/tutorials_examples/howto/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-89f298e6").then(t)}},{path:"/de/tutorials_examples/howto/index.html",redirect:"/de/tutorials_examples/howto/"},{path:"/de/tutorials_examples/howto.html",redirect:"/de/tutorials_examples/howto/"},{name:"v-65f40cc9",path:"/de/tutorials_examples/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-65f40cc9").then(t)}},{path:"/de/tutorials_examples/introduction/index.html",redirect:"/de/tutorials_examples/introduction/"},{path:"/de/tutorials_examples/introduction.html",redirect:"/de/tutorials_examples/introduction/"},{name:"v-68df3c0d",path:"/de/tutorials_examples/run-indexer/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-68df3c0d").then(t)}},{path:"/de/tutorials_examples/run-indexer/index.html",redirect:"/de/tutorials_examples/run-indexer/"},{path:"/de/tutorials_examples/run-indexer.html",redirect:"/de/tutorials_examples/run-indexer/"},{name:"v-4162124d",path:"/de/tutorials_examples/terminology/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-4162124d").then(t)}},{path:"/de/tutorials_examples/terminology/index.html",redirect:"/de/tutorials_examples/terminology/"},{path:"/de/tutorials_examples/terminology.html",redirect:"/de/tutorials_examples/terminology/"},{name:"v-1397d61e",path:"/es/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1397d61e").then(t)}},{path:"/es/index.html",redirect:"/es/"},{name:"v-514b550d",path:"/es/create/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-514b550d").then(t)}},{path:"/es/create/graphql/index.html",redirect:"/es/create/graphql/"},{path:"/es/create/graphql.html",redirect:"/es/create/graphql/"},{name:"v-7c3a4841",path:"/es/create/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7c3a4841").then(t)}},{path:"/es/create/introduction/index.html",redirect:"/es/create/introduction/"},{path:"/es/create/introduction.html",redirect:"/es/create/introduction/"},{name:"v-38986917",path:"/es/create/manifest/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-38986917").then(t)}},{path:"/es/create/manifest/index.html",redirect:"/es/create/manifest/"},{path:"/es/create/manifest.html",redirect:"/es/create/manifest/"},{name:"v-06fe97ed",path:"/es/create/mapping/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-06fe97ed").then(t)}},{path:"/es/create/mapping/index.html",redirect:"/es/create/mapping/"},{path:"/es/create/mapping.html",redirect:"/es/create/mapping/"},{name:"v-56f85486",path:"/es/faqs/faqs/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-56f85486").then(t)}},{path:"/es/faqs/faqs/index.html",redirect:"/es/faqs/faqs/"},{path:"/es/faqs/faqs.html",redirect:"/es/faqs/faqs/"},{name:"v-2f18e28d",path:"/es/install/install/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2f18e28d").then(t)}},{path:"/es/install/install/index.html",redirect:"/es/install/install/"},{path:"/es/install/install.html",redirect:"/es/install/install/"},{name:"v-76f64b99",path:"/es/miscellaneous/ambassadors/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-76f64b99").then(t)}},{path:"/es/miscellaneous/ambassadors/index.html",redirect:"/es/miscellaneous/ambassadors/"},{path:"/es/miscellaneous/ambassadors.html",redirect:"/es/miscellaneous/ambassadors/"},{name:"v-2e6d4e4d",path:"/es/miscellaneous/branding/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2e6d4e4d").then(t)}},{path:"/es/miscellaneous/branding/index.html",redirect:"/es/miscellaneous/branding/"},{path:"/es/miscellaneous/branding.html",redirect:"/es/miscellaneous/branding/"},{name:"v-29564a26",path:"/es/miscellaneous/contributing/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-29564a26").then(t)}},{path:"/es/miscellaneous/contributing/index.html",redirect:"/es/miscellaneous/contributing/"},{path:"/es/miscellaneous/contributing.html",redirect:"/es/miscellaneous/contributing/"},{name:"v-fd457426",path:"/es/miscellaneous/social_media/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-fd457426").then(t)}},{path:"/es/miscellaneous/social_media/index.html",redirect:"/es/miscellaneous/social_media/"},{path:"/es/miscellaneous/social_media.html",redirect:"/es/miscellaneous/social_media/"},{name:"v-407a5507",path:"/es/publish/connect/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-407a5507").then(t)}},{path:"/es/publish/connect/index.html",redirect:"/es/publish/connect/"},{path:"/es/publish/connect.html",redirect:"/es/publish/connect/"},{name:"v-2ecb6cbd",path:"/es/publish/publish/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2ecb6cbd").then(t)}},{path:"/es/publish/publish/index.html",redirect:"/es/publish/publish/"},{path:"/es/publish/publish.html",redirect:"/es/publish/publish/"},{name:"v-25105aba",path:"/es/publish/upgrade/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-25105aba").then(t)}},{path:"/es/publish/upgrade/index.html",redirect:"/es/publish/upgrade/"},{path:"/es/publish/upgrade.html",redirect:"/es/publish/upgrade/"},{name:"v-0b973857",path:"/es/query/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0b973857").then(t)}},{path:"/es/query/graphql/index.html",redirect:"/es/query/graphql/"},{path:"/es/query/graphql.html",redirect:"/es/query/graphql/"},{name:"v-2d2f1159",path:"/es/query/query/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2d2f1159").then(t)}},{path:"/es/query/query/index.html",redirect:"/es/query/query/"},{path:"/es/query/query.html",redirect:"/es/query/query/"},{name:"v-ee61d266",path:"/es/quickstart/helloworld-hosted/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-ee61d266").then(t)}},{path:"/es/quickstart/helloworld-hosted/index.html",redirect:"/es/quickstart/helloworld-hosted/"},{path:"/es/quickstart/helloworld-hosted.html",redirect:"/es/quickstart/helloworld-hosted/"},{name:"v-2f06345b",path:"/es/quickstart/helloworld-localhost/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2f06345b").then(t)}},{path:"/es/quickstart/helloworld-localhost/index.html",redirect:"/es/quickstart/helloworld-localhost/"},{path:"/es/quickstart/helloworld-localhost.html",redirect:"/es/quickstart/helloworld-localhost/"},{name:"v-19c469bd",path:"/es/quickstart/quickstart/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-19c469bd").then(t)}},{path:"/es/quickstart/quickstart/index.html",redirect:"/es/quickstart/quickstart/"},{path:"/es/quickstart/quickstart.html",redirect:"/es/quickstart/quickstart/"},{name:"v-6ba4f6d5",path:"/es/quickstart/understanding-helloworld/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6ba4f6d5").then(t)}},{path:"/es/quickstart/understanding-helloworld/index.html",redirect:"/es/quickstart/understanding-helloworld/"},{path:"/es/quickstart/understanding-helloworld.html",redirect:"/es/quickstart/understanding-helloworld/"},{name:"v-ab158e66",path:"/es/run/run/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-ab158e66").then(t)}},{path:"/es/run/run/index.html",redirect:"/es/run/run/"},{path:"/es/run/run.html",redirect:"/es/run/run/"},{name:"v-58d12b55",path:"/es/run/sandbox/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-58d12b55").then(t)}},{path:"/es/run/sandbox/index.html",redirect:"/es/run/sandbox/"},{path:"/es/run/sandbox.html",redirect:"/es/run/sandbox/"},{name:"v-a1803b0a",path:"/es/tutorials_examples/batch-size/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-a1803b0a").then(t)}},{path:"/es/tutorials_examples/batch-size/index.html",redirect:"/es/tutorials_examples/batch-size/"},{path:"/es/tutorials_examples/batch-size.html",redirect:"/es/tutorials_examples/batch-size/"},{name:"v-1c0d3bd5",path:"/es/tutorials_examples/block-height/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1c0d3bd5").then(t)}},{path:"/es/tutorials_examples/block-height/index.html",redirect:"/es/tutorials_examples/block-height/"},{path:"/es/tutorials_examples/block-height.html",redirect:"/es/tutorials_examples/block-height/"},{name:"v-5fbd0ffb",path:"/es/tutorials_examples/debug-projects/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5fbd0ffb").then(t)}},{path:"/es/tutorials_examples/debug-projects/index.html",redirect:"/es/tutorials_examples/debug-projects/"},{path:"/es/tutorials_examples/debug-projects.html",redirect:"/es/tutorials_examples/debug-projects/"},{name:"v-ea8fbb92",path:"/es/tutorials_examples/dictionary/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-ea8fbb92").then(t)}},{path:"/es/tutorials_examples/dictionary/index.html",redirect:"/es/tutorials_examples/dictionary/"},{path:"/es/tutorials_examples/dictionary.html",redirect:"/es/tutorials_examples/dictionary/"},{name:"v-76eb85ed",path:"/es/tutorials_examples/howto/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-76eb85ed").then(t)}},{path:"/es/tutorials_examples/howto/index.html",redirect:"/es/tutorials_examples/howto/"},{path:"/es/tutorials_examples/howto.html",redirect:"/es/tutorials_examples/howto/"},{name:"v-1f8c8e6f",path:"/es/tutorials_examples/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1f8c8e6f").then(t)}},{path:"/es/tutorials_examples/introduction/index.html",redirect:"/es/tutorials_examples/introduction/"},{path:"/es/tutorials_examples/introduction.html",redirect:"/es/tutorials_examples/introduction/"},{name:"v-f98997a6",path:"/es/tutorials_examples/run-indexer/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-f98997a6").then(t)}},{path:"/es/tutorials_examples/run-indexer/index.html",redirect:"/es/tutorials_examples/run-indexer/"},{path:"/es/tutorials_examples/run-indexer.html",redirect:"/es/tutorials_examples/run-indexer/"},{name:"v-5bbe0a6d",path:"/es/tutorials_examples/terminology/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5bbe0a6d").then(t)}},{path:"/es/tutorials_examples/terminology/index.html",redirect:"/es/tutorials_examples/terminology/"},{path:"/es/tutorials_examples/terminology.html",redirect:"/es/tutorials_examples/terminology/"},{name:"v-1265970d",path:"/faqs/faqs/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1265970d").then(t)}},{path:"/faqs/faqs/index.html",redirect:"/faqs/faqs/"},{path:"/faqs/faqs.html",redirect:"/faqs/faqs/"},{name:"v-560420fe",path:"/id/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-560420fe").then(t)}},{path:"/id/index.html",redirect:"/id/"},{name:"v-56f909a6",path:"/id/create/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-56f909a6").then(t)}},{path:"/id/create/graphql/index.html",redirect:"/id/create/graphql/"},{path:"/id/create/graphql.html",redirect:"/id/create/graphql/"},{name:"v-6a073232",path:"/id/create/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6a073232").then(t)}},{path:"/id/create/introduction/index.html",redirect:"/id/create/introduction/"},{path:"/id/create/introduction.html",redirect:"/id/create/introduction/"},{name:"v-7e31bc3d",path:"/id/create/manifest/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7e31bc3d").then(t)}},{path:"/id/create/manifest/index.html",redirect:"/id/create/manifest/"},{path:"/id/create/manifest.html",redirect:"/id/create/manifest/"},{name:"v-eb9283e6",path:"/id/create/mapping/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-eb9283e6").then(t)}},{path:"/id/create/mapping/index.html",redirect:"/id/create/mapping/"},{path:"/id/create/mapping.html",redirect:"/id/create/mapping/"},{name:"v-47ab00ba",path:"/id/faqs/faqs/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-47ab00ba").then(t)}},{path:"/id/faqs/faqs/index.html",redirect:"/id/faqs/faqs/"},{path:"/id/faqs/faqs.html",redirect:"/id/faqs/faqs/"},{name:"v-74b235b3",path:"/id/install/install/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-74b235b3").then(t)}},{path:"/id/install/install/index.html",redirect:"/id/install/install/"},{path:"/id/install/install.html",redirect:"/id/install/install/"},{name:"v-42d0237f",path:"/id/miscellaneous/ambassadors/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-42d0237f").then(t)}},{path:"/id/miscellaneous/ambassadors/index.html",redirect:"/id/miscellaneous/ambassadors/"},{path:"/id/miscellaneous/ambassadors.html",redirect:"/id/miscellaneous/ambassadors/"},{name:"v-73371d26",path:"/id/miscellaneous/branding/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-73371d26").then(t)}},{path:"/id/miscellaneous/branding/index.html",redirect:"/id/miscellaneous/branding/"},{path:"/id/miscellaneous/branding.html",redirect:"/id/miscellaneous/branding/"},{name:"v-932646e6",path:"/id/miscellaneous/contributing/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-932646e6").then(t)}},{path:"/id/miscellaneous/contributing/index.html",redirect:"/id/miscellaneous/contributing/"},{path:"/id/miscellaneous/contributing.html",redirect:"/id/miscellaneous/contributing/"},{name:"v-4c75478d",path:"/id/miscellaneous/social_media/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-4c75478d").then(t)}},{path:"/id/miscellaneous/social_media/index.html",redirect:"/id/miscellaneous/social_media/"},{path:"/id/miscellaneous/social_media.html",redirect:"/id/miscellaneous/social_media/"},{name:"v-f3d8afa6",path:"/id/publish/connect/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-f3d8afa6").then(t)}},{path:"/id/publish/connect/index.html",redirect:"/id/publish/connect/"},{path:"/id/publish/connect.html",redirect:"/id/publish/connect/"},{name:"v-7464bfe3",path:"/id/publish/publish/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7464bfe3").then(t)}},{path:"/id/publish/publish/index.html",redirect:"/id/publish/publish/"},{path:"/id/publish/publish.html",redirect:"/id/publish/publish/"},{name:"v-331125c9",path:"/id/publish/upgrade/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-331125c9").then(t)}},{path:"/id/publish/upgrade/index.html",redirect:"/id/publish/upgrade/"},{path:"/id/publish/upgrade.html",redirect:"/id/publish/upgrade/"},{name:"v-7981e486",path:"/id/query/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7981e486").then(t)}},{path:"/id/query/graphql/index.html",redirect:"/id/query/graphql/"},{path:"/id/query/graphql.html",redirect:"/id/query/graphql/"},{name:"v-5e3758ff",path:"/id/query/query/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5e3758ff").then(t)}},{path:"/id/query/query/index.html",redirect:"/id/query/query/"},{path:"/id/query/query.html",redirect:"/id/query/query/"},{name:"v-eabc40a6",path:"/id/quickstart/helloworld-hosted/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-eabc40a6").then(t)}},{path:"/id/quickstart/helloworld-hosted/index.html",redirect:"/id/quickstart/helloworld-hosted/"},{path:"/id/quickstart/helloworld-hosted.html",redirect:"/id/quickstart/helloworld-hosted/"},{name:"v-79dd94fe",path:"/id/quickstart/helloworld-localhost/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-79dd94fe").then(t)}},{path:"/id/quickstart/helloworld-localhost/index.html",redirect:"/id/quickstart/helloworld-localhost/"},{path:"/id/quickstart/helloworld-localhost.html",redirect:"/id/quickstart/helloworld-localhost/"},{name:"v-26e5d623",path:"/id/quickstart/quickstart/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-26e5d623").then(t)}},{path:"/id/quickstart/quickstart/index.html",redirect:"/id/quickstart/quickstart/"},{path:"/id/quickstart/quickstart.html",redirect:"/id/quickstart/quickstart/"},{name:"v-3977c37b",path:"/id/quickstart/understanding-helloworld/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-3977c37b").then(t)}},{path:"/id/quickstart/understanding-helloworld/index.html",redirect:"/id/quickstart/understanding-helloworld/"},{path:"/id/quickstart/understanding-helloworld.html",redirect:"/id/quickstart/understanding-helloworld/"},{name:"v-5ee434f3",path:"/id/run/run/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5ee434f3").then(t)}},{path:"/id/run/run/index.html",redirect:"/id/run/run/"},{path:"/id/run/run.html",redirect:"/id/run/run/"},{name:"v-ec4d1a0a",path:"/id/run/sandbox/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-ec4d1a0a").then(t)}},{path:"/id/run/sandbox/index.html",redirect:"/id/run/sandbox/"},{path:"/id/run/sandbox.html",redirect:"/id/run/sandbox/"},{name:"v-b00c343e",path:"/id/tutorials_examples/batch-size/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-b00c343e").then(t)}},{path:"/id/tutorials_examples/batch-size/index.html",redirect:"/id/tutorials_examples/batch-size/"},{path:"/id/tutorials_examples/batch-size.html",redirect:"/id/tutorials_examples/batch-size/"},{name:"v-9fcf860a",path:"/id/tutorials_examples/block-height/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-9fcf860a").then(t)}},{path:"/id/tutorials_examples/block-height/index.html",redirect:"/id/tutorials_examples/block-height/"},{path:"/id/tutorials_examples/block-height.html",redirect:"/id/tutorials_examples/block-height/"},{name:"v-0fc2023e",path:"/id/tutorials_examples/debug-projects/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0fc2023e").then(t)}},{path:"/id/tutorials_examples/debug-projects/index.html",redirect:"/id/tutorials_examples/debug-projects/"},{path:"/id/tutorials_examples/debug-projects.html",redirect:"/id/tutorials_examples/debug-projects/"},{name:"v-f91bb4c6",path:"/id/tutorials_examples/dictionary/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-f91bb4c6").then(t)}},{path:"/id/tutorials_examples/dictionary/index.html",redirect:"/id/tutorials_examples/dictionary/"},{path:"/id/tutorials_examples/dictionary.html",redirect:"/id/tutorials_examples/dictionary/"},{name:"v-7c9e504d",path:"/id/tutorials_examples/howto/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7c9e504d").then(t)}},{path:"/id/tutorials_examples/howto/index.html",redirect:"/id/tutorials_examples/howto/"},{path:"/id/tutorials_examples/howto.html",redirect:"/id/tutorials_examples/howto/"},{name:"v-98d0e0d6",path:"/id/tutorials_examples/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-98d0e0d6").then(t)}},{path:"/id/tutorials_examples/introduction/index.html",redirect:"/id/tutorials_examples/introduction/"},{path:"/id/tutorials_examples/introduction.html",redirect:"/id/tutorials_examples/introduction/"},{name:"v-23ca544d",path:"/id/tutorials_examples/run-indexer/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-23ca544d").then(t)}},{path:"/id/tutorials_examples/run-indexer/index.html",redirect:"/id/tutorials_examples/run-indexer/"},{path:"/id/tutorials_examples/run-indexer.html",redirect:"/id/tutorials_examples/run-indexer/"},{name:"v-0765aae6",path:"/id/tutorials_examples/terminology/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0765aae6").then(t)}},{path:"/id/tutorials_examples/terminology/index.html",redirect:"/id/tutorials_examples/terminology/"},{path:"/id/tutorials_examples/terminology.html",redirect:"/id/tutorials_examples/terminology/"},{name:"v-2680104d",path:"/install/install/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2680104d").then(t)}},{path:"/install/install/index.html",redirect:"/install/install/"},{path:"/install/install.html",redirect:"/install/install/"},{name:"v-188a7204",path:"/it/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-188a7204").then(t)}},{path:"/it/index.html",redirect:"/it/"},{name:"v-1466252d",path:"/it/create/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1466252d").then(t)}},{path:"/it/create/graphql/index.html",redirect:"/it/create/graphql/"},{path:"/it/create/graphql.html",redirect:"/it/create/graphql/"},{name:"v-73c98272",path:"/it/create/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-73c98272").then(t)}},{path:"/it/create/introduction/index.html",redirect:"/it/create/introduction/"},{path:"/it/create/introduction.html",redirect:"/it/create/introduction/"},{name:"v-1553fc1d",path:"/it/create/manifest/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1553fc1d").then(t)}},{path:"/it/create/manifest/index.html",redirect:"/it/create/manifest/"},{path:"/it/create/manifest.html",redirect:"/it/create/manifest/"},{name:"v-6bcd2fe6",path:"/it/create/mapping/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6bcd2fe6").then(t)}},{path:"/it/create/mapping/index.html",redirect:"/it/create/mapping/"},{path:"/it/create/mapping.html",redirect:"/it/create/mapping/"},{name:"v-784c5b83",path:"/it/faqs/faqs/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-784c5b83").then(t)}},{path:"/it/faqs/faqs/index.html",redirect:"/it/faqs/faqs/"},{path:"/it/faqs/faqs.html",redirect:"/it/faqs/faqs/"},{name:"v-0bd47593",path:"/it/install/install/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0bd47593").then(t)}},{path:"/it/install/install/index.html",redirect:"/it/install/install/"},{path:"/it/install/install.html",redirect:"/it/install/install/"},{name:"v-a8374142",path:"/it/miscellaneous/ambassadors/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-a8374142").then(t)}},{path:"/it/miscellaneous/ambassadors/index.html",redirect:"/it/miscellaneous/ambassadors/"},{path:"/it/miscellaneous/ambassadors.html",redirect:"/it/miscellaneous/ambassadors/"},{name:"v-2a342b6d",path:"/it/miscellaneous/branding/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2a342b6d").then(t)}},{path:"/it/miscellaneous/branding/index.html",redirect:"/it/miscellaneous/branding/"},{path:"/it/miscellaneous/branding.html",redirect:"/it/miscellaneous/branding/"},{name:"v-36e11e8d",path:"/it/miscellaneous/contributing/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-36e11e8d").then(t)}},{path:"/it/miscellaneous/contributing/index.html",redirect:"/it/miscellaneous/contributing/"},{path:"/it/miscellaneous/contributing.html",redirect:"/it/miscellaneous/contributing/"},{name:"v-0b86ffc3",path:"/it/publish/publish/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0b86ffc3").then(t)}},{path:"/it/publish/publish/index.html",redirect:"/it/publish/publish/"},{path:"/it/publish/publish.html",redirect:"/it/publish/publish/"},{name:"v-6b9934ae",path:"/it/publish/upgrade/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6b9934ae").then(t)}},{path:"/it/publish/upgrade/index.html",redirect:"/it/publish/upgrade/"},{path:"/it/publish/upgrade.html",redirect:"/it/publish/upgrade/"},{name:"v-a188fcc6",path:"/it/query/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-a188fcc6").then(t)}},{path:"/it/query/graphql/index.html",redirect:"/it/query/graphql/"},{path:"/it/query/graphql.html",redirect:"/it/query/graphql/"},{name:"v-296dfe42",path:"/it/query/query/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-296dfe42").then(t)}},{path:"/it/query/query/index.html",redirect:"/it/query/query/"},{path:"/it/query/query.html",redirect:"/it/query/query/"},{name:"v-f39834a6",path:"/it/quickstart/helloworld-hosted/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-f39834a6").then(t)}},{path:"/it/quickstart/helloworld-hosted/index.html",redirect:"/it/quickstart/helloworld-hosted/"},{path:"/it/quickstart/helloworld-hosted.html",redirect:"/it/quickstart/helloworld-hosted/"},{name:"v-0ca4553e",path:"/it/quickstart/helloworld-localhost/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0ca4553e").then(t)}},{path:"/it/quickstart/helloworld-localhost/index.html",redirect:"/it/quickstart/helloworld-localhost/"},{path:"/it/quickstart/helloworld-localhost.html",redirect:"/it/quickstart/helloworld-localhost/"},{name:"v-475b7a03",path:"/it/quickstart/quickstart/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-475b7a03").then(t)}},{path:"/it/quickstart/quickstart/index.html",redirect:"/it/quickstart/quickstart/"},{path:"/it/quickstart/quickstart.html",redirect:"/it/quickstart/quickstart/"},{name:"v-2fc0fb5b",path:"/it/quickstart/understanding-helloworld/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2fc0fb5b").then(t)}},{path:"/it/quickstart/understanding-helloworld/index.html",redirect:"/it/quickstart/understanding-helloworld/"},{path:"/it/quickstart/understanding-helloworld.html",redirect:"/it/quickstart/understanding-helloworld/"},{name:"v-ec5d765a",path:"/it/run/run/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-ec5d765a").then(t)}},{path:"/it/run/run/index.html",redirect:"/it/run/run/"},{path:"/it/run/run.html",redirect:"/it/run/run/"},{name:"v-16eb1adb",path:"/it/run/sandbox/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-16eb1adb").then(t)}},{path:"/it/run/sandbox/index.html",redirect:"/it/run/sandbox/"},{path:"/it/run/sandbox.html",redirect:"/it/run/sandbox/"},{name:"v-1098b9c1",path:"/it/tutorials_examples/batch-size/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1098b9c1").then(t)}},{path:"/it/tutorials_examples/batch-size/index.html",redirect:"/it/tutorials_examples/batch-size/"},{path:"/it/tutorials_examples/batch-size.html",redirect:"/it/tutorials_examples/batch-size/"},{name:"v-3296464a",path:"/it/tutorials_examples/block-height/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-3296464a").then(t)}},{path:"/it/tutorials_examples/block-height/index.html",redirect:"/it/tutorials_examples/block-height/"},{path:"/it/tutorials_examples/block-height.html",redirect:"/it/tutorials_examples/block-height/"},{name:"v-49346ac1",path:"/it/tutorials_examples/debug-projects/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-49346ac1").then(t)}},{path:"/it/tutorials_examples/debug-projects/index.html",redirect:"/it/tutorials_examples/debug-projects/"},{path:"/it/tutorials_examples/debug-projects.html",redirect:"/it/tutorials_examples/debug-projects/"},{name:"v-27de0d06",path:"/it/tutorials_examples/dictionary/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-27de0d06").then(t)}},{path:"/it/tutorials_examples/dictionary/index.html",redirect:"/it/tutorials_examples/dictionary/"},{path:"/it/tutorials_examples/dictionary.html",redirect:"/it/tutorials_examples/dictionary/"},{name:"v-2b97a116",path:"/it/tutorials_examples/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2b97a116").then(t)}},{path:"/it/tutorials_examples/introduction/index.html",redirect:"/it/tutorials_examples/introduction/"},{path:"/it/tutorials_examples/introduction.html",redirect:"/it/tutorials_examples/introduction/"},{name:"v-0f11ce4d",path:"/it/tutorials_examples/howto/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0f11ce4d").then(t)}},{path:"/it/tutorials_examples/howto/index.html",redirect:"/it/tutorials_examples/howto/"},{path:"/it/tutorials_examples/howto.html",redirect:"/it/tutorials_examples/howto/"},{name:"v-05571e4d",path:"/it/tutorials_examples/run-indexer/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-05571e4d").then(t)}},{path:"/it/tutorials_examples/run-indexer/index.html",redirect:"/it/tutorials_examples/run-indexer/"},{path:"/it/tutorials_examples/run-indexer.html",redirect:"/it/tutorials_examples/run-indexer/"},{name:"v-444c16e6",path:"/it/tutorials_examples/terminology/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-444c16e6").then(t)}},{path:"/it/tutorials_examples/terminology/index.html",redirect:"/it/tutorials_examples/terminology/"},{path:"/it/tutorials_examples/terminology.html",redirect:"/it/tutorials_examples/terminology/"},{name:"v-2a03c37e",path:"/ja/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2a03c37e").then(t)}},{path:"/ja/index.html",redirect:"/ja/"},{name:"v-045024ad",path:"/ja/create/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-045024ad").then(t)}},{path:"/ja/create/graphql/index.html",redirect:"/ja/create/graphql/"},{path:"/ja/create/graphql.html",redirect:"/ja/create/graphql/"},{name:"v-027260af",path:"/ja/create/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-027260af").then(t)}},{path:"/ja/create/introduction/index.html",redirect:"/ja/create/introduction/"},{path:"/ja/create/introduction.html",redirect:"/ja/create/introduction/"},{name:"v-f2a4a7f6",path:"/ja/create/manifest/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-f2a4a7f6").then(t)}},{path:"/ja/create/manifest/index.html",redirect:"/ja/create/manifest/"},{path:"/ja/create/manifest.html",redirect:"/ja/create/manifest/"},{name:"v-8bf930e6",path:"/ja/create/mapping/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-8bf930e6").then(t)}},{path:"/ja/create/mapping/index.html",redirect:"/ja/create/mapping/"},{path:"/ja/create/mapping.html",redirect:"/ja/create/mapping/"},{name:"v-6d65c06b",path:"/ja/faqs/faqs/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6d65c06b").then(t)}},{path:"/ja/faqs/faqs/index.html",redirect:"/ja/faqs/faqs/"},{path:"/ja/faqs/faqs.html",redirect:"/ja/faqs/faqs/"},{name:"v-7d2e257b",path:"/ja/install/install/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7d2e257b").then(t)}},{path:"/ja/install/install/index.html",redirect:"/ja/install/install/"},{path:"/ja/install/install.html",redirect:"/ja/install/install/"},{name:"v-0a98e772",path:"/ja/miscellaneous/ambassadors/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0a98e772").then(t)}},{path:"/ja/miscellaneous/ambassadors/index.html",redirect:"/ja/miscellaneous/ambassadors/"},{path:"/ja/miscellaneous/ambassadors.html",redirect:"/ja/miscellaneous/ambassadors/"},{name:"v-95e01226",path:"/ja/miscellaneous/branding/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-95e01226").then(t)}},{path:"/ja/miscellaneous/branding/index.html",redirect:"/ja/miscellaneous/branding/"},{path:"/ja/miscellaneous/branding.html",redirect:"/ja/miscellaneous/branding/"},{name:"v-1738500d",path:"/ja/miscellaneous/contributing/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1738500d").then(t)}},{path:"/ja/miscellaneous/contributing/index.html",redirect:"/ja/miscellaneous/contributing/"},{path:"/ja/miscellaneous/contributing.html",redirect:"/ja/miscellaneous/contributing/"},{name:"v-a57e89e6",path:"/ja/miscellaneous/social_media/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-a57e89e6").then(t)}},{path:"/ja/miscellaneous/social_media/index.html",redirect:"/ja/miscellaneous/social_media/"},{path:"/ja/miscellaneous/social_media.html",redirect:"/ja/miscellaneous/social_media/"},{name:"v-e2e0d016",path:"/ja/publish/connect/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-e2e0d016").then(t)}},{path:"/ja/publish/connect/index.html",redirect:"/ja/publish/connect/"},{path:"/ja/publish/connect.html",redirect:"/ja/publish/connect/"},{name:"v-7ce0afab",path:"/ja/publish/publish/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7ce0afab").then(t)}},{path:"/ja/publish/publish/index.html",redirect:"/ja/publish/publish/"},{path:"/ja/publish/publish.html",redirect:"/ja/publish/publish/"},{name:"v-3b8d1591",path:"/ja/publish/upgrade/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-3b8d1591").then(t)}},{path:"/ja/publish/upgrade/index.html",redirect:"/ja/publish/upgrade/"},{path:"/ja/publish/upgrade.html",redirect:"/ja/publish/upgrade/"},{name:"v-bf8e4ef6",path:"/ja/query/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-bf8e4ef6").then(t)}},{path:"/ja/query/graphql/index.html",redirect:"/ja/query/graphql/"},{path:"/ja/query/graphql.html",redirect:"/ja/query/graphql/"},{name:"v-d5d38272",path:"/ja/query/query/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-d5d38272").then(t)}},{path:"/ja/query/query/index.html",redirect:"/ja/query/query/"},{path:"/ja/query/query.html",redirect:"/ja/query/query/"},{name:"v-02e16a2d",path:"/ja/quickstart/helloworld-hosted/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-02e16a2d").then(t)}},{path:"/ja/quickstart/helloworld-hosted/index.html",redirect:"/ja/quickstart/helloworld-hosted/"},{path:"/ja/quickstart/helloworld-hosted.html",redirect:"/ja/quickstart/helloworld-hosted/"},{name:"v-bab9656e",path:"/ja/quickstart/helloworld-localhost/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-bab9656e").then(t)}},{path:"/ja/quickstart/helloworld-localhost/index.html",redirect:"/ja/quickstart/helloworld-localhost/"},{path:"/ja/quickstart/helloworld-localhost.html",redirect:"/ja/quickstart/helloworld-localhost/"},{name:"v-c098962a",path:"/ja/quickstart/quickstart/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-c098962a").then(t)}},{path:"/ja/quickstart/quickstart/index.html",redirect:"/ja/quickstart/quickstart/"},{path:"/ja/quickstart/quickstart.html",redirect:"/ja/quickstart/quickstart/"},{name:"v-2f10357a",path:"/ja/quickstart/understanding-helloworld/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2f10357a").then(t)}},{path:"/ja/quickstart/understanding-helloworld/index.html",redirect:"/ja/quickstart/understanding-helloworld/"},{path:"/ja/quickstart/understanding-helloworld.html",redirect:"/ja/quickstart/understanding-helloworld/"},{name:"v-6a0310bb",path:"/ja/run/run/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6a0310bb").then(t)}},{path:"/ja/run/run/index.html",redirect:"/ja/run/run/"},{path:"/ja/run/run.html",redirect:"/ja/run/run/"},{name:"v-7e8f4e7a",path:"/ja/run/sandbox/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7e8f4e7a").then(t)}},{path:"/ja/run/sandbox/index.html",redirect:"/ja/run/sandbox/"},{path:"/ja/run/sandbox.html",redirect:"/ja/run/sandbox/"},{name:"v-c1e04eae",path:"/ja/tutorials_examples/batch-size/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-c1e04eae").then(t)}},{path:"/ja/tutorials_examples/batch-size/index.html",redirect:"/ja/tutorials_examples/batch-size/"},{path:"/ja/tutorials_examples/batch-size.html",redirect:"/ja/tutorials_examples/batch-size/"},{name:"v-e0ab567a",path:"/ja/tutorials_examples/block-height/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-e0ab567a").then(t)}},{path:"/ja/tutorials_examples/block-height/index.html",redirect:"/ja/tutorials_examples/block-height/"},{path:"/ja/tutorials_examples/block-height.html",redirect:"/ja/tutorials_examples/block-height/"},{name:"v-73f708ae",path:"/ja/tutorials_examples/debug-projects/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-73f708ae").then(t)}},{path:"/ja/tutorials_examples/debug-projects/index.html",redirect:"/ja/tutorials_examples/debug-projects/"},{path:"/ja/tutorials_examples/debug-projects.html",redirect:"/ja/tutorials_examples/debug-projects/"},{name:"v-7a881865",path:"/ja/tutorials_examples/dictionary/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7a881865").then(t)}},{path:"/ja/tutorials_examples/dictionary/index.html",redirect:"/ja/tutorials_examples/dictionary/"},{path:"/ja/tutorials_examples/dictionary.html",redirect:"/ja/tutorials_examples/dictionary/"},{name:"v-062f2666",path:"/ja/tutorials_examples/howto/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-062f2666").then(t)}},{path:"/ja/tutorials_examples/howto/index.html",redirect:"/ja/tutorials_examples/howto/"},{path:"/ja/tutorials_examples/howto.html",redirect:"/ja/tutorials_examples/howto/"},{name:"v-d9acb146",path:"/ja/tutorials_examples/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-d9acb146").then(t)}},{path:"/ja/tutorials_examples/introduction/index.html",redirect:"/ja/tutorials_examples/introduction/"},{path:"/ja/tutorials_examples/introduction.html",redirect:"/ja/tutorials_examples/introduction/"},{name:"v-2e80b5cd",path:"/ja/tutorials_examples/run-indexer/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2e80b5cd").then(t)}},{path:"/ja/tutorials_examples/run-indexer/index.html",redirect:"/ja/tutorials_examples/run-indexer/"},{path:"/ja/tutorials_examples/run-indexer.html",redirect:"/ja/tutorials_examples/run-indexer/"},{name:"v-07038c0d",path:"/ja/tutorials_examples/terminology/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-07038c0d").then(t)}},{path:"/ja/tutorials_examples/terminology/index.html",redirect:"/ja/tutorials_examples/terminology/"},{path:"/ja/tutorials_examples/terminology.html",redirect:"/ja/tutorials_examples/terminology/"},{name:"v-14d51344",path:"/ko/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-14d51344").then(t)}},{path:"/ko/index.html",redirect:"/ko/"},{name:"v-f004ba66",path:"/ko/create/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-f004ba66").then(t)}},{path:"/ko/create/graphql/index.html",redirect:"/ko/create/graphql/"},{path:"/ko/create/graphql.html",redirect:"/ko/create/graphql/"},{name:"v-64b91fd5",path:"/ko/create/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-64b91fd5").then(t)}},{path:"/ko/create/introduction/index.html",redirect:"/ko/create/introduction/"},{path:"/ko/create/introduction.html",redirect:"/ko/create/introduction/"},{name:"v-6fbdffab",path:"/ko/create/manifest/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6fbdffab").then(t)}},{path:"/ko/create/manifest/index.html",redirect:"/ko/create/manifest/"},{path:"/ko/create/manifest.html",redirect:"/ko/create/manifest/"},{name:"v-3db0e5ad",path:"/ko/create/mapping/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-3db0e5ad").then(t)}},{path:"/ko/create/mapping/index.html",redirect:"/ko/create/mapping/"},{path:"/ko/create/mapping.html",redirect:"/ko/create/mapping/"},{name:"v-0484fad1",path:"/ko/faqs/faqs/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0484fad1").then(t)}},{path:"/ko/faqs/faqs/index.html",redirect:"/ko/faqs/faqs/"},{path:"/ko/faqs/faqs.html",redirect:"/ko/faqs/faqs/"},{name:"v-663e7921",path:"/ko/install/install/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-663e7921").then(t)}},{path:"/ko/install/install/index.html",redirect:"/ko/install/install/"},{path:"/ko/install/install.html",redirect:"/ko/install/install/"},{name:"v-223c74ad",path:"/ko/miscellaneous/ambassadors/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-223c74ad").then(t)}},{path:"/ko/miscellaneous/ambassadors/index.html",redirect:"/ko/miscellaneous/ambassadors/"},{path:"/ko/miscellaneous/ambassadors.html",redirect:"/ko/miscellaneous/ambassadors/"},{name:"v-846f9be6",path:"/ko/miscellaneous/branding/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-846f9be6").then(t)}},{path:"/ko/miscellaneous/branding/index.html",redirect:"/ko/miscellaneous/branding/"},{path:"/ko/miscellaneous/branding.html",redirect:"/ko/miscellaneous/branding/"},{name:"v-3f016ca6",path:"/ko/miscellaneous/contributing/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-3f016ca6").then(t)}},{path:"/ko/miscellaneous/contributing/index.html",redirect:"/ko/miscellaneous/contributing/"},{path:"/ko/miscellaneous/contributing.html",redirect:"/ko/miscellaneous/contributing/"},{name:"v-7687b4ad",path:"/ko/miscellaneous/social_media/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7687b4ad").then(t)}},{path:"/ko/miscellaneous/social_media/index.html",redirect:"/ko/miscellaneous/social_media/"},{path:"/ko/miscellaneous/social_media.html",redirect:"/ko/miscellaneous/social_media/"},{name:"v-65f10351",path:"/ko/publish/publish/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-65f10351").then(t)}},{path:"/ko/publish/publish/index.html",redirect:"/ko/publish/publish/"},{path:"/ko/publish/publish.html",redirect:"/ko/publish/publish/"},{name:"v-779feb9b",path:"/ko/publish/connect/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-779feb9b").then(t)}},{path:"/ko/publish/connect/index.html",redirect:"/ko/publish/connect/"},{path:"/ko/publish/connect.html",redirect:"/ko/publish/connect/"},{name:"v-249d6937",path:"/ko/publish/upgrade/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-249d6937").then(t)}},{path:"/ko/publish/upgrade/index.html",redirect:"/ko/publish/upgrade/"},{path:"/ko/publish/upgrade.html",redirect:"/ko/publish/upgrade/"},{name:"v-b022432a",path:"/ko/query/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-b022432a").then(t)}},{path:"/ko/query/graphql/index.html",redirect:"/ko/query/graphql/"},{path:"/ko/query/graphql.html",redirect:"/ko/query/graphql/"},{name:"v-dc503226",path:"/ko/query/query/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-dc503226").then(t)}},{path:"/ko/query/query/index.html",redirect:"/ko/query/query/"},{path:"/ko/query/query.html",redirect:"/ko/query/query/"},{name:"v-166c1b0d",path:"/ko/quickstart/helloworld-hosted/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-166c1b0d").then(t)}},{path:"/ko/quickstart/helloworld-hosted/index.html",redirect:"/ko/quickstart/helloworld-hosted/"},{path:"/ko/quickstart/helloworld-hosted.html",redirect:"/ko/quickstart/helloworld-hosted/"},{name:"v-5c3bceef",path:"/ko/quickstart/helloworld-localhost/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5c3bceef").then(t)}},{path:"/ko/quickstart/helloworld-localhost/index.html",redirect:"/ko/quickstart/helloworld-localhost/"},{path:"/ko/quickstart/helloworld-localhost.html",redirect:"/ko/quickstart/helloworld-localhost/"},{name:"v-2afe91d1",path:"/ko/quickstart/quickstart/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2afe91d1").then(t)}},{path:"/ko/quickstart/quickstart/index.html",redirect:"/ko/quickstart/quickstart/"},{path:"/ko/quickstart/quickstart.html",redirect:"/ko/quickstart/quickstart/"},{name:"v-45b45b2e",path:"/ko/quickstart/understanding-helloworld/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-45b45b2e").then(t)}},{path:"/ko/quickstart/understanding-helloworld/index.html",redirect:"/ko/quickstart/understanding-helloworld/"},{path:"/ko/quickstart/understanding-helloworld.html",redirect:"/ko/quickstart/understanding-helloworld/"},{name:"v-72bdcd61",path:"/ko/run/run/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-72bdcd61").then(t)}},{path:"/ko/run/run/index.html",redirect:"/ko/run/run/"},{path:"/ko/run/run.html",redirect:"/ko/run/run/"},{name:"v-850bfe2e",path:"/ko/run/sandbox/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-850bfe2e").then(t)}},{path:"/ko/run/sandbox/index.html",redirect:"/ko/run/sandbox/"},{path:"/ko/run/sandbox.html",redirect:"/ko/run/sandbox/"},{name:"v-1562e6e2",path:"/ko/tutorials_examples/batch-size/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1562e6e2").then(t)}},{path:"/ko/tutorials_examples/batch-size/index.html",redirect:"/ko/tutorials_examples/batch-size/"},{path:"/ko/tutorials_examples/batch-size.html",redirect:"/ko/tutorials_examples/batch-size/"},{name:"v-4942d669",path:"/ko/tutorials_examples/block-height/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-4942d669").then(t)}},{path:"/ko/tutorials_examples/block-height/index.html",redirect:"/ko/tutorials_examples/block-height/"},{path:"/ko/tutorials_examples/block-height.html",redirect:"/ko/tutorials_examples/block-height/"},{name:"v-1a10bb0f",path:"/ko/tutorials_examples/debug-projects/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1a10bb0f").then(t)}},{path:"/ko/tutorials_examples/debug-projects/index.html",redirect:"/ko/tutorials_examples/debug-projects/"},{path:"/ko/tutorials_examples/debug-projects.html",redirect:"/ko/tutorials_examples/debug-projects/"},{name:"v-5e72676a",path:"/ko/tutorials_examples/dictionary/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5e72676a").then(t)}},{path:"/ko/tutorials_examples/dictionary/index.html",redirect:"/ko/tutorials_examples/dictionary/"},{path:"/ko/tutorials_examples/dictionary.html",redirect:"/ko/tutorials_examples/dictionary/"},{name:"v-8e6581a6",path:"/ko/tutorials_examples/howto/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-8e6581a6").then(t)}},{path:"/ko/tutorials_examples/howto/index.html",redirect:"/ko/tutorials_examples/howto/"},{path:"/ko/tutorials_examples/howto.html",redirect:"/ko/tutorials_examples/howto/"},{name:"v-4cc22903",path:"/ko/tutorials_examples/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-4cc22903").then(t)}},{path:"/ko/tutorials_examples/introduction/index.html",redirect:"/ko/tutorials_examples/introduction/"},{path:"/ko/tutorials_examples/introduction.html",redirect:"/ko/tutorials_examples/introduction/"},{name:"v-48dcaded",path:"/ko/tutorials_examples/run-indexer/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-48dcaded").then(t)}},{path:"/ko/tutorials_examples/run-indexer/index.html",redirect:"/ko/tutorials_examples/run-indexer/"},{path:"/ko/tutorials_examples/run-indexer.html",redirect:"/ko/tutorials_examples/run-indexer/"},{name:"v-215f842d",path:"/ko/tutorials_examples/terminology/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-215f842d").then(t)}},{path:"/ko/tutorials_examples/terminology/index.html",redirect:"/ko/tutorials_examples/terminology/"},{path:"/ko/tutorials_examples/terminology.html",redirect:"/ko/tutorials_examples/terminology/"},{name:"v-ae40a866",path:"/miscellaneous/ambassadors/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-ae40a866").then(t)}},{path:"/miscellaneous/ambassadors/index.html",redirect:"/miscellaneous/ambassadors/"},{path:"/miscellaneous/ambassadors.html",redirect:"/miscellaneous/ambassadors/"},{name:"v-a45391be",path:"/miscellaneous/branding/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-a45391be").then(t)}},{path:"/miscellaneous/branding/index.html",redirect:"/miscellaneous/branding/"},{path:"/miscellaneous/branding.html",redirect:"/miscellaneous/branding/"},{name:"v-6d299e43",path:"/miscellaneous/contributing/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6d299e43").then(t)}},{path:"/miscellaneous/contributing/index.html",redirect:"/miscellaneous/contributing/"},{path:"/miscellaneous/contributing.html",redirect:"/miscellaneous/contributing/"},{name:"v-034044f3",path:"/miscellaneous/social_media/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-034044f3").then(t)}},{path:"/miscellaneous/social_media/index.html",redirect:"/miscellaneous/social_media/"},{path:"/miscellaneous/social_media.html",redirect:"/miscellaneous/social_media/"},{name:"v-b6710da6",path:"/publish/connect/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-b6710da6").then(t)}},{path:"/publish/connect/index.html",redirect:"/publish/connect/"},{path:"/publish/connect.html",redirect:"/publish/connect/"},{name:"v-529f2d66",path:"/publish/publish/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-529f2d66").then(t)}},{path:"/publish/publish/index.html",redirect:"/publish/publish/"},{path:"/publish/publish.html",redirect:"/publish/publish/"},{name:"v-5be2726d",path:"/publish/upgrade/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5be2726d").then(t)}},{path:"/publish/upgrade/index.html",redirect:"/publish/upgrade/"},{path:"/publish/upgrade.html",redirect:"/publish/upgrade/"},{name:"v-31c257a6",path:"/query/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-31c257a6").then(t)}},{path:"/query/graphql/index.html",redirect:"/query/graphql/"},{path:"/query/graphql.html",redirect:"/query/graphql/"},{name:"v-ecedcbe6",path:"/query/query/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-ecedcbe6").then(t)}},{path:"/query/query/index.html",redirect:"/query/query/"},{path:"/query/query.html",redirect:"/query/query/"},{name:"v-562bf2a5",path:"/quickstart/helloworld-hosted/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-562bf2a5").then(t)}},{path:"/quickstart/helloworld-hosted/index.html",redirect:"/quickstart/helloworld-hosted/"},{path:"/quickstart/helloworld-hosted.html",redirect:"/quickstart/helloworld-hosted/"},{name:"v-bc9cfe26",path:"/quickstart/helloworld-localhost/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-bc9cfe26").then(t)}},{path:"/quickstart/helloworld-localhost/index.html",redirect:"/quickstart/helloworld-localhost/"},{path:"/quickstart/helloworld-localhost.html",redirect:"/quickstart/helloworld-localhost/"},{name:"v-867568e6",path:"/quickstart/quickstart/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-867568e6").then(t)}},{path:"/quickstart/quickstart/index.html",redirect:"/quickstart/quickstart/"},{path:"/quickstart/quickstart.html",redirect:"/quickstart/quickstart/"},{name:"v-d4874966",path:"/quickstart/understanding-helloworld/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-d4874966").then(t)}},{path:"/quickstart/understanding-helloworld/index.html",redirect:"/quickstart/understanding-helloworld/"},{path:"/quickstart/understanding-helloworld.html",redirect:"/quickstart/understanding-helloworld/"},{name:"v-b4ffb0e6",path:"/references/references/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-b4ffb0e6").then(t)}},{path:"/references/references/index.html",redirect:"/references/references/"},{path:"/references/references.html",redirect:"/references/references/"},{name:"v-3bb71ffe",path:"/ru/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-3bb71ffe").then(t)}},{path:"/ru/index.html",redirect:"/ru/"},{name:"v-1b3677a6",path:"/ru/create/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1b3677a6").then(t)}},{path:"/ru/create/graphql/index.html",redirect:"/ru/create/graphql/"},{path:"/ru/create/graphql.html",redirect:"/ru/create/graphql/"},{name:"v-1e91fed2",path:"/ru/create/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1e91fed2").then(t)}},{path:"/ru/create/introduction/index.html",redirect:"/ru/create/introduction/"},{path:"/ru/create/introduction.html",redirect:"/ru/create/introduction/"},{name:"v-6a2b59ed",path:"/ru/create/manifest/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6a2b59ed").then(t)}},{path:"/ru/create/manifest/index.html",redirect:"/ru/create/manifest/"},{path:"/ru/create/manifest.html",redirect:"/ru/create/manifest/"},{name:"v-afcff1e6",path:"/ru/create/mapping/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-afcff1e6").then(t)}},{path:"/ru/create/mapping/index.html",redirect:"/ru/create/mapping/"},{path:"/ru/create/mapping.html",redirect:"/ru/create/mapping/"},{name:"v-249ce353",path:"/ru/faqs/faqs/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-249ce353").then(t)}},{path:"/ru/faqs/faqs/index.html",redirect:"/ru/faqs/faqs/"},{path:"/ru/faqs/faqs.html",redirect:"/ru/faqs/faqs/"},{name:"v-60abd363",path:"/ru/install/install/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-60abd363").then(t)}},{path:"/ru/install/install/index.html",redirect:"/ru/install/install/"},{path:"/ru/install/install.html",redirect:"/ru/install/install/"},{name:"v-4a7311a2",path:"/ru/miscellaneous/ambassadors/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-4a7311a2").then(t)}},{path:"/ru/miscellaneous/ambassadors/index.html",redirect:"/ru/miscellaneous/ambassadors/"},{path:"/ru/miscellaneous/ambassadors.html",redirect:"/ru/miscellaneous/ambassadors/"},{name:"v-7ce7626d",path:"/ru/miscellaneous/branding/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7ce7626d").then(t)}},{path:"/ru/miscellaneous/branding/index.html",redirect:"/ru/miscellaneous/branding/"},{path:"/ru/miscellaneous/branding.html",redirect:"/ru/miscellaneous/branding/"},{name:"v-0258bce6",path:"/ru/miscellaneous/contributing/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0258bce6").then(t)}},{path:"/ru/miscellaneous/contributing/index.html",redirect:"/ru/miscellaneous/contributing/"},{path:"/ru/miscellaneous/contributing.html",redirect:"/ru/miscellaneous/contributing/"},{name:"v-d647e6e6",path:"/ru/miscellaneous/social_media/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-d647e6e6").then(t)}},{path:"/ru/miscellaneous/social_media/index.html",redirect:"/ru/miscellaneous/social_media/"},{path:"/ru/miscellaneous/social_media.html",redirect:"/ru/miscellaneous/social_media/"},{name:"v-720d45dd",path:"/ru/publish/connect/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-720d45dd").then(t)}},{path:"/ru/publish/connect/index.html",redirect:"/ru/publish/connect/"},{path:"/ru/publish/connect.html",redirect:"/ru/publish/connect/"},{name:"v-1f0ac379",path:"/ru/publish/upgrade/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1f0ac379").then(t)}},{path:"/ru/publish/upgrade/index.html",redirect:"/ru/publish/upgrade/"},{path:"/ru/publish/upgrade.html",redirect:"/ru/publish/upgrade/"},{name:"v-605e5d93",path:"/ru/publish/publish/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-605e5d93").then(t)}},{path:"/ru/publish/publish/index.html",redirect:"/ru/publish/publish/"},{path:"/ru/publish/publish.html",redirect:"/ru/publish/publish/"},{name:"v-50fd6d6d",path:"/ru/query/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-50fd6d6d").then(t)}},{path:"/ru/query/graphql/index.html",redirect:"/ru/query/graphql/"},{path:"/ru/query/graphql.html",redirect:"/ru/query/graphql/"},{name:"v-0ffdfaaf",path:"/ru/query/query/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0ffdfaaf").then(t)}},{path:"/ru/query/query/index.html",redirect:"/ru/query/query/"},{path:"/ru/query/query.html",redirect:"/ru/query/query/"},{name:"v-38af4ead",path:"/ru/quickstart/helloworld-hosted/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-38af4ead").then(t)}},{path:"/ru/quickstart/helloworld-hosted/index.html",redirect:"/ru/quickstart/helloworld-hosted/"},{path:"/ru/quickstart/helloworld-hosted.html",redirect:"/ru/quickstart/helloworld-hosted/"},{name:"v-953a799e",path:"/ru/quickstart/helloworld-localhost/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-953a799e").then(t)}},{path:"/ru/quickstart/helloworld-localhost/index.html",redirect:"/ru/quickstart/helloworld-localhost/"},{path:"/ru/quickstart/helloworld-localhost.html",redirect:"/ru/quickstart/helloworld-localhost/"},{name:"v-0133a45a",path:"/ru/quickstart/quickstart/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0133a45a").then(t)}},{path:"/ru/quickstart/quickstart/index.html",redirect:"/ru/quickstart/quickstart/"},{path:"/ru/quickstart/quickstart.html",redirect:"/ru/quickstart/quickstart/"},{name:"v-05c24d2b",path:"/ru/quickstart/understanding-helloworld/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-05c24d2b").then(t)}},{path:"/ru/quickstart/understanding-helloworld/index.html",redirect:"/ru/quickstart/understanding-helloworld/"},{path:"/ru/quickstart/understanding-helloworld.html",redirect:"/ru/quickstart/understanding-helloworld/"},{name:"v-0df44aba",path:"/ru/run/run/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0df44aba").then(t)}},{path:"/ru/run/run/index.html",redirect:"/ru/run/run/"},{path:"/ru/run/run.html",redirect:"/ru/run/run/"},{name:"v-3ba014ab",path:"/ru/run/sandbox/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-3ba014ab").then(t)}},{path:"/ru/run/sandbox/index.html",redirect:"/ru/run/sandbox/"},{path:"/ru/run/sandbox.html",redirect:"/ru/run/sandbox/"},{name:"v-911794de",path:"/ru/tutorials_examples/batch-size/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-911794de").then(t)}},{path:"/ru/tutorials_examples/batch-size/index.html",redirect:"/ru/tutorials_examples/batch-size/"},{path:"/ru/tutorials_examples/batch-size.html",redirect:"/ru/tutorials_examples/batch-size/"},{name:"v-bb2c6aaa",path:"/ru/tutorials_examples/block-height/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-bb2c6aaa").then(t)}},{path:"/ru/tutorials_examples/block-height/index.html",redirect:"/ru/tutorials_examples/block-height/"},{path:"/ru/tutorials_examples/block-height.html",redirect:"/ru/tutorials_examples/block-height/"},{name:"v-542b4a91",path:"/ru/tutorials_examples/debug-projects/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-542b4a91").then(t)}},{path:"/ru/tutorials_examples/debug-projects/index.html",redirect:"/ru/tutorials_examples/debug-projects/"},{path:"/ru/tutorials_examples/debug-projects.html",redirect:"/ru/tutorials_examples/debug-projects/"},{name:"v-da271566",path:"/ru/tutorials_examples/dictionary/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-da271566").then(t)}},{path:"/ru/tutorials_examples/dictionary/index.html",redirect:"/ru/tutorials_examples/dictionary/"},{path:"/ru/tutorials_examples/dictionary.html",redirect:"/ru/tutorials_examples/dictionary/"},{name:"v-11f6eb4d",path:"/ru/tutorials_examples/howto/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-11f6eb4d").then(t)}},{path:"/ru/tutorials_examples/howto/index.html",redirect:"/ru/tutorials_examples/howto/"},{path:"/ru/tutorials_examples/howto.html",redirect:"/ru/tutorials_examples/howto/"},{name:"v-b42dc576",path:"/ru/tutorials_examples/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-b42dc576").then(t)}},{path:"/ru/tutorials_examples/introduction/index.html",redirect:"/ru/tutorials_examples/introduction/"},{path:"/ru/tutorials_examples/introduction.html",redirect:"/ru/tutorials_examples/introduction/"},{name:"v-7076ed4d",path:"/ru/tutorials_examples/run-indexer/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7076ed4d").then(t)}},{path:"/ru/tutorials_examples/run-indexer/index.html",redirect:"/ru/tutorials_examples/run-indexer/"},{path:"/ru/tutorials_examples/run-indexer.html",redirect:"/ru/tutorials_examples/run-indexer/"},{name:"v-48f9c38d",path:"/ru/tutorials_examples/terminology/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-48f9c38d").then(t)}},{path:"/ru/tutorials_examples/terminology/index.html",redirect:"/ru/tutorials_examples/terminology/"},{path:"/ru/tutorials_examples/terminology.html",redirect:"/ru/tutorials_examples/terminology/"},{name:"v-09dfd14d",path:"/run/run/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-09dfd14d").then(t)}},{path:"/run/run/index.html",redirect:"/run/run/"},{path:"/run/run.html",redirect:"/run/run/"},{name:"v-07cf064d",path:"/run/sandbox/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-07cf064d").then(t)}},{path:"/run/sandbox/index.html",redirect:"/run/sandbox/"},{path:"/run/sandbox.html",redirect:"/run/sandbox/"},{name:"v-6eb67c5e",path:"/th/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6eb67c5e").then(t)}},{path:"/th/index.html",redirect:"/th/"},{name:"v-73ea2666",path:"/th/create/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-73ea2666").then(t)}},{path:"/th/create/graphql/index.html",redirect:"/th/create/graphql/"},{path:"/th/create/graphql.html",redirect:"/th/create/graphql/"},{name:"v-11c575b5",path:"/th/create/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-11c575b5").then(t)}},{path:"/th/create/introduction/index.html",redirect:"/th/create/introduction/"},{path:"/th/create/introduction.html",redirect:"/th/create/introduction/"},{name:"v-662cece6",path:"/it/miscellaneous/social_media/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-662cece6").then(t)}},{path:"/it/miscellaneous/social_media/index.html",redirect:"/it/miscellaneous/social_media/"},{path:"/it/miscellaneous/social_media.html",redirect:"/it/miscellaneous/social_media/"},{name:"v-62c494b1",path:"/th/faqs/faqs/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-62c494b1").then(t)}},{path:"/th/faqs/faqs/index.html",redirect:"/th/faqs/faqs/"},{path:"/th/faqs/faqs.html",redirect:"/th/faqs/faqs/"},{name:"v-6f84b701",path:"/th/install/install/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6f84b701").then(t)}},{path:"/th/install/install/index.html",redirect:"/th/install/install/"},{path:"/th/install/install.html",redirect:"/th/install/install/"},{name:"v-1c946e8d",path:"/th/miscellaneous/ambassadors/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1c946e8d").then(t)}},{path:"/th/miscellaneous/ambassadors/index.html",redirect:"/th/miscellaneous/ambassadors/"},{path:"/th/miscellaneous/ambassadors.html",redirect:"/th/miscellaneous/ambassadors/"},{name:"v-1d35e80d",path:"/it/publish/connect/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1d35e80d").then(t)}},{path:"/it/publish/connect/index.html",redirect:"/it/publish/connect/"},{path:"/it/publish/connect.html",redirect:"/it/publish/connect/"},{name:"v-5e938c0d",path:"/th/miscellaneous/branding/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5e938c0d").then(t)}},{path:"/th/miscellaneous/branding/index.html",redirect:"/th/miscellaneous/branding/"},{path:"/th/miscellaneous/branding.html",redirect:"/th/miscellaneous/branding/"},{name:"v-6837abad",path:"/th/miscellaneous/contributing/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6837abad").then(t)}},{path:"/th/miscellaneous/contributing/index.html",redirect:"/th/miscellaneous/contributing/"},{path:"/th/miscellaneous/contributing.html",redirect:"/th/miscellaneous/contributing/"},{name:"v-037fd2a6",path:"/th/miscellaneous/social_media/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-037fd2a6").then(t)}},{path:"/th/miscellaneous/social_media/index.html",redirect:"/th/miscellaneous/social_media/"},{path:"/th/miscellaneous/social_media.html",redirect:"/th/miscellaneous/social_media/"},{name:"v-fe33ad0a",path:"/th/publish/connect/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-fe33ad0a").then(t)}},{path:"/th/publish/connect/index.html",redirect:"/th/publish/connect/"},{path:"/th/publish/connect.html",redirect:"/th/publish/connect/"},{name:"v-6f374131",path:"/th/publish/publish/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6f374131").then(t)}},{path:"/th/publish/publish/index.html",redirect:"/th/publish/publish/"},{path:"/th/publish/publish.html",redirect:"/th/publish/publish/"},{name:"v-2de3a717",path:"/th/publish/upgrade/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2de3a717").then(t)}},{path:"/th/publish/upgrade/index.html",redirect:"/th/publish/upgrade/"},{path:"/th/publish/upgrade.html",redirect:"/th/publish/upgrade/"},{name:"v-53b2904b",path:"/th/query/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-53b2904b").then(t)}},{path:"/th/query/graphql/index.html",redirect:"/th/query/graphql/"},{path:"/th/query/graphql.html",redirect:"/th/query/graphql/"},{name:"v-1ff7e666",path:"/th/query/query/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1ff7e666").then(t)}},{path:"/th/query/query/index.html",redirect:"/th/query/query/"},{path:"/th/query/query.html",redirect:"/th/query/query/"},{name:"v-69c2fde6",path:"/th/quickstart/helloworld-hosted/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-69c2fde6").then(t)}},{path:"/th/quickstart/helloworld-hosted/index.html",redirect:"/th/quickstart/helloworld-hosted/"},{path:"/th/quickstart/helloworld-hosted.html",redirect:"/th/quickstart/helloworld-hosted/"},{name:"v-06bb2662",path:"/th/quickstart/helloworld-localhost/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-06bb2662").then(t)}},{path:"/th/quickstart/helloworld-localhost/index.html",redirect:"/th/quickstart/helloworld-localhost/"},{path:"/th/quickstart/helloworld-localhost.html",redirect:"/th/quickstart/helloworld-localhost/"},{name:"v-52ce73b1",path:"/th/quickstart/quickstart/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-52ce73b1").then(t)}},{path:"/th/quickstart/quickstart/index.html",redirect:"/th/quickstart/quickstart/"},{path:"/th/quickstart/quickstart.html",redirect:"/th/quickstart/quickstart/"},{name:"v-38028849",path:"/th/quickstart/understanding-helloworld/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-38028849").then(t)}},{path:"/th/quickstart/understanding-helloworld/index.html",redirect:"/th/quickstart/understanding-helloworld/"},{path:"/th/quickstart/understanding-helloworld.html",redirect:"/th/quickstart/understanding-helloworld/"},{name:"v-4c7bdb41",path:"/th/run/run/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-4c7bdb41").then(t)}},{path:"/th/run/run/index.html",redirect:"/th/run/run/"},{path:"/th/run/run.html",redirect:"/th/run/run/"},{name:"v-1ba626c9",path:"/th/run/sandbox/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1ba626c9").then(t)}},{path:"/th/run/sandbox/index.html",redirect:"/th/run/sandbox/"},{path:"/th/run/sandbox.html",redirect:"/th/run/sandbox/"},{name:"v-304ac322",path:"/th/tutorials_examples/batch-size/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-304ac322").then(t)}},{path:"/th/tutorials_examples/batch-size/index.html",redirect:"/th/tutorials_examples/batch-size/"},{path:"/th/tutorials_examples/batch-size.html",redirect:"/th/tutorials_examples/batch-size/"},{name:"v-2cad176e",path:"/th/tutorials_examples/block-height/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2cad176e").then(t)}},{path:"/th/tutorials_examples/block-height/index.html",redirect:"/th/tutorials_examples/block-height/"},{path:"/th/tutorials_examples/block-height.html",redirect:"/th/tutorials_examples/block-height/"},{name:"v-7c7ce4ef",path:"/th/tutorials_examples/debug-projects/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7c7ce4ef").then(t)}},{path:"/th/tutorials_examples/debug-projects/index.html",redirect:"/th/tutorials_examples/debug-projects/"},{path:"/th/tutorials_examples/debug-projects.html",redirect:"/th/tutorials_examples/debug-projects/"},{name:"v-795a43aa",path:"/th/tutorials_examples/dictionary/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-795a43aa").then(t)}},{path:"/th/tutorials_examples/dictionary/index.html",redirect:"/th/tutorials_examples/dictionary/"},{path:"/th/tutorials_examples/dictionary.html",redirect:"/th/tutorials_examples/dictionary/"},{name:"v-25ae723a",path:"/th/tutorials_examples/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-25ae723a").then(t)}},{path:"/th/tutorials_examples/introduction/index.html",redirect:"/th/tutorials_examples/introduction/"},{path:"/th/tutorials_examples/introduction.html",redirect:"/th/tutorials_examples/introduction/"},{name:"v-433617ed",path:"/th/tutorials_examples/run-indexer/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-433617ed").then(t)}},{path:"/th/tutorials_examples/run-indexer/index.html",redirect:"/th/tutorials_examples/run-indexer/"},{path:"/th/tutorials_examples/run-indexer.html",redirect:"/th/tutorials_examples/run-indexer/"},{name:"v-1bb8ee2d",path:"/th/tutorials_examples/terminology/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1bb8ee2d").then(t)}},{path:"/th/tutorials_examples/terminology/index.html",redirect:"/th/tutorials_examples/terminology/"},{path:"/th/tutorials_examples/terminology.html",redirect:"/th/tutorials_examples/terminology/"},{name:"v-1d6eb7c4",path:"/tr/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1d6eb7c4").then(t)}},{path:"/tr/index.html",redirect:"/tr/"},{name:"v-e40ed1e6",path:"/tr/create/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-e40ed1e6").then(t)}},{path:"/tr/create/graphql/index.html",redirect:"/tr/create/graphql/"},{path:"/tr/create/graphql.html",redirect:"/tr/create/graphql/"},{name:"v-228e86be",path:"/tr/create/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-228e86be").then(t)}},{path:"/tr/create/introduction/index.html",redirect:"/tr/create/introduction/"},{path:"/tr/create/introduction.html",redirect:"/tr/create/introduction/"},{name:"v-5779a577",path:"/tr/create/manifest/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5779a577").then(t)}},{path:"/tr/create/manifest/index.html",redirect:"/tr/create/manifest/"},{path:"/tr/create/manifest.html",redirect:"/tr/create/manifest/"},{name:"v-43abd9ed",path:"/tr/create/mapping/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-43abd9ed").then(t)}},{path:"/tr/create/mapping/index.html",redirect:"/tr/create/mapping/"},{path:"/tr/create/mapping.html",redirect:"/tr/create/mapping/"},{name:"v-f74c83c6",path:"/tr/faqs/faqs/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-f74c83c6").then(t)}},{path:"/tr/faqs/faqs/index.html",redirect:"/tr/faqs/faqs/"},{path:"/tr/faqs/faqs.html",redirect:"/tr/faqs/faqs/"},{name:"v-4dfa1eed",path:"/tr/install/install/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-4dfa1eed").then(t)}},{path:"/tr/install/install/index.html",redirect:"/tr/install/install/"},{path:"/tr/install/install.html",redirect:"/tr/install/install/"},{name:"v-5e4113f9",path:"/tr/miscellaneous/ambassadors/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5e4113f9").then(t)}},{path:"/tr/miscellaneous/ambassadors/index.html",redirect:"/tr/miscellaneous/ambassadors/"},{path:"/tr/miscellaneous/ambassadors.html",redirect:"/tr/miscellaneous/ambassadors/"},{name:"v-7cf5604d",path:"/tr/miscellaneous/branding/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7cf5604d").then(t)}},{path:"/tr/miscellaneous/branding/index.html",redirect:"/tr/miscellaneous/branding/"},{path:"/tr/miscellaneous/branding.html",redirect:"/tr/miscellaneous/branding/"},{name:"v-788054ed",path:"/tr/miscellaneous/contributing/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-788054ed").then(t)}},{path:"/tr/miscellaneous/contributing/index.html",redirect:"/tr/miscellaneous/contributing/"},{path:"/tr/miscellaneous/contributing.html",redirect:"/tr/miscellaneous/contributing/"},{name:"v-0e88bfed",path:"/tr/miscellaneous/social_media/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0e88bfed").then(t)}},{path:"/tr/miscellaneous/social_media/index.html",redirect:"/tr/miscellaneous/social_media/"},{path:"/tr/miscellaneous/social_media.html",redirect:"/tr/miscellaneous/social_media/"},{name:"v-5f5b9167",path:"/tr/publish/connect/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5f5b9167").then(t)}},{path:"/tr/publish/connect/index.html",redirect:"/tr/publish/connect/"},{path:"/tr/publish/connect.html",redirect:"/tr/publish/connect/"},{name:"v-4daca91d",path:"/tr/publish/publish/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-4daca91d").then(t)}},{path:"/tr/publish/publish/index.html",redirect:"/tr/publish/publish/"},{path:"/tr/publish/publish.html",redirect:"/tr/publish/publish/"},{name:"v-0c590f03",path:"/tr/publish/upgrade/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0c590f03").then(t)}},{path:"/tr/publish/upgrade/index.html",redirect:"/tr/publish/upgrade/"},{path:"/tr/publish/upgrade.html",redirect:"/tr/publish/upgrade/"},{name:"v-719f4e92",path:"/tr/query/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-719f4e92").then(t)}},{path:"/tr/query/graphql/index.html",redirect:"/tr/query/graphql/"},{path:"/tr/query/graphql.html",redirect:"/tr/query/graphql/"},{name:"v-282f15b9",path:"/tr/query/query/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-282f15b9").then(t)}},{path:"/tr/query/query/index.html",redirect:"/tr/query/query/"},{path:"/tr/query/query.html",redirect:"/tr/query/query/"},{name:"v-0859c4cd",path:"/tr/quickstart/helloworld-hosted/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0859c4cd").then(t)}},{path:"/tr/quickstart/helloworld-hosted/index.html",redirect:"/tr/quickstart/helloworld-hosted/"},{path:"/tr/quickstart/helloworld-hosted.html",redirect:"/tr/quickstart/helloworld-hosted/"},{name:"v-5ec450bb",path:"/tr/quickstart/helloworld-localhost/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5ec450bb").then(t)}},{path:"/tr/quickstart/helloworld-localhost/index.html",redirect:"/tr/quickstart/helloworld-localhost/"},{path:"/tr/quickstart/helloworld-localhost.html",redirect:"/tr/quickstart/helloworld-localhost/"},{name:"v-71d00bc6",path:"/tr/quickstart/quickstart/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-71d00bc6").then(t)}},{path:"/tr/quickstart/quickstart/index.html",redirect:"/tr/quickstart/quickstart/"},{path:"/tr/quickstart/quickstart.html",redirect:"/tr/quickstart/quickstart/"},{name:"v-51f04b35",path:"/tr/quickstart/understanding-helloworld/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-51f04b35").then(t)}},{path:"/tr/quickstart/understanding-helloworld/index.html",redirect:"/tr/quickstart/understanding-helloworld/"},{path:"/tr/quickstart/understanding-helloworld.html",redirect:"/tr/quickstart/understanding-helloworld/"},{name:"v-f15ff5a6",path:"/tr/run/run/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-f15ff5a6").then(t)}},{path:"/tr/run/run/index.html",redirect:"/tr/run/run/"},{path:"/tr/run/run.html",redirect:"/tr/run/run/"},{name:"v-53d12fb5",path:"/tr/run/sandbox/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-53d12fb5").then(t)}},{path:"/tr/run/sandbox/index.html",redirect:"/tr/run/sandbox/"},{path:"/tr/run/sandbox.html",redirect:"/tr/run/sandbox/"},{name:"v-ed843a4a",path:"/tr/tutorials_examples/batch-size/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-ed843a4a").then(t)}},{path:"/tr/tutorials_examples/batch-size/index.html",redirect:"/tr/tutorials_examples/batch-size/"},{path:"/tr/tutorials_examples/batch-size.html",redirect:"/tr/tutorials_examples/batch-size/"},{name:"v-4bcb5835",path:"/tr/tutorials_examples/block-height/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-4bcb5835").then(t)}},{path:"/tr/tutorials_examples/block-height/index.html",redirect:"/tr/tutorials_examples/block-height/"},{path:"/tr/tutorials_examples/block-height.html",redirect:"/tr/tutorials_examples/block-height/"},{name:"v-e1ab6f4a",path:"/tr/tutorials_examples/debug-projects/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-e1ab6f4a").then(t)}},{path:"/tr/tutorials_examples/debug-projects/index.html",redirect:"/tr/tutorials_examples/debug-projects/"},{path:"/tr/tutorials_examples/debug-projects.html",redirect:"/tr/tutorials_examples/debug-projects/"},{name:"v-64b62297",path:"/tr/tutorials_examples/dictionary/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-64b62297").then(t)}},{path:"/tr/tutorials_examples/dictionary/index.html",redirect:"/tr/tutorials_examples/dictionary/"},{path:"/tr/tutorials_examples/dictionary.html",redirect:"/tr/tutorials_examples/dictionary/"},{name:"v-4f4aaacf",path:"/tr/tutorials_examples/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-4f4aaacf").then(t)}},{path:"/tr/tutorials_examples/introduction/index.html",redirect:"/tr/tutorials_examples/introduction/"},{path:"/tr/tutorials_examples/introduction.html",redirect:"/tr/tutorials_examples/introduction/"},{name:"v-102e162d",path:"/tr/tutorials_examples/run-indexer/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-102e162d").then(t)}},{path:"/tr/tutorials_examples/run-indexer/index.html",redirect:"/tr/tutorials_examples/run-indexer/"},{path:"/tr/tutorials_examples/run-indexer.html",redirect:"/tr/tutorials_examples/run-indexer/"},{name:"v-2e9e2726",path:"/tr/tutorials_examples/terminology/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2e9e2726").then(t)}},{path:"/tr/tutorials_examples/terminology/index.html",redirect:"/tr/tutorials_examples/terminology/"},{path:"/tr/tutorials_examples/terminology.html",redirect:"/tr/tutorials_examples/terminology/"},{name:"v-295c5866",path:"/tutorials_examples/block-height/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-295c5866").then(t)}},{path:"/tutorials_examples/block-height/index.html",redirect:"/tutorials_examples/block-height/"},{path:"/tutorials_examples/block-height.html",redirect:"/tutorials_examples/block-height/"},{name:"v-1bc67126",path:"/tutorials_examples/debug-projects/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1bc67126").then(t)}},{path:"/tutorials_examples/debug-projects/index.html",redirect:"/tutorials_examples/debug-projects/"},{path:"/tutorials_examples/debug-projects.html",redirect:"/tutorials_examples/debug-projects/"},{name:"v-685a2e6d",path:"/tutorials_examples/batch-size/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-685a2e6d").then(t)}},{path:"/tutorials_examples/batch-size/index.html",redirect:"/tutorials_examples/batch-size/"},{path:"/tutorials_examples/batch-size.html",redirect:"/tutorials_examples/batch-size/"},{name:"v-1f91922d",path:"/tutorials_examples/dictionary/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1f91922d").then(t)}},{path:"/tutorials_examples/dictionary/index.html",redirect:"/tutorials_examples/dictionary/"},{path:"/tutorials_examples/dictionary.html",redirect:"/tutorials_examples/dictionary/"},{name:"v-65affcad",path:"/tutorials_examples/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-65affcad").then(t)}},{path:"/tutorials_examples/introduction/index.html",redirect:"/tutorials_examples/introduction/"},{path:"/tutorials_examples/introduction.html",redirect:"/tutorials_examples/introduction/"},{name:"v-4e5b9057",path:"/tutorials_examples/run-indexer/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-4e5b9057").then(t)}},{path:"/tutorials_examples/run-indexer/index.html",redirect:"/tutorials_examples/run-indexer/"},{path:"/tutorials_examples/run-indexer.html",redirect:"/tutorials_examples/run-indexer/"},{name:"v-05bf836b",path:"/tutorials_examples/terminology/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-05bf836b").then(t)}},{path:"/tutorials_examples/terminology/index.html",redirect:"/tutorials_examples/terminology/"},{path:"/tutorials_examples/terminology.html",redirect:"/tutorials_examples/terminology/"},{name:"v-6dcc960d",path:"/uk/create/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6dcc960d").then(t)}},{path:"/uk/create/graphql/index.html",redirect:"/uk/create/graphql/"},{path:"/uk/create/graphql.html",redirect:"/uk/create/graphql/"},{name:"v-67670071",path:"/uk/create/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-67670071").then(t)}},{path:"/uk/create/introduction/index.html",redirect:"/uk/create/introduction/"},{path:"/uk/create/introduction.html",redirect:"/uk/create/introduction/"},{name:"v-5dda9d1e",path:"/uk/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5dda9d1e").then(t)}},{path:"/uk/index.html",redirect:"/uk/"},{name:"v-3a2d0547",path:"/uk/create/manifest/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-3a2d0547").then(t)}},{path:"/uk/create/manifest/index.html",redirect:"/uk/create/manifest/"},{path:"/uk/create/manifest.html",redirect:"/uk/create/manifest/"},{name:"v-237fd8ed",path:"/uk/create/mapping/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-237fd8ed").then(t)}},{path:"/uk/create/mapping/index.html",redirect:"/uk/create/mapping/"},{path:"/uk/create/mapping.html",redirect:"/uk/create/mapping/"},{name:"v-6e8c87ed",path:"/uk/faqs/faqs/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6e8c87ed").then(t)}},{path:"/uk/faqs/faqs/index.html",redirect:"/uk/faqs/faqs/"},{path:"/uk/faqs/faqs.html",redirect:"/uk/faqs/faqs/"},{name:"v-30ad7ebd",path:"/uk/install/install/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-30ad7ebd").then(t)}},{path:"/uk/install/install/index.html",redirect:"/uk/install/install/"},{path:"/uk/install/install.html",redirect:"/uk/install/install/"},{name:"v-0841246e",path:"/uk/miscellaneous/ambassadors/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0841246e").then(t)}},{path:"/uk/miscellaneous/ambassadors/index.html",redirect:"/uk/miscellaneous/ambassadors/"},{path:"/uk/miscellaneous/ambassadors.html",redirect:"/uk/miscellaneous/ambassadors/"},{name:"v-daa61166",path:"/uk/miscellaneous/branding/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-daa61166").then(t)}},{path:"/uk/miscellaneous/branding/index.html",redirect:"/uk/miscellaneous/branding/"},{path:"/uk/miscellaneous/branding.html",redirect:"/uk/miscellaneous/branding/"},{name:"v-392eb7ed",path:"/uk/miscellaneous/contributing/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-392eb7ed").then(t)}},{path:"/uk/miscellaneous/contributing/index.html",redirect:"/uk/miscellaneous/contributing/"},{path:"/uk/miscellaneous/contributing.html",redirect:"/uk/miscellaneous/contributing/"},{name:"v-6191ba26",path:"/uk/miscellaneous/social_media/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6191ba26").then(t)}},{path:"/uk/miscellaneous/social_media/index.html",redirect:"/uk/miscellaneous/social_media/"},{path:"/uk/miscellaneous/social_media.html",redirect:"/uk/miscellaneous/social_media/"},{name:"v-420ef137",path:"/uk/publish/connect/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-420ef137").then(t)}},{path:"/uk/publish/connect/index.html",redirect:"/uk/publish/connect/"},{path:"/uk/publish/connect.html",redirect:"/uk/publish/connect/"},{name:"v-306008ed",path:"/uk/publish/publish/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-306008ed").then(t)}},{path:"/uk/publish/publish/index.html",redirect:"/uk/publish/publish/"},{path:"/uk/publish/publish.html",redirect:"/uk/publish/publish/"},{name:"v-21e7225a",path:"/uk/publish/upgrade/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-21e7225a").then(t)}},{path:"/uk/publish/upgrade/index.html",redirect:"/uk/publish/upgrade/"},{path:"/uk/publish/upgrade.html",redirect:"/uk/publish/upgrade/"},{name:"v-ada9f2f2",path:"/uk/query/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-ada9f2f2").then(t)}},{path:"/uk/query/graphql/index.html",redirect:"/uk/query/graphql/"},{path:"/uk/query/graphql.html",redirect:"/uk/query/graphql/"},{name:"v-7bc99189",path:"/uk/query/query/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7bc99189").then(t)}},{path:"/uk/query/query/index.html",redirect:"/uk/query/query/"},{path:"/uk/query/query.html",redirect:"/uk/query/query/"},{name:"v-01b4cdcd",path:"/uk/quickstart/helloworld-hosted/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-01b4cdcd").then(t)}},{path:"/uk/quickstart/helloworld-hosted/index.html",redirect:"/uk/quickstart/helloworld-hosted/"},{path:"/uk/quickstart/helloworld-hosted.html",redirect:"/uk/quickstart/helloworld-hosted/"},{name:"v-9ea17eea",path:"/uk/quickstart/helloworld-localhost/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-9ea17eea").then(t)}},{path:"/uk/quickstart/helloworld-localhost/index.html",redirect:"/uk/quickstart/helloworld-localhost/"},{path:"/uk/quickstart/helloworld-localhost.html",redirect:"/uk/quickstart/helloworld-localhost/"},{name:"v-77c86fed",path:"/uk/quickstart/quickstart/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-77c86fed").then(t)}},{path:"/uk/quickstart/quickstart/index.html",redirect:"/uk/quickstart/quickstart/"},{path:"/uk/quickstart/quickstart.html",redirect:"/uk/quickstart/quickstart/"},{name:"v-7943c1f6",path:"/uk/quickstart/understanding-helloworld/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7943c1f6").then(t)}},{path:"/uk/quickstart/understanding-helloworld/index.html",redirect:"/uk/quickstart/understanding-helloworld/"},{path:"/uk/quickstart/understanding-helloworld.html",redirect:"/uk/quickstart/understanding-helloworld/"},{name:"v-47b39cfd",path:"/uk/run/run/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-47b39cfd").then(t)}},{path:"/uk/run/run/index.html",redirect:"/uk/run/run/"},{path:"/uk/run/run.html",redirect:"/uk/run/run/"},{name:"v-b128a8f6",path:"/uk/run/sandbox/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-b128a8f6").then(t)}},{path:"/uk/run/sandbox/index.html",redirect:"/uk/run/sandbox/"},{path:"/uk/run/sandbox.html",redirect:"/uk/run/sandbox/"},{name:"v-b3a7beaa",path:"/uk/tutorials_examples/batch-size/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-b3a7beaa").then(t)}},{path:"/uk/tutorials_examples/batch-size/index.html",redirect:"/uk/tutorials_examples/batch-size/"},{path:"/uk/tutorials_examples/batch-size.html",redirect:"/uk/tutorials_examples/batch-size/"},{name:"v-c4936ff6",path:"/uk/tutorials_examples/block-height/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-c4936ff6").then(t)}},{path:"/uk/tutorials_examples/block-height/index.html",redirect:"/uk/tutorials_examples/block-height/"},{path:"/uk/tutorials_examples/block-height.html",redirect:"/uk/tutorials_examples/block-height/"},{name:"v-ee6b2baa",path:"/uk/tutorials_examples/debug-projects/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-ee6b2baa").then(t)}},{path:"/uk/tutorials_examples/debug-projects/index.html",redirect:"/uk/tutorials_examples/debug-projects/"},{path:"/uk/tutorials_examples/debug-projects.html",redirect:"/uk/tutorials_examples/debug-projects/"},{name:"v-fcb73f32",path:"/uk/tutorials_examples/dictionary/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-fcb73f32").then(t)}},{path:"/uk/tutorials_examples/dictionary/index.html",redirect:"/uk/tutorials_examples/dictionary/"},{path:"/uk/tutorials_examples/dictionary.html",redirect:"/uk/tutorials_examples/dictionary/"},{name:"v-2ca3ee26",path:"/uk/tutorials_examples/howto/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2ca3ee26").then(t)}},{path:"/uk/tutorials_examples/howto/index.html",redirect:"/uk/tutorials_examples/howto/"},{path:"/uk/tutorials_examples/howto.html",redirect:"/uk/tutorials_examples/howto/"},{name:"v-bd94cac2",path:"/uk/tutorials_examples/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-bd94cac2").then(t)}},{path:"/uk/tutorials_examples/introduction/index.html",redirect:"/uk/tutorials_examples/introduction/"},{path:"/uk/tutorials_examples/introduction.html",redirect:"/uk/tutorials_examples/introduction/"},{name:"v-6281452d",path:"/uk/tutorials_examples/run-indexer/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6281452d").then(t)}},{path:"/uk/tutorials_examples/run-indexer/index.html",redirect:"/uk/tutorials_examples/run-indexer/"},{path:"/uk/tutorials_examples/run-indexer.html",redirect:"/uk/tutorials_examples/run-indexer/"},{name:"v-e894ac04",path:"/vi/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-e894ac04").then(t)}},{path:"/vi/index.html",redirect:"/vi/"},{name:"v-3b041b6d",path:"/uk/tutorials_examples/terminology/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-3b041b6d").then(t)}},{path:"/uk/tutorials_examples/terminology/index.html",redirect:"/uk/tutorials_examples/terminology/"},{path:"/uk/tutorials_examples/terminology.html",redirect:"/uk/tutorials_examples/terminology/"},{name:"v-9cd12ba6",path:"/vi/create/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-9cd12ba6").then(t)}},{path:"/vi/create/graphql/index.html",redirect:"/vi/create/graphql/"},{path:"/vi/create/graphql.html",redirect:"/vi/create/graphql/"},{name:"v-62e23092",path:"/vi/create/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-62e23092").then(t)}},{path:"/vi/create/introduction/index.html",redirect:"/vi/create/introduction/"},{path:"/vi/create/introduction.html",redirect:"/vi/create/introduction/"},{name:"v-674aad0d",path:"/vi/create/mapping/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-674aad0d").then(t)}},{path:"/vi/create/mapping/index.html",redirect:"/vi/create/mapping/"},{path:"/vi/create/mapping.html",redirect:"/vi/create/mapping/"},{name:"v-e7c9cde6",path:"/vi/create/manifest/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-e7c9cde6").then(t)}},{path:"/vi/create/manifest/index.html",redirect:"/vi/create/manifest/"},{path:"/vi/create/manifest.html",redirect:"/vi/create/manifest/"},{name:"v-fac8dafa",path:"/vi/install/install/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-fac8dafa").then(t)}},{path:"/vi/install/install/index.html",redirect:"/vi/install/install/"},{path:"/vi/install/install.html",redirect:"/vi/install/install/"},{name:"v-6989e673",path:"/vi/faqs/faqs/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6989e673").then(t)}},{path:"/vi/faqs/faqs/index.html",redirect:"/vi/faqs/faqs/"},{path:"/vi/faqs/faqs.html",redirect:"/vi/faqs/faqs/"},{name:"v-8b57cb62",path:"/vi/miscellaneous/ambassadors/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-8b57cb62").then(t)}},{path:"/vi/miscellaneous/ambassadors/index.html",redirect:"/vi/miscellaneous/ambassadors/"},{path:"/vi/miscellaneous/ambassadors.html",redirect:"/vi/miscellaneous/ambassadors/"},{name:"v-3795786d",path:"/vi/miscellaneous/branding/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-3795786d").then(t)}},{path:"/vi/miscellaneous/branding/index.html",redirect:"/vi/miscellaneous/branding/"},{path:"/vi/miscellaneous/branding.html",redirect:"/vi/miscellaneous/branding/"},{name:"v-fbfd20e6",path:"/vi/miscellaneous/contributing/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-fbfd20e6").then(t)}},{path:"/vi/miscellaneous/contributing/index.html",redirect:"/vi/miscellaneous/contributing/"},{path:"/vi/miscellaneous/contributing.html",redirect:"/vi/miscellaneous/contributing/"},{name:"v-1809da8d",path:"/vi/miscellaneous/social_media/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-1809da8d").then(t)}},{path:"/vi/miscellaneous/social_media/index.html",redirect:"/vi/miscellaneous/social_media/"},{path:"/vi/miscellaneous/social_media.html",redirect:"/vi/miscellaneous/social_media/"},{name:"v-fb63c69a",path:"/vi/publish/publish/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-fb63c69a").then(t)}},{path:"/vi/publish/publish/index.html",redirect:"/vi/publish/publish/"},{path:"/vi/publish/publish.html",redirect:"/vi/publish/publish/"},{name:"v-40fa8299",path:"/vi/publish/upgrade/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-40fa8299").then(t)}},{path:"/vi/publish/upgrade/index.html",redirect:"/vi/publish/upgrade/"},{path:"/vi/publish/upgrade.html",redirect:"/vi/publish/upgrade/"},{name:"v-7636cee6",path:"/vi/query/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7636cee6").then(t)}},{path:"/vi/query/graphql/index.html",redirect:"/vi/query/graphql/"},{path:"/vi/query/graphql.html",redirect:"/vi/query/graphql/"},{name:"v-290cdc62",path:"/vi/query/query/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-290cdc62").then(t)}},{path:"/vi/query/query/index.html",redirect:"/vi/query/query/"},{path:"/vi/query/query.html",redirect:"/vi/query/query/"},{name:"v-19ad78ad",path:"/vi/quickstart/helloworld-hosted/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-19ad78ad").then(t)}},{path:"/vi/quickstart/helloworld-hosted/index.html",redirect:"/vi/quickstart/helloworld-hosted/"},{path:"/vi/quickstart/helloworld-hosted.html",redirect:"/vi/quickstart/helloworld-hosted/"},{name:"v-33ab2251",path:"/vi/quickstart/helloworld-localhost/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-33ab2251").then(t)}},{path:"/vi/quickstart/helloworld-localhost/index.html",redirect:"/vi/quickstart/helloworld-localhost/"},{path:"/vi/quickstart/helloworld-localhost.html",redirect:"/vi/quickstart/helloworld-localhost/"},{name:"v-3ac4ae1a",path:"/vi/quickstart/quickstart/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-3ac4ae1a").then(t)}},{path:"/vi/quickstart/quickstart/index.html",redirect:"/vi/quickstart/quickstart/"},{path:"/vi/quickstart/quickstart.html",redirect:"/vi/quickstart/quickstart/"},{name:"v-7c7a576a",path:"/vi/quickstart/understanding-helloworld/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7c7a576a").then(t)}},{path:"/vi/quickstart/understanding-helloworld/index.html",redirect:"/vi/quickstart/understanding-helloworld/"},{path:"/vi/quickstart/understanding-helloworld.html",redirect:"/vi/quickstart/understanding-helloworld/"},{name:"v-258149c3",path:"/vi/run/run/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-258149c3").then(t)}},{path:"/vi/run/run/index.html",redirect:"/vi/run/run/"},{path:"/vi/run/run.html",redirect:"/vi/run/run/"},{name:"v-171babcb",path:"/vi/run/sandbox/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-171babcb").then(t)}},{path:"/vi/run/sandbox/index.html",redirect:"/vi/run/sandbox/"},{path:"/vi/run/sandbox.html",redirect:"/vi/run/sandbox/"},{name:"v-d867fe9e",path:"/vi/tutorials_examples/batch-size/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-d867fe9e").then(t)}},{path:"/vi/tutorials_examples/batch-size/index.html",redirect:"/vi/tutorials_examples/batch-size/"},{path:"/vi/tutorials_examples/batch-size.html",redirect:"/vi/tutorials_examples/batch-size/"},{name:"v-20b229cb",path:"/vi/tutorials_examples/block-height/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-20b229cb").then(t)}},{path:"/vi/tutorials_examples/block-height/index.html",redirect:"/vi/tutorials_examples/block-height/"},{path:"/vi/tutorials_examples/block-height.html",redirect:"/vi/tutorials_examples/block-height/"},{name:"v-e87d849e",path:"/vi/tutorials_examples/debug-projects/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-e87d849e").then(t)}},{path:"/vi/tutorials_examples/debug-projects/index.html",redirect:"/vi/tutorials_examples/debug-projects/"},{path:"/vi/tutorials_examples/debug-projects.html",redirect:"/vi/tutorials_examples/debug-projects/"},{name:"v-6f44406d",path:"/vi/tutorials_examples/dictionary/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-6f44406d").then(t)}},{path:"/vi/tutorials_examples/dictionary/index.html",redirect:"/vi/tutorials_examples/dictionary/"},{path:"/vi/tutorials_examples/dictionary.html",redirect:"/vi/tutorials_examples/dictionary/"},{name:"v-131f5d4d",path:"/vi/tutorials_examples/howto/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-131f5d4d").then(t)}},{path:"/vi/tutorials_examples/howto/index.html",redirect:"/vi/tutorials_examples/howto/"},{path:"/vi/tutorials_examples/howto.html",redirect:"/vi/tutorials_examples/howto/"},{name:"v-24317c65",path:"/vi/tutorials_examples/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-24317c65").then(t)}},{path:"/vi/tutorials_examples/introduction/index.html",redirect:"/vi/tutorials_examples/introduction/"},{path:"/vi/tutorials_examples/introduction.html",redirect:"/vi/tutorials_examples/introduction/"},{name:"v-c95f1966",path:"/vi/tutorials_examples/run-indexer/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-c95f1966").then(t)}},{path:"/vi/tutorials_examples/run-indexer/index.html",redirect:"/vi/tutorials_examples/run-indexer/"},{path:"/vi/tutorials_examples/run-indexer.html",redirect:"/vi/tutorials_examples/run-indexer/"},{name:"v-73d3498d",path:"/vi/tutorials_examples/terminology/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-73d3498d").then(t)}},{path:"/vi/tutorials_examples/terminology/index.html",redirect:"/vi/tutorials_examples/terminology/"},{path:"/vi/tutorials_examples/terminology.html",redirect:"/vi/tutorials_examples/terminology/"},{name:"v-8fbc73c4",path:"/zh/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-8fbc73c4").then(t)}},{path:"/zh/index.html",redirect:"/zh/"},{name:"v-4cb5e50d",path:"/zh/create/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-4cb5e50d").then(t)}},{path:"/zh/create/graphql/index.html",redirect:"/zh/create/graphql/"},{path:"/zh/create/graphql.html",redirect:"/zh/create/graphql/"},{name:"v-8de7f97e",path:"/zh/create/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-8de7f97e").then(t)}},{path:"/zh/create/introduction/index.html",redirect:"/zh/create/introduction/"},{path:"/zh/create/introduction.html",redirect:"/zh/create/introduction/"},{name:"v-541b37d2",path:"/zh/create/manifest/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-541b37d2").then(t)}},{path:"/zh/create/manifest/index.html",redirect:"/zh/create/manifest/"},{path:"/zh/create/manifest.html",redirect:"/zh/create/manifest/"},{name:"v-026927ed",path:"/zh/create/mapping/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-026927ed").then(t)}},{path:"/zh/create/mapping/index.html",redirect:"/zh/create/mapping/"},{path:"/zh/create/mapping.html",redirect:"/zh/create/mapping/"},{name:"v-39ce30bd",path:"/zh/faqs/faqs/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-39ce30bd").then(t)}},{path:"/zh/faqs/faqs/index.html",redirect:"/zh/faqs/faqs/"},{path:"/zh/faqs/faqs.html",redirect:"/zh/faqs/faqs/"},{name:"v-671a44e6",path:"/zh/install/install/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-671a44e6").then(t)}},{path:"/zh/install/install/index.html",redirect:"/zh/install/install/"},{path:"/zh/install/install.html",redirect:"/zh/install/install/"},{name:"v-d805f606",path:"/vi/publish/connect/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-d805f606").then(t)}},{path:"/vi/publish/connect/index.html",redirect:"/vi/publish/connect/"},{path:"/vi/publish/connect.html",redirect:"/vi/publish/connect/"},{name:"v-3bc0b2ce",path:"/zh/miscellaneous/ambassadors/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-3bc0b2ce").then(t)}},{path:"/zh/miscellaneous/ambassadors/index.html",redirect:"/zh/miscellaneous/ambassadors/"},{path:"/zh/miscellaneous/ambassadors.html",redirect:"/zh/miscellaneous/ambassadors/"},{name:"v-0501aa26",path:"/zh/miscellaneous/contributing/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0501aa26").then(t)}},{path:"/zh/miscellaneous/contributing/index.html",redirect:"/zh/miscellaneous/contributing/"},{path:"/zh/miscellaneous/contributing.html",redirect:"/zh/miscellaneous/contributing/"},{name:"v-723b4366",path:"/zh/miscellaneous/branding/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-723b4366").then(t)}},{path:"/zh/miscellaneous/branding/index.html",redirect:"/zh/miscellaneous/branding/"},{path:"/zh/miscellaneous/branding.html",redirect:"/zh/miscellaneous/branding/"},{name:"v-d8f0d426",path:"/zh/miscellaneous/social_media/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-d8f0d426").then(t)}},{path:"/zh/miscellaneous/social_media/index.html",redirect:"/zh/miscellaneous/social_media/"},{path:"/zh/miscellaneous/social_media.html",redirect:"/zh/miscellaneous/social_media/"},{name:"v-44575ff2",path:"/zh/publish/connect/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-44575ff2").then(t)}},{path:"/zh/publish/connect/index.html",redirect:"/zh/publish/connect/"},{path:"/zh/publish/connect.html",redirect:"/zh/publish/connect/"},{name:"v-67b53086",path:"/zh/publish/publish/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-67b53086").then(t)}},{path:"/zh/publish/publish/index.html",redirect:"/zh/publish/publish/"},{path:"/zh/publish/publish.html",redirect:"/zh/publish/publish/"},{name:"v-ea5c64ba",path:"/zh/publish/upgrade/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-ea5c64ba").then(t)}},{path:"/zh/publish/upgrade/index.html",redirect:"/zh/publish/upgrade/"},{path:"/zh/publish/upgrade.html",redirect:"/zh/publish/upgrade/"},{name:"v-29ed5952",path:"/zh/query/graphql/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-29ed5952").then(t)}},{path:"/zh/query/graphql/index.html",redirect:"/zh/query/graphql/"},{path:"/zh/query/graphql.html",redirect:"/zh/query/graphql/"},{name:"v-37f14c59",path:"/zh/query/query/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-37f14c59").then(t)}},{path:"/zh/query/query/index.html",redirect:"/zh/query/query/"},{path:"/zh/query/query.html",redirect:"/zh/query/query/"},{name:"v-50bff266",path:"/zh/quickstart/helloworld-hosted/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-50bff266").then(t)}},{path:"/zh/quickstart/helloworld-hosted/index.html",redirect:"/zh/quickstart/helloworld-hosted/"},{path:"/zh/quickstart/helloworld-hosted.html",redirect:"/zh/quickstart/helloworld-hosted/"},{name:"v-9101a14a",path:"/zh/quickstart/helloworld-localhost/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-9101a14a").then(t)}},{path:"/zh/quickstart/helloworld-localhost/index.html",redirect:"/zh/quickstart/helloworld-localhost/"},{path:"/zh/quickstart/helloworld-localhost.html",redirect:"/zh/quickstart/helloworld-localhost/"},{name:"v-2c2604bd",path:"/zh/quickstart/quickstart/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-2c2604bd").then(t)}},{path:"/zh/quickstart/quickstart/index.html",redirect:"/zh/quickstart/quickstart/"},{path:"/zh/quickstart/quickstart.html",redirect:"/zh/quickstart/quickstart/"},{name:"v-31d49c56",path:"/zh/quickstart/understanding-helloworld/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-31d49c56").then(t)}},{path:"/zh/quickstart/understanding-helloworld/index.html",redirect:"/zh/quickstart/understanding-helloworld/"},{path:"/zh/quickstart/understanding-helloworld.html",redirect:"/zh/quickstart/understanding-helloworld/"},{name:"v-5f7fb3cd",path:"/zh/run/run/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-5f7fb3cd").then(t)}},{path:"/zh/run/run/index.html",redirect:"/zh/run/run/"},{path:"/zh/run/run.html",redirect:"/zh/run/run/"},{name:"v-63936655",path:"/zh/run/sandbox/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-63936655").then(t)}},{path:"/zh/run/sandbox/index.html",redirect:"/zh/run/sandbox/"},{path:"/zh/run/sandbox.html",redirect:"/zh/run/sandbox/"},{name:"v-0810fd7b",path:"/zh/tutorials_examples/batch-size/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0810fd7b").then(t)}},{path:"/zh/tutorials_examples/batch-size/index.html",redirect:"/zh/tutorials_examples/batch-size/"},{path:"/zh/tutorials_examples/batch-size.html",redirect:"/zh/tutorials_examples/batch-size/"},{name:"v-b6f39256",path:"/zh/tutorials_examples/block-height/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-b6f39256").then(t)}},{path:"/zh/tutorials_examples/block-height/index.html",redirect:"/zh/tutorials_examples/block-height/"},{path:"/zh/tutorials_examples/block-height.html",redirect:"/zh/tutorials_examples/block-height/"},{name:"v-0b15eafb",path:"/zh/tutorials_examples/debug-projects/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-0b15eafb").then(t)}},{path:"/zh/tutorials_examples/debug-projects/index.html",redirect:"/zh/tutorials_examples/debug-projects/"},{path:"/zh/tutorials_examples/debug-projects.html",redirect:"/zh/tutorials_examples/debug-projects/"},{name:"v-38ed8592",path:"/zh/tutorials_examples/dictionary/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-38ed8592").then(t)}},{path:"/zh/tutorials_examples/dictionary/index.html",redirect:"/zh/tutorials_examples/dictionary/"},{path:"/zh/tutorials_examples/dictionary.html",redirect:"/zh/tutorials_examples/dictionary/"},{name:"v-58f735ed",path:"/zh/tutorials_examples/howto/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-58f735ed").then(t)}},{path:"/zh/tutorials_examples/howto/index.html",redirect:"/zh/tutorials_examples/howto/"},{path:"/zh/tutorials_examples/howto.html",redirect:"/zh/tutorials_examples/howto/"},{name:"v-aff4ed22",path:"/zh/tutorials_examples/introduction/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-aff4ed22").then(t)}},{path:"/zh/tutorials_examples/introduction/index.html",redirect:"/zh/tutorials_examples/introduction/"},{path:"/zh/tutorials_examples/introduction.html",redirect:"/zh/tutorials_examples/introduction/"},{name:"v-7d8a77a6",path:"/zh/tutorials_examples/run-indexer/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7d8a77a6").then(t)}},{path:"/zh/tutorials_examples/run-indexer/index.html",redirect:"/zh/tutorials_examples/run-indexer/"},{path:"/zh/tutorials_examples/run-indexer.html",redirect:"/zh/tutorials_examples/run-indexer/"},{name:"v-cc84cb26",path:"/zh/tutorials_examples/terminology/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-cc84cb26").then(t)}},{path:"/zh/tutorials_examples/terminology/index.html",redirect:"/zh/tutorials_examples/terminology/"},{path:"/zh/tutorials_examples/terminology.html",redirect:"/zh/tutorials_examples/terminology/"},{name:"v-79043d8b",path:"/th/create/manifest/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-79043d8b").then(t)}},{path:"/th/create/manifest/index.html",redirect:"/th/create/manifest/"},{path:"/th/create/manifest.html",redirect:"/th/create/manifest/"},{name:"v-7bbe2fad",path:"/th/create/mapping/",component:Dn,beforeEnter:(e,n,t)=>{pn("Layout","v-7bbe2fad").then(t)}},{path:"/th/create/mapping/index.html",redirect:"/th/create/mapping/"},{path:"/th/create/mapping.html",redirect:"/th/create/mapping/"},{name:"v-6453f364",path:"/article/",component:Dn,beforeEnter:(e,n,t)=>{pn("Blog","v-6453f364").then(t)}},{path:"/article/index.html",redirect:"/article/"},{name:"v-4340f7e8",path:"/star/",component:Dn,beforeEnter:(e,n,t)=>{pn("Blog","v-4340f7e8").then(t)}},{path:"/star/index.html",redirect:"/star/"},{name:"v-7d484ebf",path:"/encrypt/",component:Dn,beforeEnter:(e,n,t)=>{pn("Blog","v-7d484ebf").then(t)}},{path:"/encrypt/index.html",redirect:"/encrypt/"},{name:"v-2470be33",path:"/slide/",component:Dn,beforeEnter:(e,n,t)=>{pn("Blog","v-2470be33").then(t)}},{path:"/slide/index.html",redirect:"/slide/"},{name:"v-6319eb4e",path:"/timeline/",component:Dn,beforeEnter:(e,n,t)=>{pn("Blog","v-6319eb4e").then(t)}},{path:"/timeline/index.html",redirect:"/timeline/"},{name:"v-b1564aac",path:"/tag/",component:Dn,beforeEnter:(e,n,t)=>{pn("Blog","v-b1564aac").then(t)},meta:{pid:"tag",id:"tag"}},{path:"/tag/index.html",redirect:"/tag/"},{name:"v-28e6393c",path:"/category/",component:Dn,beforeEnter:(e,n,t)=>{pn("Blog","v-28e6393c").then(t)},meta:{pid:"category",id:"category"}},{path:"/category/index.html",redirect:"/category/"},{path:"*",component:Dn}],Bn={title:"",description:"",base:"/",headTags:[["link",{rel:"manifest",href:"/manifest.webmanifest",crossorigin:"use-credentials"}],["meta",{name:"theme-color",content:"#46bd87"}],["meta",{name:"viewport",content:"width=device-width, initial-scale=1.0, viewport-fit=cover"}]],pages:[{title:"GraphQL Schema",frontmatter:{summary:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict",meta:[{property:"og:url",content:"/create/graphql.html"},{property:"og:title",content:"GraphQL Schema"},{property:"og:description",content:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/create/graphql.html",relativePath:"create/graphql.md",key:"v-86b1f726",path:"/create/graphql/",headers:[{level:2,title:"Defining Entities",slug:"defining-entities",normalizedTitle:"defining entities",charIndex:21},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:30},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:931},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1282},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1186},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3290},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3759},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:4063},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5097},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1268},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6446},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7146}],readingTime:{minutes:3.9,words:1170},headersStr:"Defining Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL Schema\n\n\n# Defining Entities\n\nThe schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates the shape of your data from SubQuery. To learn more about how to write in GraphQL schema language, we recommend checking out Schemas and Types.\n\nImportant: When you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# Entities\n\nEach entity must define its required fields id with the type of ID!. It is used as the primary key and unique among all entities of the same type.\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field \n}\n\ntype Title @entity {\n  id: ID!  \n  name: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nWhen code generation is run, this will automatically create a getByName under the User model, and the foreign key field title will create a getByTitleId method, which both can directly be accessed in the mapping function.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from \"../types/models/User\"\nimport {Title} from \"../types/models/Title\"\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account] \n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID! \n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactCard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# graphql schema\n\n\n# defining entities\n\nthe schema.graphql file defines the various graphql schemas. due to the way that the graphql query language works, the schema file essentially dictates the shape of your data from subquery. to learn more about how to write in graphql schema language, we recommend checking out schemas and types.\n\nimportant: when you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# entities\n\neach entity must define its required fields id with the type of id!. it is used as the primary key and unique among all entities of the same type.\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field \n}\n\ntype title @entity {\n  id: id!  \n  name: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nwhen code generation is run, this will automatically create a getbyname under the user model, and the foreign key field title will create a getbytitleid method, which both can directly be accessed in the mapping function.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from \"../types/models/user\"\nimport {title} from \"../types/models/title\"\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account] \n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id! \n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactcard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Welcome to SubQuery",frontmatter:{summary:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello",meta:[{property:"og:url",content:"/"},{property:"og:description",content:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/",relativePath:"README.md",key:"v-47639a6e",path:"/",readingTime:{minutes:2.99,words:896},headersStr:null,content:"Welcome to SubQuery’s Docs\n\nExplore and transform your chain data to build intuitive dApps faster!\n\n\nQuick Start Guide\n\nUnderstand SubQuery by getting hands on with a traditional Hello World example. Using a template project within a Docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * The SubQuery Network\n   \n   SubQuery’s decentralised future. Read more about how indexers and consumers are rewarded.\n\n\nFAQ\n\n * What is SubQuery?\n   \n   SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n   \n   READ MORE\n * What is the best way to get started with SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n * How can I contribute or give feedback to SubQuery?\n   \n   We love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guidelines (coming soon).\n   \n   READ MORE\n * How much does it cost to host my project in SubQuery Projects?\n   \n   Hosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nIntegrating with your Custom Chain?\n\nWhether you're building a new parachain or an entirely new blockchain on Substrate - SubQuery can help you index and troubleshoot your chain's data. SubQuery is designed to easily integrate with a custom Substrate based chain.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nSupport and Contribute\n\nHave a question or interested to know more or how you can contribute? We’d love to hear from you. Please contact us via email or social media from the links below. Need technical expertise? Join our Discord community and receive support from our passionate community members.\n\nJOIN THE CONVERSATION ON DISCORD\nContact us hello@subquery.network\nFollow us on social\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"welcome to subquery’s docs\n\nexplore and transform your chain data to build intuitive dapps faster!\n\n\nquick start guide\n\nunderstand subquery by getting hands on with a traditional hello world example. using a template project within a docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * the subquery network\n   \n   subquery’s decentralised future. read more about how indexers and consumers are rewarded.\n\n\nfaq\n\n * what is subquery?\n   \n   subquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n   \n   read more\n * what is the best way to get started with subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n * how can i contribute or give feedback to subquery?\n   \n   we love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guidelines (coming soon).\n   \n   read more\n * how much does it cost to host my project in subquery projects?\n   \n   hosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nintegrating with your custom chain?\n\nwhether you're building a new parachain or an entirely new blockchain on substrate - subquery can help you index and troubleshoot your chain's data. subquery is designed to easily integrate with a custom substrate based chain.\n\nlearn how to integrate with your chain\n\nsupport and contribute\n\nhave a question or interested to know more or how you can contribute? we’d love to hear from you. please contact us via email or social media from the links below. need technical expertise? join our discord community and receive support from our passionate community members.\n\njoin the conversation on discord\ncontact us hello@subquery.network\nfollow us on social\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/create/introduction.html",relativePath:"create/introduction.md",key:"v-94114ee6",path:"/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2311}],readingTime:{minutes:1.79,words:537},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\nyarn build\n\n\n1\n\n\nnpm run-script build\n\n\n1\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\nyarn build\n\n\n1\n\n\nnpm run-script build\n\n\n1\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/create/manifest.html",relativePath:"create/manifest.md",key:"v-5d960c2d",path:"/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:2013},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3238},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4555}],readingTime:{minutes:2.5,words:751},headersStr:"Network Filters Mapping Filters Custom Chains",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - read how a SubQuery Dictionary works.\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - read how a subquery dictionary works.\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/create/mapping.html",relativePath:"create/mapping.md",key:"v-03d2d023",path:"/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3141},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4151},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5111},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5541},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6209},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5061},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6926},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10271},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11506},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11728}],readingTime:{minutes:6.91,words:2073},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from "@subql/types";\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n    // Create a new StarterEntity with the block hash as it\'s ID\n    const record = new starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from "ethers/lib/utils"; //Good way\nimport {utils} from "ethers" //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api.query.kitties.nextKittyId();\n    // return the Kitty type, input parameters types are AccountId and KittyIndex\n    const allKitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`Next kitty id ${nextKittyId}`)\n    //Custom rpc, set undefined to blockhash\n    const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined,nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from "@subql/types";\n\nexport async function handleblock(block: substrateblock): promise<void> {\n    // create a new starterentity with the block hash as it\'s id\n    const record = new starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from "ethers/lib/utils"; //good way\nimport {utils} from "ethers" //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api.query.kitties.nextkittyid();\n    // return the kitty type, input parameters types are accountid and kittyindex\n    const allkitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`next kitty id ${nextkittyid}`)\n    //custom rpc, set undefined to blockhash\n    const kittyprice = await api.rpc.kitties.getkittyprice(undefined,nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{frontmatter:{summary:"Herzlich Willkommen bei den Dokumenten von SubQuery Erkunden und transformieren Sie Ihre Kettendaten, um intuitive dApps schneller zu erstellen! Schnellstart Anleitung Verständnis ",meta:[{property:"og:url",content:"/de/"},{property:"og:description",content:"Herzlich Willkommen bei den Dokumenten von SubQuery Erkunden und transformieren Sie Ihre Kettendaten, um intuitive dApps schneller zu erstellen! Schnellstart Anleitung Verständnis "},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/",relativePath:"de/README.md",key:"v-4806233e",path:"/de/",readingTime:{minutes:3.04,words:911},headersStr:null,content:"Herzlich Willkommen bei den Dokumenten von SubQuery\n\nErkunden und transformieren Sie Ihre Kettendaten, um intuitive dApps schneller zu erstellen!\n\n\nSchnellstart Anleitung\n\nVerständnis von SubQuery, indem Sie ein traditionelles Hallo World-Beispiel ausprobieren. Mit einem Vorlagenprojekt in einer Docker-Umgebung können Sie einen Knoten schnell zum Laufen bringen und mit wenigen einfachen Befehlen in wenigen Minuten eine Blockchain abfragen.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * Das SubQuery-Netzwerk\n   \n   Die dezentrale Zukunft von SubQuery. Lesen Sie mehr darüber, wie Indexer und Verbraucher belohnt werden.\n\n\nFAQ\n\n * Was ist SubQuery?\n   \n   SubQuery ist ein Open-Source-Projekt, das es Entwicklern ermöglicht, Substratkettendaten zu indizieren, umzuwandeln und abzufragen, um ihre Anwendungen zu unterstützen.\n   \n   READ MORE\n * Was ist der beste Weg, um mit SubQuery zu beginnen?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. Dies ist ein einfacher 5-minütiger Spaziergang durch das Herunterladen der Starter-Vorlage, das Erstellen des Projekts und die anschließende Verwendung von Docker, um einen Knoten auf Ihrem localhost auszuführen und eine einfache Abfrage auszuführen.\n\n * Wie kann ich SubQuery beitragen oder Feedback geben?\n   \n   Wir lieben Beiträge und Feedback aus der Community. Um Code beizutragen, verzweigen Sie das gewünschte Repository und nehmen Sie Ihre Änderungen vor. Senden Sie dann einen PR- oder Pull-Request. Oh, vergiss auch nicht zu testen! Sehen Sie sich auch unsere Beitragsrichtlinien an (demnächst).\n   \n   READ MORE\n * Wie viel kostet es, mein Projekt in SubQuery-Projekten zu hosten?\n   \n   Das Hosten Ihres Projekts in SubQuery Projects ist absolut kostenlos - es ist unsere Art, der Community etwas zurückzugeben. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nIntegration in Ihre benutzerdefinierte Kette?\n\nEgal, ob Sie eine neue Parachain oder eine völlig neue Blockchain auf Substrate erstellen – SubQuery kann Ihnen helfen, die Daten Ihrer Kette zu indizieren und Fehler zu beheben. SubQuery wurde für die einfache Integration in eine benutzerdefinierte, auf Substraten basierende Kette entwickelt.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nUnterstützen und beitragen\n\nHaben Sie eine Frage oder möchten Sie mehr wissen oder wie Sie dazu beitragen können? Wir würden uns freuen, von dir zu hören. Bitte kontaktieren Sie uns per E-Mail oder Social Media über die untenstehenden Links. Benötigen Sie technische Expertise? Treten Sie unserer Discord-Community bei und erhalten Sie Unterstützung von unseren leidenschaftlichen Community-Mitgliedern.\n\nTEILNEHMEN DEM GESPRÄCH AUF DISCORD\nKontaktieren Sie uns hello@subquery.network\nFolgen Sie uns in den sozialen Netzwerken\ndiscord twitter medium telegramm github Matrix linkedin\nSubQuery © 2021",normalizedContent:"herzlich willkommen bei den dokumenten von subquery\n\nerkunden und transformieren sie ihre kettendaten, um intuitive dapps schneller zu erstellen!\n\n\nschnellstart anleitung\n\nverstandnis von subquery, indem sie ein traditionelles hallo world-beispiel ausprobieren. mit einem vorlagenprojekt in einer docker-umgebung konnen sie einen knoten schnell zum laufen bringen und mit wenigen einfachen befehlen in wenigen minuten eine blockchain abfragen.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * das subquery-netzwerk\n   \n   die dezentrale zukunft von subquery. lesen sie mehr daruber, wie indexer und verbraucher belohnt werden.\n\n\nfaq\n\n * was ist subquery?\n   \n   subquery ist ein open-source-projekt, das es entwicklern ermoglicht, substratkettendaten zu indizieren, umzuwandeln und abzufragen, um ihre anwendungen zu unterstutzen.\n   \n   read more\n * was ist der beste weg, um mit subquery zu beginnen?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. dies ist ein einfacher 5-minutiger spaziergang durch das herunterladen der starter-vorlage, das erstellen des projekts und die anschließende verwendung von docker, um einen knoten auf ihrem localhost auszufuhren und eine einfache abfrage auszufuhren.\n\n * wie kann ich subquery beitragen oder feedback geben?\n   \n   wir lieben beitrage und feedback aus der community. um code beizutragen, verzweigen sie das gewunschte repository und nehmen sie ihre anderungen vor. senden sie dann einen pr- oder pull-request. oh, vergiss auch nicht zu testen! sehen sie sich auch unsere beitragsrichtlinien an (demnachst).\n   \n   read more\n * wie viel kostet es, mein projekt in subquery-projekten zu hosten?\n   \n   das hosten ihres projekts in subquery projects ist absolut kostenlos - es ist unsere art, der community etwas zuruckzugeben. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nintegration in ihre benutzerdefinierte kette?\n\negal, ob sie eine neue parachain oder eine vollig neue blockchain auf substrate erstellen – subquery kann ihnen helfen, die daten ihrer kette zu indizieren und fehler zu beheben. subquery wurde fur die einfache integration in eine benutzerdefinierte, auf substraten basierende kette entwickelt.\n\nlearn how to integrate with your chain\n\nunterstutzen und beitragen\n\nhaben sie eine frage oder mochten sie mehr wissen oder wie sie dazu beitragen konnen? wir wurden uns freuen, von dir zu horen. bitte kontaktieren sie uns per e-mail oder social media uber die untenstehenden links. benotigen sie technische expertise? treten sie unserer discord-community bei und erhalten sie unterstutzung von unseren leidenschaftlichen community-mitgliedern.\n\nteilnehmen dem gesprach auf discord\nkontaktieren sie uns hello@subquery.network\nfolgen sie uns in den sozialen netzwerken\ndiscord twitter medium telegramm github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"GraphQL-Schema",frontmatter:{summary:"GraphQL-Schema Definieren von Entitäten Die schema.graphql Datei definiert die verschiedenen GraphQL Schemas. Aufgrund der Funktionsweise der GraphQL-Abfragesprache bestimmt die Sc",meta:[{property:"og:url",content:"/de/create/graphql.html"},{property:"og:title",content:"GraphQL-Schema"},{property:"og:description",content:"GraphQL-Schema Definieren von Entitäten Die schema.graphql Datei definiert die verschiedenen GraphQL Schemas. Aufgrund der Funktionsweise der GraphQL-Abfragesprache bestimmt die Sc"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/create/graphql.html",relativePath:"de/create/graphql.md",key:"v-64c45226",path:"/de/create/graphql/",headers:[{level:2,title:"Definieren von Entitäten",slug:"definieren-von-entitaten",normalizedTitle:"definieren von entitaten",charIndex:21},{level:3,title:"Entitäten",slug:"entitaten",normalizedTitle:"entitaten",charIndex:36},{level:3,title:"Unterstützte Skalare und Typen",slug:"unterstutzte-skalare-und-typen",normalizedTitle:"unterstutzte skalare und typen",charIndex:1046},{level:2,title:"Indizierung nach Nicht-Primärschlüssel-Feld",slug:"indizierung-nach-nicht-primarschlussel-feld",normalizedTitle:"indizierung nach nicht-primarschlussel-feld",charIndex:1418},{level:2,title:"Entitäts-Beziehungen",slug:"entitats-beziehungen",normalizedTitle:"entitats-beziehungen",charIndex:3349},{level:3,title:"Ein-zu-Eins-Beziehungen",slug:"ein-zu-eins-beziehungen",normalizedTitle:"ein-zu-eins-beziehungen",charIndex:3743},{level:3,title:"One-to-Many Beziehungen",slug:"one-to-many-beziehungen",normalizedTitle:"one-to-many beziehungen",charIndex:4249},{level:3,title:"Viele-zu-Viele-Beziehungen",slug:"viele-zu-viele-beziehungen",normalizedTitle:"viele-zu-viele-beziehungen",charIndex:4563},{level:3,title:"Reverse-Lookups",slug:"reverse-lookups",normalizedTitle:"reverse-lookups",charIndex:5665},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:6494},{level:3,title:"JSON-Direktive definieren",slug:"json-direktive-definieren",normalizedTitle:"json-direktive definieren",charIndex:7258},{level:3,title:"Abfragen von JSON-Feldern",slug:"abfragen-von-json-feldern",normalizedTitle:"abfragen von json-feldern",charIndex:8031}],readingTime:{minutes:3.82,words:1147},headersStr:"Definieren von Entitäten Entitäten Unterstützte Skalare und Typen Indizierung nach Nicht-Primärschlüssel-Feld Entitäts-Beziehungen Ein-zu-Eins-Beziehungen One-to-Many Beziehungen Viele-zu-Viele-Beziehungen Reverse-Lookups JSON type JSON-Direktive definieren Abfragen von JSON-Feldern",content:"# GraphQL-Schema\n\n\n# Definieren von Entitäten\n\nDie schema.graphql Datei definiert die verschiedenen GraphQL Schemas. Aufgrund der Funktionsweise der GraphQL-Abfragesprache bestimmt die Schemadatei im Wesentlichen die Form Ihrer Daten aus SubQuery. Um mehr über das Schreiben in der GraphQL-Schemasprache zu erfahren, empfehlen wir Ihnen, sich Schemas und Typen anzusehen.\n\nWichtig: Wenn Sie Änderungen an der Schemadatei vornehmen, stellen Sie bitte sicher, dass Sie Ihr Typenverzeichnis mit dem folgenden Befehl yarn codegen. neu generieren\n\n\n# Entitäten\n\nJede Entität muss ihre Pflichtfelder id mit dem Typ ID! definieren. Er wird als Primärschlüssel verwendet und ist unter allen Entitäten desselben Typs eindeutig.\n\nFelder, die keine Null-Werte enthalten können, sind in der Entität durch gekennzeichnet Bitte sehen Sie das Beispiel unten:\n\nTyp Beispiel @entity {\n    id: ID! # id-Feld ist immer erforderlich und muss so aussehen\n   name: String! # Das ist ein Pflichtfeld\n   address: String # Dies ist ein optionales Feld\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Unterstützte Skalare und Typen\n\nWir unterstützen derzeit fließende Skalartypen:\n\n * ID\n * Int\n * String\n * BigInt\n * Datum\n * Boolean\n * <EntityName> für verschachtelte Beziehungsentitäten können Sie den Namen der definierten Entität als eines der Felder verwenden. Siehe Beziehungen zu Entitäten.\n * JSON kann strukturierte Daten alternativ speichern, siehe JSON-Typ\n\n\n# Indizierung nach Nicht-Primärschlüssel-Feld\n\nUm die Abfrageleistung zu verbessern, indizieren Sie ein Entitätsfeld einfach, indem Sie die Annotation @index in einem Nicht-Primärschlüsselfeld implementieren.\n\nAllerdings erlauben wir Benutzern nicht, @index Anmerkungen zu irgendeinem JSON Objekt hinzuzufügen. Standardmäßig werden Indizes automatisch zu Fremdschlüsseln und für JSON-Felder in der Datenbank hinzugefügt, jedoch nur, um die Leistung des Abfragedienstes zu verbessern.\n\nHier ist ein Beispiel.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) #  kann auf wahr oder falsch\n  Titel gesetzt werden!\n  title: Title! # Indizes werden automatisch zum Fremdschlüsselfeld hinzugefügt\n}\n\ntype Title @entity {\n  id: ID!\n  name: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\nAngenommen, wir kennen den Namen dieses Benutzers, kennen aber nicht den genauen ID-Wert, anstatt alle Benutzer zu extrahieren und dann nach Namen zu filtern, können wir @index hinter dem Namensfeld hinzufügen. Dies macht die Abfrage viel schneller und wir können zusätzlich das unique: true übergeben, um die Eindeutigkeit zu gewährleisten.\n\nWenn ein Feld nicht eindeutig ist, ist die maximale Ergebnismenge 100\n\nWenn die Codegenerierung ausgeführt wird, wird automatisch ein getByName nach dem Benutzer-Modell erstellt, und das Fremdschlüsselfeld Titel erstellt ein getByTitleId-Methode, die beide direkt in der Mapping-Funktion aufgerufen werden können.\n\n/* Vorbereitung eines Datensatzes für die Titelentität */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in der Mapping-Funktion\nimport {User} from '../types/models/User';\nimport {Title} from '../types/models/Title';\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // Liste aller Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entitäts-Beziehungen\n\nEine Entität hat oft verschachtelte Beziehungen zu anderen Entitäten. Wenn Sie den Feldwert auf einen anderen Entitätsnamen festlegen, wird standardmäßig eine Eins-zu-Eins-Beziehung zwischen diesen beiden Entitäten definiert.\n\nAnhand der folgenden Beispiele können verschiedene Entitätsbeziehungen (eins-zu-eins, eins-zu-viele und viele-zu-viele) konfiguriert werden.\n\n\n# Ein-zu-Eins-Beziehungen\n\nEins-zu-eins-Beziehungen sind die Standardeinstellung, wenn nur eine einzelne Entität einer anderen zugeordnet wird.\n\nBeispiel: Ein Reisepass gehört nur einer Person und eine Person hat nur einen Reisepass (in diesem Beispiel):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  Besitzer: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\noder\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many Beziehungen\n\nSie können eckige Klammern verwenden, um anzugeben, dass ein Feldtyp mehrere Entitäten enthält.\n\nBeispiel: Eine Person kann mehrere Konten haben.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account]\n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Viele-zu-Viele-Beziehungen\n\nEine Viele-zu-Viele-Beziehung kann erreicht werden, indem eine Abbildungsentität implementiert wird, um die anderen beiden Entitäten zu verbinden.\n\nBeispiel: Jede Person ist Teil mehrerer Gruppen (PersonGroup) und Gruppen haben mehrere verschiedene Personen (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAußerdem ist es möglich, eine Verbindung derselben Entität in mehreren Feldern der mittleren Entität zu erstellen.\n\nEin Konto kann beispielsweise über mehrere Überweisungen verfügen und jede Überweisung hat ein Quell- und ein Zielkonto.\n\nDadurch wird eine bidirektionale Beziehung zwischen zwei Konten (von und zu) über die Transfertabelle hergestellt.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse-Lookups\n\nUm eine umgekehrte Suche einer Entität zu einer Beziehung zu ermöglichen, hängen Sie @derivedFrom an das Feld an und zeigen Sie auf ihr umgekehrtes Nachschlagefeld einer anderen Entität.\n\nDadurch wird ein virtuelles Feld auf der Entität erstellt, das abgefragt werden kann.\n\nAuf die Überweisung \"von\" einem Konto kann von der Kontoentität aus zugegriffen werden, indem der Wert von sentTransfer oder ReceivedTransfer so eingestellt wird, dass ihr Wert aus den entsprechenden from- oder to-Feldern abgeleitet wird.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWir unterstützen das Speichern von Daten als JSON-Typ, was eine schnelle Möglichkeit zum Speichern strukturierter Daten darstellt. Wir generieren automatisch entsprechende JSON-Schnittstellen zum Abfragen dieser Daten und sparen Ihnen Zeit beim Definieren und Verwalten von Entitäten.\n\nWir empfehlen Benutzern, den JSON-Typ in den folgenden Szenarien zu verwenden:\n\n * Das Speichern strukturierter Daten in einem einzelnen Feld ist einfacher zu verwalten als das Erstellen mehrerer separater Entitäten.\n * Speichern beliebiger Schlüssel/Wert-Benutzereinstellungen (wobei der Wert boolesch, textuell oder numerisch sein kann und Sie keine separaten Spalten für verschiedene Datentypen haben möchten)\n * Das Schema ist flüchtig und ändert sich häufig\n\n\n# JSON-Direktive definieren\n\nDefinieren Sie die Eigenschaft als JSON-Typ, indem Sie die Annotation jsonField in der Entität hinzufügen. Dadurch werden automatisch Schnittstellen für alle JSON-Objekte in Ihrem Projekt unter types/interfaces.ts generiert, auf die Sie in Ihrer Mapping-Funktion zugreifen können.\n\nIm Gegensatz zur Entität erfordert das jsonField-Direktivenobjekt kein id-Feld. Ein JSON-Objekt kann auch mit anderen JSON-Objekten verschachtelt werden.\n\nschreibe AddressDetail @jsonField {\n   street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID!\n  contact: [ContactCard] # Speichern Sie eine Liste von JSON-Objekten\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Abfragen von JSON-Feldern\n\nDer Nachteil der Verwendung von JSON-Typen ist eine geringfügige Auswirkung auf die Abfrageeffizienz beim Filtern, da es sich bei jeder Textsuche um die gesamte Entität handelt.\n\nDie Auswirkungen sind in unserem Abfrageservice jedoch noch akzeptabel. Hier ist ein Beispiel für die Verwendung des Operators enthält in der GraphQL-Abfrage für ein JSON-Feld, um die ersten fünf Benutzer zu finden, die eine Telefonnummer besitzen, die „0064“ enthält.\n\n#Um die ersten 5 Benutzer zu finden, enthält die eigene Telefonnummer '0064'.\n\nquery {\n  user(first: 5, filter: {contactCard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",normalizedContent:"# graphql-schema\n\n\n# definieren von entitaten\n\ndie schema.graphql datei definiert die verschiedenen graphql schemas. aufgrund der funktionsweise der graphql-abfragesprache bestimmt die schemadatei im wesentlichen die form ihrer daten aus subquery. um mehr uber das schreiben in der graphql-schemasprache zu erfahren, empfehlen wir ihnen, sich schemas und typen anzusehen.\n\nwichtig: wenn sie anderungen an der schemadatei vornehmen, stellen sie bitte sicher, dass sie ihr typenverzeichnis mit dem folgenden befehl yarn codegen. neu generieren\n\n\n# entitaten\n\njede entitat muss ihre pflichtfelder id mit dem typ id! definieren. er wird als primarschlussel verwendet und ist unter allen entitaten desselben typs eindeutig.\n\nfelder, die keine null-werte enthalten konnen, sind in der entitat durch gekennzeichnet bitte sehen sie das beispiel unten:\n\ntyp beispiel @entity {\n    id: id! # id-feld ist immer erforderlich und muss so aussehen\n   name: string! # das ist ein pflichtfeld\n   address: string # dies ist ein optionales feld\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# unterstutzte skalare und typen\n\nwir unterstutzen derzeit fließende skalartypen:\n\n * id\n * int\n * string\n * bigint\n * datum\n * boolean\n * <entityname> fur verschachtelte beziehungsentitaten konnen sie den namen der definierten entitat als eines der felder verwenden. siehe beziehungen zu entitaten.\n * json kann strukturierte daten alternativ speichern, siehe json-typ\n\n\n# indizierung nach nicht-primarschlussel-feld\n\num die abfrageleistung zu verbessern, indizieren sie ein entitatsfeld einfach, indem sie die annotation @index in einem nicht-primarschlusselfeld implementieren.\n\nallerdings erlauben wir benutzern nicht, @index anmerkungen zu irgendeinem json objekt hinzuzufugen. standardmaßig werden indizes automatisch zu fremdschlusseln und fur json-felder in der datenbank hinzugefugt, jedoch nur, um die leistung des abfragedienstes zu verbessern.\n\nhier ist ein beispiel.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) #  kann auf wahr oder falsch\n  titel gesetzt werden!\n  title: title! # indizes werden automatisch zum fremdschlusselfeld hinzugefugt\n}\n\ntype title @entity {\n  id: id!\n  name: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\nangenommen, wir kennen den namen dieses benutzers, kennen aber nicht den genauen id-wert, anstatt alle benutzer zu extrahieren und dann nach namen zu filtern, konnen wir @index hinter dem namensfeld hinzufugen. dies macht die abfrage viel schneller und wir konnen zusatzlich das unique: true ubergeben, um die eindeutigkeit zu gewahrleisten.\n\nwenn ein feld nicht eindeutig ist, ist die maximale ergebnismenge 100\n\nwenn die codegenerierung ausgefuhrt wird, wird automatisch ein getbyname nach dem benutzer-modell erstellt, und das fremdschlusselfeld titel erstellt ein getbytitleid-methode, die beide direkt in der mapping-funktion aufgerufen werden konnen.\n\n/* vorbereitung eines datensatzes fur die titelentitat */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in der mapping-funktion\nimport {user} from '../types/models/user';\nimport {title} from '../types/models/title';\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // liste aller captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entitats-beziehungen\n\neine entitat hat oft verschachtelte beziehungen zu anderen entitaten. wenn sie den feldwert auf einen anderen entitatsnamen festlegen, wird standardmaßig eine eins-zu-eins-beziehung zwischen diesen beiden entitaten definiert.\n\nanhand der folgenden beispiele konnen verschiedene entitatsbeziehungen (eins-zu-eins, eins-zu-viele und viele-zu-viele) konfiguriert werden.\n\n\n# ein-zu-eins-beziehungen\n\neins-zu-eins-beziehungen sind die standardeinstellung, wenn nur eine einzelne entitat einer anderen zugeordnet wird.\n\nbeispiel: ein reisepass gehort nur einer person und eine person hat nur einen reisepass (in diesem beispiel):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  besitzer: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\noder\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many beziehungen\n\nsie konnen eckige klammern verwenden, um anzugeben, dass ein feldtyp mehrere entitaten enthalt.\n\nbeispiel: eine person kann mehrere konten haben.\n\ntype person @entity {\n  id: id!\n  accounts: [account]\n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# viele-zu-viele-beziehungen\n\neine viele-zu-viele-beziehung kann erreicht werden, indem eine abbildungsentitat implementiert wird, um die anderen beiden entitaten zu verbinden.\n\nbeispiel: jede person ist teil mehrerer gruppen (persongroup) und gruppen haben mehrere verschiedene personen (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\naußerdem ist es moglich, eine verbindung derselben entitat in mehreren feldern der mittleren entitat zu erstellen.\n\nein konto kann beispielsweise uber mehrere uberweisungen verfugen und jede uberweisung hat ein quell- und ein zielkonto.\n\ndadurch wird eine bidirektionale beziehung zwischen zwei konten (von und zu) uber die transfertabelle hergestellt.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse-lookups\n\num eine umgekehrte suche einer entitat zu einer beziehung zu ermoglichen, hangen sie @derivedfrom an das feld an und zeigen sie auf ihr umgekehrtes nachschlagefeld einer anderen entitat.\n\ndadurch wird ein virtuelles feld auf der entitat erstellt, das abgefragt werden kann.\n\nauf die uberweisung \"von\" einem konto kann von der kontoentitat aus zugegriffen werden, indem der wert von senttransfer oder receivedtransfer so eingestellt wird, dass ihr wert aus den entsprechenden from- oder to-feldern abgeleitet wird.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwir unterstutzen das speichern von daten als json-typ, was eine schnelle moglichkeit zum speichern strukturierter daten darstellt. wir generieren automatisch entsprechende json-schnittstellen zum abfragen dieser daten und sparen ihnen zeit beim definieren und verwalten von entitaten.\n\nwir empfehlen benutzern, den json-typ in den folgenden szenarien zu verwenden:\n\n * das speichern strukturierter daten in einem einzelnen feld ist einfacher zu verwalten als das erstellen mehrerer separater entitaten.\n * speichern beliebiger schlussel/wert-benutzereinstellungen (wobei der wert boolesch, textuell oder numerisch sein kann und sie keine separaten spalten fur verschiedene datentypen haben mochten)\n * das schema ist fluchtig und andert sich haufig\n\n\n# json-direktive definieren\n\ndefinieren sie die eigenschaft als json-typ, indem sie die annotation jsonfield in der entitat hinzufugen. dadurch werden automatisch schnittstellen fur alle json-objekte in ihrem projekt unter types/interfaces.ts generiert, auf die sie in ihrer mapping-funktion zugreifen konnen.\n\nim gegensatz zur entitat erfordert das jsonfield-direktivenobjekt kein id-feld. ein json-objekt kann auch mit anderen json-objekten verschachtelt werden.\n\nschreibe addressdetail @jsonfield {\n   street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id!\n  contact: [contactcard] # speichern sie eine liste von json-objekten\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# abfragen von json-feldern\n\nder nachteil der verwendung von json-typen ist eine geringfugige auswirkung auf die abfrageeffizienz beim filtern, da es sich bei jeder textsuche um die gesamte entitat handelt.\n\ndie auswirkungen sind in unserem abfrageservice jedoch noch akzeptabel. hier ist ein beispiel fur die verwendung des operators enthalt in der graphql-abfrage fur ein json-feld, um die ersten funf benutzer zu finden, die eine telefonnummer besitzen, die „0064“ enthalt.\n\n#um die ersten 5 benutzer zu finden, enthalt die eigene telefonnummer '0064'.\n\nquery {\n  user(first: 5, filter: {contactcard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Erstellung eines SubQuery-Projekts",frontmatter:{summary:"Erstellung eines SubQuery-Projekts In der Kurzanleitung haben wir sehr schnell ein Beispiel durchgespielt, um Ihnen einen Eindruck davon zu geben, was SubQuery ist und wie es funkt",meta:[{property:"og:url",content:"/de/create/introduction.html"},{property:"og:title",content:"Erstellung eines SubQuery-Projekts"},{property:"og:description",content:"Erstellung eines SubQuery-Projekts In der Kurzanleitung haben wir sehr schnell ein Beispiel durchgespielt, um Ihnen einen Eindruck davon zu geben, was SubQuery ist und wie es funkt"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/create/introduction.html",relativePath:"de/create/introduction.md",key:"v-19f3891b",path:"/de/create/introduction/",headers:[{level:2,title:"Der grundlegende Arbeitsablauf",slug:"der-grundlegende-arbeitsablauf",normalizedTitle:"der grundlegende arbeitsablauf",charIndex:320},{level:2,title:"Verzeichnisaufbau",slug:"verzeichnisaufbau",normalizedTitle:"verzeichnisaufbau",charIndex:1414},{level:2,title:"Codegenerierung",slug:"codegenerierung",normalizedTitle:"codegenerierung",charIndex:1826},{level:2,title:"Bauen",slug:"bauen",normalizedTitle:"bauen",charIndex:2353},{level:2,title:"Protokollierung",slug:"protokollierung",normalizedTitle:"protokollierung",charIndex:2617}],readingTime:{minutes:1.7,words:511},headersStr:"Der grundlegende Arbeitsablauf Verzeichnisaufbau Codegenerierung Bauen Protokollierung",content:"# Erstellung eines SubQuery-Projekts\n\nIn der Kurzanleitung haben wir sehr schnell ein Beispiel durchgespielt, um Ihnen einen Eindruck davon zu geben, was SubQuery ist und wie es funktioniert. Hier sehen wir uns den Workflow beim Erstellen Ihres Projekts und die Schlüsseldateien, mit denen Sie arbeiten, genauer an.\n\n\n# Der grundlegende Arbeitsablauf\n\nEinige der folgenden Beispiele gehen davon aus, dass Sie das Startpaket im Abschnitt Schnellstart erfolgreich initialisiert haben. Ausgehend von diesem Startpaket durchlaufen wir den Standardprozess zum Anpassen und Implementieren Ihres SubQuery-Projekts.\n\n 1. Initialisieren Sie Ihr Projekt mit subql init PROJECT_NAME\n 2. Aktualisieren Sie die Manifestdatei (project.yaml), um Informationen über Ihre Blockchain und die zuzuordnenden Entitäten aufzunehmen – siehe Manifestdatei\n 3. Erstellen Sie GraphQL-Entitäten in Ihrem Schema (schema.graphql), die die Form der Daten definieren, die Sie extrahieren und für die Abfrage beibehalten – siehe GraphQL-Schema\n 4. Fügen Sie alle Mapping-Funktionen (zB mappingHandlers.ts) hinzu, die Sie aufrufen möchten, um Kettendaten in die von Ihnen definierten GraphQL-Entitäten umzuwandeln - siehe Mapping\n 5. Generieren, erstellen und veröffentlichen Sie Ihren Code in SubQuery-Projekten (oder führen Sie ihn in Ihrem eigenen lokalen Knoten aus) - siehe Starterprojekt ausführen und abfragen in unserer Kurzanleitung.\n\n\n# Verzeichnisaufbau\n\nDie folgende Übersicht bietet einen Überblick über die Verzeichnisstruktur eines SubQuery-Projekts, wenn der Befehl init ausgeführt wird.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nZum Beispiel:\n\n\n\n\n# Codegenerierung\n\nImmer wenn Sie Ihre GraphQL-Entitäten ändern, müssen Sie Ihr Typenverzeichnis mit dem folgenden Befehl neu generieren.\n\nyarn codegen\n\n\n1\n\n\nDadurch wird ein neues Verzeichnis erstellt (oder das vorhandene aktualisiert) src/types, das generierte Entitätsklassen für jeden Typ enthält, den Sie zuvor in schema.graphql definiert haben. Diese Klassen bieten typsicheres Laden von Entitäten sowie Lese- und Schreibzugriff auf Entitätsfelder. Weitere Informationen zu diesem Prozess finden Sie im GraphQL-Schema.\n\n\n# Bauen\n\nUm Ihr SubQuery-Projekt auf einem lokal gehosteten SubQuery-Knoten auszuführen, müssen Sie zuerst Ihre Arbeit erstellen.\n\nFühren Sie den Build-Befehl aus dem Stammverzeichnis des Projekts aus.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Protokollierung\n\nDie console.log Methode wird nicht mehr unterstützt. Stattdessen wurde ein Logger-Modul in die Typen eingefügt, was bedeutet, dass wir einen Logger unterstützen können, der verschiedene Logging-Level akzeptiert.\n\nlogger.info('Info Level Message');\nlogger.debug('Debugger Level Message');\nlogger.warn('Warnung Level Message');\n\n\n1\n2\n3\n\n\nUm logger.info oder logger.warnzu verwenden, legen Sie die Zeile einfach in Ihre Mapping-Datei ein.\n\n\n\nUm logger.debugzu verwenden, ist ein zusätzlicher Schritt erforderlich. Fügen Sie --log-level=debug zu Ihrer Befehlszeile hinzu.\n\nWenn Sie einen Docker-Container ausführen, fügen Sie diese Zeile zu Ihrer Datei docker-compose.yaml hinzu.\n\n\n\nSie sollten nun die neue Protokollierung auf dem Terminalbildschirm sehen.\n\n",normalizedContent:"# erstellung eines subquery-projekts\n\nin der kurzanleitung haben wir sehr schnell ein beispiel durchgespielt, um ihnen einen eindruck davon zu geben, was subquery ist und wie es funktioniert. hier sehen wir uns den workflow beim erstellen ihres projekts und die schlusseldateien, mit denen sie arbeiten, genauer an.\n\n\n# der grundlegende arbeitsablauf\n\neinige der folgenden beispiele gehen davon aus, dass sie das startpaket im abschnitt schnellstart erfolgreich initialisiert haben. ausgehend von diesem startpaket durchlaufen wir den standardprozess zum anpassen und implementieren ihres subquery-projekts.\n\n 1. initialisieren sie ihr projekt mit subql init project_name\n 2. aktualisieren sie die manifestdatei (project.yaml), um informationen uber ihre blockchain und die zuzuordnenden entitaten aufzunehmen – siehe manifestdatei\n 3. erstellen sie graphql-entitaten in ihrem schema (schema.graphql), die die form der daten definieren, die sie extrahieren und fur die abfrage beibehalten – siehe graphql-schema\n 4. fugen sie alle mapping-funktionen (zb mappinghandlers.ts) hinzu, die sie aufrufen mochten, um kettendaten in die von ihnen definierten graphql-entitaten umzuwandeln - siehe mapping\n 5. generieren, erstellen und veroffentlichen sie ihren code in subquery-projekten (oder fuhren sie ihn in ihrem eigenen lokalen knoten aus) - siehe starterprojekt ausfuhren und abfragen in unserer kurzanleitung.\n\n\n# verzeichnisaufbau\n\ndie folgende ubersicht bietet einen uberblick uber die verzeichnisstruktur eines subquery-projekts, wenn der befehl init ausgefuhrt wird.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nzum beispiel:\n\n\n\n\n# codegenerierung\n\nimmer wenn sie ihre graphql-entitaten andern, mussen sie ihr typenverzeichnis mit dem folgenden befehl neu generieren.\n\nyarn codegen\n\n\n1\n\n\ndadurch wird ein neues verzeichnis erstellt (oder das vorhandene aktualisiert) src/types, das generierte entitatsklassen fur jeden typ enthalt, den sie zuvor in schema.graphql definiert haben. diese klassen bieten typsicheres laden von entitaten sowie lese- und schreibzugriff auf entitatsfelder. weitere informationen zu diesem prozess finden sie im graphql-schema.\n\n\n# bauen\n\num ihr subquery-projekt auf einem lokal gehosteten subquery-knoten auszufuhren, mussen sie zuerst ihre arbeit erstellen.\n\nfuhren sie den build-befehl aus dem stammverzeichnis des projekts aus.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# protokollierung\n\ndie console.log methode wird nicht mehr unterstutzt. stattdessen wurde ein logger-modul in die typen eingefugt, was bedeutet, dass wir einen logger unterstutzen konnen, der verschiedene logging-level akzeptiert.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warnung level message');\n\n\n1\n2\n3\n\n\num logger.info oder logger.warnzu verwenden, legen sie die zeile einfach in ihre mapping-datei ein.\n\n\n\num logger.debugzu verwenden, ist ein zusatzlicher schritt erforderlich. fugen sie --log-level=debug zu ihrer befehlszeile hinzu.\n\nwenn sie einen docker-container ausfuhren, fugen sie diese zeile zu ihrer datei docker-compose.yaml hinzu.\n\n\n\nsie sollten nun die neue protokollierung auf dem terminalbildschirm sehen.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Manifest-Datei",frontmatter:{summary:"Manifest-Datei Die Datei Manifest project.yaml kann als Einstiegspunkt Ihres Projekts angesehen werden und definiert die meisten Details darüber, wie SubQuery die Kettendaten indiz",meta:[{property:"og:url",content:"/de/create/manifest.html"},{property:"og:title",content:"Manifest-Datei"},{property:"og:description",content:"Manifest-Datei Die Datei Manifest project.yaml kann als Einstiegspunkt Ihres Projekts angesehen werden und definiert die meisten Details darüber, wie SubQuery die Kettendaten indiz"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/create/manifest.html",relativePath:"de/create/manifest.md",key:"v-4f881571",path:"/de/create/manifest/",headers:[{level:2,title:"Netzwerkfilter",slug:"netzwerkfilter",normalizedTitle:"netzwerkfilter",charIndex:1972},{level:2,title:"Zuordnungsfilter",slug:"zuordnungsfilter",normalizedTitle:"zuordnungsfilter",charIndex:3514},{level:2,title:"Kundenspezifische Ketten",slug:"kundenspezifische-ketten",normalizedTitle:"kundenspezifische ketten",charIndex:4993}],readingTime:{minutes:2.44,words:731},headersStr:"Netzwerkfilter Zuordnungsfilter Kundenspezifische Ketten",content:"# Manifest-Datei\n\nDie Datei Manifest project.yaml kann als Einstiegspunkt Ihres Projekts angesehen werden und definiert die meisten Details darüber, wie SubQuery die Kettendaten indiziert und transformiert.\n\nDas Manifest kann entweder im YAML- oder im JSON-Format vorliegen. In diesem Dokument verwenden wir YAML in allen Beispielen. Unten ist ein Standardbeispiel für eine einfache project.yaml.\n\nspecVersion: '0.0.1'\ndescription: ''\nrepository: 'https://github.com/subquery/subql-starter'\n\nschema: './schema.graphql'\n\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: 'https://api.subquery.network/sq/subquery/dictionary-polkadot'\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary stellt optional den HTTP-Endpunkt eines vollständigen Kettenwörterbuchs bereit, um die Verarbeitung zu beschleunigen - siehe Ausführen eines Indexers\n * dataSources definiert die Daten, die gefiltert und extrahiert werden, sowie die Position des Mapping-Funktionshandlers für die anzuwendende Datentransformation.\n   * kind unterstützt vorerst nur Substrat/Runtime.\n   * startBlock gibt die Blockhöhe an, ab der die Indizierung gestartet werden soll.\n   * filter filtert die auszuführende Datenquelle nach dem Netzwerk-Endpunkt-Spezifikationsnamen, siehe Netzwerkfilter\n   * mapping.handlers listet alle Mapping-Funktionen und ihre entsprechenden Handler-Typen mit zusätzlichen Mapping-Filtern auf.\n\n\n# Netzwerkfilter\n\nNormalerweise erstellt der Benutzer eine SubQuery und erwartet, sie sowohl für seine Testnet- als auch für seine Mainnet-Umgebungen (z. B. Polkadot und Kusama) wiederzuverwenden. Zwischen Netzwerken sind wahrscheinlich verschiedene Optionen unterschiedlich (z. B. Index-Startblock). Daher ermöglichen wir es Benutzern, für jede Datenquelle unterschiedliche Details zu definieren, was bedeutet, dass ein SubQuery-Projekt immer noch in mehreren Netzwerken verwendet werden kann.\n\nBenutzer können einen Filter für dataSources hinzufügen, um zu entscheiden, welche Datenquelle in jedem Netzwerk ausgeführt werden soll.\n\nUnten sehen Sie ein Beispiel, das verschiedene Datenquellen für das Polkadot- und das Kusama-Netzwerk zeigt.\n\n\n---\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n\n#Erstellen Sie eine Vorlage, um Redundanzen zu vermeiden\nDefinitionen:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter: #Optional\n      specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter:\n      specName: kusama\n    startBlock: 12000\n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# Zuordnungsfilter\n\nMapping-Filter sind eine äußerst nützliche Funktion, um zu entscheiden, welcher Block, welches Ereignis oder welcher Extrinsic einen Mapping-Handler auslöst.\n\nNur eingehende Daten, die die Filterbedingungen erfüllen, werden von den Mapping-Funktionen verarbeitet. Zuordnungsfilter sind optional, werden jedoch empfohlen, da sie die von Ihrem SubQuery-Projekt verarbeitete Datenmenge erheblich reduzieren und die Indexierungsleistung verbessern.\n\n#Beispielfilter von callHandler\nFilter:\n    module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nIn der folgenden Tabelle werden Filter erläutert, die von verschiedenen Handlern unterstützt werden.\n\nHANDLER        UNTERSTÜTZTER FILTER\nBlockhandler   specVersion\nEventhandler   module,method\nCallHandler    module,method ,success\n\n * Modul- und Methodenfilter werden auf jeder substratbasierten Kette unterstützt.\n * Der Filter Erfolg nimmt einen booleschen Wert an und kann verwendet werden, um den Extrinsischen nach seinem Erfolgsstatus zu filtern.\n * Der Filter specVersion gibt den Spezifikationsversionsbereich für einen Substratblock an. In den folgenden Beispielen wird beschrieben, wie Versionsbereiche festgelegt werden.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index Block mit specVersion größer oder gleich 100.\n  specVersion: [null, 23] #Indexblock mit specVersion kleiner oder gleich 23.\n\n\n1\n2\n3\n4\n\n\n\n# Kundenspezifische Ketten\n\nSie können Daten aus benutzerdefinierten Ketten indizieren, indem Sie auch Kettentypen in die project.yaml aufnehmen. Deklarieren Sie die spezifischen Typen, die von dieser Blockchain unterstützt werden, in network.types. Wir unterstützen die zusätzlichen Typen, die von Substrat-Laufzeitmodulen verwendet werden.\n\ntypesAlias, typesBundle, typesChain, und typesSpec werden ebenfalls unterstützt.\n\nspecVersion: '0.0.1'\ndescription: 'Diese SubQuery indiziert die Geburtsdaten von Kätzchen'\nrepository: 'https://github.com/onfinality-io/subql-examples'\nschema: './schema.graphql'\nnetwork:\n  endpoint: 'ws://host.kittychain.io/public-ws'\n  types: {'KittyIndex': 'u32', 'Kitty': '[u8; 16]'}\n# typesChain: { chain: { Type5: 'example' } }\n# typesSpec: { spec: { Type6: 'example' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter: #Optional\n      specName: kitty-chain\n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n",normalizedContent:"# manifest-datei\n\ndie datei manifest project.yaml kann als einstiegspunkt ihres projekts angesehen werden und definiert die meisten details daruber, wie subquery die kettendaten indiziert und transformiert.\n\ndas manifest kann entweder im yaml- oder im json-format vorliegen. in diesem dokument verwenden wir yaml in allen beispielen. unten ist ein standardbeispiel fur eine einfache project.yaml.\n\nspecversion: '0.0.1'\ndescription: ''\nrepository: 'https://github.com/subquery/subql-starter'\n\nschema: './schema.graphql'\n\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: 'https://api.subquery.network/sq/subquery/dictionary-polkadot'\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary stellt optional den http-endpunkt eines vollstandigen kettenworterbuchs bereit, um die verarbeitung zu beschleunigen - siehe ausfuhren eines indexers\n * datasources definiert die daten, die gefiltert und extrahiert werden, sowie die position des mapping-funktionshandlers fur die anzuwendende datentransformation.\n   * kind unterstutzt vorerst nur substrat/runtime.\n   * startblock gibt die blockhohe an, ab der die indizierung gestartet werden soll.\n   * filter filtert die auszufuhrende datenquelle nach dem netzwerk-endpunkt-spezifikationsnamen, siehe netzwerkfilter\n   * mapping.handlers listet alle mapping-funktionen und ihre entsprechenden handler-typen mit zusatzlichen mapping-filtern auf.\n\n\n# netzwerkfilter\n\nnormalerweise erstellt der benutzer eine subquery und erwartet, sie sowohl fur seine testnet- als auch fur seine mainnet-umgebungen (z. b. polkadot und kusama) wiederzuverwenden. zwischen netzwerken sind wahrscheinlich verschiedene optionen unterschiedlich (z. b. index-startblock). daher ermoglichen wir es benutzern, fur jede datenquelle unterschiedliche details zu definieren, was bedeutet, dass ein subquery-projekt immer noch in mehreren netzwerken verwendet werden kann.\n\nbenutzer konnen einen filter fur datasources hinzufugen, um zu entscheiden, welche datenquelle in jedem netzwerk ausgefuhrt werden soll.\n\nunten sehen sie ein beispiel, das verschiedene datenquellen fur das polkadot- und das kusama-netzwerk zeigt.\n\n\n---\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n\n#erstellen sie eine vorlage, um redundanzen zu vermeiden\ndefinitionen:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter: #optional\n      specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter:\n      specname: kusama\n    startblock: 12000\n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# zuordnungsfilter\n\nmapping-filter sind eine außerst nutzliche funktion, um zu entscheiden, welcher block, welches ereignis oder welcher extrinsic einen mapping-handler auslost.\n\nnur eingehende daten, die die filterbedingungen erfullen, werden von den mapping-funktionen verarbeitet. zuordnungsfilter sind optional, werden jedoch empfohlen, da sie die von ihrem subquery-projekt verarbeitete datenmenge erheblich reduzieren und die indexierungsleistung verbessern.\n\n#beispielfilter von callhandler\nfilter:\n    module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nin der folgenden tabelle werden filter erlautert, die von verschiedenen handlern unterstutzt werden.\n\nhandler        unterstutzter filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * modul- und methodenfilter werden auf jeder substratbasierten kette unterstutzt.\n * der filter erfolg nimmt einen booleschen wert an und kann verwendet werden, um den extrinsischen nach seinem erfolgsstatus zu filtern.\n * der filter specversion gibt den spezifikationsversionsbereich fur einen substratblock an. in den folgenden beispielen wird beschrieben, wie versionsbereiche festgelegt werden.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block mit specversion großer oder gleich 100.\n  specversion: [null, 23] #indexblock mit specversion kleiner oder gleich 23.\n\n\n1\n2\n3\n4\n\n\n\n# kundenspezifische ketten\n\nsie konnen daten aus benutzerdefinierten ketten indizieren, indem sie auch kettentypen in die project.yaml aufnehmen. deklarieren sie die spezifischen typen, die von dieser blockchain unterstutzt werden, in network.types. wir unterstutzen die zusatzlichen typen, die von substrat-laufzeitmodulen verwendet werden.\n\ntypesalias, typesbundle, typeschain, und typesspec werden ebenfalls unterstutzt.\n\nspecversion: '0.0.1'\ndescription: 'diese subquery indiziert die geburtsdaten von katzchen'\nrepository: 'https://github.com/onfinality-io/subql-examples'\nschema: './schema.graphql'\nnetwork:\n  endpoint: 'ws://host.kittychain.io/public-ws'\n  types: {'kittyindex': 'u32', 'kitty': '[u8; 16]'}\n# typeschain: { chain: { type5: 'example' } }\n# typesspec: { spec: { type6: 'example' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter: #optional\n      specname: kitty-chain\n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Zuordnung",frontmatter:{summary:"Zuordnung Zuordnungsfunktionen definieren, wie Kettendaten in die optimierten GraphQL-Entitäten umgewandelt werden, die wir zuvor in der Datei schema.graphql definiert haben. Mappi",meta:[{property:"og:url",content:"/de/create/mapping.html"},{property:"og:title",content:"Zuordnung"},{property:"og:description",content:"Zuordnung Zuordnungsfunktionen definieren, wie Kettendaten in die optimierten GraphQL-Entitäten umgewandelt werden, die wir zuvor in der Datei schema.graphql definiert haben. Mappi"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/create/mapping.html",relativePath:"de/create/mapping.md",key:"v-f95dcc66",path:"/de/create/mapping/",headers:[{level:2,title:"Blockhandler",slug:"blockhandler",normalizedTitle:"blockhandler",charIndex:593},{level:2,title:"Ereignishandler",slug:"ereignishandler",normalizedTitle:"ereignishandler",charIndex:607},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:2747},{level:2,title:"Abfragestatus",slug:"abfragestatus",normalizedTitle:"abfragestatus",charIndex:3418},{level:2,title:"RPC-Anrufe",slug:"rpc-anrufe",normalizedTitle:"rpc-anrufe",charIndex:4565},{level:2,title:"Module und Bibliotheken",slug:"module-und-bibliotheken",normalizedTitle:"module und bibliotheken",charIndex:5711},{level:3,title:"Eingebaute Module",slug:"eingebaute-module",normalizedTitle:"eingebaute module",charIndex:6263},{level:3,title:"Bibliotheken von Drittanbietern",slug:"bibliotheken-von-drittanbietern",normalizedTitle:"bibliotheken von drittanbietern",charIndex:5943},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:7334},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:7688},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10764},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11985},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:12207}],readingTime:{minutes:6.85,words:2054},headersStr:"Blockhandler Ereignishandler Call Handler Abfragestatus RPC-Anrufe Module und Bibliotheken Eingebaute Module Bibliotheken von Drittanbietern Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Zuordnung\n\nZuordnungsfunktionen definieren, wie Kettendaten in die optimierten GraphQL-Entitäten umgewandelt werden, die wir zuvor in der Datei schema.graphql definiert haben.\n\nMappings werden in einer Teilmenge von TypeScript namens AssemblyScript geschrieben, die in WASM (WebAssembly) kompiliert werden kann.\n\n * Mappings werden im Verzeichnis src/mappings definiert und als Funktion exportiert\n * Diese Zuordnungen werden auch in src/index.ts exportiert\n * Die Mapping-Dateien sind in project.yaml unter den Mapping-Handlern referenziert.\n\nEs gibt drei Klassen von Zuordnungsfunktionen; Blockhandler, Ereignishandler und Anrufhandler.\n\n\n# Blockhandler\n\nSie können Blockhandler verwenden, um jedes Mal Informationen zu erfassen, wenn ein neuer Block an die Substratkette angehängt wird, z. Blocknummer. Dazu wird für jeden Block einmal ein definierter BlockHandler aufgerufen.\n\nimport {SubstrateBlock} from \'@subql/types\';\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n  // Create a new StarterEntity with the block hash as it\'s ID\n  const record = new starterEntity(block.block.header.hash.toString());\n  record.field1 = block.block.header.number.toNumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nEin SubstrateBlock ist ein erweiterter Schnittstellentyp von signedBlock, beinhaltet aber auch die specVersion und den timestamp.\n\n\n# Ereignishandler\n\nSie können Ereignishandler verwenden, um Informationen zu erfassen, wenn bestimmte Ereignisse in einem neuen Block enthalten sind. Die Ereignisse, die Teil der standardmäßigen Substrate-Laufzeit und ein Block sind, können mehrere Ereignisse enthalten.\n\nWährend der Verarbeitung erhält der Ereignishandler ein Substratereignis als Argument mit den typisierten Ein- und Ausgaben des Ereignisses. Jede Art von Ereignis löst das Mapping aus, sodass Aktivitäten mit der Datenquelle erfasst werden können. Sie sollten in Ihrem Manifest Zuordnungsfilter verwenden, um Ereignisse zu filtern, um die Zeit zum Indexieren von Daten zu verkürzen und die Zuordnungsleistung zu verbessern.\n\nimportiere {SubstrateEvent} aus "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n     const {Ereignis: {Daten: [Konto, Kontostand]}} = Ereignis;\n     // Abrufen des Datensatzes nach seiner ID\n     const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n     record.field2 = account.toString();\n     record.field3 = (saldo als Balance).toBigInt();\n     warten record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nEin SubstrateEvent ist ein erweiterter Schnittstellentyp des EventRecord. Neben den Ereignisdaten enthält es auch eine id (der Block, zu dem dieses Ereignis gehört) und die Extrinsic innerhalb dieses Blocks.\n\n\n# Call Handler\n\nCall-Handler werden verwendet, wenn Sie Informationen zu bestimmten externen Substraten erfassen möchten.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    warten record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nDas SubstrateExtrinsic erweitert GenericExtrinsic. Ihm wird eine id zugewiesen (der Block, zu dem diese Extrinsic gehört) und stellt eine extrinsische Eigenschaft bereit, die die Ereignisse innerhalb dieses Blocks erweitert. Darüber hinaus zeichnet es den Erfolgsstatus dieses Extrinsic auf.\n\n\n# Abfragestatus\n\nUnser Ziel ist es, alle Datenquellen für Benutzer für das Mapping von Handlern abzudecken (mehr als nur die drei oben genannten Schnittstellenereignistypen). Aus diesem Grund haben wir einige der @polkadot/api-Schnittstellen bereitgestellt, um die Fähigkeiten zu erweitern.\n\nDies sind die Schnittstellen, die wir derzeit unterstützen:\n\n * api.query.<module>.<method>() fragt den aktuellen Block ab.\n * 72 / 5000 api.query.<module>.<method>.multi() führt im aktuellen Block mehrere Abfragen des gleichen-Typs durch.\n * api.queryMulti() führt im aktuellen Block mehrere Abfragen verschiedener Typen durch.\n\nDies sind die Schnittstellen, die wir derzeit NICHT unterstützen:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.abfrage.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSehen Sie sich ein Beispiel für die Verwendung dieser API in unserem validator-threshold-Beispielanwendungsfall an.\n\n\n# RPC-Anrufe\n\nWir unterstützen auch einige API-RPC-Methoden, bei denen es sich um Remoteaufrufe handelt, die es der Zuordnungsfunktion ermöglichen, mit dem tatsächlichen Knoten, der Abfrage und der Übermittlung zu interagieren. Eine Kernprämisse von SubQuery ist, dass es deterministisch ist. Um die Ergebnisse konsistent zu halten, erlauben wir daher nur historische RPC-Aufrufe.\n\nDokumente in JSON-RPC stellen einige Methoden bereit, die BlockHash als Eingabeparameter verwenden (z. B. at?: BlockHash), die jetzt erlaubt sind. Wir haben diese Methoden auch geändert, um standardmäßig den aktuellen Indexierungsblock-Hash zu verwenden.\n\n// Nehmen wir an, wir indizieren gerade einen Block mit dieser Hash-Nummer\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Originalmethode hat eine optionale Eingabe ist Blockhash\nconst b1 = warten api.rpc.chain.getBlock(blockhash);\n\n// Es wird der aktuelle Block verwendet, der standardmäßig so ist\nconst b2 = api.rpc.chain.getBlock() erwarten;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * Informationen zu Benutzerdefinierten Substratketten RPC-Aufrufen finden Sie unter Verwendung.\n\n\n# Module und Bibliotheken\n\nUm die Datenverarbeitungsfähigkeiten von SubQuery zu verbessern, haben wir einige der integrierten Module von NodeJS zum Ausführen von Mapping-Funktionen in der Sandbox zugelassen und den Benutzern erlaubt, Bibliotheken von Drittanbietern aufzurufen.\n\nBitte beachten Sie, dass dies eine experimentelle Funktion ist und Sie möglicherweise auf Fehler oder Probleme stoßen, die sich negativ auf Ihre Mapping-Funktionen auswirken können. Bitte melden Sie alle Fehler, die Sie finden, indem Sie ein Problem in GitHub erstellen.\n\n\n# Eingebaute Module\n\nDerzeit erlauben wir die folgenden NodeJS-Module: assert, buffer, crypto, util und path.\n\nAnstatt das gesamte Modul zu importieren, empfehlen wir, nur die erforderliche(n) Methode(n) zu importieren. Einige Methoden in diesen Modulen weisen möglicherweise nicht unterstützte Abhängigkeiten auf und schlagen beim Importieren fehl.\n\nimport {hashMessage} from \'ethers/lib/utils\'; //Good way\nimport {utils} from \'ethers\'; //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n  const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n  record.field1 = hashMessage(\'Hello\');\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Bibliotheken von Drittanbietern\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport {default as kitties} from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n    // this is the package name we use (in the interface imports, --package for generators) */\n    "kitty-birthinfo/*": ["src/*"],\n    // here we replace the @polkadot/api augmentation with our own, generated from chain\n    "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n    // replace the augmented types with our own, as generated from definitions\n    "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n  //return the KittyIndex type\n  const nextKittyId = await api.query.kitties.nextKittyId();\n  // return the Kitty type, input parameters types are AccountId and KittyIndex\n  const allKitties = await api.query.kitties.kitties(\'xxxxxxxxx\', 123);\n  logger.info(`Next kitty id ${nextKittyId}`);\n  //Custom rpc, set undefined to blockhash\n  const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined, nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# zuordnung\n\nzuordnungsfunktionen definieren, wie kettendaten in die optimierten graphql-entitaten umgewandelt werden, die wir zuvor in der datei schema.graphql definiert haben.\n\nmappings werden in einer teilmenge von typescript namens assemblyscript geschrieben, die in wasm (webassembly) kompiliert werden kann.\n\n * mappings werden im verzeichnis src/mappings definiert und als funktion exportiert\n * diese zuordnungen werden auch in src/index.ts exportiert\n * die mapping-dateien sind in project.yaml unter den mapping-handlern referenziert.\n\nes gibt drei klassen von zuordnungsfunktionen; blockhandler, ereignishandler und anrufhandler.\n\n\n# blockhandler\n\nsie konnen blockhandler verwenden, um jedes mal informationen zu erfassen, wenn ein neuer block an die substratkette angehangt wird, z. blocknummer. dazu wird fur jeden block einmal ein definierter blockhandler aufgerufen.\n\nimport {substrateblock} from \'@subql/types\';\n\nexport async function handleblock(block: substrateblock): promise<void> {\n  // create a new starterentity with the block hash as it\'s id\n  const record = new starterentity(block.block.header.hash.tostring());\n  record.field1 = block.block.header.number.tonumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nein substrateblock ist ein erweiterter schnittstellentyp von signedblock, beinhaltet aber auch die specversion und den timestamp.\n\n\n# ereignishandler\n\nsie konnen ereignishandler verwenden, um informationen zu erfassen, wenn bestimmte ereignisse in einem neuen block enthalten sind. die ereignisse, die teil der standardmaßigen substrate-laufzeit und ein block sind, konnen mehrere ereignisse enthalten.\n\nwahrend der verarbeitung erhalt der ereignishandler ein substratereignis als argument mit den typisierten ein- und ausgaben des ereignisses. jede art von ereignis lost das mapping aus, sodass aktivitaten mit der datenquelle erfasst werden konnen. sie sollten in ihrem manifest zuordnungsfilter verwenden, um ereignisse zu filtern, um die zeit zum indexieren von daten zu verkurzen und die zuordnungsleistung zu verbessern.\n\nimportiere {substrateevent} aus "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n     const {ereignis: {daten: [konto, kontostand]}} = ereignis;\n     // abrufen des datensatzes nach seiner id\n     const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n     record.field2 = account.tostring();\n     record.field3 = (saldo als balance).tobigint();\n     warten record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nein substrateevent ist ein erweiterter schnittstellentyp des eventrecord. neben den ereignisdaten enthalt es auch eine id (der block, zu dem dieses ereignis gehort) und die extrinsic innerhalb dieses blocks.\n\n\n# call handler\n\ncall-handler werden verwendet, wenn sie informationen zu bestimmten externen substraten erfassen mochten.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    warten record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\ndas substrateextrinsic erweitert genericextrinsic. ihm wird eine id zugewiesen (der block, zu dem diese extrinsic gehort) und stellt eine extrinsische eigenschaft bereit, die die ereignisse innerhalb dieses blocks erweitert. daruber hinaus zeichnet es den erfolgsstatus dieses extrinsic auf.\n\n\n# abfragestatus\n\nunser ziel ist es, alle datenquellen fur benutzer fur das mapping von handlern abzudecken (mehr als nur die drei oben genannten schnittstellenereignistypen). aus diesem grund haben wir einige der @polkadot/api-schnittstellen bereitgestellt, um die fahigkeiten zu erweitern.\n\ndies sind die schnittstellen, die wir derzeit unterstutzen:\n\n * api.query.<module>.<method>() fragt den aktuellen block ab.\n * 72 / 5000 api.query.<module>.<method>.multi() fuhrt im aktuellen block mehrere abfragen des gleichen-typs durch.\n * api.querymulti() fuhrt im aktuellen block mehrere abfragen verschiedener typen durch.\n\ndies sind die schnittstellen, die wir derzeit nicht unterstutzen:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.abfrage.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsehen sie sich ein beispiel fur die verwendung dieser api in unserem validator-threshold-beispielanwendungsfall an.\n\n\n# rpc-anrufe\n\nwir unterstutzen auch einige api-rpc-methoden, bei denen es sich um remoteaufrufe handelt, die es der zuordnungsfunktion ermoglichen, mit dem tatsachlichen knoten, der abfrage und der ubermittlung zu interagieren. eine kernpramisse von subquery ist, dass es deterministisch ist. um die ergebnisse konsistent zu halten, erlauben wir daher nur historische rpc-aufrufe.\n\ndokumente in json-rpc stellen einige methoden bereit, die blockhash als eingabeparameter verwenden (z. b. at?: blockhash), die jetzt erlaubt sind. wir haben diese methoden auch geandert, um standardmaßig den aktuellen indexierungsblock-hash zu verwenden.\n\n// nehmen wir an, wir indizieren gerade einen block mit dieser hash-nummer\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// originalmethode hat eine optionale eingabe ist blockhash\nconst b1 = warten api.rpc.chain.getblock(blockhash);\n\n// es wird der aktuelle block verwendet, der standardmaßig so ist\nconst b2 = api.rpc.chain.getblock() erwarten;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * informationen zu benutzerdefinierten substratketten rpc-aufrufen finden sie unter verwendung.\n\n\n# module und bibliotheken\n\num die datenverarbeitungsfahigkeiten von subquery zu verbessern, haben wir einige der integrierten module von nodejs zum ausfuhren von mapping-funktionen in der sandbox zugelassen und den benutzern erlaubt, bibliotheken von drittanbietern aufzurufen.\n\nbitte beachten sie, dass dies eine experimentelle funktion ist und sie moglicherweise auf fehler oder probleme stoßen, die sich negativ auf ihre mapping-funktionen auswirken konnen. bitte melden sie alle fehler, die sie finden, indem sie ein problem in github erstellen.\n\n\n# eingebaute module\n\nderzeit erlauben wir die folgenden nodejs-module: assert, buffer, crypto, util und path.\n\nanstatt das gesamte modul zu importieren, empfehlen wir, nur die erforderliche(n) methode(n) zu importieren. einige methoden in diesen modulen weisen moglicherweise nicht unterstutzte abhangigkeiten auf und schlagen beim importieren fehl.\n\nimport {hashmessage} from \'ethers/lib/utils\'; //good way\nimport {utils} from \'ethers\'; //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n  const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n  record.field1 = hashmessage(\'hello\');\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# bibliotheken von drittanbietern\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport {default as kitties} from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n    // this is the package name we use (in the interface imports, --package for generators) */\n    "kitty-birthinfo/*": ["src/*"],\n    // here we replace the @polkadot/api augmentation with our own, generated from chain\n    "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n    // replace the augmented types with our own, as generated from definitions\n    "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n  //return the kittyindex type\n  const nextkittyid = await api.query.kitties.nextkittyid();\n  // return the kitty type, input parameters types are accountid and kittyindex\n  const allkitties = await api.query.kitties.kitties(\'xxxxxxxxx\', 123);\n  logger.info(`next kitty id ${nextkittyid}`);\n  //custom rpc, set undefined to blockhash\n  const kittyprice = await api.rpc.kitties.getkittyprice(undefined, nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/de/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/faqs/faqs.html",relativePath:"de/faqs/faqs.md",key:"v-3d649b57",path:"/de/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/de/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/install/install.html",relativePath:"de/install/install.md",key:"v-46088ee7",path:"/de/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/de/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/miscellaneous/ambassadors.html",relativePath:"de/miscellaneous/ambassadors.md",key:"v-4f6d6333",path:"/de/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/de/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/miscellaneous/branding.html",relativePath:"de/miscellaneous/branding.md",key:"v-25b5132d",path:"/de/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/de/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/miscellaneous/contributing.html",relativePath:"de/miscellaneous/contributing.md",key:"v-220de14d",path:"/de/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/de/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/miscellaneous/social_media.html",relativePath:"de/miscellaneous/social_media.md",key:"v-8fd36766",path:"/de/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/de/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/publish/connect.html",relativePath:"de/publish/connect.md",key:"v-576a0161",path:"/de/publish/connect/",readingTime:{minutes:.61,words:182},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/de/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/publish/publish.html",relativePath:"de/publish/publish.md",key:"v-45bb1917",path:"/de/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3817},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4272}],readingTime:{minutes:3.78,words:1134},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. Um Ihr GitHub-Organisationskonto zu verbinden, können Sie die Schritte hier ausführen.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. _We're almost there! We just need to deploy a new version of it. _\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. um ihr github-organisationskonto zu verbinden, konnen sie die schritte hier ausfuhren.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. _we're almost there! we just need to deploy a new version of it. _\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/de/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/query/graphql.html",relativePath:"de/query/graphql.md",key:"v-03e13271",path:"/de/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/de/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/publish/upgrade.html",relativePath:"de/publish/upgrade.md",key:"v-04677efd",path:"/de/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/de/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/query/query.html",relativePath:"de/query/query.md",key:"v-306d6933",path:"/de/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/de/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/quickstart/helloworld-hosted.html",relativePath:"de/quickstart/helloworld-hosted.md",key:"v-754465ed",path:"/de/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/de/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/quickstart/helloworld-localhost.html",relativePath:"de/quickstart/helloworld-localhost.md",key:"v-756db2b5",path:"/de/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"Step 1: Initialise project",slug:"step-1-initialise-project",normalizedTitle:"step 1: initialise project",charIndex:1455},{level:2,title:"Step 2: Install dependencies",slug:"step-2-install-dependencies",normalizedTitle:"step 2: install dependencies",charIndex:2035},{level:2,title:"Step 3: Generate code",slug:"step-3-generate-code",normalizedTitle:"step 3: generate code",charIndex:2477},{level:2,title:"Step 4: Build code",slug:"step-4-build-code",normalizedTitle:"step 4: build code",charIndex:3087},{level:2,title:"Step 5: Run Docker",slug:"step-5-run-docker",normalizedTitle:"step 5: run docker",charIndex:3319},{level:2,title:"Step 6: Browse playground",slug:"step-6-browse-playground",normalizedTitle:"step 6: browse playground",charIndex:4586},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:5027}],readingTime:{minutes:2.85,words:855},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Initialise project Step 2: Install dependencies Step 3: Generate code Step 4: Build code Step 5: Run Docker Step 6: Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Step 5: Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Step 6: Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# step 5: run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# step 6: browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/de/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/quickstart/quickstart.html",relativePath:"de/quickstart/quickstart.md",key:"v-e30ce652",path:"/de/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2566},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3009},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3388},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3628},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3981},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4548},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5235}],readingTime:{minutes:3.22,words:967},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/de/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/quickstart/understanding-helloworld.html",relativePath:"de/quickstart/understanding-helloworld.md",key:"v-76f709af",path:"/de/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1170},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:2007},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2348},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2575},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3256}],readingTime:{minutes:2.27,words:681},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. Wie in der offiziellen Dokumentation vermerkt, arbeiten Sie hauptsächlich an den folgenden Dateien:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. wie in der offiziellen dokumentation vermerkt, arbeiten sie hauptsachlich an den folgenden dateien:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/de/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/run/run.html",relativePath:"de/run/run.md",key:"v-bc8b07b2",path:"/de/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3939},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4182}],readingTime:{minutes:2.57,words:772},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/de/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/run/sandbox.html",relativePath:"de/run/sandbox.md",key:"v-5c0f832f",path:"/de/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to change the blockchain fetching batch size?",frontmatter:{summary:"How to change the blockchain fetching batch size? Video guide Introduction The default batch size is 100, but this can be changed by using the extra command --batch-size=xx. You ne",meta:[{property:"og:url",content:"/de/tutorials_examples/batch-size.html"},{property:"og:title",content:"How to change the blockchain fetching batch size?"},{property:"og:description",content:"How to change the blockchain fetching batch size? Video guide Introduction The default batch size is 100, but this can be changed by using the extra command --batch-size=xx. You ne"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/tutorials_examples/batch-size.html",relativePath:"de/tutorials_examples/batch-size.md",key:"v-59012e95",path:"/de/tutorials_examples/batch-size/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:56},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:72},{level:2,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:744}],readingTime:{minutes:.47,words:141},headersStr:"Video guide Introduction Why change the batch size?",content:'# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive.',normalizedContent:'# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to start at a different block height?",frontmatter:{summary:"How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from b",meta:[{property:"og:url",content:"/de/tutorials_examples/block-height.html"},{property:"og:title",content:"How to start at a different block height?"},{property:"og:description",content:"How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from b"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/tutorials_examples/block-height.html",relativePath:"de/tutorials_examples/block-height.md",key:"v-6274ba2f",path:"/de/tutorials_examples/block-height/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:48},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:64},{level:2,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:952},{level:2,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1259},{level:2,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1439},{level:2,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1633}],readingTime:{minutes:1.02,words:307},headersStr:"Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen?",content:'# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.',normalizedContent:'# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to debug a SubQuery project?",frontmatter:{summary:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will",meta:[{property:"og:url",content:"/de/tutorials_examples/debug-projects.html"},{property:"og:title",content:"How to debug a SubQuery project?"},{property:"og:description",content:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/tutorials_examples/debug-projects.html",relativePath:"de/tutorials_examples/debug-projects.md",key:"v-0bb0d095",path:"/de/tutorials_examples/debug-projects/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:39},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:55},{level:2,title:"Node inspector",slug:"node-inspector",normalizedTitle:"node inspector",charIndex:272},{level:2,title:"Chrome devtools",slug:"chrome-devtools",normalizedTitle:"chrome devtools",charIndex:683}],readingTime:{minutes:.65,words:196},headersStr:"Video guide Introduction Node inspector Chrome devtools",content:"# How to debug a SubQuery project?\n\n\n# Video guide\n\n\n# Introduction\n\nIn order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a Node.js inspector in conjunction with Chrome developer tools.\n\n\n# Node inspector\n\nRun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nFor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# Chrome devtools\n\nOpen up Chrome DevTools and navigate to the Sources tab. Note that clicking on the green icon will open up a new window.\n\n\n\nNavigate to Filesystem and add your project folder to the workspace. Then open the dist > mappings folder and select the code you wish to debug. Then step through the code as with any standard debugging tool.\n\n",normalizedContent:"# how to debug a subquery project?\n\n\n# video guide\n\n\n# introduction\n\nin order to debug subquery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a node.js inspector in conjunction with chrome developer tools.\n\n\n# node inspector\n\nrun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nfor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# chrome devtools\n\nopen up chrome devtools and navigate to the sources tab. note that clicking on the green icon will open up a new window.\n\n\n\nnavigate to filesystem and add your project folder to the workspace. then open the dist > mappings folder and select the code you wish to debug. then step through the code as with any standard debugging tool.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How does a SubQuery dictionary work?",frontmatter:{summary:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod",meta:[{property:"og:url",content:"/de/tutorials_examples/dictionary.html"},{property:"og:title",content:"How does a SubQuery dictionary work?"},{property:"og:description",content:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/tutorials_examples/dictionary.html",relativePath:"de/tutorials_examples/dictionary.md",key:"v-34796e51",path:"/de/tutorials_examples/dictionary/",headers:[{level:2,title:"How to incorporate a dictionary into your project?",slug:"how-to-incorporate-a-dictionary-into-your-project",normalizedTitle:"how to incorporate a dictionary into your project?",charIndex:1024},{level:2,title:"What happens when a dictionary IS NOT used?",slug:"what-happens-when-a-dictionary-is-not-used",normalizedTitle:"what happens when a dictionary is not used?",charIndex:1350},{level:2,title:"What happens when a dictionary IS used?",slug:"what-happens-when-a-dictionary-is-used",normalizedTitle:"what happens when a dictionary is used?",charIndex:1772},{level:2,title:"When is a dictionary NOT useful?",slug:"when-is-a-dictionary-not-useful",normalizedTitle:"when is a dictionary not useful?",charIndex:2849}],readingTime:{minutes:2,words:601},headersStr:"How to incorporate a dictionary into your project? What happens when a dictionary IS NOT used? What happens when a dictionary IS used? When is a dictionary NOT useful?",content:"# How does a SubQuery dictionary work?\n\nThe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. Another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nThe network.dictionary endpoint is an optional parameter that if present, the SDK will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\nTaking the SubQuery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specVersion. These 3 entities contain 6, 4, and 2 fields respectively. When this project is run, these fields are reflected in the database tables.\n\n\n\nData from the blockchain is then stored in these tables and indexed for performance. The project is then hosted in SubQuery Projects and the API endpoint is available to be added to the manifest file.\n\n\n# How to incorporate a dictionary into your project?\n\nAdd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. Eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# What happens when a dictionary IS NOT used?\n\nWhen a dictionary is NOT used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. Later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# What happens when a dictionary IS used?\n\nWhen a dictionary IS used, the indexer will first take the call and event filters as parameters and merge this into a GraphQL query. It then uses the dictionary's API to obtain a list of relevant block heights only that contains the specific events and extrinsics. Often this is substantially less than 100 if the default is used.\n\nFor example, imagine a situation where you're indexing transfer events. Not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nThe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. This is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nThis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. But compared to the traditional method, it adds an additional step to get data from the dictionary’s API.\n\n\n# When is a dictionary NOT useful?\n\nWhen block handlers are used to grab data from a chain, every block needs to be processed. Therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nAlso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",normalizedContent:"# how does a subquery dictionary work?\n\nthe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nthe network.dictionary endpoint is an optional parameter that if present, the sdk will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\ntaking the subquery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specversion. these 3 entities contain 6, 4, and 2 fields respectively. when this project is run, these fields are reflected in the database tables.\n\n\n\ndata from the blockchain is then stored in these tables and indexed for performance. the project is then hosted in subquery projects and the api endpoint is available to be added to the manifest file.\n\n\n# how to incorporate a dictionary into your project?\n\nadd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# what happens when a dictionary is not used?\n\nwhen a dictionary is not used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# what happens when a dictionary is used?\n\nwhen a dictionary is used, the indexer will first take the call and event filters as parameters and merge this into a graphql query. it then uses the dictionary's api to obtain a list of relevant block heights only that contains the specific events and extrinsics. often this is substantially less than 100 if the default is used.\n\nfor example, imagine a situation where you're indexing transfer events. not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nthe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. this is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nthis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. but compared to the traditional method, it adds an additional step to get data from the dictionary’s api.\n\n\n# when is a dictionary not useful?\n\nwhen block handlers are used to grab data from a chain, every block needs to be processed. therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nalso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/de/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/tutorials_examples/howto.html",relativePath:"de/tutorials_examples/howto.md",key:"v-89f298e6",path:"/de/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri",meta:[{property:"og:url",content:"/de/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/tutorials_examples/introduction.html",relativePath:"de/tutorials_examples/introduction.md",key:"v-65f40cc9",path:"/de/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:155}],readingTime:{minutes:.77,words:231},headersStr:"SubQuery Examples",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# SubQuery Examples\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# subquery examples\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to run an indexer node?",frontmatter:{summary:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r",meta:[{property:"og:url",content:"/de/tutorials_examples/run-indexer.html"},{property:"og:title",content:"How to run an indexer node?"},{property:"og:description",content:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/tutorials_examples/run-indexer.html",relativePath:"de/tutorials_examples/run-indexer.md",key:"v-68df3c0d",path:"/de/tutorials_examples/run-indexer/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:34},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:50},{level:2,title:"Postgres",slug:"postgres",normalizedTitle:"postgres",charIndex:300},{level:2,title:"Install subql/node",slug:"install-subql-node",normalizedTitle:"install subql/node",charIndex:484},{level:2,title:"Setting DB configs",slug:"setting-db-configs",normalizedTitle:"setting db configs",charIndex:802},{level:2,title:"Indexing a project",slug:"indexing-a-project",normalizedTitle:"indexing a project",charIndex:1380},{level:2,title:"Inspecting Postgres",slug:"inspecting-postgres",normalizedTitle:"inspecting postgres",charIndex:1687}],readingTime:{minutes:1.18,words:353},headersStr:"Video guide Introduction Postgres Install subql/node Setting DB configs Indexing a project Inspecting Postgres",content:"# How to run an indexer node?\n\n\n# Video guide\n\n\n# Introduction\n\nRunning an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It requires more time and effort but will enhance your understanding of how SubQuery works under the covers.\n\n\n# Postgres\n\nRunning an indexer node on your infrastructure will require the setup of a Postgres database. You can install Postgres from here and ensure the version is 12 or greater.\n\n\n# Install subql/node\n\nThen to run a SubQuery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nThe -g flag means to install it globally which means on OSX, the location will be /usr/local/lib/node_modules.\n\nOnce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# Setting DB configs\n\nNext, you need to set the following environmental variables:\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\n\n\n1\n2\n3\n4\n5\n\n\nOf course, if you have different values for the above keys, please adjust accordingly. Note that the env command will display the current environment variables and that this process only sets these values temporarily. That is, they are only valid for the duration of the terminal session. To set them permanently, store them in your ~/bash_profile instead.\n\n\n# Indexing a project\n\nTo start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nIf you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. You should see the indexer node kick into life and start indexing blocks.\n\n\n# Inspecting Postgres\n\nIf you navigate to Postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. The starter_entities table contains the indexes. To view the data, run select (*) from subquery_1.starter_entities.",normalizedContent:"# how to run an indexer node?\n\n\n# video guide\n\n\n# introduction\n\nrunning an indexer node is another option outside of using docker or having a project hosted for you at subquery projects. it requires more time and effort but will enhance your understanding of how subquery works under the covers.\n\n\n# postgres\n\nrunning an indexer node on your infrastructure will require the setup of a postgres database. you can install postgres from here and ensure the version is 12 or greater.\n\n\n# install subql/node\n\nthen to run a subquery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nthe -g flag means to install it globally which means on osx, the location will be /usr/local/lib/node_modules.\n\nonce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# setting db configs\n\nnext, you need to set the following environmental variables:\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\n\n\n1\n2\n3\n4\n5\n\n\nof course, if you have different values for the above keys, please adjust accordingly. note that the env command will display the current environment variables and that this process only sets these values temporarily. that is, they are only valid for the duration of the terminal session. to set them permanently, store them in your ~/bash_profile instead.\n\n\n# indexing a project\n\nto start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nif you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. you should see the indexer node kick into life and start indexing blocks.\n\n\n# inspecting postgres\n\nif you navigate to postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. the starter_entities table contains the indexes. to view the data, run select (*) from subquery_1.starter_entities.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/de/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"de"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/de/tutorials_examples/terminology.html",relativePath:"de/tutorials_examples/terminology.md",key:"v-4162124d",path:"/de/tutorials_examples/terminology/",headers:[{level:2,title:"Terminology",slug:"terminology",normalizedTitle:"terminology",charIndex:2}],readingTime:{minutes:.49,words:147},headersStr:"Terminology",content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{frontmatter:{summary:"Bienvenido a los documentos de SubQuery ¡Explora y transforma los datos de tu cadena para crear dApps intuitivos más rápido! Inicio rápido Guía Vamos a comprender SubQuery poniendo",meta:[{property:"og:url",content:"/es/"},{property:"og:description",content:"Bienvenido a los documentos de SubQuery ¡Explora y transforma los datos de tu cadena para crear dApps intuitivos más rápido! Inicio rápido Guía Vamos a comprender SubQuery poniendo"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/",relativePath:"es/README.md",key:"v-1397d61e",path:"/es/",readingTime:{minutes:3.09,words:926},headersStr:null,content:"Bienvenido a los documentos de SubQuery\n\n¡Explora y transforma los datos de tu cadena para crear dApps intuitivos más rápido!\n\n\nInicio rápido Guía\n\nVamos a comprender SubQuery poniendo manos a la obra un ejemplo tradicional de Hola Mundo. Utilizando un proyecto de plantilla dentro de un entorno Docker puede obtener rápidamente un nodo funcionando y comenzar a consultar un blockchain en tan solo unos minutos con algunos comandos simples.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * La red de SubQuery\n   \n   El futuro descentralizado de SubQuery. Lea más sobre cómo se recompensa a los indexadores y consumidores.\n\n\nPreguntas Frecuentes (FAQ)\n\n * ¿Qué es SubQuery?\n   \n   SubQuery es un proyecto de código abierto que permite a los desarrolladores indexar, transformar y consultar datos en cadena de Substrate para potenciar sus aplicaciones.\n   \n   READ MORE\n * ¿Cuál es la mejor manera de comenzar con SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. Este es un simple paseo de 5 minutos para descargar la plantilla de inicio, construir el proyecto, y luego usar Docker para ejecutar un nodo en su localhost y ejecutar una simple consulta.\n\n * ¿Cómo puedo contribuir o dar comentarios a SubQuery?\n   \n   Nos encantan las contribuciones y comentarios de la comunidad. Para contribuir con el código, bifurca el repositorio de interés y realice sus cambios. Luego envíe un PR o Pull Request. ¡Oh, no te olvides del test probar también! Consulte también nuestras directrices de contribuciones (próximamente).\n   \n   READ MORE\n * ¿Cuánto cuesta alojar mi proyecto en SubQuery Projects?\n   \n   Hospedar tu proyecto en SubQuery Projects es absolutamente gratuito - es nuestra manera de devolver a la comunidad. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\n¿Integrar con tu cadena personalizada?\n\nYa sea que esté construyendo una nueva cadena de bloques o una cadena de bloques completamente nueva en Substrate - SubQuery puede ayudarle a indexar y solucionar problemas los datos de su cadena. SubQuery está diseñado para integrar fácilmente con una cadena basada en Substrate personalizada.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nSoporte y contribución\n\nHave a question or interested to know more or how you can contribute? We’d love to hear from you. ¡Queremos saber tu opinión! Por favor contáctenos a través de correo electrónico o redes sociales desde los siguientes enlaces. ¿Necesita conocimientos técnicos? Únete a nuestra comunidad de Discord y recibe apoyo de nuestros apasionados miembros de la comunidad.\n\nÚNETE A LA CONVERSACIÓN EN DISCORD\nContáctanos hello@subquery.network\nSíguenos en las redes sociales\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"bienvenido a los documentos de subquery\n\n¡explora y transforma los datos de tu cadena para crear dapps intuitivos mas rapido!\n\n\ninicio rapido guia\n\nvamos a comprender subquery poniendo manos a la obra un ejemplo tradicional de hola mundo. utilizando un proyecto de plantilla dentro de un entorno docker puede obtener rapidamente un nodo funcionando y comenzar a consultar un blockchain en tan solo unos minutos con algunos comandos simples.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * la red de subquery\n   \n   el futuro descentralizado de subquery. lea mas sobre como se recompensa a los indexadores y consumidores.\n\n\npreguntas frecuentes (faq)\n\n * ¿que es subquery?\n   \n   subquery es un proyecto de codigo abierto que permite a los desarrolladores indexar, transformar y consultar datos en cadena de substrate para potenciar sus aplicaciones.\n   \n   read more\n * ¿cual es la mejor manera de comenzar con subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. este es un simple paseo de 5 minutos para descargar la plantilla de inicio, construir el proyecto, y luego usar docker para ejecutar un nodo en su localhost y ejecutar una simple consulta.\n\n * ¿como puedo contribuir o dar comentarios a subquery?\n   \n   nos encantan las contribuciones y comentarios de la comunidad. para contribuir con el codigo, bifurca el repositorio de interes y realice sus cambios. luego envie un pr o pull request. ¡oh, no te olvides del test probar tambien! consulte tambien nuestras directrices de contribuciones (proximamente).\n   \n   read more\n * ¿cuanto cuesta alojar mi proyecto en subquery projects?\n   \n   hospedar tu proyecto en subquery projects es absolutamente gratuito - es nuestra manera de devolver a la comunidad. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\n¿integrar con tu cadena personalizada?\n\nya sea que este construyendo una nueva cadena de bloques o una cadena de bloques completamente nueva en substrate - subquery puede ayudarle a indexar y solucionar problemas los datos de su cadena. subquery esta disenado para integrar facilmente con una cadena basada en substrate personalizada.\n\nlearn how to integrate with your chain\n\nsoporte y contribucion\n\nhave a question or interested to know more or how you can contribute? we’d love to hear from you. ¡queremos saber tu opinion! por favor contactenos a traves de correo electronico o redes sociales desde los siguientes enlaces. ¿necesita conocimientos tecnicos? unete a nuestra comunidad de discord y recibe apoyo de nuestros apasionados miembros de la comunidad.\n\nunete a la conversacion en discord\ncontactanos hello@subquery.network\nsiguenos en las redes sociales\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"GraphQL Schema",frontmatter:{summary:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict",meta:[{property:"og:url",content:"/es/create/graphql.html"},{property:"og:title",content:"GraphQL Schema"},{property:"og:description",content:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/create/graphql.html",relativePath:"es/create/graphql.md",key:"v-514b550d",path:"/es/create/graphql/",headers:[{level:2,title:"Defining Entities",slug:"defining-entities",normalizedTitle:"defining entities",charIndex:21},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:30},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:931},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1282},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1186},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3290},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3759},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:4062},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5096},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1268},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6445},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7144}],readingTime:{minutes:3.9,words:1170},headersStr:"Defining Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL Schema\n\n\n# Defining Entities\n\nThe schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates the shape of your data from SubQuery. To learn more about how to write in GraphQL schema language, we recommend checking out Schemas and Types.\n\nImportant: When you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# Entities\n\nEach entity must define its required fields id with the type of ID!. It is used as the primary key and unique among all entities of the same type.\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field\n}\n\ntype Title @entity {\n  id: ID!\n  name: String! @index(unique: true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nWhen code generation is run, this will automatically create a getByName under the User model, and the foreign key field title will create a getByTitleId method, which both can directly be accessed in the mapping function.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from '../types/models/User';\nimport {Title} from '../types/models/Title';\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account]\n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID!\n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery {\n  user(first: 5, filter: {contactCard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",normalizedContent:"# graphql schema\n\n\n# defining entities\n\nthe schema.graphql file defines the various graphql schemas. due to the way that the graphql query language works, the schema file essentially dictates the shape of your data from subquery. to learn more about how to write in graphql schema language, we recommend checking out schemas and types.\n\nimportant: when you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# entities\n\neach entity must define its required fields id with the type of id!. it is used as the primary key and unique among all entities of the same type.\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field\n}\n\ntype title @entity {\n  id: id!\n  name: string! @index(unique: true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nwhen code generation is run, this will automatically create a getbyname under the user model, and the foreign key field title will create a getbytitleid method, which both can directly be accessed in the mapping function.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from '../types/models/user';\nimport {title} from '../types/models/title';\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account]\n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id!\n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery {\n  user(first: 5, filter: {contactcard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Crear un proyecto de Subquery",frontmatter:{summary:"Crear un proyecto de Subquery En la guía de inicio rápido encontraremos un ejemplo para darle una muestra de lo que es SubQuery y cómo funciona. Here we'll take a closer look at th",meta:[{property:"og:url",content:"/es/create/introduction.html"},{property:"og:title",content:"Crear un proyecto de Subquery"},{property:"og:description",content:"Crear un proyecto de Subquery En la guía de inicio rápido encontraremos un ejemplo para darle una muestra de lo que es SubQuery y cómo funciona. Here we'll take a closer look at th"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/create/introduction.html",relativePath:"es/create/introduction.md",key:"v-7c3a4841",path:"/es/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:267},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1230},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1623},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2084},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2321}],readingTime:{minutes:1.75,words:524},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Crear un proyecto de Subquery\n\nEn la guía de inicio rápido encontraremos un ejemplo para darle una muestra de lo que es SubQuery y cómo funciona. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# crear un proyecto de subquery\n\nen la guia de inicio rapido encontraremos un ejemplo para darle una muestra de lo que es subquery y como funciona. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/es/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/create/manifest.html",relativePath:"es/create/manifest.md",key:"v-38986917",path:"/es/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:1998},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3220},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4533}],readingTime:{minutes:2.51,words:752},headersStr:"Network Filters Mapping Filters Custom Chains",content:"# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: '0.0.1'\ndescription: ''\nrepository: 'https://github.com/subquery/subql-starter'\n\nschema: './schema.graphql'\n\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: 'https://api.subquery.network/sq/subquery/dictionary-polkadot'\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - see Running an Indexer\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n\n---\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter: #Optional\n      specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter:\n      specName: kusama\n    startBlock: 12000\n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter:\n  module: balances\n  method: Deposit\n  success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: '0.0.1'\ndescription: \"This subquery indexes kitty's birth info\"\nrepository: 'https://github.com/onfinality-io/subql-examples'\nschema: './schema.graphql'\nnetwork:\n  endpoint: 'ws://host.kittychain.io/public-ws'\n  types: {'KittyIndex': 'u32', 'Kitty': '[u8; 16]'}\n# typesChain: { chain: { Type5: 'example' } }\n# typesSpec: { spec: { Type6: 'example' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter: #Optional\n      specName: kitty-chain\n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n",normalizedContent:"# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: '0.0.1'\ndescription: ''\nrepository: 'https://github.com/subquery/subql-starter'\n\nschema: './schema.graphql'\n\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: 'https://api.subquery.network/sq/subquery/dictionary-polkadot'\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - see running an indexer\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n\n---\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter: #optional\n      specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter:\n      specname: kusama\n    startblock: 12000\n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter:\n  module: balances\n  method: deposit\n  success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: '0.0.1'\ndescription: \"this subquery indexes kitty's birth info\"\nrepository: 'https://github.com/onfinality-io/subql-examples'\nschema: './schema.graphql'\nnetwork:\n  endpoint: 'ws://host.kittychain.io/public-ws'\n  types: {'kittyindex': 'u32', 'kitty': '[u8; 16]'}\n# typeschain: { chain: { type5: 'example' } }\n# typesspec: { spec: { type6: 'example' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter: #optional\n      specname: kitty-chain\n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/es/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/create/mapping.html",relativePath:"es/create/mapping.md",key:"v-06fe97ed",path:"/es/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3127},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4137},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5097},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5527},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6190},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5047},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6907},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10097},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11318},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11540}],readingTime:{minutes:6.93,words:2080},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from \'@subql/types\';\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n  // Create a new StarterEntity with the block hash as it\'s ID\n  const record = new starterEntity(block.block.header.hash.toString());\n  record.field1 = block.block.header.number.toNumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n  const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n  record.field4 = extrinsic.block.timestamp;\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from \'ethers/lib/utils\'; //Good way\nimport {utils} from \'ethers\'; //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n  const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n  record.field1 = hashMessage(\'Hello\');\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport {default as kitties} from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n  // custom types\n  types: {\n    Address: \'AccountId\',\n    LookupSource: \'AccountId\',\n    KittyIndex: \'u32\',\n    Kitty: \'[u8; 16]\',\n  },\n  // custom rpc : api.rpc.kitties.getKittyPrice\n  rpc: {\n    getKittyPrice: {\n      description: \'Get Kitty price\',\n      params: [\n        {\n          name: \'at\',\n          type: \'BlockHash\',\n          isHistoric: true,\n          isOptional: false,\n        },\n        {\n          name: \'kittyIndex\',\n          type: \'KittyIndex\',\n          isOptional: false,\n        },\n      ],\n      type: \'Balance\',\n    },\n  },\n};\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n    // this is the package name we use (in the interface imports, --package for generators) */\n    "kitty-birthinfo/*": ["src/*"],\n    // here we replace the @polkadot/api augmentation with our own, generated from chain\n    "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n    // replace the augmented types with our own, as generated from definitions\n    "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n  //return the KittyIndex type\n  const nextKittyId = await api.query.kitties.nextKittyId();\n  // return the Kitty type, input parameters types are AccountId and KittyIndex\n  const allKitties = await api.query.kitties.kitties(\'xxxxxxxxx\', 123);\n  logger.info(`Next kitty id ${nextKittyId}`);\n  //Custom rpc, set undefined to blockhash\n  const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined, nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from \'@subql/types\';\n\nexport async function handleblock(block: substrateblock): promise<void> {\n  // create a new starterentity with the block hash as it\'s id\n  const record = new starterentity(block.block.header.hash.tostring());\n  record.field1 = block.block.header.number.tonumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n  const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n  record.field4 = extrinsic.block.timestamp;\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from \'ethers/lib/utils\'; //good way\nimport {utils} from \'ethers\'; //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n  const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n  record.field1 = hashmessage(\'hello\');\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport {default as kitties} from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n  // custom types\n  types: {\n    address: \'accountid\',\n    lookupsource: \'accountid\',\n    kittyindex: \'u32\',\n    kitty: \'[u8; 16]\',\n  },\n  // custom rpc : api.rpc.kitties.getkittyprice\n  rpc: {\n    getkittyprice: {\n      description: \'get kitty price\',\n      params: [\n        {\n          name: \'at\',\n          type: \'blockhash\',\n          ishistoric: true,\n          isoptional: false,\n        },\n        {\n          name: \'kittyindex\',\n          type: \'kittyindex\',\n          isoptional: false,\n        },\n      ],\n      type: \'balance\',\n    },\n  },\n};\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n    // this is the package name we use (in the interface imports, --package for generators) */\n    "kitty-birthinfo/*": ["src/*"],\n    // here we replace the @polkadot/api augmentation with our own, generated from chain\n    "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n    // replace the augmented types with our own, as generated from definitions\n    "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n  //return the kittyindex type\n  const nextkittyid = await api.query.kitties.nextkittyid();\n  // return the kitty type, input parameters types are accountid and kittyindex\n  const allkitties = await api.query.kitties.kitties(\'xxxxxxxxx\', 123);\n  logger.info(`next kitty id ${nextkittyid}`);\n  //custom rpc, set undefined to blockhash\n  const kittyprice = await api.rpc.kitties.getkittyprice(undefined, nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/es/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/faqs/faqs.html",relativePath:"es/faqs/faqs.md",key:"v-56f85486",path:"/es/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/es/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/install/install.html",relativePath:"es/install/install.md",key:"v-2f18e28d",path:"/es/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/es/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/miscellaneous/ambassadors.html",relativePath:"es/miscellaneous/ambassadors.md",key:"v-76f64b99",path:"/es/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/es/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/miscellaneous/branding.html",relativePath:"es/miscellaneous/branding.md",key:"v-2e6d4e4d",path:"/es/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/es/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/miscellaneous/contributing.html",relativePath:"es/miscellaneous/contributing.md",key:"v-29564a26",path:"/es/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/es/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/miscellaneous/social_media.html",relativePath:"es/miscellaneous/social_media.md",key:"v-fd457426",path:"/es/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/es/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/publish/connect.html",relativePath:"es/publish/connect.md",key:"v-407a5507",path:"/es/publish/connect/",readingTime:{minutes:.61,words:182},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/es/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/publish/publish.html",relativePath:"es/publish/publish.md",key:"v-2ecb6cbd",path:"/es/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1134},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. _We're almost there! We just need to deploy a new version of it. _\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. _we're almost there! we just need to deploy a new version of it. _\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/es/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/publish/upgrade.html",relativePath:"es/publish/upgrade.md",key:"v-25105aba",path:"/es/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/es/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/query/graphql.html",relativePath:"es/query/graphql.md",key:"v-0b973857",path:"/es/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/es/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/query/query.html",relativePath:"es/query/query.md",key:"v-2d2f1159",path:"/es/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/es/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/quickstart/helloworld-hosted.html",relativePath:"es/quickstart/helloworld-hosted.md",key:"v-ee61d266",path:"/es/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/es/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/quickstart/helloworld-localhost.html",relativePath:"es/quickstart/helloworld-localhost.md",key:"v-2f06345b",path:"/es/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"Step 1: Initialise project",slug:"step-1-initialise-project",normalizedTitle:"step 1: initialise project",charIndex:1455},{level:2,title:"Step 2: Install dependencies",slug:"step-2-install-dependencies",normalizedTitle:"step 2: install dependencies",charIndex:2035},{level:2,title:"Step 3: Generate code",slug:"step-3-generate-code",normalizedTitle:"step 3: generate code",charIndex:2477},{level:2,title:"Step 4: Build code",slug:"step-4-build-code",normalizedTitle:"step 4: build code",charIndex:3087},{level:2,title:"Step 5: Run Docker",slug:"step-5-run-docker",normalizedTitle:"step 5: run docker",charIndex:3319},{level:2,title:"Step 6: Browse playground",slug:"step-6-browse-playground",normalizedTitle:"step 6: browse playground",charIndex:4586},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:5027}],readingTime:{minutes:2.85,words:855},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Initialise project Step 2: Install dependencies Step 3: Generate code Step 4: Build code Step 5: Run Docker Step 6: Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Step 5: Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Step 6: Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# step 5: run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# step 6: browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/es/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/quickstart/quickstart.html",relativePath:"es/quickstart/quickstart.md",key:"v-19c469bd",path:"/es/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2566},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3009},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3388},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3628},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3981},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4548},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5235}],readingTime:{minutes:3.22,words:967},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/es/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/quickstart/understanding-helloworld.html",relativePath:"es/quickstart/understanding-helloworld.md",key:"v-6ba4f6d5",path:"/es/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/es/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/run/run.html",relativePath:"es/run/run.md",key:"v-ab158e66",path:"/es/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3939},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4182}],readingTime:{minutes:2.57,words:772},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/es/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/run/sandbox.html",relativePath:"es/run/sandbox.md",key:"v-58d12b55",path:"/es/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"¿Cómo cambiar el tamaño del lote de la búsqueda en cadena de bloques?",frontmatter:{summary:"¿Cómo cambiar el tamaño del lote de la búsqueda en cadena de bloques? Guía en vídeo Introducción El tamaño del lote por defecto es 100, pero esto se puede cambiar usando el comando",meta:[{property:"og:url",content:"/es/tutorials_examples/batch-size.html"},{property:"og:title",content:"¿Cómo cambiar el tamaño del lote de la búsqueda en cadena de bloques?"},{property:"og:description",content:"¿Cómo cambiar el tamaño del lote de la búsqueda en cadena de bloques? Guía en vídeo Introducción El tamaño del lote por defecto es 100, pero esto se puede cambiar usando el comando"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/tutorials_examples/batch-size.html",relativePath:"es/tutorials_examples/batch-size.md",key:"v-a1803b0a",path:"/es/tutorials_examples/batch-size/",headers:[{level:2,title:"Guía en vídeo",slug:"guia-en-video",normalizedTitle:"guia en video",charIndex:76},{level:2,title:"Introducción",slug:"introduccion",normalizedTitle:"introduccion",charIndex:94},{level:2,title:"¿Por qué cambiar el tamaño del lote?",slug:"¿por-que-cambiar-el-tamano-del-lote",normalizedTitle:"¿por que cambiar el tamano del lote?",charIndex:788}],readingTime:{minutes:.52,words:156},headersStr:"Guía en vídeo Introducción ¿Por qué cambiar el tamaño del lote?",content:'# ¿Cómo cambiar el tamaño del lote de la búsqueda en cadena de bloques?\n\n\n# Guía en vídeo\n\n\n# Introducción\n\nEl tamaño del lote por defecto es 100, pero esto se puede cambiar usando el comando extra --batch-size=xx.\n\nNecesitas esto a la línea de comandos como una bandera extra o si estás usando Docker, modificar el docker-compose.yml con:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nEste ejemplo establece el tamaño del lote a 50.\n\n\n# ¿Por qué cambiar el tamaño del lote?\n\nUsar un tamaño por lotes más pequeño puede reducir el uso de memoria y no dejar a los usuarios colgando para grandes consultas. En otras palabras, su aplicación puede ser más receptiva.',normalizedContent:'# ¿como cambiar el tamano del lote de la busqueda en cadena de bloques?\n\n\n# guia en video\n\n\n# introduccion\n\nel tamano del lote por defecto es 100, pero esto se puede cambiar usando el comando extra --batch-size=xx.\n\nnecesitas esto a la linea de comandos como una bandera extra o si estas usando docker, modificar el docker-compose.yml con:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\neste ejemplo establece el tamano del lote a 50.\n\n\n# ¿por que cambiar el tamano del lote?\n\nusar un tamano por lotes mas pequeno puede reducir el uso de memoria y no dejar a los usuarios colgando para grandes consultas. en otras palabras, su aplicacion puede ser mas receptiva.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"¿Cómo empezar a una altura de bloque diferente?",frontmatter:{summary:"¿Cómo empezar a una altura de bloque diferente? Guía en vídeo Introducción De forma predeterminada, todos los proyectos iniciales comienzan a sincronizar el blockchain del bloque g",meta:[{property:"og:url",content:"/es/tutorials_examples/block-height.html"},{property:"og:title",content:"¿Cómo empezar a una altura de bloque diferente?"},{property:"og:description",content:"¿Cómo empezar a una altura de bloque diferente? Guía en vídeo Introducción De forma predeterminada, todos los proyectos iniciales comienzan a sincronizar el blockchain del bloque g"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/tutorials_examples/block-height.html",relativePath:"es/tutorials_examples/block-height.md",key:"v-1c0d3bd5",path:"/es/tutorials_examples/block-height/",headers:[{level:2,title:"Guía en vídeo",slug:"guia-en-video",normalizedTitle:"guia en video",charIndex:54},{level:2,title:"Introducción",slug:"introduccion",normalizedTitle:"introduccion",charIndex:72},{level:2,title:"¿Por qué no partir de cero?",slug:"¿por-que-no-partir-de-cero",normalizedTitle:"¿por que no partir de cero?",charIndex:1057},{level:2,title:"¿Cuáles son los inconvenientes de no partir de cero?",slug:"¿cuales-son-los-inconvenientes-de-no-partir-de-cero",normalizedTitle:"¿cuales son los inconvenientes de no partir de cero?",charIndex:1409},{level:2,title:"¿Cómo averiguar la altura actual del blockchain?",slug:"¿como-averiguar-la-altura-actual-del-blockchain",normalizedTitle:"¿como averiguar la altura actual del blockchain?",charIndex:1566},{level:2,title:"¿Tengo que hacer una reconstrucción o un códegen?",slug:"¿tengo-que-hacer-una-reconstruccion-o-un-codegen",normalizedTitle:"¿tengo que hacer una reconstruccion o un codegen?",charIndex:1749}],readingTime:{minutes:1.03,words:308},headersStr:"Guía en vídeo Introducción ¿Por qué no partir de cero? ¿Cuáles son los inconvenientes de no partir de cero? ¿Cómo averiguar la altura actual del blockchain? ¿Tengo que hacer una reconstrucción o un códegen?",content:'# ¿Cómo empezar a una altura de bloque diferente?\n\n\n# Guía en vídeo\n\n\n# Introducción\n\nDe forma predeterminada, todos los proyectos iniciales comienzan a sincronizar el blockchain del bloque génesis. En otras palabras, del bloque 1. Para blockchains grandes, esto puede tardar días o incluso semanas en sincronizarse completamente.\n\nPara iniciar una sincronización de nodo de SubQuery desde una altura diferente a cero, todo lo que tiene que hacer es modificar su proyecto, el archivo project.yaml y cambiar la tecla startBlock.\n\nDebajo hay un archivo project.yaml donde el bloque de inicio se ha establecido a 1.000.000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# ¿Por qué no partir de cero?\n\nLa razón principal es que puede reducir el tiempo para sincronizar la cadena de bloques. Esto significa que si solo estás interesado en las transacciones en los últimos 3 meses, sólo puedes sincronizar los últimos 3 meses que valgan la pena significar menos tiempo de espera y puedes comenzar tu desarrollo más rápido.\n\n\n# ¿Cuáles son los inconvenientes de no partir de cero?\n\nEl inconveniente más obvio será que no podrá consultar datos en la cadena de bloques que no tiene.\n\n\n# ¿Cómo averiguar la altura actual del blockchain?\n\nSi está utilizando la red Polkadot, puede visitar https://polkascan.io/, seleccionar la red y ver la figura "Bloque Finalizado".\n\n\n# ¿Tengo que hacer una reconstrucción o un códegen?\n\nNo. Debido a que está modificando el archivo project.yaml, que es esencialmente un archivo de configuración, no tendrá que reconstruir o regenerar el código de typescript.',normalizedContent:'# ¿como empezar a una altura de bloque diferente?\n\n\n# guia en video\n\n\n# introduccion\n\nde forma predeterminada, todos los proyectos iniciales comienzan a sincronizar el blockchain del bloque genesis. en otras palabras, del bloque 1. para blockchains grandes, esto puede tardar dias o incluso semanas en sincronizarse completamente.\n\npara iniciar una sincronizacion de nodo de subquery desde una altura diferente a cero, todo lo que tiene que hacer es modificar su proyecto, el archivo project.yaml y cambiar la tecla startblock.\n\ndebajo hay un archivo project.yaml donde el bloque de inicio se ha establecido a 1.000.000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# ¿por que no partir de cero?\n\nla razon principal es que puede reducir el tiempo para sincronizar la cadena de bloques. esto significa que si solo estas interesado en las transacciones en los ultimos 3 meses, solo puedes sincronizar los ultimos 3 meses que valgan la pena significar menos tiempo de espera y puedes comenzar tu desarrollo mas rapido.\n\n\n# ¿cuales son los inconvenientes de no partir de cero?\n\nel inconveniente mas obvio sera que no podra consultar datos en la cadena de bloques que no tiene.\n\n\n# ¿como averiguar la altura actual del blockchain?\n\nsi esta utilizando la red polkadot, puede visitar https://polkascan.io/, seleccionar la red y ver la figura "bloque finalizado".\n\n\n# ¿tengo que hacer una reconstruccion o un codegen?\n\nno. debido a que esta modificando el archivo project.yaml, que es esencialmente un archivo de configuracion, no tendra que reconstruir o regenerar el codigo de typescript.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"¿Cómo depurar un proyecto SubQuery?",frontmatter:{summary:"¿Cómo depurar un proyecto SubQuery? Guía en vídeo Introducción Para depurar proyectos de SubQuery como pasar por el código, establecer puntos de interrupción y inspeccionar variabl",meta:[{property:"og:url",content:"/es/tutorials_examples/debug-projects.html"},{property:"og:title",content:"¿Cómo depurar un proyecto SubQuery?"},{property:"og:description",content:"¿Cómo depurar un proyecto SubQuery? Guía en vídeo Introducción Para depurar proyectos de SubQuery como pasar por el código, establecer puntos de interrupción y inspeccionar variabl"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/tutorials_examples/debug-projects.html",relativePath:"es/tutorials_examples/debug-projects.md",key:"v-5fbd0ffb",path:"/es/tutorials_examples/debug-projects/",headers:[{level:2,title:"Guía en vídeo",slug:"guia-en-video",normalizedTitle:"guia en video",charIndex:42},{level:2,title:"Introducción",slug:"introduccion",normalizedTitle:"introduccion",charIndex:60},{level:2,title:"Inpector del nodo",slug:"inpector-del-nodo",normalizedTitle:"inpector del nodo",charIndex:294},{level:2,title:"Devtools de Chrome",slug:"devtools-de-chrome",normalizedTitle:"devtools de chrome",charIndex:705}],readingTime:{minutes:.67,words:202},headersStr:"Guía en vídeo Introducción Inpector del nodo Devtools de Chrome",content:"# ¿Cómo depurar un proyecto SubQuery?\n\n\n# Guía en vídeo\n\n\n# Introducción\n\nPara depurar proyectos de SubQuery como pasar por el código, establecer puntos de interrupción y inspeccionar variables, tendrá que usar un Node.js inspector en conjunto con las herramientas de desarrollo de Chrome.\n\n\n# Inpector del nodo\n\nEjecuta el siguiente comando en tu terminal.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nPor ejemplo:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# Devtools de Chrome\n\nAbra Chrome DevTools y vaya a la pestaña Fuentes. Tenga en cuenta que hacer clic en el icono verde abrirá una nueva ventana.\n\n\n\nVaya a Filesystem y añada la carpeta del proyecto al área de trabajo. Luego abra la carpeta dist > mapeos y seleccione el código que desea depurar. Luego pase por el código como cualquier herramienta de depuración estándar.\n\n",normalizedContent:"# ¿como depurar un proyecto subquery?\n\n\n# guia en video\n\n\n# introduccion\n\npara depurar proyectos de subquery como pasar por el codigo, establecer puntos de interrupcion y inspeccionar variables, tendra que usar un node.js inspector en conjunto con las herramientas de desarrollo de chrome.\n\n\n# inpector del nodo\n\nejecuta el siguiente comando en tu terminal.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\npor ejemplo:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# devtools de chrome\n\nabra chrome devtools y vaya a la pestana fuentes. tenga en cuenta que hacer clic en el icono verde abrira una nueva ventana.\n\n\n\nvaya a filesystem y anada la carpeta del proyecto al area de trabajo. luego abra la carpeta dist > mapeos y seleccione el codigo que desea depurar. luego pase por el codigo como cualquier herramienta de depuracion estandar.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"¿Cómo funciona un diccionario SubQuery?",frontmatter:{summary:"¿Cómo funciona un diccionario SubQuery? La idea completa de un proyecto de diccionario genérico es indexar todos los datos de un blockchain y registrar los eventos, extrinsics, y s",meta:[{property:"og:url",content:"/es/tutorials_examples/dictionary.html"},{property:"og:title",content:"¿Cómo funciona un diccionario SubQuery?"},{property:"og:description",content:"¿Cómo funciona un diccionario SubQuery? La idea completa de un proyecto de diccionario genérico es indexar todos los datos de un blockchain y registrar los eventos, extrinsics, y s"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/tutorials_examples/dictionary.html",relativePath:"es/tutorials_examples/dictionary.md",key:"v-ea8fbb92",path:"/es/tutorials_examples/dictionary/",headers:[{level:2,title:"¿Cómo incorporar un diccionario en su proyecto?",slug:"¿como-incorporar-un-diccionario-en-su-proyecto",normalizedTitle:"¿como incorporar un diccionario en su proyecto?",charIndex:1102},{level:2,title:"¿Qué sucede cuando un diccionario NO se utiliza?",slug:"¿que-sucede-cuando-un-diccionario-no-se-utiliza",normalizedTitle:"¿que sucede cuando un diccionario no se utiliza?",charIndex:1437},{level:2,title:"¿Qué sucede cuando se utiliza un diccionario?",slug:"¿que-sucede-cuando-se-utiliza-un-diccionario",normalizedTitle:"¿que sucede cuando se utiliza un diccionario?",charIndex:1914},{level:2,title:"¿Cuándo un diccionario NO es útil?",slug:"¿cuando-un-diccionario-no-es-util",normalizedTitle:"¿cuando un diccionario no es util?",charIndex:3132}],readingTime:{minutes:2.12,words:635},headersStr:"¿Cómo incorporar un diccionario en su proyecto? ¿Qué sucede cuando un diccionario NO se utiliza? ¿Qué sucede cuando se utiliza un diccionario? ¿Cuándo un diccionario NO es útil?",content:"# ¿Cómo funciona un diccionario SubQuery?\n\nLa idea completa de un proyecto de diccionario genérico es indexar todos los datos de un blockchain y registrar los eventos, extrinsics, y sus tipos (módulo y método) en una base de datos en orden de altura de bloques. Otro proyecto puede consultar este endpoint network.dictionary en lugar del network.endpoint predeterminado definido en el archivo manifest.\n\nEl endpoint network.dictionary es un parámetro opcional que si está presente, el SDK detectará y usará automáticamente. network.endpoint es obligatorio y no compilará si no está presente.\n\nTomando como ejemplo el proyecto de diccionario de SubQuery, el archivo del esquema define 3 entidades; extrínseco, eventos, specVersion. Estas 3 entidades contienen 6, 4 y 2 campos respectivamente. Cuando se ejecuta este proyecto, estos campos se reflejan en las tablas de la base de datos.\n\n\n\nLos datos del blockchain se almacenan en estas tablas e indexados para su rendimiento. El proyecto está alojado en SubQuery Projects y el endpoint API está disponible para ser añadido al archivo de manifiesto.\n\n\n# ¿Cómo incorporar un diccionario en su proyecto?\n\nAñade el diccionario : https://api.subquery.network/sq/subquery/dictionary-polkadot a la sección de red del manifiesto. Por ejemplo:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# ¿Qué sucede cuando un diccionario NO se utiliza?\n\nCuando un diccionario NO es usado, un indexador obtendrá todos los datos de bloque a través de la api polkadot de acuerdo con la bandera tamaño del lote que es 100 por defecto, y coloque esto en un búfer para procesarlo. Más tarde, el indexador toma todos estos bloques del buffer y mientras procesa los datos del bloque comprueba si el evento y extrínseco en estos bloques coinciden con el filtro definido por el usuario.\n\n\n# ¿Qué sucede cuando se utiliza un diccionario?\n\nCuando se utiliza un diccionario, el indexador tomará primero los filtros de llamadas y eventos como parámetros y lo fusionará en una consulta GraphQL. A continuación, utiliza la API del diccionario para obtener una lista de alturas de bloque relevantes sólo que contiene los eventos específicos y extrínsecos. A menudo esto es sustancialmente inferior a 100 si se utiliza el valor por defecto.\n\nPor ejemplo, imagina una situación en la que indexas eventos de transferencia. No todos los bloques tienen este evento (en la imagen inferior no hay eventos de transferencia en los bloques 3 y 4).\n\n\n\nEl diccionario permite que tu proyecto se salte esto en lugar de buscar en cada bloque un evento de transferencia, se salta a los bloques 1, 2 y 5. Esto se debe a que el diccionario es una referencia precalculada a todas las llamadas y eventos de cada bloque.\n\nEsto significa que el uso de un diccionario puede reducir la cantidad de datos que el indexador obtiene de la cadena y reducir el número de bloques “no deseados” almacenados en el búfer local. Pero en comparación con el método tradicional, añade un paso adicional para obtener datos de la API del diccionario.\n\n\n# ¿Cuándo un diccionario NO es útil?\n\nCuando manejadores de bloques se utilizan para extraer datos de una cadena, cada bloque necesita ser procesado. Por lo tanto, el uso de un diccionario en este caso no proporciona ninguna ventaja y el indexador cambiará automáticamente al enfoque no diccionario predeterminado.\n\nTambién, cuando se trata de eventos o extrínsecos que ocurren o existen en cada bloque como timestamp.set, el uso de un diccionario no ofrecerá ninguna ventaja adicional.",normalizedContent:"# ¿como funciona un diccionario subquery?\n\nla idea completa de un proyecto de diccionario generico es indexar todos los datos de un blockchain y registrar los eventos, extrinsics, y sus tipos (modulo y metodo) en una base de datos en orden de altura de bloques. otro proyecto puede consultar este endpoint network.dictionary en lugar del network.endpoint predeterminado definido en el archivo manifest.\n\nel endpoint network.dictionary es un parametro opcional que si esta presente, el sdk detectara y usara automaticamente. network.endpoint es obligatorio y no compilara si no esta presente.\n\ntomando como ejemplo el proyecto de diccionario de subquery, el archivo del esquema define 3 entidades; extrinseco, eventos, specversion. estas 3 entidades contienen 6, 4 y 2 campos respectivamente. cuando se ejecuta este proyecto, estos campos se reflejan en las tablas de la base de datos.\n\n\n\nlos datos del blockchain se almacenan en estas tablas e indexados para su rendimiento. el proyecto esta alojado en subquery projects y el endpoint api esta disponible para ser anadido al archivo de manifiesto.\n\n\n# ¿como incorporar un diccionario en su proyecto?\n\nanade el diccionario : https://api.subquery.network/sq/subquery/dictionary-polkadot a la seccion de red del manifiesto. por ejemplo:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# ¿que sucede cuando un diccionario no se utiliza?\n\ncuando un diccionario no es usado, un indexador obtendra todos los datos de bloque a traves de la api polkadot de acuerdo con la bandera tamano del lote que es 100 por defecto, y coloque esto en un bufer para procesarlo. mas tarde, el indexador toma todos estos bloques del buffer y mientras procesa los datos del bloque comprueba si el evento y extrinseco en estos bloques coinciden con el filtro definido por el usuario.\n\n\n# ¿que sucede cuando se utiliza un diccionario?\n\ncuando se utiliza un diccionario, el indexador tomara primero los filtros de llamadas y eventos como parametros y lo fusionara en una consulta graphql. a continuacion, utiliza la api del diccionario para obtener una lista de alturas de bloque relevantes solo que contiene los eventos especificos y extrinsecos. a menudo esto es sustancialmente inferior a 100 si se utiliza el valor por defecto.\n\npor ejemplo, imagina una situacion en la que indexas eventos de transferencia. no todos los bloques tienen este evento (en la imagen inferior no hay eventos de transferencia en los bloques 3 y 4).\n\n\n\nel diccionario permite que tu proyecto se salte esto en lugar de buscar en cada bloque un evento de transferencia, se salta a los bloques 1, 2 y 5. esto se debe a que el diccionario es una referencia precalculada a todas las llamadas y eventos de cada bloque.\n\nesto significa que el uso de un diccionario puede reducir la cantidad de datos que el indexador obtiene de la cadena y reducir el numero de bloques “no deseados” almacenados en el bufer local. pero en comparacion con el metodo tradicional, anade un paso adicional para obtener datos de la api del diccionario.\n\n\n# ¿cuando un diccionario no es util?\n\ncuando manejadores de bloques se utilizan para extraer datos de una cadena, cada bloque necesita ser procesado. por lo tanto, el uso de un diccionario en este caso no proporciona ninguna ventaja y el indexador cambiara automaticamente al enfoque no diccionario predeterminado.\n\ntambien, cuando se trata de eventos o extrinsecos que ocurren o existen en cada bloque como timestamp.set, el uso de un diccionario no ofrecera ninguna ventaja adicional.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/es/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/tutorials_examples/howto.html",relativePath:"es/tutorials_examples/howto.md",key:"v-76eb85ed",path:"/es/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri",meta:[{property:"og:url",content:"/es/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/tutorials_examples/introduction.html",relativePath:"es/tutorials_examples/introduction.md",key:"v-1f8c8e6f",path:"/es/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:155}],readingTime:{minutes:.77,words:231},headersStr:"SubQuery Examples",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# SubQuery Examples\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# subquery examples\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"¿Cómo ejecutar un nodo indexador?",frontmatter:{summary:"¿Cómo ejecutar un nodo indexador? Guía en vídeo Introducción Ejecutar un nodo indexador es otra opción fuera de usar Docker o tener un proyecto alojado para usted en SubQuery Proje",meta:[{property:"og:url",content:"/es/tutorials_examples/run-indexer.html"},{property:"og:title",content:"¿Cómo ejecutar un nodo indexador?"},{property:"og:description",content:"¿Cómo ejecutar un nodo indexador? Guía en vídeo Introducción Ejecutar un nodo indexador es otra opción fuera de usar Docker o tener un proyecto alojado para usted en SubQuery Proje"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/tutorials_examples/run-indexer.html",relativePath:"es/tutorials_examples/run-indexer.md",key:"v-f98997a6",path:"/es/tutorials_examples/run-indexer/",headers:[{level:2,title:"Guía en vídeo",slug:"guia-en-video",normalizedTitle:"guia en video",charIndex:40},{level:2,title:"Introducción",slug:"introduccion",normalizedTitle:"introduccion",charIndex:58},{level:2,title:"Postgres",slug:"postgres",normalizedTitle:"postgres",charIndex:306},{level:2,title:"Instalar subql/node",slug:"instalar-subql-node",normalizedTitle:"instalar subql/node",charIndex:511},{level:2,title:"Configurando la Base de Datos",slug:"configurando-la-base-de-datos",normalizedTitle:"configurando la base de datos",charIndex:861},{level:2,title:"Indexar un proyecto",slug:"indexar-un-proyecto",normalizedTitle:"indexar un proyecto",charIndex:1490},{level:2,title:"Inspección de Postgres",slug:"inspeccion-de-postgres",normalizedTitle:"inspeccion de postgres",charIndex:1812}],readingTime:{minutes:1.19,words:356},headersStr:"Guía en vídeo Introducción Postgres Instalar subql/node Configurando la Base de Datos Indexar un proyecto Inspección de Postgres",content:'# ¿Cómo ejecutar un nodo indexador?\n\n\n# Guía en vídeo\n\n\n# Introducción\n\nEjecutar un nodo indexador es otra opción fuera de usar Docker o tener un proyecto alojado para usted en SubQuery Projects. Requiere más tiempo y esfuerzo, pero mejorará su comprensión de cómo trabaja SubQuery bajo las cubiertas.\n\n\n# Postgres\n\nEjecutar un nodo indexador en su infraestructura requerirá la configuración de una base de datos de Postgres. Puede instalar Postgres desde aquí y asegurarse de que la versión es 12 o mayor.\n\n\n# Instalar subql/node\n\nLuego para ejecutar un nodo SubQuery, ejecute el siguiente comando:\n\nnpm install -g @subql/node\n\n\n1\n\n\nEl parámetro -g significa instalarlo globalmente, lo que significa que en OSX, la ubicación será /usr/local/lib/node_modules.\n\nUna vez instalado, puede comprobar la versión ejecutando:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# Configurando la Base de Datos\n\nA continuación, necesita configurar las siguientes variables de entorno:\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\n\n\n1\n2\n3\n4\n5\n\n\nPor supuesto, si tiene diferentes valores para las claves de arriba, por favor ajuste en consecuencia. Tenga en cuenta que el comando env mostrará las variables de entorno actuales y que este proceso sólo establece estos valores temporalmente. Es decir, sólo son válidos durante la sesión de la terminal. Para establecerlos permanentemente, guárdelos en tu ~/bash_profile en su lugar.\n\n\n# Indexar un proyecto\n\nPara comenzar a indexar un proyecto, navega en la carpeta de tu proyecto y ejecuta el siguiente comando:\n\nsubql-node -f .\n\n\n1\n\n\nSi no tienes un proyecto práctico, git clone https://github.com/subquery/subql-helloworld. Deberías ver el nodo indexador patear a la vida y comenzar a indexar bloques.\n\n\n# Inspección de Postgres\n\nSi navega a Postgres, verá dos tablas creadas. public.subqueries y subquery_1.starter_entities.\n\npublic.subqueries sólo contiene 1 fila de la que el indexador comprueba al inicio para "entender el estado actual" para que sepa desde dónde continuar. La tabla starter_entities contiene los índices. Para ver los datos, ejecute select (*) desde subquery_1.starter_entities.',normalizedContent:'# ¿como ejecutar un nodo indexador?\n\n\n# guia en video\n\n\n# introduccion\n\nejecutar un nodo indexador es otra opcion fuera de usar docker o tener un proyecto alojado para usted en subquery projects. requiere mas tiempo y esfuerzo, pero mejorara su comprension de como trabaja subquery bajo las cubiertas.\n\n\n# postgres\n\nejecutar un nodo indexador en su infraestructura requerira la configuracion de una base de datos de postgres. puede instalar postgres desde aqui y asegurarse de que la version es 12 o mayor.\n\n\n# instalar subql/node\n\nluego para ejecutar un nodo subquery, ejecute el siguiente comando:\n\nnpm install -g @subql/node\n\n\n1\n\n\nel parametro -g significa instalarlo globalmente, lo que significa que en osx, la ubicacion sera /usr/local/lib/node_modules.\n\nuna vez instalado, puede comprobar la version ejecutando:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# configurando la base de datos\n\na continuacion, necesita configurar las siguientes variables de entorno:\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\n\n\n1\n2\n3\n4\n5\n\n\npor supuesto, si tiene diferentes valores para las claves de arriba, por favor ajuste en consecuencia. tenga en cuenta que el comando env mostrara las variables de entorno actuales y que este proceso solo establece estos valores temporalmente. es decir, solo son validos durante la sesion de la terminal. para establecerlos permanentemente, guardelos en tu ~/bash_profile en su lugar.\n\n\n# indexar un proyecto\n\npara comenzar a indexar un proyecto, navega en la carpeta de tu proyecto y ejecuta el siguiente comando:\n\nsubql-node -f .\n\n\n1\n\n\nsi no tienes un proyecto practico, git clone https://github.com/subquery/subql-helloworld. deberias ver el nodo indexador patear a la vida y comenzar a indexar bloques.\n\n\n# inspeccion de postgres\n\nsi navega a postgres, vera dos tablas creadas. public.subqueries y subquery_1.starter_entities.\n\npublic.subqueries solo contiene 1 fila de la que el indexador comprueba al inicio para "entender el estado actual" para que sepa desde donde continuar. la tabla starter_entities contiene los indices. para ver los datos, ejecute select (*) desde subquery_1.starter_entities.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/es/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/es/tutorials_examples/terminology.html",relativePath:"es/tutorials_examples/terminology.md",key:"v-5bbe0a6d",path:"/es/tutorials_examples/terminology/",headers:[{level:2,title:"Terminology",slug:"terminology",normalizedTitle:"terminology",charIndex:2}],readingTime:{minutes:.49,words:147},headersStr:"Terminology",content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/faqs/faqs.html",relativePath:"faqs/faqs.md",key:"v-1265970d",path:"/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566},{level:2,title:"What is the endpoint for the Kusama network?",slug:"what-is-the-endpoint-for-the-kusama-network",normalizedTitle:"what is the endpoint for the kusama network?",charIndex:3600},{level:2,title:"What is the endpoint for the Polkadot mainnet network?",slug:"what-is-the-endpoint-for-the-polkadot-mainnet-network",normalizedTitle:"what is the endpoint for the polkadot mainnet network?",charIndex:3739}],readingTime:{minutes:2.2,words:659},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics? What is the endpoint for the Kusama network? What is the endpoint for the Polkadot mainnet network?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.\n\n\n# What is the endpoint for the Kusama network?\n\nThe network.endpoint for the Kusama network is wss://kusama.api.onfinality.io/public-ws.\n\n\n# What is the endpoint for the Polkadot mainnet network?\n\nThe network.endpoint for the Polkadot network is wss://polkadot.api.onfinality.io/public-ws.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.\n\n\n# what is the endpoint for the kusama network?\n\nthe network.endpoint for the kusama network is wss://kusama.api.onfinality.io/public-ws.\n\n\n# what is the endpoint for the polkadot mainnet network?\n\nthe network.endpoint for the polkadot network is wss://polkadot.api.onfinality.io/public-ws.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{frontmatter:{summary:"Welcome to SubQuery’s Indonesian Docs Jelajahi dan ubah data chain untuk membangun dApps yang intuitif dengan lebih cepat! Cara Memulai Panduan Memahami SubQuery dengan mengenali c",meta:[{property:"og:url",content:"/id/"},{property:"og:description",content:"Welcome to SubQuery’s Indonesian Docs Jelajahi dan ubah data chain untuk membangun dApps yang intuitif dengan lebih cepat! Cara Memulai Panduan Memahami SubQuery dengan mengenali c"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/",relativePath:"id/README.md",key:"v-560420fe",path:"/id/",readingTime:{minutes:2.87,words:861},headersStr:null,content:"Welcome to SubQuery’s Indonesian Docs\n\nJelajahi dan ubah data chain untuk membangun dApps yang intuitif dengan lebih cepat!\n\n\nCara Memulai Panduan\n\nMemahami SubQuery dengan mengenali contoh tradisional Halo Dunia. Menggunakan proyek templat dari Docker, anda bisa dengan cepat memulai dan menjalankan node dan mulai query blockchain dalam beberapa menit saja menggunakan perintah sederhana.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * Jaringan SubQuery\n   \n   Masa depan terdesentralisasi SubQuery. Cari tahu lebih lanjut tentang bagaimana indexer dan konsumen bisa mendapat hadiah.\n\n\nPertanyaan Umum\n\n * Apa itu SubQuery?\n   \n   SubQuery adalah proyek open source yang memungkinkan developer untuk mengindeks, mengubah, dan melakukan query Substrate data chain untuk mentenagai aplikasi mereka.\n   \n   READ MORE\n * Apa cara terbaik untuk memulai SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. Ini adalah tutorial 5 menit yang simpel berisikan pengunduhan templat, membangun proyek, kemudian menggunakan Docker untuk menjalankan node di localhost dan menjalankan query yang sederhana.\n\n * Bagaimana saya bisa berkontribusi atau memberi masukan ke SubQuery?\n   \n   Kami sangat menghargai kontribusi dan masukan dari komunitas. Untuk mengkontribusi kode, fork repositori yang menarik dan buat perubahan yang anda inginkan. Lalu kirimkan PR atau Pull Request. Oh, jangan lupa untuk mengetesnya dulu! Periksa juga panduan kontribusi kami (segera hadir).\n   \n   READ MORE\n * Berapa biaya untuk hosting proyek saya di SubQuery Projects?\n   \n   Hosting proyek anda di SubQuery Projects sepenuhnya gratis - ini adalah cara kami untuk memberi kembali kepada komunitas kami. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nMengintegrasi Custom Chain anda?\n\nBaik anda sedang membangun parachain baru atau blockchain baru di Substrate - SubQuery bisa membantu anda mengindeks dan menyelesaikan masalah di data chain anda. SubQuery didesain agar mudah diintegrasi dengan custom Substrate chain.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nDukung dan Kontribusi\n\nPunya pertanyaan atau berminat untuk cari tahu cara anda bisa berkontribusi? Kami dengan senang hati akan menjawab anda. Silakan hubungi kami via email atau media sosial dari tautan di bawah. Butuh ahli teknis? Gabung komunitas Discord kami dan dapatkan bantuan dari anggota komunitas kami.\n\nGABUNG PERBINCANGAN DI DISCORD\nHubungi kami hello@subquery.network\nIkuti kami di socialbn\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"welcome to subquery’s indonesian docs\n\njelajahi dan ubah data chain untuk membangun dapps yang intuitif dengan lebih cepat!\n\n\ncara memulai panduan\n\nmemahami subquery dengan mengenali contoh tradisional halo dunia. menggunakan proyek templat dari docker, anda bisa dengan cepat memulai dan menjalankan node dan mulai query blockchain dalam beberapa menit saja menggunakan perintah sederhana.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * jaringan subquery\n   \n   masa depan terdesentralisasi subquery. cari tahu lebih lanjut tentang bagaimana indexer dan konsumen bisa mendapat hadiah.\n\n\npertanyaan umum\n\n * apa itu subquery?\n   \n   subquery adalah proyek open source yang memungkinkan developer untuk mengindeks, mengubah, dan melakukan query substrate data chain untuk mentenagai aplikasi mereka.\n   \n   read more\n * apa cara terbaik untuk memulai subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. ini adalah tutorial 5 menit yang simpel berisikan pengunduhan templat, membangun proyek, kemudian menggunakan docker untuk menjalankan node di localhost dan menjalankan query yang sederhana.\n\n * bagaimana saya bisa berkontribusi atau memberi masukan ke subquery?\n   \n   kami sangat menghargai kontribusi dan masukan dari komunitas. untuk mengkontribusi kode, fork repositori yang menarik dan buat perubahan yang anda inginkan. lalu kirimkan pr atau pull request. oh, jangan lupa untuk mengetesnya dulu! periksa juga panduan kontribusi kami (segera hadir).\n   \n   read more\n * berapa biaya untuk hosting proyek saya di subquery projects?\n   \n   hosting proyek anda di subquery projects sepenuhnya gratis - ini adalah cara kami untuk memberi kembali kepada komunitas kami. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nmengintegrasi custom chain anda?\n\nbaik anda sedang membangun parachain baru atau blockchain baru di substrate - subquery bisa membantu anda mengindeks dan menyelesaikan masalah di data chain anda. subquery didesain agar mudah diintegrasi dengan custom substrate chain.\n\nlearn how to integrate with your chain\n\ndukung dan kontribusi\n\npunya pertanyaan atau berminat untuk cari tahu cara anda bisa berkontribusi? kami dengan senang hati akan menjawab anda. silakan hubungi kami via email atau media sosial dari tautan di bawah. butuh ahli teknis? gabung komunitas discord kami dan dapatkan bantuan dari anggota komunitas kami.\n\ngabung perbincangan di discord\nhubungi kami hello@subquery.network\nikuti kami di socialbn\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Skema GraphQL",frontmatter:{summary:"Skema GraphQL Menentukan Entitas File schema.graphql menentukan berbagai skema GraphQL. Karena cara kerja bahasa kueri GraphQL, file skema pada dasarnya menentukan bentuk data Anda",meta:[{property:"og:url",content:"/id/create/graphql.html"},{property:"og:title",content:"Skema GraphQL"},{property:"og:description",content:"Skema GraphQL Menentukan Entitas File schema.graphql menentukan berbagai skema GraphQL. Karena cara kerja bahasa kueri GraphQL, file skema pada dasarnya menentukan bentuk data Anda"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/create/graphql.html",relativePath:"id/create/graphql.md",key:"v-56f909a6",path:"/id/create/graphql/",headers:[{level:2,title:"Menentukan Entitas",slug:"menentukan-entitas",normalizedTitle:"menentukan entitas",charIndex:20},{level:3,title:"Entitas",slug:"entitas",normalizedTitle:"entitas",charIndex:31},{level:3,title:"Skalar dan jenis yang didukung",slug:"skalar-dan-jenis-yang-didukung",normalizedTitle:"skalar dan jenis yang didukung",charIndex:979},{level:2,title:"Mengindeks berdasarkan bidang kunci non primer",slug:"mengindeks-berdasarkan-bidang-kunci-non-primer",normalizedTitle:"mengindeks berdasarkan bidang kunci non primer",charIndex:1359},{level:2,title:"Hubungan Entitas",slug:"hubungan-entitas",normalizedTitle:"hubungan entitas",charIndex:1250},{level:3,title:"Hubungan Satu Per Satu",slug:"hubungan-satu-per-satu",normalizedTitle:"hubungan satu per satu",charIndex:3524},{level:3,title:"Hubungan Satu ke Banyak",slug:"hubungan-satu-ke-banyak",normalizedTitle:"hubungan satu ke banyak",charIndex:3996},{level:3,title:"Hubungan Banyak ke Banyak",slug:"hubungan-banyak-ke-banyak",normalizedTitle:"hubungan banyak ke banyak",charIndex:4330},{level:3,title:"Pencarian Terbalik",slug:"pencarian-terbalik",normalizedTitle:"pencarian terbalik",charIndex:5375},{level:2,title:"Jenis JSON",slug:"jenis-json",normalizedTitle:"jenis json",charIndex:6061},{level:3,title:"Menentukan direktif JSON",slug:"menentukan-direktif-json",normalizedTitle:"menentukan direktif json",charIndex:6764},{level:3,title:"Mengkueri bidang JSON",slug:"mengkueri-bidang-json",normalizedTitle:"mengkueri bidang json",charIndex:7480}],readingTime:{minutes:3.6,words:1081},headersStr:"Menentukan Entitas Entitas Skalar dan jenis yang didukung Mengindeks berdasarkan bidang kunci non primer Hubungan Entitas Hubungan Satu Per Satu Hubungan Satu ke Banyak Hubungan Banyak ke Banyak Pencarian Terbalik Jenis JSON Menentukan direktif JSON Mengkueri bidang JSON",content:"# Skema GraphQL\n\n\n# Menentukan Entitas\n\nFile schema.graphql menentukan berbagai skema GraphQL. Karena cara kerja bahasa kueri GraphQL, file skema pada dasarnya menentukan bentuk data Anda dari SubQuery. Untuk mempelajari lebih lanjut tentang bagaimana cara menulis di bahasa skema GraphQL, kami menyarankan untuk memeriksa Skema dan Jenis.\n\nPenting: Saat Anda membuat perubahan apa pun ke file skema, mohon memastikan bahwa Anda meregenerasi direktori jenis Anda dengan perintah berikut yarn codegen\n\n\n# Entitas\n\nMasing-masing entitas harus menentukan bidangnya yang diperlukan id dengan jenis ID!. Digunakan sebagai kunci utama dan unik di antara semua entitas berjenis sama.\n\nBidang yang tidak bisa di null diindikasikan dengan !. Mohon lihat contoh di bawah ini:\n\ntype Example @entity {\n  id: ID! # bidang id selalu diperlukan dan harus terlihat seperti ini\n  name: String! # Ini adalah bidang yang diperlukan\n  address: String # Ini adalah bidang opsional\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Skalar dan jenis yang didukung\n\nKami saat ini mendukung jenis skalar:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> untuk entitas hubungan yang bersarang, Anda bisa menggunakan nama entitas yang ditentukan sebagai salah satu bidang. Mohon lihat di Hubungan Entitas.\n * JSON secara alternatif bisa menyimpan data yang terstruktur, mohon lihat jenis JSON\n\n\n# Mengindeks berdasarkan bidang kunci non primer\n\nUntuk meningkatkan performa kueri, indeks bidang entitas dengan mengimplementasikan anotasi @index di bidang kunci non primer.\n\nAkan tetapi, kami tidak mengizinkan pengguna untuk menambahkan anotasi @index di obyek JSON apa pun. Secara default, indeks secara otomatis ditambahkan ke kunci asing dan bidang JSON mana pun di database, tetapi hanya untuk mendorong performa layanan kueri.\n\nBerikut sebuah contoh.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique bisa diatur menjadi true atau false\n  title: Title! # Indeks secara otomatis ditambahkan ke bidang kunci asing\n}\n\ntype Title @entity {\n  id: ID!\n  name: String! @index(unique: true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nBerasumsi kita mengetahui nama pengguna ini, tetapi kita tidak mengetahui nilai id persisnya, daripada mengekstrak semua pengguna dan kemudian memfilter berdasarkan nama kita bisa menambahkan @indexdi belakang bidang nama. Ini menjadikan kueri jauh lebih cepat dan kita bisa dengan tambahan melewati unique: trueuntuk memastikan keunikan.\n\nJika sebuah bidang tidak unik, ukuran hasil maksimalnya adalah 100\n\nSaat pembuatan kode berjalan, ini akan secara otomatis membuat getByName di bawah model User, dan bidang kunci asing title akan membuat metode getByTitleId, yang keduanya bisa diakses langsung di fungsi pemetaan.\n\n/* Persiapkan catatan untuk entitas judul */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from '../types/models/User';\nimport {Title} from '../types/models/Title';\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Hubungan Entitas\n\nEntitas sering kali telah menyarangkan hubungan dengan entitas lain. Mengatur nilai bidang ke nama entitas lain akan menentukan hubungan satu per satu di antara dua entitas ini secara default.\n\nHubungan entitas berbeda (satu per satu, satu ke banyak, dan banyak ke banyak) bisa dikonfigurasikan menggunakan contoh di bawah ini.\n\n\n# Hubungan Satu Per Satu\n\nHubungan satu per satu adalah hubungan default saat hanya satu entitas yang dipetakan.\n\nContoh: Sebuah paspor hanya milik satu orang saja dan satu orang hanya memiliki satu paspor (dalam contoh ini):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Hubungan Satu ke Banyak\n\nAnda bisa menggunakan tanda kurung siku untuk mengindikasikan bahwa sebuah jenis bidang menyertakan beberapa entitas.\n\nContoh: Seseorang bisa memiliki beberapa akun.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account]\n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Hubungan Banyak ke Banyak\n\nHubungan banyak ke banyak bisa diraih dengan mengimplementasikan entitas pemetaan untuk menghubungkan dua entitas lainnya.\n\nContoh: Setiap orang merupakan bagian dari beberapa kelompok (PersonGroup) dan kelompok memiliki beberapa orang berbeda (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nMemungkinkan juga halnya untuk membuat koneksi entitas yang sama di beberapa bidang entitas tengah.\n\nContohnya, sebuah akun bisa memiliki beberapa transfer, dan masing-masing transfer memiliki sumber dan akun tujuan.\n\nIni akan mendasarkan hubungan dua arah antara dua Akun (dari dan ke) melalui tabel Transfer.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Pencarian Terbalik\n\nUntuk menyalakan pencarian terbalik di sebuah entitas ke hubungan, lampirkan @derivedFrom ke bidang dan tunjuk ke bidang pencarian terbaliknya di entitas lain.\n\nIni menciptakan bidang virtual pada entitas yang bisa dikuerikan.\n\nTransfer \"dari\" sebuah Akun bisa diakses dari entitas Akun dengan mengatur transferTerkirim atau transferDiterima dari bidang dari atau ke.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Jenis JSON\n\nKami mendukung penyimpanan data sebagai jenis JSON, yang merupakan cara cepat untuk menyimpan data terstruktur. Kami akan secara otomatis menghasilkan antarmuka JSON yang berkaitan untuk mengkueri data ini dan menghemat waktu Anda menentukan dan mengatur entitas.\n\nKami menyarankan pengguna menggunakan jenis JSON di skenario berikut:\n\n * Saat menyimpan data terstruktur di satu bidang lebih bisa diatur daripada membuat beberapa entitas berbeda.\n * Menyimpan kunci yang berubah-ubah/preferensi nilai pengguna (di mana nilai bisa menjadi boolean, tekstual, atau numerik, dan Anda tidak ingin memiliki kolom terpisah untuk jenis data berbeda)\n * Skema ini tidak stabil dan sering berubah\n\n\n# Menentukan direktif JSON\n\nMenentukan properti sebagai jenis JSON dengan menambahkan anotasi jsonField di entitas. Ini akan secara otomatis menghasilkan antarmuka untuk semua obyek JSON di proyek Anda di bawah types/interfaces.ts, dan Anda bisa mengaksesnya di fungsi pemetaan Anda.\n\nTidak seperti entitas, obyek direktif jsonField tidak memerlukan bidang id apa pun. Obyek JSON juga bisa bersarang dengan obyek JSON lainnya.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID!\n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Mengkueri bidang JSON\n\nKekurangan menggunakan jenis JSON adalah dampak sekilas pada efisiensi kueri saat memfilter, karena setiap kali melakukan pencarian teks, begitu pula di seluruh entitas.\n\nAkan tetapi, dampaknya masih bisa diterima di layanan kueri kami. Berikut sebuah contoh cara menggunakan operator contains di kueri GraphQL pada bidang JSON untuk mencari 5 pengguna pertama yang memiliki nomor telepon yang mengandung '0064'.\n\n#Untuk mencari 5 pengguna pertama yang memiliki nomor telepon yang mengandung '0064'.\n\nquery {\n  user(first: 5, filter: {contactCard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",normalizedContent:"# skema graphql\n\n\n# menentukan entitas\n\nfile schema.graphql menentukan berbagai skema graphql. karena cara kerja bahasa kueri graphql, file skema pada dasarnya menentukan bentuk data anda dari subquery. untuk mempelajari lebih lanjut tentang bagaimana cara menulis di bahasa skema graphql, kami menyarankan untuk memeriksa skema dan jenis.\n\npenting: saat anda membuat perubahan apa pun ke file skema, mohon memastikan bahwa anda meregenerasi direktori jenis anda dengan perintah berikut yarn codegen\n\n\n# entitas\n\nmasing-masing entitas harus menentukan bidangnya yang diperlukan id dengan jenis id!. digunakan sebagai kunci utama dan unik di antara semua entitas berjenis sama.\n\nbidang yang tidak bisa di null diindikasikan dengan !. mohon lihat contoh di bawah ini:\n\ntype example @entity {\n  id: id! # bidang id selalu diperlukan dan harus terlihat seperti ini\n  name: string! # ini adalah bidang yang diperlukan\n  address: string # ini adalah bidang opsional\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# skalar dan jenis yang didukung\n\nkami saat ini mendukung jenis skalar:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> untuk entitas hubungan yang bersarang, anda bisa menggunakan nama entitas yang ditentukan sebagai salah satu bidang. mohon lihat di hubungan entitas.\n * json secara alternatif bisa menyimpan data yang terstruktur, mohon lihat jenis json\n\n\n# mengindeks berdasarkan bidang kunci non primer\n\nuntuk meningkatkan performa kueri, indeks bidang entitas dengan mengimplementasikan anotasi @index di bidang kunci non primer.\n\nakan tetapi, kami tidak mengizinkan pengguna untuk menambahkan anotasi @index di obyek json apa pun. secara default, indeks secara otomatis ditambahkan ke kunci asing dan bidang json mana pun di database, tetapi hanya untuk mendorong performa layanan kueri.\n\nberikut sebuah contoh.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique bisa diatur menjadi true atau false\n  title: title! # indeks secara otomatis ditambahkan ke bidang kunci asing\n}\n\ntype title @entity {\n  id: id!\n  name: string! @index(unique: true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nberasumsi kita mengetahui nama pengguna ini, tetapi kita tidak mengetahui nilai id persisnya, daripada mengekstrak semua pengguna dan kemudian memfilter berdasarkan nama kita bisa menambahkan @indexdi belakang bidang nama. ini menjadikan kueri jauh lebih cepat dan kita bisa dengan tambahan melewati unique: trueuntuk memastikan keunikan.\n\njika sebuah bidang tidak unik, ukuran hasil maksimalnya adalah 100\n\nsaat pembuatan kode berjalan, ini akan secara otomatis membuat getbyname di bawah model user, dan bidang kunci asing title akan membuat metode getbytitleid, yang keduanya bisa diakses langsung di fungsi pemetaan.\n\n/* persiapkan catatan untuk entitas judul */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from '../types/models/user';\nimport {title} from '../types/models/title';\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# hubungan entitas\n\nentitas sering kali telah menyarangkan hubungan dengan entitas lain. mengatur nilai bidang ke nama entitas lain akan menentukan hubungan satu per satu di antara dua entitas ini secara default.\n\nhubungan entitas berbeda (satu per satu, satu ke banyak, dan banyak ke banyak) bisa dikonfigurasikan menggunakan contoh di bawah ini.\n\n\n# hubungan satu per satu\n\nhubungan satu per satu adalah hubungan default saat hanya satu entitas yang dipetakan.\n\ncontoh: sebuah paspor hanya milik satu orang saja dan satu orang hanya memiliki satu paspor (dalam contoh ini):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# hubungan satu ke banyak\n\nanda bisa menggunakan tanda kurung siku untuk mengindikasikan bahwa sebuah jenis bidang menyertakan beberapa entitas.\n\ncontoh: seseorang bisa memiliki beberapa akun.\n\ntype person @entity {\n  id: id!\n  accounts: [account]\n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# hubungan banyak ke banyak\n\nhubungan banyak ke banyak bisa diraih dengan mengimplementasikan entitas pemetaan untuk menghubungkan dua entitas lainnya.\n\ncontoh: setiap orang merupakan bagian dari beberapa kelompok (persongroup) dan kelompok memiliki beberapa orang berbeda (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nmemungkinkan juga halnya untuk membuat koneksi entitas yang sama di beberapa bidang entitas tengah.\n\ncontohnya, sebuah akun bisa memiliki beberapa transfer, dan masing-masing transfer memiliki sumber dan akun tujuan.\n\nini akan mendasarkan hubungan dua arah antara dua akun (dari dan ke) melalui tabel transfer.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# pencarian terbalik\n\nuntuk menyalakan pencarian terbalik di sebuah entitas ke hubungan, lampirkan @derivedfrom ke bidang dan tunjuk ke bidang pencarian terbaliknya di entitas lain.\n\nini menciptakan bidang virtual pada entitas yang bisa dikuerikan.\n\ntransfer \"dari\" sebuah akun bisa diakses dari entitas akun dengan mengatur transferterkirim atau transferditerima dari bidang dari atau ke.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# jenis json\n\nkami mendukung penyimpanan data sebagai jenis json, yang merupakan cara cepat untuk menyimpan data terstruktur. kami akan secara otomatis menghasilkan antarmuka json yang berkaitan untuk mengkueri data ini dan menghemat waktu anda menentukan dan mengatur entitas.\n\nkami menyarankan pengguna menggunakan jenis json di skenario berikut:\n\n * saat menyimpan data terstruktur di satu bidang lebih bisa diatur daripada membuat beberapa entitas berbeda.\n * menyimpan kunci yang berubah-ubah/preferensi nilai pengguna (di mana nilai bisa menjadi boolean, tekstual, atau numerik, dan anda tidak ingin memiliki kolom terpisah untuk jenis data berbeda)\n * skema ini tidak stabil dan sering berubah\n\n\n# menentukan direktif json\n\nmenentukan properti sebagai jenis json dengan menambahkan anotasi jsonfield di entitas. ini akan secara otomatis menghasilkan antarmuka untuk semua obyek json di proyek anda di bawah types/interfaces.ts, dan anda bisa mengaksesnya di fungsi pemetaan anda.\n\ntidak seperti entitas, obyek direktif jsonfield tidak memerlukan bidang id apa pun. obyek json juga bisa bersarang dengan obyek json lainnya.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id!\n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# mengkueri bidang json\n\nkekurangan menggunakan jenis json adalah dampak sekilas pada efisiensi kueri saat memfilter, karena setiap kali melakukan pencarian teks, begitu pula di seluruh entitas.\n\nakan tetapi, dampaknya masih bisa diterima di layanan kueri kami. berikut sebuah contoh cara menggunakan operator contains di kueri graphql pada bidang json untuk mencari 5 pengguna pertama yang memiliki nomor telepon yang mengandung '0064'.\n\n#untuk mencari 5 pengguna pertama yang memiliki nomor telepon yang mengandung '0064'.\n\nquery {\n  user(first: 5, filter: {contactcard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Membuat Proyek SubQuery",frontmatter:{summary:"Membuat Proyek SubQuery Di panduan mulai cepat, kami dengan sangat cepat memberikan contoh untuk menjelaskan pada Anda apa itu SubQuery dan bagaimana cara kerjanya. Di sini kita ak",meta:[{property:"og:url",content:"/id/create/introduction.html"},{property:"og:title",content:"Membuat Proyek SubQuery"},{property:"og:description",content:"Membuat Proyek SubQuery Di panduan mulai cepat, kami dengan sangat cepat memberikan contoh untuk menjelaskan pada Anda apa itu SubQuery dan bagaimana cara kerjanya. Di sini kita ak"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/create/introduction.html",relativePath:"id/create/introduction.md",key:"v-6a073232",path:"/id/create/introduction/",headers:[{level:2,title:"Alur Kerja Dasar",slug:"alur-kerja-dasar",normalizedTitle:"alur kerja dasar",charIndex:291},{level:2,title:"Struktur Direktori",slug:"struktur-direktori",normalizedTitle:"struktur direktori",charIndex:1278},{level:2,title:"Pembuatan Kode",slug:"pembuatan-kode",normalizedTitle:"pembuatan kode",charIndex:1651},{level:2,title:"Bentuk",slug:"bentuk",normalizedTitle:"bentuk",charIndex:2166},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2412}],readingTime:{minutes:1.61,words:482},headersStr:"Alur Kerja Dasar Struktur Direktori Pembuatan Kode Bentuk Logging",content:"# Membuat Proyek SubQuery\n\nDi panduan mulai cepat, kami dengan sangat cepat memberikan contoh untuk menjelaskan pada Anda apa itu SubQuery dan bagaimana cara kerjanya. Di sini kita akan melihat lebih dekat alur kerja saat membuat proyek Anda dan file kunci yang akan Anda ikut sertakan.\n\n\n# Alur Kerja Dasar\n\nSebagian contoh berikut akan mengasumsikan Anda telah berhasil menginisialisasi paket pemula di bagian Mulai cepat. Dari paket pemula itu, kita akan berjalan melewati proses standar untuk menyesuaikan dan mengimplementasikan proyek SubQuery Anda.\n\n 1. Inisialisasi proyek Anda menggunakan subql init PROJECT_NAME\n 2. Perbarui file Manifest (project.yaml) untuk menyertakan informasi tentang blockchain Anda, dan entitas yang akan Anda petakan - lihat File Manifest\n 3. Buat entitas GraphQL di skema Anda (schema.graphql) yang menentuakn bentuk data yang akan Anda ekstrak dan coba untuk kueri - lihat Skema GraphQL\n 4. Tambahkan semua fungsi pemetaan (mis mappingHandlers.ts yang ingin Anda minta untuk ubah data chainnya ke entitas GraphQL yang sudah Anda tentukan - lihat Pemetaan\n 5. Hasilkan, bentuk, dan terbitkan kode Anda ke Proyek SubQuery (atau jalankan di node lokal Anda) - lihat Menjalankan dan Mengkueri Proyek Pemula Anda di panduan mulai cepat kami.\n\n\n# Struktur Direktori\n\nPeta berikut ini memberikan gambaran struktur direktori proyek SubQuery saat perintah init berjalan.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nContohnya:\n\n\n\n\n# Pembuatan Kode\n\nKapan pun Anda mengubah entitas GraphQL Anda, Anda harus menghasilkan ulang direktori jenis Anda dengan perintah berikut.\n\nyarn codegen\n\n\n1\n\n\nIni akan menciptakan direktori baru (atau memperbarui yang ada)src/types yang berisi kelas entitas yang dihasilkan untuk setiap jenis yang telah Anda tentukan sebelumnya di schema.graphql. Kelas-kelas ini memberikan pemuatan entitas berjenis aman, membaca dan menuliskan akses ke bidang entitas - lihat lebih banyak tentang proses ini di Skema GraphQL.\n\n\n# Bentuk\n\nUntuk menjalankan Proyek SubQuery Anda di host Node SubQuery secara lokal, pertama-tama Anda perlu membentuk pekerjaan Anda.\n\nJalankan perintah bentuk dari direktori proyek.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Logging\n\nMetode console.log tidak lagi didukung. Modul logger telah dimasukkan ke dalam jenis, yang berarti kami bisa mendukung logger yang bisa menerima berbagai tingkat logging.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nUntuk menggunakan logger.info atau logger.warn, tempatkan barisannya ke file pemetaan Anda.\n\n\n\nUntuk menggunakan logger.debug, langkah tambahan diperlukan. Untuk menggunakan logger. debug, langkah tambahan diperlukan.\n\nJika Anda sedang menjalankan docker container, tambahkan barisan ini ke file docker-compose.yaml Anda.\n\n\n\nAnda sekarang akan melihat logging baru di layar terminal.\n\n",normalizedContent:"# membuat proyek subquery\n\ndi panduan mulai cepat, kami dengan sangat cepat memberikan contoh untuk menjelaskan pada anda apa itu subquery dan bagaimana cara kerjanya. di sini kita akan melihat lebih dekat alur kerja saat membuat proyek anda dan file kunci yang akan anda ikut sertakan.\n\n\n# alur kerja dasar\n\nsebagian contoh berikut akan mengasumsikan anda telah berhasil menginisialisasi paket pemula di bagian mulai cepat. dari paket pemula itu, kita akan berjalan melewati proses standar untuk menyesuaikan dan mengimplementasikan proyek subquery anda.\n\n 1. inisialisasi proyek anda menggunakan subql init project_name\n 2. perbarui file manifest (project.yaml) untuk menyertakan informasi tentang blockchain anda, dan entitas yang akan anda petakan - lihat file manifest\n 3. buat entitas graphql di skema anda (schema.graphql) yang menentuakn bentuk data yang akan anda ekstrak dan coba untuk kueri - lihat skema graphql\n 4. tambahkan semua fungsi pemetaan (mis mappinghandlers.ts yang ingin anda minta untuk ubah data chainnya ke entitas graphql yang sudah anda tentukan - lihat pemetaan\n 5. hasilkan, bentuk, dan terbitkan kode anda ke proyek subquery (atau jalankan di node lokal anda) - lihat menjalankan dan mengkueri proyek pemula anda di panduan mulai cepat kami.\n\n\n# struktur direktori\n\npeta berikut ini memberikan gambaran struktur direktori proyek subquery saat perintah init berjalan.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\ncontohnya:\n\n\n\n\n# pembuatan kode\n\nkapan pun anda mengubah entitas graphql anda, anda harus menghasilkan ulang direktori jenis anda dengan perintah berikut.\n\nyarn codegen\n\n\n1\n\n\nini akan menciptakan direktori baru (atau memperbarui yang ada)src/types yang berisi kelas entitas yang dihasilkan untuk setiap jenis yang telah anda tentukan sebelumnya di schema.graphql. kelas-kelas ini memberikan pemuatan entitas berjenis aman, membaca dan menuliskan akses ke bidang entitas - lihat lebih banyak tentang proses ini di skema graphql.\n\n\n# bentuk\n\nuntuk menjalankan proyek subquery anda di host node subquery secara lokal, pertama-tama anda perlu membentuk pekerjaan anda.\n\njalankan perintah bentuk dari direktori proyek.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# logging\n\nmetode console.log tidak lagi didukung. modul logger telah dimasukkan ke dalam jenis, yang berarti kami bisa mendukung logger yang bisa menerima berbagai tingkat logging.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nuntuk menggunakan logger.info atau logger.warn, tempatkan barisannya ke file pemetaan anda.\n\n\n\nuntuk menggunakan logger.debug, langkah tambahan diperlukan. untuk menggunakan logger. debug, langkah tambahan diperlukan.\n\njika anda sedang menjalankan docker container, tambahkan barisan ini ke file docker-compose.yaml anda.\n\n\n\nanda sekarang akan melihat logging baru di layar terminal.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"File Manifest",frontmatter:{summary:"File Manifest File Manifest project.yaml bisa dilihat sebagai titik masuk proyek Anda dan menentukan sebagian besar detil tentang bagaimana SubQuery akan mengindeks dan mengubah da",meta:[{property:"og:url",content:"/id/create/manifest.html"},{property:"og:title",content:"File Manifest"},{property:"og:description",content:"File Manifest File Manifest project.yaml bisa dilihat sebagai titik masuk proyek Anda dan menentukan sebagian besar detil tentang bagaimana SubQuery akan mengindeks dan mengubah da"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/create/manifest.html",relativePath:"id/create/manifest.md",key:"v-7e31bc3d",path:"/id/create/manifest/",headers:[{level:2,title:"Filter Jaringan",slug:"filter-jaringan",normalizedTitle:"filter jaringan",charIndex:2034},{level:2,title:"Filter Pemetaan",slug:"filter-pemetaan",normalizedTitle:"filter pemetaan",charIndex:3424},{level:2,title:"Chain Kustom",slug:"chain-kustom",normalizedTitle:"chain kustom",charIndex:4806}],readingTime:{minutes:2.34,words:702},headersStr:"Filter Jaringan Filter Pemetaan Chain Kustom",content:"# File Manifest\n\nFile Manifest project.yaml bisa dilihat sebagai titik masuk proyek Anda dan menentukan sebagian besar detil tentang bagaimana SubQuery akan mengindeks dan mengubah data chain.\n\nManifest bisa dalam format YAML atau JSON. Dalam dokumen ini, kita akan menggunakan YAML di semua contoh. Di bawah ini merupakan contoh standar project.yaml standar.\n\nspecVersion: '0.0.1'\ndescription: ''\nrepository: 'https://github.com/subquery/subql-starter'\n\nschema: './schema.graphql'\n\nnetwork:\n  endpoint:\n    'wss://polkadot.api.onfinality.io/public-ws'\n    # Secara opsional memberikan endpoint HTTP kamus chain lengkap untuk mempercepat pemrosesan\n  dictionary: 'https://api.subquery.network/sq/subquery/dictionary-polkadot'\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter opsional tetapi disarankan untuk mempercepat pemrosesan acara\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n * network.endpoint menentukan endpoint wss atau ws blockchain untuk diindeks - Harus merupakan node arsip lengkap.\n * network.dictionary secara opsional memberikan endpoint HTTP kamus chain lengkap untuk mempercepat pemrosesan - lihat Menjalankan Pengindeks\n * dataSources menentukan data yang akan difilter dan diekstrak dan lokasi penanganan fungsi pemetaan untuk transformasi data untuk diaplikasikan.\n   * kind hanya mendukung substrate/Runtime untuk sekarang.\n   * startBlock menjelaskan tinggi balok untuk mulai diindeks.\n   * filter akan memfilter sumber data untuk berjalan pada nama spek endpoint jaringan, lihat filter jaringan\n   * mapping.handlers akan menuliskan semua fungsi pemetaan dan jenis penanganannya yang berkaitan, dengan filter pemetaan tambahan.\n\n\n# Filter Jaringan\n\nBiasanya pengguna akan membuat SubQuery dan berharap untuk menggunakannya kembali untuk testnet dan mainnetnya (misalnya Polkadot dan Kusama). Biasanya pengguna akan membuat SubQuery dan berharap untuk menggunakannya kembali untuk testnet dan mainnetnya (misalnya Polkadot dan Kusama). Dengan demikian, kami mengizinkan pengguna untuk menentukan detil berbeda untuk masing-masing sumber data yang berarti bahwa satu proyek SubQuery masih bisa digunakan di beberapa jaringan berbeda.\n\nPengguna bisa menambahkan filter di dataSources untuk memutuskan sumber data mana untuk dijalankan di masing-masing jaringan.\n\nDi bawah ini merupakan contoh yang menunjukkan sumber data berbeda untuk jaringan Polkadot dan Kusama.\n\n\n---\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n\n#Buat template untuk menghindari kelebihan\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter: #Optional\n      specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #gunakan template di sini\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter:\n      specName: kusama\n    startBlock: 12000\n    mapping: *mymapping # bisa digunakan ulang atau diganti\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# Filter Pemetaan\n\nFilter pemetaan merupakan sebuah filter yang sangat berguna untuk memutuskan balok, acara, atau ekstrinsik apa yang akan memicu penanganan pemetaan.\n\nHanya data masuk yang memenuhi ketentuan filter yang akan diproses oleh fungsi pemetaan. Filter pemetaan opsional tetapi disarankan karena mengurangi jumlah data yang diproses oleh proyek SubQuery Anda secara signifikan dan akan meningkatkan performa pengindeksan.\n\n#Contoh filter dari callHandler\nfilter:\n  module: balances\n  method: Deposit\n  success: true\n\n\n1\n2\n3\n4\n5\n\n\nTabel berikut menjelaskan filter didukung oleh penanganan berbeda.\n\nPENANGANAN     FILTER YANG DIDUKUNG\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Filter modul dan metode didukung di chain apa pun yang berbasis substrat.\n * Filter success membawa nilai boolean dan bisa digunakan untuk memfilter ekstrinsik berdasarkan status kesuksesannya.\n * Filter specVersion menentukan kisaran versi spek untuk balok substrat. Contoh berikut ini menjelaskan bagaimana cara mengatur kisaran versi.\n\nfilter:\n  specVersion: [23, 24]   #Balok indeks dengan specVersion antara 23 dan 24 (inklusif).\n  specVersion: [100]      #Balok indeks dengan specVersion lebih besar dari atau sama dengan 100.\n  specVersion: [null, 23] #Balok indeks dengan specVersion kurang dari atau sama dengan 23.\n\n\n1\n2\n3\n4\n\n\n\n# Chain Kustom\n\nAnda bisa mengindeks data dari chain kustom dengan juga menyertakan indeks chain di project.yaml. Nyatakan jenis spesifik yang didukung oleh blockchain ini ini network.types. Kami mendukung jenis tambahan yang digunakan oleh modul runtime substrat.\n\ntypesAlias, typesBundle, typesChain, and typesSpec juga didukung.\n\nspecVersion: '0.0.1'\ndescription: \"This subquery indexes kitty's birth info\"\nrepository: 'https://github.com/onfinality-io/subql-examples'\nschema: './schema.graphql'\nnetwork:\n  endpoint: 'ws://host.kittychain.io/public-ws'\n  types: {'KittyIndex': 'u32', 'Kitty': '[u8; 16]'}\n# typesChain: { chain: { Type5: 'example' } }\n# typesSpec: { spec: { Type6: 'example' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter: #Optional\n      specName: kitty-chain\n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n",normalizedContent:"# file manifest\n\nfile manifest project.yaml bisa dilihat sebagai titik masuk proyek anda dan menentukan sebagian besar detil tentang bagaimana subquery akan mengindeks dan mengubah data chain.\n\nmanifest bisa dalam format yaml atau json. dalam dokumen ini, kita akan menggunakan yaml di semua contoh. di bawah ini merupakan contoh standar project.yaml standar.\n\nspecversion: '0.0.1'\ndescription: ''\nrepository: 'https://github.com/subquery/subql-starter'\n\nschema: './schema.graphql'\n\nnetwork:\n  endpoint:\n    'wss://polkadot.api.onfinality.io/public-ws'\n    # secara opsional memberikan endpoint http kamus chain lengkap untuk mempercepat pemrosesan\n  dictionary: 'https://api.subquery.network/sq/subquery/dictionary-polkadot'\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter opsional tetapi disarankan untuk mempercepat pemrosesan acara\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n * network.endpoint menentukan endpoint wss atau ws blockchain untuk diindeks - harus merupakan node arsip lengkap.\n * network.dictionary secara opsional memberikan endpoint http kamus chain lengkap untuk mempercepat pemrosesan - lihat menjalankan pengindeks\n * datasources menentukan data yang akan difilter dan diekstrak dan lokasi penanganan fungsi pemetaan untuk transformasi data untuk diaplikasikan.\n   * kind hanya mendukung substrate/runtime untuk sekarang.\n   * startblock menjelaskan tinggi balok untuk mulai diindeks.\n   * filter akan memfilter sumber data untuk berjalan pada nama spek endpoint jaringan, lihat filter jaringan\n   * mapping.handlers akan menuliskan semua fungsi pemetaan dan jenis penanganannya yang berkaitan, dengan filter pemetaan tambahan.\n\n\n# filter jaringan\n\nbiasanya pengguna akan membuat subquery dan berharap untuk menggunakannya kembali untuk testnet dan mainnetnya (misalnya polkadot dan kusama). biasanya pengguna akan membuat subquery dan berharap untuk menggunakannya kembali untuk testnet dan mainnetnya (misalnya polkadot dan kusama). dengan demikian, kami mengizinkan pengguna untuk menentukan detil berbeda untuk masing-masing sumber data yang berarti bahwa satu proyek subquery masih bisa digunakan di beberapa jaringan berbeda.\n\npengguna bisa menambahkan filter di datasources untuk memutuskan sumber data mana untuk dijalankan di masing-masing jaringan.\n\ndi bawah ini merupakan contoh yang menunjukkan sumber data berbeda untuk jaringan polkadot dan kusama.\n\n\n---\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n\n#buat template untuk menghindari kelebihan\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter: #optional\n      specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #gunakan template di sini\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter:\n      specname: kusama\n    startblock: 12000\n    mapping: *mymapping # bisa digunakan ulang atau diganti\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# filter pemetaan\n\nfilter pemetaan merupakan sebuah filter yang sangat berguna untuk memutuskan balok, acara, atau ekstrinsik apa yang akan memicu penanganan pemetaan.\n\nhanya data masuk yang memenuhi ketentuan filter yang akan diproses oleh fungsi pemetaan. filter pemetaan opsional tetapi disarankan karena mengurangi jumlah data yang diproses oleh proyek subquery anda secara signifikan dan akan meningkatkan performa pengindeksan.\n\n#contoh filter dari callhandler\nfilter:\n  module: balances\n  method: deposit\n  success: true\n\n\n1\n2\n3\n4\n5\n\n\ntabel berikut menjelaskan filter didukung oleh penanganan berbeda.\n\npenanganan     filter yang didukung\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * filter modul dan metode didukung di chain apa pun yang berbasis substrat.\n * filter success membawa nilai boolean dan bisa digunakan untuk memfilter ekstrinsik berdasarkan status kesuksesannya.\n * filter specversion menentukan kisaran versi spek untuk balok substrat. contoh berikut ini menjelaskan bagaimana cara mengatur kisaran versi.\n\nfilter:\n  specversion: [23, 24]   #balok indeks dengan specversion antara 23 dan 24 (inklusif).\n  specversion: [100]      #balok indeks dengan specversion lebih besar dari atau sama dengan 100.\n  specversion: [null, 23] #balok indeks dengan specversion kurang dari atau sama dengan 23.\n\n\n1\n2\n3\n4\n\n\n\n# chain kustom\n\nanda bisa mengindeks data dari chain kustom dengan juga menyertakan indeks chain di project.yaml. nyatakan jenis spesifik yang didukung oleh blockchain ini ini network.types. kami mendukung jenis tambahan yang digunakan oleh modul runtime substrat.\n\ntypesalias, typesbundle, typeschain, and typesspec juga didukung.\n\nspecversion: '0.0.1'\ndescription: \"this subquery indexes kitty's birth info\"\nrepository: 'https://github.com/onfinality-io/subql-examples'\nschema: './schema.graphql'\nnetwork:\n  endpoint: 'ws://host.kittychain.io/public-ws'\n  types: {'kittyindex': 'u32', 'kitty': '[u8; 16]'}\n# typeschain: { chain: { type5: 'example' } }\n# typesspec: { spec: { type6: 'example' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter: #optional\n      specname: kitty-chain\n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Pemetaan",frontmatter:{summary:"Pemetaan Fungsi pemetaan menentukan bagaimana data chain diubah menjadi entitas GraphQL yang dioptimalkan yang sebelumnya telah kita tentukan di file schema.graphql. Pemetaan ditul",meta:[{property:"og:url",content:"/id/create/mapping.html"},{property:"og:title",content:"Pemetaan"},{property:"og:description",content:"Pemetaan Fungsi pemetaan menentukan bagaimana data chain diubah menjadi entitas GraphQL yang dioptimalkan yang sebelumnya telah kita tentukan di file schema.graphql. Pemetaan ditul"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/create/mapping.html",relativePath:"id/create/mapping.md",key:"v-eb9283e6",path:"/id/create/mapping/",headers:[{level:2,title:"Penanganan Balok",slug:"penanganan-balok",normalizedTitle:"penanganan balok",charIndex:590},{level:2,title:"Penanganan Acara",slug:"penanganan-acara",normalizedTitle:"penanganan acara",charIndex:1320},{level:2,title:"Penanganan Telepon",slug:"penanganan-telepon",normalizedTitle:"penanganan telepon",charIndex:2571},{level:2,title:"Keadaan Kueri",slug:"keadaan-kueri",normalizedTitle:"keadaan kueri",charIndex:3181},{level:2,title:"Panggilan RPC",slug:"panggilan-rpc",normalizedTitle:"panggilan rpc",charIndex:4218},{level:2,title:"Modul dan Perpustakaan",slug:"modul-dan-perpustakaan",normalizedTitle:"modul dan perpustakaan",charIndex:5284},{level:3,title:"Modul bawaan",slug:"modul-bawaan",normalizedTitle:"modul bawaan",charIndex:5765},{level:3,title:"Perpustakaan pihak ketiga",slug:"perpustakaan-pihak-ketiga",normalizedTitle:"perpustakaan pihak ketiga",charIndex:6448},{level:2,title:"Chain Substrat Kustom",slug:"chain-substrat-kustom",normalizedTitle:"chain substrat kustom",charIndex:5239},{level:3,title:"Persiapan",slug:"persiapan",normalizedTitle:"persiapan",charIndex:7252},{level:3,title:"Penghasil jenis",slug:"penghasil-jenis",normalizedTitle:"penghasil jenis",charIndex:10561},{level:3,title:"Penggunaan",slug:"penggunaan",normalizedTitle:"penggunaan",charIndex:11866},{level:3,title:"Panggilan rpc chain kustom",slug:"panggilan-rpc-chain-kustom",normalizedTitle:"panggilan rpc chain kustom",charIndex:12119}],readingTime:{minutes:6.46,words:1939},headersStr:"Penanganan Balok Penanganan Acara Penanganan Telepon Keadaan Kueri Panggilan RPC Modul dan Perpustakaan Modul bawaan Perpustakaan pihak ketiga Chain Substrat Kustom Persiapan Penghasil jenis Penggunaan Panggilan rpc chain kustom",content:'# Pemetaan\n\nFungsi pemetaan menentukan bagaimana data chain diubah menjadi entitas GraphQL yang dioptimalkan yang sebelumnya telah kita tentukan di file schema.graphql.\n\nPemetaan dituliskan di seubset TypeScript yang disebut Assembly Script yang bisa dikumpulkan menjadi WASM (Web Assembly).\n\n * Pemetaan ditentukan di direktori src/mappings dan diekspor sebagai sebuah fungsi\n * Pemetaan ini juga diekspor di src/index.ts\n * File pemetaan adalah referensi di project.yaml di bawah penanganan pemetaan.\n\nAda tiga kelas fungsi pemetaan;Block handlers, Event Handlers, and Call Handlers.\n\n\n# Penanganan Balok\n\nAnda bisa menggunakan penanganan balok untuk menangkap informasi setiap kali balok baru terlampir ke chain Substrat, misal balok angka. Untuk meraih ini, BlockHandler yang ditentukan akan dipanggil sekali untuk setiap balok.\n\nimport {SubstrateBlock} from \'@subql/types\';\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n  // Buat baru dengan StarterEntity with the block hash as it\'s ID\n  const record = new starterEntity(block.block.header.hash.toString());\n  record.field1 = block.block.header.number.toNumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nSubstrateBlock adalah jenis antarmuka yang diperluas dari signedBlock, tetapi juga menyertakan specVersion dan timestamp.\n\n\n# Penanganan Acara\n\nAnda bisa menggunakan penanganan acara untuk menangkap informasi saat acara tertentu disertakan di balok baru. Acara yang merupakan bagian dari runtime Substrat default dan balok mungkin berisi beberapa acara.\n\nSelama pemrosesan, penanganan acara akan menerima acara substrat sebagai argumen dengan input dan output acara. Segala jenis acara akan memicu pemetaan, mengizinkan aktivitas dengan sumber data untuk ditangkap. Anda harus menggunakan Filter Pemetaan di manifest Anda untuk memfilter acara untuk mengurangi waktu yang diperlukan untuk mengindeks data dan meningkatkan performa pemetaan.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Ambil catatan berdasarkan IDnya\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nSubstrateEvent merupakan jenis antarmuka yang diperluas dari EventRecord. Selain data acara, juga menyertakan id (balok yang merupakan milik acara ini) dan ekstrinsik di dalam balok ini.\n\n\n# Penanganan Telepon\n\nPenanganan telepon digunakan saat Anda ingin menangkap informasi pada ekstrinsik substrat tertentu.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n  const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n  record.field4 = extrinsic.block.timestamp;\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nSubstrateExtrinsic memperluas GenericExtrinsic. Ditandai id (balok yang merupakan milik ekstrinsik ini) dan memberikan properti ekstrinsik yang memperluas acara di antara balok ini. Tambahannya, mencatat status kesuksesan ekstrinsik ini.\n\n\n# Keadaan Kueri\n\nTujuan kami adalah menutupi semua sumber data untuk pengguna untuk penanganan pemetaan (lebih dari hanya tiga jenis acara antarmuka di atas). Dengan demikian, kami telah membuka sebagian antarmuka @polkadot/api untuk meningkatkan kemampuan.\n\nBerikut adalah antarmuka yang saat ini kami dukung:\n\n * api.query.<module>.<method>() akan mengkueri balok current.\n * api.query.<module>.<method>.multi() akan membuat beberapa jenis kueri yang sama di balok saat ini.\n * api.queryMulti() akan membuat beberapa jenis kueri berbeda di balok saat ini.\n\nBerikut antarmuka yang TIDAK kami dukung saat ini:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nLihat contoh menggunakan API ini di kasus contoh penggunaan validator-threshold kami.\n\n\n# Panggilan RPC\n\nKami juga mendukung metode API RPC yang merupakan panggilan jarak jauh yang mengizinkan fungsi pemetaan untuk berinteraksi dengan node, kueri, dan pengumpulan sesungguhnya. Premis inti SubQuery adalah sifatnya yang deterministik, dan oleh karena itu, untuk menjaga agar hasil tetap konsisten, kami hanya mengizinkan panggilan RPC historis.\n\nDokumen di JSON-RPC memberikan beberapa metode yang mengambil BlockHash sebagai parameter input (mis. at?: BlockHash), yang sekarang diizinkan. Kami juga telah mengubah metode-metode ini untuk mengambil block hash pengindeks saat ini secara default.\n\n// Mari menganggap kita saat ini mengindeks balok dengan nomor hash ini\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Metode asli memiliki input opsional yang merupakan block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// Akan menggunakan balok saat ini secara default\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * Untuk panggilan RPC Chain Substrat Kustom, lihat penggunaan.\n\n\n# Modul dan Perpustakaan\n\nUntuk meningkatkan kemampuan pemrosesan data SubQuery, kami telah mengizinkan sebagian modul bawaan NodeJS untuk menjalankan fungsi pemetaan di sandbox, dan telah mengizinkan pengguna untuk memanggil perpustakaan pihak ketiga.\n\nMohon ingat ini adalah fitur eksperimental dan Anda mungkin menemui bugs atau masalah yang mungkin mempengaruhi fungsi pemetaan Anda secara negatif. Mohon laporkan bugs apa pun yang Anda temukan dengan membuat isu di GitHub.\n\n\n# Modul bawaan\n\nSaat ini, kami mengizinkan modul NodeJS berikut ini: assert, buffer, crypto, util, dan path.\n\nDaripada mengimpor seluruh modul, kami menyarankan hanya mengimpor metode diperlukan yang Anda butuhkan. Sebagian metode di modul-modul ini mungkin memiliki ketergantungan yang tidak didukung dan akan gagal pada pengimporan.\n\nimport {hashMessage} from \'ethers/lib/utils\'; //Good way\nimport {utils} from \'ethers\'; //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n  const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n  record.field1 = hashMessage(\'Hello\');\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Perpustakaan pihak ketiga\n\nKarena pembatasan mesin virtual di sandbox kami, saat ini, kami hanya mendukung perpustakaan pihak ketiga yang ditulis oleh CommonJS.\n\nKami hanya mendukung perpustakaan hybrid seperti @polkadot/* yang menggunakan ESM sebagai default. Akan tetapi, jika perpustakaan lain bergantung pada modul apa pun dalam format ESM, mesin virtual TIDAK akan menyusun dan memberikan error.\n\n\n# Chain Substrat Kustom\n\nSubQuery bisa digunakan pada chain berbasis Substrat apa pun, tidak hanya Polkadot atau Kusama.\n\nAnda bisa menggunakan chain berbasis Substrat dan kami menyediakan alat-alat untuk mengimpor jenis, antarmuka, dan metode tambahan secara otomatis menggunakan @polkadot/typegen.\n\nDi bagian berikut, kami menggunakan contoh anak kucing kami untuk menjelaskan proses integrasi.\n\n\n# Persiapan\n\nBuat direktori baru api-interfaces di bawah proyek folder src untuk menyimpan semua file yang diperlukan dan dihasilkan. Kami juga membuat direktory api-interfaces/kitties karena kami ingin menambahkan dekorasi di API dari modul kitties.\n\n# Metadata\n\nKami memerlukan metadata untuk menghasilkan endpoint API yang sesungguhnya. Di contoh anak kucing, kami menggunakan endpoint dari testnet lokal, dan memberikan jenis tambahan. Ikuti langkah-langkah di pengaturan metadata PolkadotJS untuk mengambil metadata node dari endpoint HTTP.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\natau dari endpoint websocket dengan bantuan dari wesocat:\n\n//Instal websocat\nbrew install websocat\n\n//Dapatkan metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nBerikutnya, salin dan tempelkan output ke file JSON. Di contoh anak kucing kami, kami telah membuat api-interface.kitty.json.\n\n# Definisi jenis\n\nKami menganggap bahwa pengguna tahu jenis spesifik dan dukungan RPC dari chain, dan didefinisikan di Manifest.\n\nMengikuti pengaturan jenis, kami membuat :\n\n * src/api-interfaces/definitions.ts - ini mengekspor semua definisi sub-folder\n\nexport {default as kitties} from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - definisi jenis dari modul anak kucing\n\nexport default {\n  // custom types\n  types: {\n    Address: \'AccountId\',\n    LookupSource: \'AccountId\',\n    KittyIndex: \'u32\',\n    Kitty: \'[u8; 16]\',\n  },\n  // custom rpc : api.rpc.kitties.getKittyPrice\n  rpc: {\n    getKittyPrice: {\n      description: \'Get Kitty price\',\n      params: [\n        {\n          name: \'at\',\n          type: \'BlockHash\',\n          isHistoric: true,\n          isOptional: false,\n        },\n        {\n          name: \'kittyIndex\',\n          type: \'KittyIndex\',\n          isOptional: false,\n        },\n      ],\n      type: \'Balance\',\n    },\n  },\n};\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Paket\n\n * Di file package.json, pastikan untuk menambahkan @polkadot/typegen sebagai ketergantungan pembangunan dan @polkadot/api sebagai ketergantungan biasa (idealnya versi yang sama). Kita juga memerlukan ts-node sebagai ketergantungan pembangunan untuk membantu kita menjalankan script.\n * Kita menambahkan script untuk menjalankan kedua jenis; generate:defs dan penghasil generate:meta metadata (dalam urutan itu, sehingga metadata bisa menggunakan jenisnya).\n\nBerikut adalah versi package.json yang disederhanakan. Pastikan di bagian scripts nama paketnya betul dan direktorinya valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Penghasil jenis\n\nSekarang setelah persiapannya selesai, kita siap untuk menghasilkan jenis dan metadata. Jalankan perintah di bawah ini:\n\n# Yarn untuk menginstal ketergantungan baru\nyarn\n\n# Menghasilkan jenis\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nDi setiap folder modul (mis /kitties), seharusnya sekarang ada types.ts yang dihasilkan yang menentukan semua antarmuka dari definisi modul ini, juga file index.ts yang mengeskpor semuanya.\n\n# Menghasilkan metadata\nyarn generate:meta\n\n\n1\n2\n\n\nPerintah ini akan menghasilkan metadata dan api-augment baru untuk API. Karena kita tidak ingin menggunakan API bawaan, kita akan perlu menggantinya dengan menambahkan timpaan eksplisit di tsconfig.json kami. Setelah pembaruan, path di config akan terlihat seperti ini (tanpa komentarnya):\n\n{\n  "compilerOptions": {\n    // ini adalah nama paket yang kita gunakan (in the interface imports, --package for generators) */\n    "kitty-birthinfo/*": ["src/*"],\n    // di sini kita mengganti augmentasi @polkadot/api dengan milik kita sendiri, dihasilkan dari chain\n    "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n    // mengganti jenis tambahan dengan milik kita sendiri, seperti yang dihasilkan dari definisi\n    "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Penggunaan\n\nSekarang di fungsi pemetaan, kita bisa menunjukkan bagaimana metadata dan jenis sebenarnya menghias API. Endpoint RPC akan mendukung modul dan metode yang kita nyatakan di atas. Dan untuk menggunakan panggilan rpc kustom, mohon lihat bagian Panggilan rpc chain kustom\n\nexport async function kittyApiHandler(): Promise<void> {\n  //mengembalikan jenis KittyIndex\n  const nextKittyId = await api.query.kitties.nextKittyId();\n  //  mengembalikan jenis Kitty, jenis parameter input adalah AccountID dan KittyIndex\n  const allKitties = await api.query.kitties.kitties(\'xxxxxxxxx\', 123);\n  logger.info(`Next kitty id ${nextKittyId}`);\n  //Custom rpc, set undefined to blockhash\n  const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined, nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nJika Anda ingin menerbitkan proyek ini ke penjelajah kami, mohon sertakan file yang dihasilkan di src/api-interfaces.\n\n\n# Panggilan rpc chain kustom\n\nUntuk mendukung panggilan RPC chain yang dikustom, kami harus secara manual memasukkan definisi RPC untuk typesBundle, mengizinkan konfigurasi per-spek. Anda bisa menentukan typesBundle di project.yml. Dan mohon ingat hanya jenis panggilan isHistoric yang didukung.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# pemetaan\n\nfungsi pemetaan menentukan bagaimana data chain diubah menjadi entitas graphql yang dioptimalkan yang sebelumnya telah kita tentukan di file schema.graphql.\n\npemetaan dituliskan di seubset typescript yang disebut assembly script yang bisa dikumpulkan menjadi wasm (web assembly).\n\n * pemetaan ditentukan di direktori src/mappings dan diekspor sebagai sebuah fungsi\n * pemetaan ini juga diekspor di src/index.ts\n * file pemetaan adalah referensi di project.yaml di bawah penanganan pemetaan.\n\nada tiga kelas fungsi pemetaan;block handlers, event handlers, and call handlers.\n\n\n# penanganan balok\n\nanda bisa menggunakan penanganan balok untuk menangkap informasi setiap kali balok baru terlampir ke chain substrat, misal balok angka. untuk meraih ini, blockhandler yang ditentukan akan dipanggil sekali untuk setiap balok.\n\nimport {substrateblock} from \'@subql/types\';\n\nexport async function handleblock(block: substrateblock): promise<void> {\n  // buat baru dengan starterentity with the block hash as it\'s id\n  const record = new starterentity(block.block.header.hash.tostring());\n  record.field1 = block.block.header.number.tonumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nsubstrateblock adalah jenis antarmuka yang diperluas dari signedblock, tetapi juga menyertakan specversion dan timestamp.\n\n\n# penanganan acara\n\nanda bisa menggunakan penanganan acara untuk menangkap informasi saat acara tertentu disertakan di balok baru. acara yang merupakan bagian dari runtime substrat default dan balok mungkin berisi beberapa acara.\n\nselama pemrosesan, penanganan acara akan menerima acara substrat sebagai argumen dengan input dan output acara. segala jenis acara akan memicu pemetaan, mengizinkan aktivitas dengan sumber data untuk ditangkap. anda harus menggunakan filter pemetaan di manifest anda untuk memfilter acara untuk mengurangi waktu yang diperlukan untuk mengindeks data dan meningkatkan performa pemetaan.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // ambil catatan berdasarkan idnya\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nsubstrateevent merupakan jenis antarmuka yang diperluas dari eventrecord. selain data acara, juga menyertakan id (balok yang merupakan milik acara ini) dan ekstrinsik di dalam balok ini.\n\n\n# penanganan telepon\n\npenanganan telepon digunakan saat anda ingin menangkap informasi pada ekstrinsik substrat tertentu.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n  const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n  record.field4 = extrinsic.block.timestamp;\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nsubstrateextrinsic memperluas genericextrinsic. ditandai id (balok yang merupakan milik ekstrinsik ini) dan memberikan properti ekstrinsik yang memperluas acara di antara balok ini. tambahannya, mencatat status kesuksesan ekstrinsik ini.\n\n\n# keadaan kueri\n\ntujuan kami adalah menutupi semua sumber data untuk pengguna untuk penanganan pemetaan (lebih dari hanya tiga jenis acara antarmuka di atas). dengan demikian, kami telah membuka sebagian antarmuka @polkadot/api untuk meningkatkan kemampuan.\n\nberikut adalah antarmuka yang saat ini kami dukung:\n\n * api.query.<module>.<method>() akan mengkueri balok current.\n * api.query.<module>.<method>.multi() akan membuat beberapa jenis kueri yang sama di balok saat ini.\n * api.querymulti() akan membuat beberapa jenis kueri berbeda di balok saat ini.\n\nberikut antarmuka yang tidak kami dukung saat ini:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nlihat contoh menggunakan api ini di kasus contoh penggunaan validator-threshold kami.\n\n\n# panggilan rpc\n\nkami juga mendukung metode api rpc yang merupakan panggilan jarak jauh yang mengizinkan fungsi pemetaan untuk berinteraksi dengan node, kueri, dan pengumpulan sesungguhnya. premis inti subquery adalah sifatnya yang deterministik, dan oleh karena itu, untuk menjaga agar hasil tetap konsisten, kami hanya mengizinkan panggilan rpc historis.\n\ndokumen di json-rpc memberikan beberapa metode yang mengambil blockhash sebagai parameter input (mis. at?: blockhash), yang sekarang diizinkan. kami juga telah mengubah metode-metode ini untuk mengambil block hash pengindeks saat ini secara default.\n\n// mari menganggap kita saat ini mengindeks balok dengan nomor hash ini\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// metode asli memiliki input opsional yang merupakan block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// akan menggunakan balok saat ini secara default\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * untuk panggilan rpc chain substrat kustom, lihat penggunaan.\n\n\n# modul dan perpustakaan\n\nuntuk meningkatkan kemampuan pemrosesan data subquery, kami telah mengizinkan sebagian modul bawaan nodejs untuk menjalankan fungsi pemetaan di sandbox, dan telah mengizinkan pengguna untuk memanggil perpustakaan pihak ketiga.\n\nmohon ingat ini adalah fitur eksperimental dan anda mungkin menemui bugs atau masalah yang mungkin mempengaruhi fungsi pemetaan anda secara negatif. mohon laporkan bugs apa pun yang anda temukan dengan membuat isu di github.\n\n\n# modul bawaan\n\nsaat ini, kami mengizinkan modul nodejs berikut ini: assert, buffer, crypto, util, dan path.\n\ndaripada mengimpor seluruh modul, kami menyarankan hanya mengimpor metode diperlukan yang anda butuhkan. sebagian metode di modul-modul ini mungkin memiliki ketergantungan yang tidak didukung dan akan gagal pada pengimporan.\n\nimport {hashmessage} from \'ethers/lib/utils\'; //good way\nimport {utils} from \'ethers\'; //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n  const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n  record.field1 = hashmessage(\'hello\');\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# perpustakaan pihak ketiga\n\nkarena pembatasan mesin virtual di sandbox kami, saat ini, kami hanya mendukung perpustakaan pihak ketiga yang ditulis oleh commonjs.\n\nkami hanya mendukung perpustakaan hybrid seperti @polkadot/* yang menggunakan esm sebagai default. akan tetapi, jika perpustakaan lain bergantung pada modul apa pun dalam format esm, mesin virtual tidak akan menyusun dan memberikan error.\n\n\n# chain substrat kustom\n\nsubquery bisa digunakan pada chain berbasis substrat apa pun, tidak hanya polkadot atau kusama.\n\nanda bisa menggunakan chain berbasis substrat dan kami menyediakan alat-alat untuk mengimpor jenis, antarmuka, dan metode tambahan secara otomatis menggunakan @polkadot/typegen.\n\ndi bagian berikut, kami menggunakan contoh anak kucing kami untuk menjelaskan proses integrasi.\n\n\n# persiapan\n\nbuat direktori baru api-interfaces di bawah proyek folder src untuk menyimpan semua file yang diperlukan dan dihasilkan. kami juga membuat direktory api-interfaces/kitties karena kami ingin menambahkan dekorasi di api dari modul kitties.\n\n# metadata\n\nkami memerlukan metadata untuk menghasilkan endpoint api yang sesungguhnya. di contoh anak kucing, kami menggunakan endpoint dari testnet lokal, dan memberikan jenis tambahan. ikuti langkah-langkah di pengaturan metadata polkadotjs untuk mengambil metadata node dari endpoint http.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\natau dari endpoint websocket dengan bantuan dari wesocat:\n\n//instal websocat\nbrew install websocat\n\n//dapatkan metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nberikutnya, salin dan tempelkan output ke file json. di contoh anak kucing kami, kami telah membuat api-interface.kitty.json.\n\n# definisi jenis\n\nkami menganggap bahwa pengguna tahu jenis spesifik dan dukungan rpc dari chain, dan didefinisikan di manifest.\n\nmengikuti pengaturan jenis, kami membuat :\n\n * src/api-interfaces/definitions.ts - ini mengekspor semua definisi sub-folder\n\nexport {default as kitties} from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - definisi jenis dari modul anak kucing\n\nexport default {\n  // custom types\n  types: {\n    address: \'accountid\',\n    lookupsource: \'accountid\',\n    kittyindex: \'u32\',\n    kitty: \'[u8; 16]\',\n  },\n  // custom rpc : api.rpc.kitties.getkittyprice\n  rpc: {\n    getkittyprice: {\n      description: \'get kitty price\',\n      params: [\n        {\n          name: \'at\',\n          type: \'blockhash\',\n          ishistoric: true,\n          isoptional: false,\n        },\n        {\n          name: \'kittyindex\',\n          type: \'kittyindex\',\n          isoptional: false,\n        },\n      ],\n      type: \'balance\',\n    },\n  },\n};\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# paket\n\n * di file package.json, pastikan untuk menambahkan @polkadot/typegen sebagai ketergantungan pembangunan dan @polkadot/api sebagai ketergantungan biasa (idealnya versi yang sama). kita juga memerlukan ts-node sebagai ketergantungan pembangunan untuk membantu kita menjalankan script.\n * kita menambahkan script untuk menjalankan kedua jenis; generate:defs dan penghasil generate:meta metadata (dalam urutan itu, sehingga metadata bisa menggunakan jenisnya).\n\nberikut adalah versi package.json yang disederhanakan. pastikan di bagian scripts nama paketnya betul dan direktorinya valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# penghasil jenis\n\nsekarang setelah persiapannya selesai, kita siap untuk menghasilkan jenis dan metadata. jalankan perintah di bawah ini:\n\n# yarn untuk menginstal ketergantungan baru\nyarn\n\n# menghasilkan jenis\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\ndi setiap folder modul (mis /kitties), seharusnya sekarang ada types.ts yang dihasilkan yang menentukan semua antarmuka dari definisi modul ini, juga file index.ts yang mengeskpor semuanya.\n\n# menghasilkan metadata\nyarn generate:meta\n\n\n1\n2\n\n\nperintah ini akan menghasilkan metadata dan api-augment baru untuk api. karena kita tidak ingin menggunakan api bawaan, kita akan perlu menggantinya dengan menambahkan timpaan eksplisit di tsconfig.json kami. setelah pembaruan, path di config akan terlihat seperti ini (tanpa komentarnya):\n\n{\n  "compileroptions": {\n    // ini adalah nama paket yang kita gunakan (in the interface imports, --package for generators) */\n    "kitty-birthinfo/*": ["src/*"],\n    // di sini kita mengganti augmentasi @polkadot/api dengan milik kita sendiri, dihasilkan dari chain\n    "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n    // mengganti jenis tambahan dengan milik kita sendiri, seperti yang dihasilkan dari definisi\n    "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# penggunaan\n\nsekarang di fungsi pemetaan, kita bisa menunjukkan bagaimana metadata dan jenis sebenarnya menghias api. endpoint rpc akan mendukung modul dan metode yang kita nyatakan di atas. dan untuk menggunakan panggilan rpc kustom, mohon lihat bagian panggilan rpc chain kustom\n\nexport async function kittyapihandler(): promise<void> {\n  //mengembalikan jenis kittyindex\n  const nextkittyid = await api.query.kitties.nextkittyid();\n  //  mengembalikan jenis kitty, jenis parameter input adalah accountid dan kittyindex\n  const allkitties = await api.query.kitties.kitties(\'xxxxxxxxx\', 123);\n  logger.info(`next kitty id ${nextkittyid}`);\n  //custom rpc, set undefined to blockhash\n  const kittyprice = await api.rpc.kitties.getkittyprice(undefined, nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\njika anda ingin menerbitkan proyek ini ke penjelajah kami, mohon sertakan file yang dihasilkan di src/api-interfaces.\n\n\n# panggilan rpc chain kustom\n\nuntuk mendukung panggilan rpc chain yang dikustom, kami harus secara manual memasukkan definisi rpc untuk typesbundle, mengizinkan konfigurasi per-spek. anda bisa menentukan typesbundle di project.yml. dan mohon ingat hanya jenis panggilan ishistoric yang didukung.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Pertanyaan yang sering diajukan",frontmatter:{summary:"Pertanyaan yang sering diajukan Apa itu SubQuery? SubQuery adalah sebuah proyek sumber terbuka yang memungkinkan pengembang untuk menyusun, mengubah, dan membuat kueri data rantai ",meta:[{property:"og:url",content:"/id/faqs/faqs.html"},{property:"og:title",content:"Pertanyaan yang sering diajukan"},{property:"og:description",content:"Pertanyaan yang sering diajukan Apa itu SubQuery? SubQuery adalah sebuah proyek sumber terbuka yang memungkinkan pengembang untuk menyusun, mengubah, dan membuat kueri data rantai "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/faqs/faqs.html",relativePath:"id/faqs/faqs.md",key:"v-47ab00ba",path:"/id/faqs/faqs/",headers:[{level:2,title:"Apa itu SubQuery?",slug:"apa-itu-subquery",normalizedTitle:"apa itu subquery?",charIndex:38},{level:2,title:"Apa cara terbaik untuk memulai SubQuery?",slug:"apa-cara-terbaik-untuk-memulai-subquery",normalizedTitle:"apa cara terbaik untuk memulai subquery?",charIndex:446},{level:2,title:"Bagaimana saya bisa berkontribusi atau memberi umpan balik ke SubQuery?",slug:"bagaimana-saya-bisa-berkontribusi-atau-memberi-umpan-balik-ke-subquery",normalizedTitle:"bagaimana saya bisa berkontribusi atau memberi umpan balik ke subquery?",charIndex:763},{level:2,title:"Berapa biaya untuk menyelenggarakan proyek saya di Proyek SubQuery?",slug:"berapa-biaya-untuk-menyelenggarakan-proyek-saya-di-proyek-subquery",normalizedTitle:"berapa biaya untuk menyelenggarakan proyek saya di proyek subquery?",charIndex:1213},{level:2,title:"Apa itu slot penyebaran?",slug:"apa-itu-slot-penyebaran",normalizedTitle:"apa itu slot penyebaran?",charIndex:1541},{level:2,title:"Apa keuntungan dari slot tahapan?",slug:"apa-keuntungan-dari-slot-tahapan",normalizedTitle:"apa keuntungan dari slot tahapan?",charIndex:2223},{level:2,title:"Apa itu ekstrinsik?",slug:"apa-itu-ekstrinsik",normalizedTitle:"apa itu ekstrinsik?",charIndex:2732}],readingTime:{minutes:1.75,words:526},headersStr:"Apa itu SubQuery? Apa cara terbaik untuk memulai SubQuery? Bagaimana saya bisa berkontribusi atau memberi umpan balik ke SubQuery? Berapa biaya untuk menyelenggarakan proyek saya di Proyek SubQuery? Apa itu slot penyebaran? Apa keuntungan dari slot tahapan? Apa itu ekstrinsik?",content:'# Pertanyaan yang sering diajukan\n\n\n# Apa itu SubQuery?\n\nSubQuery adalah sebuah proyek sumber terbuka yang memungkinkan pengembang untuk menyusun, mengubah, dan membuat kueri data rantai Substrat untuk menggerakkan aplikasi mereka.\n\nSubQuery juga menyediakan penyelenggaraan proyek kelas produksi gratis untuk pengembang yang menghilangkan tanggung jawab mengelola infrastruktur, dan membiarkan pengembang melakukan yang terbaik - membangun.\n\n\n# Apa cara terbaik untuk memulai SubQuery?\n\nCara terbaik untuk memulai SubQuery adalah dengan mencoba tutorial Hello World kami. Ini adalah 5 menit sederhana untuk mengunduh template pemula, membangun proyek, dan kemudian menggunakan Docker untuk menjalankan node di localhost Anda dan menjalankan kueri sederhana.\n\n\n# Bagaimana saya bisa berkontribusi atau memberi umpan balik ke SubQuery?\n\nKami menyukai kontribusi dan umpan balik dari komunitas. Untuk menyumbang kode, pisahkan penyimpanan yang menarik dan buat perubahan Anda. Kemudian kirimkan PR atau Pull Request. Oh, jangan lupa juga untuk menguji! Lihat juga garis panduan kontribusi kami (akan diberitahu).\n\nUntuk memberi umpan balik, hubungi kami di hello@subquery.network atau buka discord channel kami\n\n\n# Berapa biaya untuk menyelenggarakan proyek saya di Proyek SubQuery?\n\nMenyelenggarakan proyek Anda di Proyek SubQuery sepenuhnya gratis - ini adalah cara kami mengembalikan kepada komunitas. Untuk mempelajari bagaimana menyelenggarakan proyek Anda bersama kami, silakan lihat tutorial Hello World (SubQuery diselenggarakan).\n\n\n# Apa itu slot penyebaran?\n\nSlot penyebaran adalah fitur di Proyek SubQuery yang setara dengan lingkungan pengembangan. Contohnya, dalam organisasi perangkat lunak apa pun biasanya ada lingkungan pengembangan dan lingkungan produksi minimal (mengabaikan localhost). Biasanya lingkungan tambahan seperti tahapan dan pra-produksi atau bahkan QA sudah termasuk tergantung pada kebutuhan organisasi dan pengaturan pengembangannya.\n\nSubQuery saat ini memiliki dua slot yang tersedia. Sebuah slot tahapan dan slot produksi. Ini memungkinkan pengembang untuk menyebarkan SubQuery mereka ke lingkungan tahapan dan semuanya berjalan dengan baik, "maju ke produksi" dengan mengklik tombol.\n\n\n# Apa keuntungan dari slot tahapan?\n\nKeuntungan utama menggunakan slot tahapan adalah memungkinkan Anda menyiapkan rilis proyek SubQuery baru Anda tanpa memaparkannya secara publik. Anda dapat menunggu slot tahapan untuk menyusun ulang semua data tanpa mempengaruhi aplikasi produksi Anda.\n\nSlot tahapan tidak ditampilkan kepada publik di Explorer dan memiliki URL unik yang hanya dapat dilihat oleh Anda. Dan tentu saja, lingkungan terpisah memungkinkan Anda menguji kode baru tanpa mempengaruhi produksi.\n\n\n# Apa itu ekstrinsik?\n\nJika Anda sudah akrab dengan konsep blockchain, Anda dapat menganggap ekstrinsik sebanding dengan transaksi. Lebih formal, ekstrinsik adalah sepotong informasi yang berasal dari luar rantai dan termasuk dalam blok. Ada tiga kategori ekstrinsik. Yaitu inheren, transaksi yang ditandatangani, dan transaksi yang tidak ditandatangani.\n\nEkstrinsik inheren adalah potongan informasi yang tidak ditandatangani dan hanya dimasukkan ke dalam blok oleh pencipta blok.\n\nEkstrinsik transaksi yang ditandatangani adalah transaksi yang berisi tanda tangan dari rekening yang mengeluarkan transaksi. Mereka ada untuk membayar biaya agar transaksi termasuk dalam rantai.\n\nTransaksi ekstrinsik yang tidak ditandatangani adalah transaksi yang tidak berisi tanda tangan dari rekening yang mengeluarkan transaksi. Ekstrinsik transaksi yang tidak ditandatangani harus digunakan dengan hati-hati karena tidak ada yang membayar biaya, karena itu ditandatangani. Karena ini, antrian transaksi kekurangan logika ekonomi untuk mencegah spam.\n\nUntuk informasi lebih lanjut, klik di sini.',normalizedContent:'# pertanyaan yang sering diajukan\n\n\n# apa itu subquery?\n\nsubquery adalah sebuah proyek sumber terbuka yang memungkinkan pengembang untuk menyusun, mengubah, dan membuat kueri data rantai substrat untuk menggerakkan aplikasi mereka.\n\nsubquery juga menyediakan penyelenggaraan proyek kelas produksi gratis untuk pengembang yang menghilangkan tanggung jawab mengelola infrastruktur, dan membiarkan pengembang melakukan yang terbaik - membangun.\n\n\n# apa cara terbaik untuk memulai subquery?\n\ncara terbaik untuk memulai subquery adalah dengan mencoba tutorial hello world kami. ini adalah 5 menit sederhana untuk mengunduh template pemula, membangun proyek, dan kemudian menggunakan docker untuk menjalankan node di localhost anda dan menjalankan kueri sederhana.\n\n\n# bagaimana saya bisa berkontribusi atau memberi umpan balik ke subquery?\n\nkami menyukai kontribusi dan umpan balik dari komunitas. untuk menyumbang kode, pisahkan penyimpanan yang menarik dan buat perubahan anda. kemudian kirimkan pr atau pull request. oh, jangan lupa juga untuk menguji! lihat juga garis panduan kontribusi kami (akan diberitahu).\n\nuntuk memberi umpan balik, hubungi kami di hello@subquery.network atau buka discord channel kami\n\n\n# berapa biaya untuk menyelenggarakan proyek saya di proyek subquery?\n\nmenyelenggarakan proyek anda di proyek subquery sepenuhnya gratis - ini adalah cara kami mengembalikan kepada komunitas. untuk mempelajari bagaimana menyelenggarakan proyek anda bersama kami, silakan lihat tutorial hello world (subquery diselenggarakan).\n\n\n# apa itu slot penyebaran?\n\nslot penyebaran adalah fitur di proyek subquery yang setara dengan lingkungan pengembangan. contohnya, dalam organisasi perangkat lunak apa pun biasanya ada lingkungan pengembangan dan lingkungan produksi minimal (mengabaikan localhost). biasanya lingkungan tambahan seperti tahapan dan pra-produksi atau bahkan qa sudah termasuk tergantung pada kebutuhan organisasi dan pengaturan pengembangannya.\n\nsubquery saat ini memiliki dua slot yang tersedia. sebuah slot tahapan dan slot produksi. ini memungkinkan pengembang untuk menyebarkan subquery mereka ke lingkungan tahapan dan semuanya berjalan dengan baik, "maju ke produksi" dengan mengklik tombol.\n\n\n# apa keuntungan dari slot tahapan?\n\nkeuntungan utama menggunakan slot tahapan adalah memungkinkan anda menyiapkan rilis proyek subquery baru anda tanpa memaparkannya secara publik. anda dapat menunggu slot tahapan untuk menyusun ulang semua data tanpa mempengaruhi aplikasi produksi anda.\n\nslot tahapan tidak ditampilkan kepada publik di explorer dan memiliki url unik yang hanya dapat dilihat oleh anda. dan tentu saja, lingkungan terpisah memungkinkan anda menguji kode baru tanpa mempengaruhi produksi.\n\n\n# apa itu ekstrinsik?\n\njika anda sudah akrab dengan konsep blockchain, anda dapat menganggap ekstrinsik sebanding dengan transaksi. lebih formal, ekstrinsik adalah sepotong informasi yang berasal dari luar rantai dan termasuk dalam blok. ada tiga kategori ekstrinsik. yaitu inheren, transaksi yang ditandatangani, dan transaksi yang tidak ditandatangani.\n\nekstrinsik inheren adalah potongan informasi yang tidak ditandatangani dan hanya dimasukkan ke dalam blok oleh pencipta blok.\n\nekstrinsik transaksi yang ditandatangani adalah transaksi yang berisi tanda tangan dari rekening yang mengeluarkan transaksi. mereka ada untuk membayar biaya agar transaksi termasuk dalam rantai.\n\ntransaksi ekstrinsik yang tidak ditandatangani adalah transaksi yang tidak berisi tanda tangan dari rekening yang mengeluarkan transaksi. ekstrinsik transaksi yang tidak ditandatangani harus digunakan dengan hati-hati karena tidak ada yang membayar biaya, karena itu ditandatangani. karena ini, antrian transaksi kekurangan logika ekonomi untuk mencegah spam.\n\nuntuk informasi lebih lanjut, klik di sini.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Memasang SubQuery",frontmatter:{summary:"Memasang SubQuery Ada berbagai komponen yang diperlukan saat membuat proyek SubQuery. Komponen @subql/node diperlukan untuk menjalankan pengindeks. Pustaka @subql/query diperlukan ",meta:[{property:"og:url",content:"/id/install/install.html"},{property:"og:title",content:"Memasang SubQuery"},{property:"og:description",content:"Memasang SubQuery Ada berbagai komponen yang diperlukan saat membuat proyek SubQuery. Komponen @subql/node diperlukan untuk menjalankan pengindeks. Pustaka @subql/query diperlukan "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/install/install.html",relativePath:"id/install/install.md",key:"v-74b235b3",path:"/id/install/install/",headers:[{level:2,title:"Pasang @subql/cli",slug:"pasang-subql-cli",normalizedTitle:"pasang @subql/cli",charIndex:213},{level:2,title:"Pasang @subql/node",slug:"pasang-subql-node",normalizedTitle:"pasang @subql/node",charIndex:663},{level:2,title:"Pasang @subql/query",slug:"pasang-subql-query",normalizedTitle:"pasang @subql/query",charIndex:1309}],readingTime:{minutes:.97,words:290},headersStr:"Pasang @subql/cli Pasang @subql/node Pasang @subql/query",content:'# Memasang SubQuery\n\nAda berbagai komponen yang diperlukan saat membuat proyek SubQuery. Komponen @subql/node diperlukan untuk menjalankan pengindeks. Pustaka @subql/query diperlukan untuk menghasilkan kueri.\n\n\n# Pasang @subql/cli\n\nPustaka @subql/cli membantu membuat kerangka kerja proyek atau perancah yang berarti Anda tidak harus memulai dari awal.\n\nPasang SubQuery CLI secara global di terminal Anda dengan menggunakan Yarn atau NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nAnda kemudian dapat menjalankan bantuan untuk melihat perintah dan penggunaan yang tersedia yang disediakan oleh CLI:\n\nbantuan subql\n\n\n1\n\n\n\n# Pasang @subql/node\n\nNode SubQuery adalah implementasi yang mengekstrak data blockchain berbasis substrat per proyek SubQuery dan menyimpannya ke dalam database Postgres.\n\nPasang node SubQuery secara global di terminal Anda dengan menggunakan Yarn atau NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nSetelah terpasang, Anda dapat memulai node dengan:\n\nsubql-simpul <command>\n\n\n1\n\n\n> Catatan: Jika Anda menggunakan Docker atau menyelenggarakan proyek Anda di Proyek SubQuery, Anda dapat melewati langkah ini. Ini karena node SubQuery sudah disediakan di wadah Docker dan penyelenggaraan infrastruktur.\n\n\n# Pasang @subql/query\n\nPustaka kueri SubQuery menyediakan layanan yang memungkinkan Anda membuat kueri proyek Anda di lingkungan "taman bermain" melalui browser Anda.\n\nPasang kueri SubQuery secara global di terminal Anda dengan menggunakan Yarn atau NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Catatan: Jika Anda menggunakan Docker atau menyelenggarakan proyek Anda di Proyek SubQuery, Anda juga dapat melewati langkah ini. Ini karena node SubQuery sudah disediakan di wadah Docker dan penyelenggaraan infrastruktur.',normalizedContent:'# memasang subquery\n\nada berbagai komponen yang diperlukan saat membuat proyek subquery. komponen @subql/node diperlukan untuk menjalankan pengindeks. pustaka @subql/query diperlukan untuk menghasilkan kueri.\n\n\n# pasang @subql/cli\n\npustaka @subql/cli membantu membuat kerangka kerja proyek atau perancah yang berarti anda tidak harus memulai dari awal.\n\npasang subquery cli secara global di terminal anda dengan menggunakan yarn atau npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nanda kemudian dapat menjalankan bantuan untuk melihat perintah dan penggunaan yang tersedia yang disediakan oleh cli:\n\nbantuan subql\n\n\n1\n\n\n\n# pasang @subql/node\n\nnode subquery adalah implementasi yang mengekstrak data blockchain berbasis substrat per proyek subquery dan menyimpannya ke dalam database postgres.\n\npasang node subquery secara global di terminal anda dengan menggunakan yarn atau npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nsetelah terpasang, anda dapat memulai node dengan:\n\nsubql-simpul <command>\n\n\n1\n\n\n> catatan: jika anda menggunakan docker atau menyelenggarakan proyek anda di proyek subquery, anda dapat melewati langkah ini. ini karena node subquery sudah disediakan di wadah docker dan penyelenggaraan infrastruktur.\n\n\n# pasang @subql/query\n\npustaka kueri subquery menyediakan layanan yang memungkinkan anda membuat kueri proyek anda di lingkungan "taman bermain" melalui browser anda.\n\npasang kueri subquery secara global di terminal anda dengan menggunakan yarn atau npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> catatan: jika anda menggunakan docker atau menyelenggarakan proyek anda di proyek subquery, anda juga dapat melewati langkah ini. ini karena node subquery sudah disediakan di wadah docker dan penyelenggaraan infrastruktur.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Program Duta Besar",frontmatter:{summary:"Program Duta Besar Kami memahami bahwa salah satu kekuatan terbesar kami adalah komunitas kami, dan dengan bantuan Anda, kami ingin mengembangkan dan membentuk duta besar lokal unt",meta:[{property:"og:url",content:"/id/miscellaneous/ambassadors.html"},{property:"og:title",content:"Program Duta Besar"},{property:"og:description",content:"Program Duta Besar Kami memahami bahwa salah satu kekuatan terbesar kami adalah komunitas kami, dan dengan bantuan Anda, kami ingin mengembangkan dan membentuk duta besar lokal unt"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/miscellaneous/ambassadors.html",relativePath:"id/miscellaneous/ambassadors.md",key:"v-42d0237f",path:"/id/miscellaneous/ambassadors/",headers:[{level:2,title:"Apa yang Kami Yakini",slug:"apa-yang-kami-yakini",normalizedTitle:"apa yang kami yakini",charIndex:238},{level:2,title:"Program Duta Besar Kami",slug:"program-duta-besar-kami",normalizedTitle:"program duta besar kami",charIndex:1443},{level:3,title:"Keuntungan Duta Besar",slug:"keuntungan-duta-besar",normalizedTitle:"keuntungan duta besar",charIndex:1832},{level:2,title:"Bagaimana cara kerjanya",slug:"bagaimana-cara-kerjanya",normalizedTitle:"bagaimana cara kerjanya",charIndex:3168},{level:2,title:"Kegiatan Duta Besar",slug:"kegiatan-duta-besar",normalizedTitle:"kegiatan duta besar",charIndex:4191}],readingTime:{minutes:2.82,words:847},headersStr:"Apa yang Kami Yakini Program Duta Besar Kami Keuntungan Duta Besar Bagaimana cara kerjanya Kegiatan Duta Besar",content:"# Program Duta Besar\n\n\n\nKami memahami bahwa salah satu kekuatan terbesar kami adalah komunitas kami, dan dengan bantuan Anda, kami ingin mengembangkan dan membentuk duta besar lokal untuk komunitas di seluruh dunia.\n\nDaftar Sekarang!\n\n\n# Apa yang Kami Yakini\n\nTim kami bersatu dengan visi bersama untuk membangun yayasan layanan data yang fleksibel dan inklusif untuk ekosistem Polkadot.\n\nDibangun oleh pengembang, untuk pengembang: SubQuery adalah komunitas yang sedang berkembang yang fokus pada penyediaan produk dan layanan terbaik untuk pengembang kami, dan pembangun di ekosistem kami. SubQuery hanya berhasil jika ekosistem Polkadot berhasil, dan semua yang kami lakukan adalah mempertimbangkan pelanggan kami.\n\nIntegritas dan Akuntabilitas: Kami memiliki anggota tim di Auckland, Shanghai, dan Sydney sehingga pekerjaan jarak jauh penting bagi kami. Kami berharap tim kami diberdayakan dan bekerja sama secara mandiri untuk mencapai tujuan kami. Persyaratan utama untuk ini adalah agar tim kami bertanggung jawab atas tindakan mereka dan menjaga integritas mereka.\n\nDukungan dan Bimbingan Inklusif: Blockchain itu sulit, dan setiap orang terkadang membutuhkan bantuan. Tidak ada pertanyaan bodoh di komunitas kami dan semua orang di tim kami diharapkan membantu mendukung pengguna kami. Kami mempelajari beberapa wawasan paling berharga tentang layanan kami (dan bagaimana kami dapat meningkatkannya) langsung dari komunitas kami.\n\n\n# Program Duta Besar Kami\n\nProgram Duta Besar SubQuery kami bertujuan untuk menemukan pemimpin komunitas yang tertarik tentang Polkadot dan SubQuery. Kami mencari para pemula yang dapat menyebarkan berita tentang SubQuery di area lokal mereka dan menyediakan dukungan kepada pengembang baru yang ingin menggunakan SubQuery untuk membuat aplikasi dan layanan yang luar biasa di Polkadot.\n\n\n# Keuntungan Duta Besar\n\nDi SubQuery, kami bekerja keras untuk mencapai apa yang kami lakukan. Demikian juga, para Duta Besar diharapkan untuk meluangkan waktu ketika bergabung dengan tim kami tetapi akan diberi imbalan dengan keuntungan.\n\nPendanaan dan Dukungan: Anda akan diberi imbalan untuk pekerjaan yang baik dengan peluang awal untuk penjualan dan hadiah pribadi. Selain itu, kami akan menyediakan dana untuk Anda untuk menjalankan pertemuan komunitas.\n\nAkses Tim SubQuery: Anda akan memiliki akses langsung ke tim SubQuery inti dengan peluang untuk pelatihan langsung, AMA eksklusif dengan para pemimpin dan pengembang kami, dan wawasan tentang peta jalan kami.\n\nPengembangan Jaringan: Berharap untuk mengembangkan jaringan profesional Anda dengan menjadi Duta Besar untuk salah satu proyek Polkadot teratas. Bertemu duta besar lain di seluruh dunia dan berkenalan dengan proyek Polkadot lokal yang perlu kami dukung secara lokal. Anda bahkan mungkin bisa masuk gratis untuk mewakili SubQuery dalam acara di area lokal Anda.\n\nHadiah dan barang gratis lainnya: Semua orang suka barang gratis! Menerima alokasi tahunan hadiah SubQuery yang akan membuat Anda menonjol di antara orang banyak. Ditambah alokasi tambahan yang bisa Anda bagikan di acara komunitas. Anda juga akan menerima NFT eksklusif untuk status Duta Besar Anda.\n\n\n# Bagaimana cara kerjanya\n\nProgram Duta Besar kami memiliki beberapa tingkatan, setiap tingkatan memiliki keuntungan dan kemampuan yang berbeda. Anda dapat naik tingkatan dengan berpartisipasi dalam aktivitas Duta Besar dan bekerja keras untuk kami.\n\nSetelah Anda mengirim melalui aplikasi, kami akan memilih kandidat yang sesuai dengan nilai-nilai kami. Jika terpilih, Anda ditempatkan dalam program pelatihan kami dan akan menerima paket informasi, memperluas pemahaman Anda tentang SubQuery. Setelah ini, Anda dapat mulai bekerja melalui program pelatihan dengan menyelesaikan tugas orientasi tertentu (misalnya membuat Proyek SubQuery). Kami akan menyelenggarakan lokakarya selama proses ini untuk mendukung Anda.\n\nSetelah Anda lulus program pelatihan, Anda dapat menyebut diri Anda sebagai duta besar SubQuery dan akan diterima dalam program penuh kami. Dari sini Anda dapat terus bekerja melalui program dan naik tingkatan, mendapatkan lebih banyak hadiah dan keuntungan saat Anda naik peringkat.\n\nDaftar Sekarang!\n\n\n# Kegiatan Duta Besar\n\nDuta Besar SubQuery dapat berkontribusi melalui empat area utama, termasuk manajemen acara, pembuatan konten, penerjemahan, dan moderasi komunitas. Anda dapat berpartisipasi di sebanyak mungkin area yang Anda inginkan, Anda tidak terikat pada satu pun.\n\nManajemen Acara: Bangun komunitas lokal dengan menyelenggarakan, mengatur, dan mengelola berbagai acara. Membangun komunitas lokal akan menjadi bagian utama dalam mengembangkan komunitas SubQuery. SubQuery akan mendukung Anda dengan menyediakan dana untuk acara, mengirimkan barang curian/merchandise untuk dibagikan, serta menghadiri Tanya Jawab atau acara online sebagai pembicara atau dalam sesi AMA.\n\nPembuatan Konten: Kami memiliki daftar panjang konten dan materi pendukung yang perlu bantuan untuk membuatnya. Ingat, kesuksesan kami bergantung pada kemampuan pelanggan kami untuk membangun hal-hal luar biasa pada layanan kami, jadi kami membutuhkan bantuan Anda untuk membuatnya lebih mudah. Konten mencakup video, infografis, tutorial, animasi, atau materi terkait lainnya, untuk menginformasikan, mendidik, atau menginspirasi anggota komunitas dalam Ekosistem SubQuery. SubQuery akan mendukung Pembuat Konten dengan menyediakan aset dan keahlian pembuatan merek. Kami juga akan menggunakan saluran pemasaran SubQuery untuk meningkatkan kesadaran akan konten Anda (dan Anda sendiri).\n\nPenerjemahan: Pelanggan kami tidak hanya berbicara bahasa Inggris! Kami membutuhkan bantuan Anda membuat SubQuery lebih mudah diakses dengan menerjemahkan konten kami ke dalam bahasa Anda sendiri, serta membantu membagikan kepada komunitas internasional kami.\n\nModerasi Komunitas: Moderator akan membantu mengembangkan komunitas SubQuery dengan memastikan bahwa saluran komunitas resmi aktif dan menarik. SubQuery akan mendukung Moderator dengan mempromosikan saluran yang mereka pantau, serta menyediakan bimbingan untuk harapan kami.\n\nDaftar Sekarang!",normalizedContent:"# program duta besar\n\n\n\nkami memahami bahwa salah satu kekuatan terbesar kami adalah komunitas kami, dan dengan bantuan anda, kami ingin mengembangkan dan membentuk duta besar lokal untuk komunitas di seluruh dunia.\n\ndaftar sekarang!\n\n\n# apa yang kami yakini\n\ntim kami bersatu dengan visi bersama untuk membangun yayasan layanan data yang fleksibel dan inklusif untuk ekosistem polkadot.\n\ndibangun oleh pengembang, untuk pengembang: subquery adalah komunitas yang sedang berkembang yang fokus pada penyediaan produk dan layanan terbaik untuk pengembang kami, dan pembangun di ekosistem kami. subquery hanya berhasil jika ekosistem polkadot berhasil, dan semua yang kami lakukan adalah mempertimbangkan pelanggan kami.\n\nintegritas dan akuntabilitas: kami memiliki anggota tim di auckland, shanghai, dan sydney sehingga pekerjaan jarak jauh penting bagi kami. kami berharap tim kami diberdayakan dan bekerja sama secara mandiri untuk mencapai tujuan kami. persyaratan utama untuk ini adalah agar tim kami bertanggung jawab atas tindakan mereka dan menjaga integritas mereka.\n\ndukungan dan bimbingan inklusif: blockchain itu sulit, dan setiap orang terkadang membutuhkan bantuan. tidak ada pertanyaan bodoh di komunitas kami dan semua orang di tim kami diharapkan membantu mendukung pengguna kami. kami mempelajari beberapa wawasan paling berharga tentang layanan kami (dan bagaimana kami dapat meningkatkannya) langsung dari komunitas kami.\n\n\n# program duta besar kami\n\nprogram duta besar subquery kami bertujuan untuk menemukan pemimpin komunitas yang tertarik tentang polkadot dan subquery. kami mencari para pemula yang dapat menyebarkan berita tentang subquery di area lokal mereka dan menyediakan dukungan kepada pengembang baru yang ingin menggunakan subquery untuk membuat aplikasi dan layanan yang luar biasa di polkadot.\n\n\n# keuntungan duta besar\n\ndi subquery, kami bekerja keras untuk mencapai apa yang kami lakukan. demikian juga, para duta besar diharapkan untuk meluangkan waktu ketika bergabung dengan tim kami tetapi akan diberi imbalan dengan keuntungan.\n\npendanaan dan dukungan: anda akan diberi imbalan untuk pekerjaan yang baik dengan peluang awal untuk penjualan dan hadiah pribadi. selain itu, kami akan menyediakan dana untuk anda untuk menjalankan pertemuan komunitas.\n\nakses tim subquery: anda akan memiliki akses langsung ke tim subquery inti dengan peluang untuk pelatihan langsung, ama eksklusif dengan para pemimpin dan pengembang kami, dan wawasan tentang peta jalan kami.\n\npengembangan jaringan: berharap untuk mengembangkan jaringan profesional anda dengan menjadi duta besar untuk salah satu proyek polkadot teratas. bertemu duta besar lain di seluruh dunia dan berkenalan dengan proyek polkadot lokal yang perlu kami dukung secara lokal. anda bahkan mungkin bisa masuk gratis untuk mewakili subquery dalam acara di area lokal anda.\n\nhadiah dan barang gratis lainnya: semua orang suka barang gratis! menerima alokasi tahunan hadiah subquery yang akan membuat anda menonjol di antara orang banyak. ditambah alokasi tambahan yang bisa anda bagikan di acara komunitas. anda juga akan menerima nft eksklusif untuk status duta besar anda.\n\n\n# bagaimana cara kerjanya\n\nprogram duta besar kami memiliki beberapa tingkatan, setiap tingkatan memiliki keuntungan dan kemampuan yang berbeda. anda dapat naik tingkatan dengan berpartisipasi dalam aktivitas duta besar dan bekerja keras untuk kami.\n\nsetelah anda mengirim melalui aplikasi, kami akan memilih kandidat yang sesuai dengan nilai-nilai kami. jika terpilih, anda ditempatkan dalam program pelatihan kami dan akan menerima paket informasi, memperluas pemahaman anda tentang subquery. setelah ini, anda dapat mulai bekerja melalui program pelatihan dengan menyelesaikan tugas orientasi tertentu (misalnya membuat proyek subquery). kami akan menyelenggarakan lokakarya selama proses ini untuk mendukung anda.\n\nsetelah anda lulus program pelatihan, anda dapat menyebut diri anda sebagai duta besar subquery dan akan diterima dalam program penuh kami. dari sini anda dapat terus bekerja melalui program dan naik tingkatan, mendapatkan lebih banyak hadiah dan keuntungan saat anda naik peringkat.\n\ndaftar sekarang!\n\n\n# kegiatan duta besar\n\nduta besar subquery dapat berkontribusi melalui empat area utama, termasuk manajemen acara, pembuatan konten, penerjemahan, dan moderasi komunitas. anda dapat berpartisipasi di sebanyak mungkin area yang anda inginkan, anda tidak terikat pada satu pun.\n\nmanajemen acara: bangun komunitas lokal dengan menyelenggarakan, mengatur, dan mengelola berbagai acara. membangun komunitas lokal akan menjadi bagian utama dalam mengembangkan komunitas subquery. subquery akan mendukung anda dengan menyediakan dana untuk acara, mengirimkan barang curian/merchandise untuk dibagikan, serta menghadiri tanya jawab atau acara online sebagai pembicara atau dalam sesi ama.\n\npembuatan konten: kami memiliki daftar panjang konten dan materi pendukung yang perlu bantuan untuk membuatnya. ingat, kesuksesan kami bergantung pada kemampuan pelanggan kami untuk membangun hal-hal luar biasa pada layanan kami, jadi kami membutuhkan bantuan anda untuk membuatnya lebih mudah. konten mencakup video, infografis, tutorial, animasi, atau materi terkait lainnya, untuk menginformasikan, mendidik, atau menginspirasi anggota komunitas dalam ekosistem subquery. subquery akan mendukung pembuat konten dengan menyediakan aset dan keahlian pembuatan merek. kami juga akan menggunakan saluran pemasaran subquery untuk meningkatkan kesadaran akan konten anda (dan anda sendiri).\n\npenerjemahan: pelanggan kami tidak hanya berbicara bahasa inggris! kami membutuhkan bantuan anda membuat subquery lebih mudah diakses dengan menerjemahkan konten kami ke dalam bahasa anda sendiri, serta membantu membagikan kepada komunitas internasional kami.\n\nmoderasi komunitas: moderator akan membantu mengembangkan komunitas subquery dengan memastikan bahwa saluran komunitas resmi aktif dan menarik. subquery akan mendukung moderator dengan mempromosikan saluran yang mereka pantau, serta menyediakan bimbingan untuk harapan kami.\n\ndaftar sekarang!",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Materi Merek",frontmatter:{summary:"Materi Merek Semua fitur merek SubQuery adalah hak milik dan kami memperlakukan merek kami dengan sangat serius. Jika Anda memilih untuk menggunakan merek dagang, logo, desain, ata",meta:[{property:"og:url",content:"/id/miscellaneous/branding.html"},{property:"og:title",content:"Materi Merek"},{property:"og:description",content:"Materi Merek Semua fitur merek SubQuery adalah hak milik dan kami memperlakukan merek kami dengan sangat serius. Jika Anda memilih untuk menggunakan merek dagang, logo, desain, ata"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/miscellaneous/branding.html",relativePath:"id/miscellaneous/branding.md",key:"v-73371d26",path:"/id/miscellaneous/branding/",headers:[{level:2,title:"File Figma yang Dapat Diekspor",slug:"file-figma-yang-dapat-diekspor",normalizedTitle:"file figma yang dapat diekspor",charIndex:341},{level:2,title:"Paket Aset Merek",slug:"paket-aset-merek",normalizedTitle:"paket aset merek",charIndex:521}],readingTime:{minutes:.36,words:108},headersStr:"File Figma yang Dapat Diekspor Paket Aset Merek",content:"# Materi Merek\n\nSemua fitur merek SubQuery adalah hak milik dan kami memperlakukan merek kami dengan sangat serius.\n\nJika Anda memilih untuk menggunakan merek dagang, logo, desain, atau fitur merek lainnya, harap ikuti panduan di sini dengan cermat atau hubungi kami melalui media sosial untuk klarifikasi.\n\nJika ragu, silakan bertanya!\n\n\n# File Figma yang Dapat Diekspor\n\nFile Figma kami memiliki koleksi lengkap semua aset merek (logo, font, warna, gambar, dll.) untuk diekspor.\n\nFigma - Sumber Daya Merek SubQuery\n\n\n# Paket Aset Merek\n\nPaket aset merek dengan file ZIP yang lebih kecil\n\npublic_branding.zip",normalizedContent:"# materi merek\n\nsemua fitur merek subquery adalah hak milik dan kami memperlakukan merek kami dengan sangat serius.\n\njika anda memilih untuk menggunakan merek dagang, logo, desain, atau fitur merek lainnya, harap ikuti panduan di sini dengan cermat atau hubungi kami melalui media sosial untuk klarifikasi.\n\njika ragu, silakan bertanya!\n\n\n# file figma yang dapat diekspor\n\nfile figma kami memiliki koleksi lengkap semua aset merek (logo, font, warna, gambar, dll.) untuk diekspor.\n\nfigma - sumber daya merek subquery\n\n\n# paket aset merek\n\npaket aset merek dengan file zip yang lebih kecil\n\npublic_branding.zip",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Berkontribusi Untuk SubQuery",frontmatter:{summary:"Berkontribusi Untuk SubQuery Selamat datang dan terima kasih banyak telah mempertimbangkan untuk berkontribusi pada proyek SubQuery ini! Bersama-sama kita dapat membuka jalan menuj",meta:[{property:"og:url",content:"/id/miscellaneous/contributing.html"},{property:"og:title",content:"Berkontribusi Untuk SubQuery"},{property:"og:description",content:"Berkontribusi Untuk SubQuery Selamat datang dan terima kasih banyak telah mempertimbangkan untuk berkontribusi pada proyek SubQuery ini! Bersama-sama kita dapat membuka jalan menuj"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/miscellaneous/contributing.html",relativePath:"id/miscellaneous/contributing.md",key:"v-932646e6",path:"/id/miscellaneous/contributing/",headers:[{level:2,title:"Kode Etik",slug:"kode-etik",normalizedTitle:"kode etik",charIndex:1017},{level:2,title:"Memulai",slug:"memulai",normalizedTitle:"memulai",charIndex:1290},{level:2,title:"Bagaimana Berkontribusi",slug:"bagaimana-berkontribusi",normalizedTitle:"bagaimana berkontribusi",charIndex:1819},{level:3,title:"Melaporkan Bug",slug:"melaporkan-bug",normalizedTitle:"melaporkan bug",charIndex:1847},{level:3,title:"Mengirimkan Pull Request",slug:"mengirimkan-pull-request",normalizedTitle:"mengirimkan pull request",charIndex:2374},{level:2,title:"Konvensi Coding",slug:"konvensi-coding",normalizedTitle:"konvensi coding",charIndex:2785},{level:3,title:"Pesan Git Commit",slug:"pesan-git-commit",normalizedTitle:"pesan git commit",charIndex:2805},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:3050}],readingTime:{minutes:1.42,words:426},headersStr:"Kode Etik Memulai Bagaimana Berkontribusi Melaporkan Bug Mengirimkan Pull Request Konvensi Coding Pesan Git Commit JavaScript Styleguide",content:'# Berkontribusi Untuk SubQuery\n\nSelamat datang dan terima kasih banyak telah mempertimbangkan untuk berkontribusi pada proyek SubQuery ini! Bersama-sama kita dapat membuka jalan menuju masa depan yang lebih terdesentralisasi.\n\n> Dokumentasi ini dikelola secara aktif oleh tim SubQuery. Kami menyambut kontribusi Anda, Anda dapat melakukannya dengan melakukan forking pada proyek GitHub kami dan membuat perubahan pada semua file dokumentasi markdown di bawah direktori docs.\n\nBerikut ini adalah seperangkat pedoman (bukan aturan) untuk berkontribusi pada SubQuery. Mengikuti panduan ini akan membantu kami membuat proses kontribusi menjadi mudah dan efektif untuk semua orang yang terlibat. Ini juga menyampaikan bahwa Anda setuju untuk menghormati waktu dari developer yang mengelola dan mengembangkan proyek ini. Sebagai imbalannya, kami akan membalas rasa hormat itu dengan mengatasi masalah Anda, mempertimbangkan perubahan, berkolaborasi dalam peningkatan, dan membantu Anda menyelesaikan pull request Anda.\n\n\n# Kode Etik\n\nKami menganggap serius proyek dan tanggung jawab komunitas open source kami dan menjaga diri kami dan kontributor lain pada standar komunikasi yang tinggi. Dengan berpartisipasi dan berkontribusi pada proyek ini, Anda setuju untuk menjunjung Kode Etik kami.\n\n\n# Memulai\n\nKontribusi ke repositori kami dilakukan melalui Issue and Pull Request (PR). Beberapa pedoman umum yang mencakup keduanya:\n\n * Cari Issue and PR yang ada terlebih dahulu sebelum membuat milik Anda sendiri.\n * Kami bekerja keras untuk memastikan issue ditangani dengan segera, tetapi tergantung pada dampaknya, mungkin bisa memakan waktu cukup lama untuk menyelidiki akar masalahnya. Sebuah @ sebutan ramah di utas komentar kepada pengirim atau kontributor dapat membantu menarik perhatian jika issue Anda terblokir.\n\n\n# Bagaimana Berkontribusi\n\n\n# Melaporkan Bug\n\nBug dilacak sebagai issue GitHub. Saat mencatatkan log issue, jelaskan masalahnya dan sertakan detail tambahan untuk membantu pengelola mereproduksi masalah itu:\n\n * Gunakan judul issue yang jelas dan deskriptif untuk mengidentifikasi masalah.\n * Jelaskan langkah-langkah yang akurat untuk mereproduksi masalah.\n * Jelaskan perilaku yang Anda amati setelah mengikuti langkah-langkah tersebut.\n * Jelaskan perilaku mana yang Anda harapkan untuk dilihat dan mengapa.\n * Sertakan screenshot jika memungkinkan.\n\n\n# Mengirimkan Pull Request\n\nSecara umum, kami mengikuti alur kerja "fork-and-pull" Git\n\n * Fork repositori ke akun Github Anda sendiri\n * Clone proyek ke mesin Anda\n * Buat branch secara lokal dengan nama yang ringkas namun deskriptif\n * Commit perubahan ke branch\n * Ikuti pedoman pemformatan dan testing apa pun yang khusus untuk repo ini\n * Push perubahan ke fork Anda\n * Buka sebuah PR di repositori kami\n\n\n# Konvensi Coding\n\n\n# Pesan Git Commit\n\n * Gunakan bentuk waktu kini ("Tambahkan fitur" bukan "Fitur yang ditambahkan")\n * Gunakan suasana perintah ("Pindahkan kursor ke..." bukan "Memindahkan kursor ke...")\n * Batasi baris pertama hingga 72 karakter atau kurang\n\n\n# JavaScript Styleguide\n\n * Semua kode JavaScript diverifikasi dengan Prettier dan ESLint',normalizedContent:'# berkontribusi untuk subquery\n\nselamat datang dan terima kasih banyak telah mempertimbangkan untuk berkontribusi pada proyek subquery ini! bersama-sama kita dapat membuka jalan menuju masa depan yang lebih terdesentralisasi.\n\n> dokumentasi ini dikelola secara aktif oleh tim subquery. kami menyambut kontribusi anda, anda dapat melakukannya dengan melakukan forking pada proyek github kami dan membuat perubahan pada semua file dokumentasi markdown di bawah direktori docs.\n\nberikut ini adalah seperangkat pedoman (bukan aturan) untuk berkontribusi pada subquery. mengikuti panduan ini akan membantu kami membuat proses kontribusi menjadi mudah dan efektif untuk semua orang yang terlibat. ini juga menyampaikan bahwa anda setuju untuk menghormati waktu dari developer yang mengelola dan mengembangkan proyek ini. sebagai imbalannya, kami akan membalas rasa hormat itu dengan mengatasi masalah anda, mempertimbangkan perubahan, berkolaborasi dalam peningkatan, dan membantu anda menyelesaikan pull request anda.\n\n\n# kode etik\n\nkami menganggap serius proyek dan tanggung jawab komunitas open source kami dan menjaga diri kami dan kontributor lain pada standar komunikasi yang tinggi. dengan berpartisipasi dan berkontribusi pada proyek ini, anda setuju untuk menjunjung kode etik kami.\n\n\n# memulai\n\nkontribusi ke repositori kami dilakukan melalui issue and pull request (pr). beberapa pedoman umum yang mencakup keduanya:\n\n * cari issue and pr yang ada terlebih dahulu sebelum membuat milik anda sendiri.\n * kami bekerja keras untuk memastikan issue ditangani dengan segera, tetapi tergantung pada dampaknya, mungkin bisa memakan waktu cukup lama untuk menyelidiki akar masalahnya. sebuah @ sebutan ramah di utas komentar kepada pengirim atau kontributor dapat membantu menarik perhatian jika issue anda terblokir.\n\n\n# bagaimana berkontribusi\n\n\n# melaporkan bug\n\nbug dilacak sebagai issue github. saat mencatatkan log issue, jelaskan masalahnya dan sertakan detail tambahan untuk membantu pengelola mereproduksi masalah itu:\n\n * gunakan judul issue yang jelas dan deskriptif untuk mengidentifikasi masalah.\n * jelaskan langkah-langkah yang akurat untuk mereproduksi masalah.\n * jelaskan perilaku yang anda amati setelah mengikuti langkah-langkah tersebut.\n * jelaskan perilaku mana yang anda harapkan untuk dilihat dan mengapa.\n * sertakan screenshot jika memungkinkan.\n\n\n# mengirimkan pull request\n\nsecara umum, kami mengikuti alur kerja "fork-and-pull" git\n\n * fork repositori ke akun github anda sendiri\n * clone proyek ke mesin anda\n * buat branch secara lokal dengan nama yang ringkas namun deskriptif\n * commit perubahan ke branch\n * ikuti pedoman pemformatan dan testing apa pun yang khusus untuk repo ini\n * push perubahan ke fork anda\n * buka sebuah pr di repositori kami\n\n\n# konvensi coding\n\n\n# pesan git commit\n\n * gunakan bentuk waktu kini ("tambahkan fitur" bukan "fitur yang ditambahkan")\n * gunakan suasana perintah ("pindahkan kursor ke..." bukan "memindahkan kursor ke...")\n * batasi baris pertama hingga 72 karakter atau kurang\n\n\n# javascript styleguide\n\n * semua kode javascript diverifikasi dengan prettier dan eslint',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tautan Media Sosial",frontmatter:{summary:"Tautan Media Sosial SubQuery adalah proyek aktif yang menjaga dan berkomunikasi dengan pengikut kami melalui banyak saluran media sosial. Merupakan tujuan kami untuk selalu mendeng",meta:[{property:"og:url",content:"/id/miscellaneous/social_media.html"},{property:"og:title",content:"Tautan Media Sosial"},{property:"og:description",content:"Tautan Media Sosial SubQuery adalah proyek aktif yang menjaga dan berkomunikasi dengan pengikut kami melalui banyak saluran media sosial. Merupakan tujuan kami untuk selalu mendeng"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/miscellaneous/social_media.html",relativePath:"id/miscellaneous/social_media.md",key:"v-4c75478d",path:"/id/miscellaneous/social_media/",headers:[{level:2,title:"Komunitas SubQuery Resmi",slug:"komunitas-subquery-resmi",normalizedTitle:"komunitas subquery resmi",charIndex:327},{level:2,title:"Komunitas SubQuery Tidak Resmi",slug:"komunitas-subquery-tidak-resmi",normalizedTitle:"komunitas subquery tidak resmi",charIndex:552}],readingTime:{minutes:.47,words:140},headersStr:"Komunitas SubQuery Resmi Komunitas SubQuery Tidak Resmi",content:"# Tautan Media Sosial\n\nSubQuery adalah proyek aktif yang menjaga dan berkomunikasi dengan pengikut kami melalui banyak saluran media sosial.\n\nMerupakan tujuan kami untuk selalu mendengarkan dan terlibat dengan komunitas setia kami, jadi silakan bergabung dalam percakapan dan kirimkan ide atau pertanyaan Anda kepada kami!\n\n\n# Komunitas SubQuery Resmi\n\n * Discord (Komunitas Utama dengan jalur dukungan teknis khusus)\n * Medium (Jalur pengumuman utama)\n * Twitter\n * WeChat\n * Telegram (Hanya jalur pengumuman)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Komunitas SubQuery Tidak Resmi\n\nKomunitas ini tidak dimoderasi oleh tim SubQuery, tetapi duta kami mungkin ada di sana untuk memberikan dukungan. Harap berhati-hati terhadap penipuan karena SubQuery tidak bertanggung jawab atas apa yang terjadi di dalamnya.",normalizedContent:"# tautan media sosial\n\nsubquery adalah proyek aktif yang menjaga dan berkomunikasi dengan pengikut kami melalui banyak saluran media sosial.\n\nmerupakan tujuan kami untuk selalu mendengarkan dan terlibat dengan komunitas setia kami, jadi silakan bergabung dalam percakapan dan kirimkan ide atau pertanyaan anda kepada kami!\n\n\n# komunitas subquery resmi\n\n * discord (komunitas utama dengan jalur dukungan teknis khusus)\n * medium (jalur pengumuman utama)\n * twitter\n * wechat\n * telegram (hanya jalur pengumuman)\n * github\n * matrix/riot\n * linkedin\n\n\n# komunitas subquery tidak resmi\n\nkomunitas ini tidak dimoderasi oleh tim subquery, tetapi duta kami mungkin ada di sana untuk memberikan dukungan. harap berhati-hati terhadap penipuan karena subquery tidak bertanggung jawab atas apa yang terjadi di dalamnya.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hubungkan ke Proyek Baru Anda",frontmatter:{summary:"Hubungkan ke Proyek Baru Anda Setelah penerapan Anda berhasil diselesaikan dan node kami telah mengindeks data Anda dari chain, Anda akan dapat terhubung ke proyek Anda melalui tit",meta:[{property:"og:url",content:"/id/publish/connect.html"},{property:"og:title",content:"Hubungkan ke Proyek Baru Anda"},{property:"og:description",content:"Hubungkan ke Proyek Baru Anda Setelah penerapan Anda berhasil diselesaikan dan node kami telah mengindeks data Anda dari chain, Anda akan dapat terhubung ke proyek Anda melalui tit"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/publish/connect.html",relativePath:"id/publish/connect.md",key:"v-f3d8afa6",path:"/id/publish/connect/",readingTime:{minutes:.56,words:167},headersStr:null,content:"# Hubungkan ke Proyek Baru Anda\n\nSetelah penerapan Anda berhasil diselesaikan dan node kami telah mengindeks data Anda dari chain, Anda akan dapat terhubung ke proyek Anda melalui titik akhir Queri yang ditampilkan.\n\n\n\nAtau, Anda dapat mengklik tiga titik di samping judul proyek Anda, dan melihatnya di SubQuery Explorer. Di sana Anda dapat menggunakan taman bermain di browser untuk memulai.\n\n\n\n\n# Pelajari lebih lanjut tentang GraphQL\n\nAnda dapat mengikuti panduan resmi GraphQL di sini untuk mempelajari lebih lanjut tentang GraphQL, cara kerjanya, dan cara menggunakannya:\n\n * Ada perpustakaan untuk membantu Anda mengimplementasikan GraphQL dalam banyak bahasa berbeda\n * Untuk pengalaman belajar yang mendalam dengan tutorial praktis, lihat Cara GraphQL.\n * Lihat kursus online gratis, Menjelajahi GraphQL: Bahasa Kueri untuk API.",normalizedContent:"# hubungkan ke proyek baru anda\n\nsetelah penerapan anda berhasil diselesaikan dan node kami telah mengindeks data anda dari chain, anda akan dapat terhubung ke proyek anda melalui titik akhir queri yang ditampilkan.\n\n\n\natau, anda dapat mengklik tiga titik di samping judul proyek anda, dan melihatnya di subquery explorer. di sana anda dapat menggunakan taman bermain di browser untuk memulai.\n\n\n\n\n# pelajari lebih lanjut tentang graphql\n\nanda dapat mengikuti panduan resmi graphql di sini untuk mempelajari lebih lanjut tentang graphql, cara kerjanya, dan cara menggunakannya:\n\n * ada perpustakaan untuk membantu anda mengimplementasikan graphql dalam banyak bahasa berbeda\n * untuk pengalaman belajar yang mendalam dengan tutorial praktis, lihat cara graphql.\n * lihat kursus online gratis, menjelajahi graphql: bahasa kueri untuk api.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Publikasikan Proyek SubQuery Anda",frontmatter:{summary:"Publikasikan Proyek SubQuery Anda Manfaat menghosting proyek Anda dengan SubQuery Kami akan menjalankan proyek SubQuery untuk Anda dalam layanan publik berkinerja tinggi, skalabel,",meta:[{property:"og:url",content:"/id/publish/publish.html"},{property:"og:title",content:"Publikasikan Proyek SubQuery Anda"},{property:"og:description",content:"Publikasikan Proyek SubQuery Anda Manfaat menghosting proyek Anda dengan SubQuery Kami akan menjalankan proyek SubQuery untuk Anda dalam layanan publik berkinerja tinggi, skalabel,"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/publish/publish.html",relativePath:"id/publish/publish.md",key:"v-7464bfe3",path:"/id/publish/publish/",headers:[{level:2,title:"Manfaat menghosting proyek Anda dengan SubQuery",slug:"manfaat-menghosting-proyek-anda-dengan-subquery",normalizedTitle:"manfaat menghosting proyek anda dengan subquery",charIndex:40},{level:2,title:"Buat Proyek Pertama Anda",slug:"buat-proyek-pertama-anda",normalizedTitle:"buat proyek pertama anda",charIndex:523},{level:2,title:"Langkah Selanjutnya - Hubungkan ke Proyek Anda",slug:"langkah-selanjutnya-hubungkan-ke-proyek-anda",normalizedTitle:"langkah selanjutnya - hubungkan ke proyek anda",charIndex:3931},{level:2,title:"Tambahkan Akun Organisasi GitHub ke Proyek SubQuery",slug:"tambahkan-akun-organisasi-github-ke-proyek-subquery",normalizedTitle:"tambahkan akun organisasi github ke proyek subquery",charIndex:4424}],readingTime:{minutes:3.42,words:1025},headersStr:"Manfaat menghosting proyek Anda dengan SubQuery Buat Proyek Pertama Anda Langkah Selanjutnya - Hubungkan ke Proyek Anda Tambahkan Akun Organisasi GitHub ke Proyek SubQuery",content:'# Publikasikan Proyek SubQuery Anda\n\n\n# Manfaat menghosting proyek Anda dengan SubQuery\n\n * Kami akan menjalankan proyek SubQuery untuk Anda dalam layanan publik berkinerja tinggi, skalabel, dan terkelola\n * Layanan ini disediakan untuk komunitas secara gratis!\n * Anda dapat menjadikan proyek Anda publik sehingga akan dicantumkan di SubQuery Explorer dan siapa saja di seluruh dunia dapat melihatnya\n * Kami terintegrasi dengan GitHub, jadi siapa pun di organisasi GitHub Anda dapat melihat proyek organisasi bersama\n\n\n# Buat Proyek Pertama Anda\n\n# Masuk ke Proyek SubQuery\n\nSebelum memulai, pastikan proyek SubQuery Anda online di repositori GitHub publik. File schema.graphql harus berada di root direktori Anda.\n\nUntuk membuat proyek pertama Anda, buka project.subquery.network. Anda harus mengautentikasi dengan akun GitHub Anda untuk masuk.\n\nPada login pertama, Anda akan diminta untuk mengotorisasi SubQuery. Kami hanya memerlukan alamat email Anda untuk mengidentifikasi akun Anda, dan kami tidak menggunakan data lain apa pun dari akun GitHub Anda untuk alasan lain apa pun. Pada langkah ini, Anda juga dapat meminta atau memberikan akses ke akun Organisasi GitHub Anda sehingga Anda dapat memposting proyek SubQuery di bawah Organisasi GitHub alih-alih akun pribadi Anda.\n\n\n\nProyek SubQuery adalah tempat Anda mengelola semua proyek yang dihosting yang diunggah ke platform SubQuery. Anda dapat membuat, menghapus, dan bahkan mengupgrade proyek semua dari aplikasi ini.\n\n\n\nJika Anda memiliki akun Organisasi GitHub yang terhubung, Anda dapat menggunakan pengalih di header untuk mengubah antara akun pribadi Anda dan akun Organisasi GitHub Anda. Proyek yang dibuat di akun Organisasi GitHub dibagikan di antara anggota di Organisasi GitHub tersebut. Untuk menghubungkan akun Organisasi GitHub Anda, Anda dapat mengikuti langkah-langkah di sini.\n\n\n\n# Buat Proyek Pertama Anda\n\nMari kita mulai dengan mengklik "Buat Proyek". Anda akan dibawa ke formulir Proyek Baru. Silakan masukkan yang berikut (Anda dapat mengubahnya di masa mendatang):\n\n * Akun GitHub: Jika Anda memiliki lebih dari satu akun GitHub, pilih akun mana yang akan dibuat proyek ini. Proyek yang dibuat di akun organisasi GitHub dibagikan di antara anggota di organisasi itu.\n * Nama\n * Subtitle\n * Deskripsi\n * URL Repositori GitHub: Ini harus berupa URL GitHub yang valid untuk repositori publik yang memiliki proyek SubQuery Anda. File schema.graphql harus berada di root direktori Anda (pelajari lebih lanjut tentang struktur direktori).\n * Sembunyikan proyek: Jika dipilih, ini akan menyembunyikan proyek dari penjelajah SubQuery publik. Biarkan ini tidak dipilih jika Anda ingin membagikan SubQuery Anda dengan komunitas!\n\nBuat proyek Anda dan Anda akan melihatnya di daftar Proyek SubQuery Anda. _Kita hampir sampai! Kita hanya perlu menerapkan versi barunya. _\n\n# Terapkan Versi pertama Anda\n\nSaat membuat proyek akan mengatur perilaku tampilan proyek, Anda harus menerapkan sebuah versi sebelum menjadi operasional. Menerapkan versi memicu operasi pengindeksan SubQuery baru untuk memulai, dan menyiapkan layanan kueri yang diperlukan untuk mulai menerima permintaan GraphQL. Anda juga dapat menerapkan versi baru ke proyek yang ada di sini.\n\nDengan proyek baru Anda, Anda akan melihat tombol Deploy New Version. Klik ini, dan isi informasi yang diperlukan tentang penerapan:\n\n * Komit Hash Versi baru: Dari GitHub, salin hash komit penuh versi basis kode proyek SubQuery yang ingin Anda terapkan\n * Versi Pengindeks: Ini adalah versi layanan simpul SubQuery yang Anda inginkan untuk menjalankan SubQuery ini. Lihat @subql/node\n * Versi Kueri: Ini adalah versi layanan kueri SubQuery yang Anda inginkan untuk menjalankan SubQuery ini. Lihat @subql/query\n\n\n\nJika berhasil diterapkan, Anda akan melihat pengindeks mulai bekerja dan melaporkan kembali kemajuan pengindeksan chain saat ini. Proses ini mungkin memakan waktu hingga mencapai 100%.\n\n\n# Langkah Selanjutnya - Hubungkan ke Proyek Anda\n\nSetelah penerapan Anda berhasil diselesaikan dan node kami telah mengindeks data Anda dari chain, Anda akan dapat terhubung ke proyek Anda melalui titik akhir Kueri GraphQL yang ditampilkan.\n\n\n\nAtau, Anda dapat mengklik tiga titik di sebelah judul proyek Anda, dan melihatnya di SubQuery Explorer. Di sana Anda dapat menggunakan taman bermain dalam browser untuk memulai - baca selengkapnya tentang cara menggunakan Explorer kami di sini.\n\n\n\n\n# Tambahkan Akun Organisasi GitHub ke Proyek SubQuery\n\nUmum untuk mempublikasikan proyek SubQuery Anda dengan nama akun Organisasi GitHub Anda daripada akun GitHub pribadi Anda. Kapan pun Anda dapat mengubah akun yang dipilih saat ini di Proyek SubQuery menggunakan pengalih akun.\n\n\n\nJika Anda tidak dapat melihat akun Organisasi GitHub Anda tercantum di pengalih, Anda mungkin perlu memberikan akses ke SubQuery untuk Organisasi GitHub Anda (atau memintanya dari administrator). Untuk melakukan ini, Anda harus terlebih dahulu mencabut izin dari akun GitHub Anda ke Aplikasi SubQuery. Untuk melakukannya, masuk ke pengaturan akun Anda di GitHub, buka Aplikasi, dan di bawah tab Aplikasi OAuth Resmi, cabut SubQuery - Anda dapat mengikuti langkah-langkah yang tepat di sini. Jangan khawatir, ini tidak akan menghapus proyek SubQuery Anda dan Anda tidak akan kehilangan data apa pun.\n\n\n\nSetelah Anda mencabut akses, keluar dari Proyek SubQuery dan masuk kembali. Anda harus diarahkan ke halaman berjudul Otorisasi SubQuery di mana Anda dapat meminta atau memberikan akses SubQuery ke akun Organisasi GitHub Anda. Jika Anda tidak memiliki izin admin, Anda harus membuat permintaan kepada administrator untuk mengaktifkannya untuk Anda.\n\n\n\nSetelah permintaan ini disetujui oleh administrator Anda (atau jika dapat mengabulkannya sendiri), Anda akan melihat akun Organisasi GitHub yang benar di pengalih akun.',normalizedContent:'# publikasikan proyek subquery anda\n\n\n# manfaat menghosting proyek anda dengan subquery\n\n * kami akan menjalankan proyek subquery untuk anda dalam layanan publik berkinerja tinggi, skalabel, dan terkelola\n * layanan ini disediakan untuk komunitas secara gratis!\n * anda dapat menjadikan proyek anda publik sehingga akan dicantumkan di subquery explorer dan siapa saja di seluruh dunia dapat melihatnya\n * kami terintegrasi dengan github, jadi siapa pun di organisasi github anda dapat melihat proyek organisasi bersama\n\n\n# buat proyek pertama anda\n\n# masuk ke proyek subquery\n\nsebelum memulai, pastikan proyek subquery anda online di repositori github publik. file schema.graphql harus berada di root direktori anda.\n\nuntuk membuat proyek pertama anda, buka project.subquery.network. anda harus mengautentikasi dengan akun github anda untuk masuk.\n\npada login pertama, anda akan diminta untuk mengotorisasi subquery. kami hanya memerlukan alamat email anda untuk mengidentifikasi akun anda, dan kami tidak menggunakan data lain apa pun dari akun github anda untuk alasan lain apa pun. pada langkah ini, anda juga dapat meminta atau memberikan akses ke akun organisasi github anda sehingga anda dapat memposting proyek subquery di bawah organisasi github alih-alih akun pribadi anda.\n\n\n\nproyek subquery adalah tempat anda mengelola semua proyek yang dihosting yang diunggah ke platform subquery. anda dapat membuat, menghapus, dan bahkan mengupgrade proyek semua dari aplikasi ini.\n\n\n\njika anda memiliki akun organisasi github yang terhubung, anda dapat menggunakan pengalih di header untuk mengubah antara akun pribadi anda dan akun organisasi github anda. proyek yang dibuat di akun organisasi github dibagikan di antara anggota di organisasi github tersebut. untuk menghubungkan akun organisasi github anda, anda dapat mengikuti langkah-langkah di sini.\n\n\n\n# buat proyek pertama anda\n\nmari kita mulai dengan mengklik "buat proyek". anda akan dibawa ke formulir proyek baru. silakan masukkan yang berikut (anda dapat mengubahnya di masa mendatang):\n\n * akun github: jika anda memiliki lebih dari satu akun github, pilih akun mana yang akan dibuat proyek ini. proyek yang dibuat di akun organisasi github dibagikan di antara anggota di organisasi itu.\n * nama\n * subtitle\n * deskripsi\n * url repositori github: ini harus berupa url github yang valid untuk repositori publik yang memiliki proyek subquery anda. file schema.graphql harus berada di root direktori anda (pelajari lebih lanjut tentang struktur direktori).\n * sembunyikan proyek: jika dipilih, ini akan menyembunyikan proyek dari penjelajah subquery publik. biarkan ini tidak dipilih jika anda ingin membagikan subquery anda dengan komunitas!\n\nbuat proyek anda dan anda akan melihatnya di daftar proyek subquery anda. _kita hampir sampai! kita hanya perlu menerapkan versi barunya. _\n\n# terapkan versi pertama anda\n\nsaat membuat proyek akan mengatur perilaku tampilan proyek, anda harus menerapkan sebuah versi sebelum menjadi operasional. menerapkan versi memicu operasi pengindeksan subquery baru untuk memulai, dan menyiapkan layanan kueri yang diperlukan untuk mulai menerima permintaan graphql. anda juga dapat menerapkan versi baru ke proyek yang ada di sini.\n\ndengan proyek baru anda, anda akan melihat tombol deploy new version. klik ini, dan isi informasi yang diperlukan tentang penerapan:\n\n * komit hash versi baru: dari github, salin hash komit penuh versi basis kode proyek subquery yang ingin anda terapkan\n * versi pengindeks: ini adalah versi layanan simpul subquery yang anda inginkan untuk menjalankan subquery ini. lihat @subql/node\n * versi kueri: ini adalah versi layanan kueri subquery yang anda inginkan untuk menjalankan subquery ini. lihat @subql/query\n\n\n\njika berhasil diterapkan, anda akan melihat pengindeks mulai bekerja dan melaporkan kembali kemajuan pengindeksan chain saat ini. proses ini mungkin memakan waktu hingga mencapai 100%.\n\n\n# langkah selanjutnya - hubungkan ke proyek anda\n\nsetelah penerapan anda berhasil diselesaikan dan node kami telah mengindeks data anda dari chain, anda akan dapat terhubung ke proyek anda melalui titik akhir kueri graphql yang ditampilkan.\n\n\n\natau, anda dapat mengklik tiga titik di sebelah judul proyek anda, dan melihatnya di subquery explorer. di sana anda dapat menggunakan taman bermain dalam browser untuk memulai - baca selengkapnya tentang cara menggunakan explorer kami di sini.\n\n\n\n\n# tambahkan akun organisasi github ke proyek subquery\n\numum untuk mempublikasikan proyek subquery anda dengan nama akun organisasi github anda daripada akun github pribadi anda. kapan pun anda dapat mengubah akun yang dipilih saat ini di proyek subquery menggunakan pengalih akun.\n\n\n\njika anda tidak dapat melihat akun organisasi github anda tercantum di pengalih, anda mungkin perlu memberikan akses ke subquery untuk organisasi github anda (atau memintanya dari administrator). untuk melakukan ini, anda harus terlebih dahulu mencabut izin dari akun github anda ke aplikasi subquery. untuk melakukannya, masuk ke pengaturan akun anda di github, buka aplikasi, dan di bawah tab aplikasi oauth resmi, cabut subquery - anda dapat mengikuti langkah-langkah yang tepat di sini. jangan khawatir, ini tidak akan menghapus proyek subquery anda dan anda tidak akan kehilangan data apa pun.\n\n\n\nsetelah anda mencabut akses, keluar dari proyek subquery dan masuk kembali. anda harus diarahkan ke halaman berjudul otorisasi subquery di mana anda dapat meminta atau memberikan akses subquery ke akun organisasi github anda. jika anda tidak memiliki izin admin, anda harus membuat permintaan kepada administrator untuk mengaktifkannya untuk anda.\n\n\n\nsetelah permintaan ini disetujui oleh administrator anda (atau jika dapat mengabulkannya sendiri), anda akan melihat akun organisasi github yang benar di pengalih akun.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Terapkan Versi Baru Proyek SubQuery Anda",frontmatter:{summary:"Terapkan Versi Baru Proyek SubQuery Anda Panduan Meskipun Anda memiliki kebebasan untuk selalu meningkatkan dan menerapkan versi baru proyek SubQuery Anda, mohon berhati-hati selam",meta:[{property:"og:url",content:"/id/publish/upgrade.html"},{property:"og:title",content:"Terapkan Versi Baru Proyek SubQuery Anda"},{property:"og:description",content:"Terapkan Versi Baru Proyek SubQuery Anda Panduan Meskipun Anda memiliki kebebasan untuk selalu meningkatkan dan menerapkan versi baru proyek SubQuery Anda, mohon berhati-hati selam"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/publish/upgrade.html",relativePath:"id/publish/upgrade.md",key:"v-331125c9",path:"/id/publish/upgrade/",headers:[{level:2,title:"Panduan",slug:"panduan",normalizedTitle:"panduan",charIndex:47},{level:2,title:"Terapkan Perubahan",slug:"terapkan-perubahan",normalizedTitle:"terapkan perubahan",charIndex:664},{level:2,title:"Langkah Selanjutnya - Hubungkan ke Proyek Anda",slug:"langkah-selanjutnya-hubungkan-ke-proyek-anda",normalizedTitle:"langkah selanjutnya - hubungkan ke proyek anda",charIndex:1579}],readingTime:{minutes:1.14,words:341},headersStr:"Panduan Terapkan Perubahan Langkah Selanjutnya - Hubungkan ke Proyek Anda",content:"# Terapkan Versi Baru Proyek SubQuery Anda\n\n\n# Panduan\n\nMeskipun Anda memiliki kebebasan untuk selalu meningkatkan dan menerapkan versi baru proyek SubQuery Anda, mohon berhati-hati selama proses ini jika proyek SubQuery Anda bersifat publik untuk dunia. Beberapa hal penting yang perlu diingat:\n\n * Jika peningkatan Anda merupakan perubahan yang melanggar, baik membuat proyek baru (misal. My SubQuery Project V2) atau memberi banyak peringatan kepada komunitas Anda tentang perubahan tersebut melalui jalur media sosial.\n * Menerapkan versi proyek SubQuery baru menyebabkan beberapa waktu henti karena versi baru mengindeks rangkaian lengkap dari blok asal.\n\n\n# Terapkan Perubahan\n\nMasuk ke SubQuery Projects, dan temukan proyek yang ingin Anda terapkan versi barunya. Di bawah Deployment Details Anda akan melihat tiga titik di kanan atas, klik tombol Deploy New Version.\n\n\n\n# Tingkatkan ke Latest Indexer and Query Service\n\nJika Anda hanya ingin meningkatkan ke pengindeks terbaru (@subql/node) atau layanan kueri (@subql/query) untuk mendapat keuntungan dari peningkatan stabilitas dan performa reguler kami, cukup pilih versi terbaru dari paket kami dan simpan. Ini hanya akan menyebabkan waktu henti beberapa menit.\n\n# Terapkan Versi Baru Proyek SubQuery Anda\n\nIsi Commit Hash dari GitHub (salin commit hash penuh) dari versi basis kode proyek SubQuery yang ingin Anda terapkan. Ini akan menyebabkan waktu henti yang lebih lama tergantung pada waktu yang diperlukan untuk mengindeks rangkaian saat ini. Anda selalu dapat melaporkan kembali ke sini untuk perkembangan.\n\n\n# Langkah Selanjutnya - Hubungkan ke Proyek Anda\n\nSetelah penerapan Anda berhasil diselesaikan dan node kami telah mengindeks data Anda dari rangkaian, Anda akan dapat terhubung ke proyek Anda melalui titik akhir GraphQL Query yang ditampilkan.\n\n\n\nKalau tidak, Anda dapat mengklik tiga titik di sebelah judul proyek Anda, dan melihatnya di SubQuery Explorer. Di sana Anda dapat menggunakan tempat bermain dalam browser untuk memulai - baca selengkapnya tentang cara menggunakan Explorer kami di sini.",normalizedContent:"# terapkan versi baru proyek subquery anda\n\n\n# panduan\n\nmeskipun anda memiliki kebebasan untuk selalu meningkatkan dan menerapkan versi baru proyek subquery anda, mohon berhati-hati selama proses ini jika proyek subquery anda bersifat publik untuk dunia. beberapa hal penting yang perlu diingat:\n\n * jika peningkatan anda merupakan perubahan yang melanggar, baik membuat proyek baru (misal. my subquery project v2) atau memberi banyak peringatan kepada komunitas anda tentang perubahan tersebut melalui jalur media sosial.\n * menerapkan versi proyek subquery baru menyebabkan beberapa waktu henti karena versi baru mengindeks rangkaian lengkap dari blok asal.\n\n\n# terapkan perubahan\n\nmasuk ke subquery projects, dan temukan proyek yang ingin anda terapkan versi barunya. di bawah deployment details anda akan melihat tiga titik di kanan atas, klik tombol deploy new version.\n\n\n\n# tingkatkan ke latest indexer and query service\n\njika anda hanya ingin meningkatkan ke pengindeks terbaru (@subql/node) atau layanan kueri (@subql/query) untuk mendapat keuntungan dari peningkatan stabilitas dan performa reguler kami, cukup pilih versi terbaru dari paket kami dan simpan. ini hanya akan menyebabkan waktu henti beberapa menit.\n\n# terapkan versi baru proyek subquery anda\n\nisi commit hash dari github (salin commit hash penuh) dari versi basis kode proyek subquery yang ingin anda terapkan. ini akan menyebabkan waktu henti yang lebih lama tergantung pada waktu yang diperlukan untuk mengindeks rangkaian saat ini. anda selalu dapat melaporkan kembali ke sini untuk perkembangan.\n\n\n# langkah selanjutnya - hubungkan ke proyek anda\n\nsetelah penerapan anda berhasil diselesaikan dan node kami telah mengindeks data anda dari rangkaian, anda akan dapat terhubung ke proyek anda melalui titik akhir graphql query yang ditampilkan.\n\n\n\nkalau tidak, anda dapat mengklik tiga titik di sebelah judul proyek anda, dan melihatnya di subquery explorer. di sana anda dapat menggunakan tempat bermain dalam browser untuk memulai - baca selengkapnya tentang cara menggunakan explorer kami di sini.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Pelajari lebih lanjut tentang GraphQL",frontmatter:{summary:"Pelajari lebih lanjut tentang GraphQL Anda dapat mengikuti panduan resmi GraphQL di sini untuk mempelajari lebih lanjut tentang GraphQL, cara kerjanya, dan cara menggunakannya: Ada",meta:[{property:"og:url",content:"/id/query/graphql.html"},{property:"og:title",content:"Pelajari lebih lanjut tentang GraphQL"},{property:"og:description",content:"Pelajari lebih lanjut tentang GraphQL Anda dapat mengikuti panduan resmi GraphQL di sini untuk mempelajari lebih lanjut tentang GraphQL, cara kerjanya, dan cara menggunakannya: Ada"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/query/graphql.html",relativePath:"id/query/graphql.md",key:"v-7981e486",path:"/id/query/graphql/",readingTime:{minutes:.27,words:80},headersStr:null,content:"# Pelajari lebih lanjut tentang GraphQL\n\nAnda dapat mengikuti panduan resmi GraphQL di sini untuk mempelajari lebih lanjut tentang GraphQL, cara kerjanya, dan cara menggunakannya:\n\n * Ada pustaka untuk membantu Anda mengimplementasikan GraphQL dalam banyak bahasa berbeda\n * Untuk pengalaman belajar yang mendalam dengan tutorial praktis, lihat Cara GraphQL.\n * Lihatlah kursus online gratis, Menjelajahi GraphQL: Bahasa Kueri untuk API.",normalizedContent:"# pelajari lebih lanjut tentang graphql\n\nanda dapat mengikuti panduan resmi graphql di sini untuk mempelajari lebih lanjut tentang graphql, cara kerjanya, dan cara menggunakannya:\n\n * ada pustaka untuk membantu anda mengimplementasikan graphql dalam banyak bahasa berbeda\n * untuk pengalaman belajar yang mendalam dengan tutorial praktis, lihat cara graphql.\n * lihatlah kursus online gratis, menjelajahi graphql: bahasa kueri untuk api.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Buat kueri Proyek Anda di SubQuery Explorer",frontmatter:{summary:"Buat kueri Proyek Anda di SubQuery Explorer SubQuery Explorer adalah layanan yang diadakan secara online (di explorer.subquery.network) yang menyediakan akses ke proyek SubQuery ya",meta:[{property:"og:url",content:"/id/query/query.html"},{property:"og:title",content:"Buat kueri Proyek Anda di SubQuery Explorer"},{property:"og:description",content:"Buat kueri Proyek Anda di SubQuery Explorer SubQuery Explorer adalah layanan yang diadakan secara online (di explorer.subquery.network) yang menyediakan akses ke proyek SubQuery ya"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/query/query.html",relativePath:"id/query/query.md",key:"v-5e3758ff",path:"/id/query/query/",readingTime:{minutes:.95,words:284},headersStr:null,content:"# Buat kueri Proyek Anda di SubQuery Explorer\n\nSubQuery Explorer adalah layanan yang diadakan secara online (di explorer.subquery.network) yang menyediakan akses ke proyek SubQuery yang dipublikasikan yang dibuat oleh kontributor di komunitas kami dan dikelola oleh tim SubQuery. Anda dapat mempublikasikan proyek SubQuery Anda sendiri ke penjelajah kami dengan mengikuti panduan kami untuk Mempublikasikan Proyek SubQuery Anda.\n\n\n\nPenjelajah SubQuery memudahkan saat memulai. Kami mengadakan proyek SubQuery ini secara online dan memungkinkan siapa saja untuk membuat kueri masing - masing secara gratis. Node terkelola ini akan dipantau dan dijalankan oleh tim SubQuery pada tingkat performa yang memungkinkan aplikasi produksi untuk menggunakan dan mengandalkannya.\n\n\n\nAnda juga akan melihat bahwa SubQuery Explorer menyediakan tempat bermain untuk menemukan data yang tersedia dengan kueri contoh - Anda dapat menguji kueri secara langsung di browser Anda tanpa menerapkan kode. Selain itu, kami telah membuat beberapa peningkatan kecil pada dokumentasi kami untuk mendukung pengembang lebih baik dalam perjalanan mereka untuk membuat kueri dan menganalisis data Polkadot dunia dengan lebih baik.\n\nDi kanan atas tempat bermain, Anda akan menemukan tombol Dokumen yang akan membuka undian dokumentasi. Dokumentasi ini dibuat secara otomatis dan membantu Anda menemukan entitas dan metode apa yang dapat Anda buatkan kueri. Pada contoh di bawah ini kami menggunakan Sum Rewards SubQuery untuk mendapatkan 5 akun dengan hadiah terbanyak (dalam hal menopang pendapatan) di Polkadot yang belum pernah dipotong.\n\n\n\nPelajari lebih lanjut tentang bahasa GraphQL Query.",normalizedContent:"# buat kueri proyek anda di subquery explorer\n\nsubquery explorer adalah layanan yang diadakan secara online (di explorer.subquery.network) yang menyediakan akses ke proyek subquery yang dipublikasikan yang dibuat oleh kontributor di komunitas kami dan dikelola oleh tim subquery. anda dapat mempublikasikan proyek subquery anda sendiri ke penjelajah kami dengan mengikuti panduan kami untuk mempublikasikan proyek subquery anda.\n\n\n\npenjelajah subquery memudahkan saat memulai. kami mengadakan proyek subquery ini secara online dan memungkinkan siapa saja untuk membuat kueri masing - masing secara gratis. node terkelola ini akan dipantau dan dijalankan oleh tim subquery pada tingkat performa yang memungkinkan aplikasi produksi untuk menggunakan dan mengandalkannya.\n\n\n\nanda juga akan melihat bahwa subquery explorer menyediakan tempat bermain untuk menemukan data yang tersedia dengan kueri contoh - anda dapat menguji kueri secara langsung di browser anda tanpa menerapkan kode. selain itu, kami telah membuat beberapa peningkatan kecil pada dokumentasi kami untuk mendukung pengembang lebih baik dalam perjalanan mereka untuk membuat kueri dan menganalisis data polkadot dunia dengan lebih baik.\n\ndi kanan atas tempat bermain, anda akan menemukan tombol dokumen yang akan membuka undian dokumentasi. dokumentasi ini dibuat secara otomatis dan membantu anda menemukan entitas dan metode apa yang dapat anda buatkan kueri. pada contoh di bawah ini kami menggunakan sum rewards subquery untuk mendapatkan 5 akun dengan hadiah terbanyak (dalam hal menopang pendapatan) di polkadot yang belum pernah dipotong.\n\n\n\npelajari lebih lanjut tentang bahasa graphql query.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (hosting SubQuery)",frontmatter:{summary:"Hello World (hosting SubQuery) Tujuan dari quick start ini adalah untuk menunjukkan bagaimana Anda dapat menjalankan proyek starter default pada SubQuery Projects (layanan terkelol",meta:[{property:"og:url",content:"/id/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (hosting SubQuery)"},{property:"og:description",content:"Hello World (hosting SubQuery) Tujuan dari quick start ini adalah untuk menunjukkan bagaimana Anda dapat menjalankan proyek starter default pada SubQuery Projects (layanan terkelol"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/quickstart/helloworld-hosted.html",relativePath:"id/quickstart/helloworld-hosted.md",key:"v-eabc40a6",path:"/id/quickstart/helloworld-hosted/",headers:[{level:2,title:"Tujuan Pembelajaran",slug:"tujuan-pembelajaran",normalizedTitle:"tujuan pembelajaran",charIndex:580},{level:2,title:"Audiens yang dituju",slug:"audiens-yang-dituju",normalizedTitle:"audiens yang dituju",charIndex:934},{level:2,title:"Panduan video",slug:"panduan-video",normalizedTitle:"panduan video",charIndex:1119},{level:2,title:"Prasyarat",slug:"prasyarat",normalizedTitle:"prasyarat",charIndex:1137},{level:2,title:"Langkah 1: Buatlah proyek Anda",slug:"langkah-1-buatlah-proyek-anda",normalizedTitle:"langkah 1: buatlah proyek anda",charIndex:1190},{level:2,title:"Langkah 2: Buatlah repo GitHub",slug:"langkah-2-buatlah-repo-github",normalizedTitle:"langkah 2: buatlah repo github",charIndex:1484},{level:2,title:"Langkah 3: Push ke GitHub",slug:"langkah-3-push-ke-github",normalizedTitle:"langkah 3: push ke github",charIndex:1767},{level:2,title:"Langkah 4: Buatlah proyek Anda",slug:"langkah-4-buatlah-proyek-anda",normalizedTitle:"langkah 4: buatlah proyek anda",charIndex:3612},{level:2,title:"Langkah 5: Terapkan proyek Anda",slug:"langkah-5-terapkan-proyek-anda",normalizedTitle:"langkah 5: terapkan proyek anda",charIndex:4872},{level:2,title:"Langkah 6: Menguji proyek Anda",slug:"langkah-6-menguji-proyek-anda",normalizedTitle:"langkah 6: menguji proyek anda",charIndex:6537},{level:2,title:"Langkah 7: Langkah bonus",slug:"langkah-7-langkah-bonus",normalizedTitle:"langkah 7: langkah bonus",charIndex:6803},{level:2,title:"Ringkasan",slug:"ringkasan",normalizedTitle:"ringkasan",charIndex:8387}],readingTime:{minutes:4.35,words:1305},headersStr:"Tujuan Pembelajaran Audiens yang dituju Panduan video Prasyarat Langkah 1: Buatlah proyek Anda Langkah 2: Buatlah repo GitHub Langkah 3: Push ke GitHub Langkah 4: Buatlah proyek Anda Langkah 5: Terapkan proyek Anda Langkah 6: Menguji proyek Anda Langkah 7: Langkah bonus Ringkasan",content:'# Hello World (hosting SubQuery)\n\nTujuan dari quick start ini adalah untuk menunjukkan bagaimana Anda dapat menjalankan proyek starter default pada SubQuery Projects (layanan terkelola kami) dengan beberapa langkah mudah.\n\nKita akan mengambil proyek starter sederhana (dan semua yang telah kami pelajari sejauh ini) tetapi alih-alih menjalankannya secara lokal pada Docker, kita akan memanfaatkan infrastruktur hosting SubQuery yang terkelola. Dengan kata lain, kita akan membiarkan SubQuery melakukan semua pekerjaan berat, menjalankan, dan mengelola infrastruktur produksi.\n\n\n# Tujuan Pembelajaran\n\nPada akhir quick start ini, Anda harus:\n\n * memahami prasyarat yang diperlukan\n * bisa menghosting proyek pada SubQuery Projects\n * menjalankan kueri sederhana untuk mendapatkan tinggi blok mainnet Polkadot menggunakan playground\n * menjalankan kueri GET sederhana untuk mendapatkan tinggi blok mainnet Polkadot menggunakan cURL\n\n\n# Audiens yang dituju\n\nPanduan ini ditujukan bagi para pengembang (developer) baru yang memiliki pengalaman pengembangan dan tertarik untuk mempelajari lebih lanjut tentang SubQuery.\n\n\n# Panduan video\n\n\n# Prasyarat\n\nAnda akan memerlukan:\n\n * akun GitHub\n\n\n# Langkah 1: Buatlah proyek Anda\n\nMari membuat proyek bernama subql_hallowworld dan menjalankan instalasi wajib, codegen, dan bangun dengan package manager favorit Anda.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nJANGAN jalankan perintah docker.\n\n\n# Langkah 2: Buatlah repo GitHub\n\nPada GitHub, buatlah repositori publik baru. Berikan nama dan atur visibilitas Anda ke publik. Di sini, semuanya akan disimpan sebagai default untuk saat ini.\n\n\n\nCatat URL GitHub Anda, ini harus bersifat publik agar SubQuery dapat mengaksesnya.\n\n\n\n\n# Langkah 3: Push ke GitHub\n\nKembali ke direktori proyek Anda, inisialisasi ini sebagai direktori git. Jika tidak, Anda mungkin akan mendapatkan kesalahan "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nKemudian tambahkan repositori jarak jauh dengan perintah:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nIni pada dasarnya akan menetapkan repositori jarak jauh Anda ke "https://github.com/seandotau/subqlHelloWorld.git" dan memberinya nama "origin" yang merupakan nomenklatur standar untuk repositori jarak jauh pada GitHub.\n\nSelanjutnya kita tambahkan kode ke repo kita dengan perintah berikut:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nPerintah push berarti "tolong push kode saya KE repo origin DARI repo lokal master saya". Refreshing GitHub harus menampilkan semua kode di GitHub.\n\n\n\nSekarang setelah Anda memasukkan kode ke GitHub, mari kita lihat bagaimana kita dapat meng-host-nya pada SubQuery Projects.\n\n\n# Langkah 4: Buatlah proyek Anda\n\nNavigasikan ke https://project.subquery.network dan masuk dengan akun GitHub Anda.\n\n\n\nKemudian buatlah proyek baru,\n\n\n\nDan isi berbagai bidang dengan detail yang sesuai.\n\n * Akun GitHub: Jika Anda memiliki lebih dari satu akun GitHub, pilihlah akun yang dipakai untuk membuat proyek ini. Proyek yang dibuat di akun organisasi GitHub akan dibagikan di antara anggota di dalam organisasi itu.\n * Nama Proyek: Berikan nama proyek Anda di sini.\n * Subtitle: Berikan subtitle untuk proyek Anda.\n * Deskripsi: Jelaskan apa yang dilakukan proyek SubQuery Anda.\n * URL Repositori GitHub: Ini harus berupa URL GitHub yang valid untuk repositori publik yang berisikan proyek SubQuery Anda. File schema.graphql harus berada di dalam root direktori Anda.\n * Sembunyikan proyek: Apabila dipilih, ini akan menyembunyikan proyek Anda dari para penjelajah SubQuery publik. Biarkan ini tidak terpilih jika Anda ingin membagikan SubQuery Anda dengan komunitas!\n\n\n\nSaat Anda mengklik buat atau create, Anda akan dibawa ke dasbor Anda.\n\n\n\nDasbor ini berisikan banyak informasi berguna seperti jaringan yang digunakan, URL repositori GitHub dari source code yang dijalankan, kapan dibuat dan terakhir diperbarui, dan khususnya detail penerapan.\n\n\n# Langkah 5: Terapkan proyek Anda\n\nSekarang setelah Anda membuat proyek di dalam SubQuery Projects, mempersiapkan perilaku tampilan, langkah selanjutnya adalah menerapkan proyek Anda menjadi operasional. Menerapkan sebuah versi akan memicu operasi pengindeksan SubQuery yang baru untuk memulai, dan menyiapkan layanan kueri yang diperlukan untuk mulai menerima permintaan GraphQL. Anda juga dapat menerapkan versi-versi baru ke proyek yang ada di sini.\n\nAnda dapat memilih untuk menerapkannya ke berbagai lingkungan (environment) seperti slot produksi atau stagging slot. Di sini kita akan menyebarkannya ke slot produksi. Mengklik tombol "Menerapkan" atau "deploy" akan menampilkan layar dengan bidang-bidang berikut:\n\n\n\n * Commit Hash Versi baru: Dari GitHub pilih commit yang benar dari codebase proyek SubQuery yang ingin Anda terapkan\n * Versi Indexer: Ini adalah versi layanan simpul SubQuery yang Anda inginkan untuk menjalankan SubQuery ini. Lihat @subql/node\n * Versi Kueri: Ini adalah versi layanan kueri SubQuery yang Anda inginkan untuk menjalankan SubQuery ini. Lihat @subql/query\n\nKarena kita hanya memiliki satu commit, hanya ada satu opsi pada drop down. Kita juga akan bekerja dengan versi indexer dan versi kueri terbaru sehingga kita akan menerima default dan kemudian klik "Terapkan Pembaruan".\n\nAnda kemudian akan melihat penerapan Anda berada dalam status "Memproses". Di sini, kode Anda akan diterapkan ke infrastruktur terkelola SubQuery. Pada dasarnya sebuah server akan diputar sesuai permintaan dan disediakan untuk Anda. Ini akan memakan waktu selama beberapa menit, jadi waktunya minum kopi!\n\n\n\nPenyebaran sekarang sedang berjalan.\n\n\n\n\n# Langkah 6: Menguji proyek Anda\n\nUntuk menguji proyek Anda, klik pada 3 elipsis dan pilihlah "lihat pada SubQuery Explorer".\n\n\n\nIni akan membawa Anda ke "Playground" yang sudah tidak asing lagi di mana Anda dapat mengeklik tombol putar dan melihat hasil kueri.\n\n\n\n\n# Langkah 7: Langkah bonus\n\nBagi yang cerdik di antara kita, Anda akan ingat bahwa di dalam tujuan pembelajaran, poin terakhirnya adalah menjalankan kueri GET yang sederhana. Untuk melakukan ini, kita perlu mengambil "Query Endpoint" yang ditampilkan pada detail penerapan.\n\n\n\nKemudian Anda dapat mengirim permintaan GET ke endpoint ini baik dengan menggunakan klien favorit Anda seperti Postman atau Mockoon atau melalui cURL pada terminal Anda. Untuk sederhananya, cURL akan ditampilkan di bawah ini.\n\nPerintah curl yang untuk dijalankan adalah:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\nmemberikan hasil dari:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nKeterbacaan tidak menjadi perhatian di sini karena Anda mungkin akan memiliki beberapa kode front-end untuk dipakai dan menguraikan respons JSON ini.\n\n\n# Ringkasan\n\nDi dalam quick start yang dihosting SubQuery ini, kami menunjukkan betapa cepat dan mudahnya mengambil proyek Subql dan menyebarkannya ke SubQuery Projects di mana semua infrastruktur telah disediakan untuk kenyamanan Anda. Terdapat playground bawaan untuk menjalankan berbagai kueri serta endpoint API untuk integrasi kode Anda.',normalizedContent:'# hello world (hosting subquery)\n\ntujuan dari quick start ini adalah untuk menunjukkan bagaimana anda dapat menjalankan proyek starter default pada subquery projects (layanan terkelola kami) dengan beberapa langkah mudah.\n\nkita akan mengambil proyek starter sederhana (dan semua yang telah kami pelajari sejauh ini) tetapi alih-alih menjalankannya secara lokal pada docker, kita akan memanfaatkan infrastruktur hosting subquery yang terkelola. dengan kata lain, kita akan membiarkan subquery melakukan semua pekerjaan berat, menjalankan, dan mengelola infrastruktur produksi.\n\n\n# tujuan pembelajaran\n\npada akhir quick start ini, anda harus:\n\n * memahami prasyarat yang diperlukan\n * bisa menghosting proyek pada subquery projects\n * menjalankan kueri sederhana untuk mendapatkan tinggi blok mainnet polkadot menggunakan playground\n * menjalankan kueri get sederhana untuk mendapatkan tinggi blok mainnet polkadot menggunakan curl\n\n\n# audiens yang dituju\n\npanduan ini ditujukan bagi para pengembang (developer) baru yang memiliki pengalaman pengembangan dan tertarik untuk mempelajari lebih lanjut tentang subquery.\n\n\n# panduan video\n\n\n# prasyarat\n\nanda akan memerlukan:\n\n * akun github\n\n\n# langkah 1: buatlah proyek anda\n\nmari membuat proyek bernama subql_hallowworld dan menjalankan instalasi wajib, codegen, dan bangun dengan package manager favorit anda.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\njangan jalankan perintah docker.\n\n\n# langkah 2: buatlah repo github\n\npada github, buatlah repositori publik baru. berikan nama dan atur visibilitas anda ke publik. di sini, semuanya akan disimpan sebagai default untuk saat ini.\n\n\n\ncatat url github anda, ini harus bersifat publik agar subquery dapat mengaksesnya.\n\n\n\n\n# langkah 3: push ke github\n\nkembali ke direktori proyek anda, inisialisasi ini sebagai direktori git. jika tidak, anda mungkin akan mendapatkan kesalahan "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nkemudian tambahkan repositori jarak jauh dengan perintah:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nini pada dasarnya akan menetapkan repositori jarak jauh anda ke "https://github.com/seandotau/subqlhelloworld.git" dan memberinya nama "origin" yang merupakan nomenklatur standar untuk repositori jarak jauh pada github.\n\nselanjutnya kita tambahkan kode ke repo kita dengan perintah berikut:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nperintah push berarti "tolong push kode saya ke repo origin dari repo lokal master saya". refreshing github harus menampilkan semua kode di github.\n\n\n\nsekarang setelah anda memasukkan kode ke github, mari kita lihat bagaimana kita dapat meng-host-nya pada subquery projects.\n\n\n# langkah 4: buatlah proyek anda\n\nnavigasikan ke https://project.subquery.network dan masuk dengan akun github anda.\n\n\n\nkemudian buatlah proyek baru,\n\n\n\ndan isi berbagai bidang dengan detail yang sesuai.\n\n * akun github: jika anda memiliki lebih dari satu akun github, pilihlah akun yang dipakai untuk membuat proyek ini. proyek yang dibuat di akun organisasi github akan dibagikan di antara anggota di dalam organisasi itu.\n * nama proyek: berikan nama proyek anda di sini.\n * subtitle: berikan subtitle untuk proyek anda.\n * deskripsi: jelaskan apa yang dilakukan proyek subquery anda.\n * url repositori github: ini harus berupa url github yang valid untuk repositori publik yang berisikan proyek subquery anda. file schema.graphql harus berada di dalam root direktori anda.\n * sembunyikan proyek: apabila dipilih, ini akan menyembunyikan proyek anda dari para penjelajah subquery publik. biarkan ini tidak terpilih jika anda ingin membagikan subquery anda dengan komunitas!\n\n\n\nsaat anda mengklik buat atau create, anda akan dibawa ke dasbor anda.\n\n\n\ndasbor ini berisikan banyak informasi berguna seperti jaringan yang digunakan, url repositori github dari source code yang dijalankan, kapan dibuat dan terakhir diperbarui, dan khususnya detail penerapan.\n\n\n# langkah 5: terapkan proyek anda\n\nsekarang setelah anda membuat proyek di dalam subquery projects, mempersiapkan perilaku tampilan, langkah selanjutnya adalah menerapkan proyek anda menjadi operasional. menerapkan sebuah versi akan memicu operasi pengindeksan subquery yang baru untuk memulai, dan menyiapkan layanan kueri yang diperlukan untuk mulai menerima permintaan graphql. anda juga dapat menerapkan versi-versi baru ke proyek yang ada di sini.\n\nanda dapat memilih untuk menerapkannya ke berbagai lingkungan (environment) seperti slot produksi atau stagging slot. di sini kita akan menyebarkannya ke slot produksi. mengklik tombol "menerapkan" atau "deploy" akan menampilkan layar dengan bidang-bidang berikut:\n\n\n\n * commit hash versi baru: dari github pilih commit yang benar dari codebase proyek subquery yang ingin anda terapkan\n * versi indexer: ini adalah versi layanan simpul subquery yang anda inginkan untuk menjalankan subquery ini. lihat @subql/node\n * versi kueri: ini adalah versi layanan kueri subquery yang anda inginkan untuk menjalankan subquery ini. lihat @subql/query\n\nkarena kita hanya memiliki satu commit, hanya ada satu opsi pada drop down. kita juga akan bekerja dengan versi indexer dan versi kueri terbaru sehingga kita akan menerima default dan kemudian klik "terapkan pembaruan".\n\nanda kemudian akan melihat penerapan anda berada dalam status "memproses". di sini, kode anda akan diterapkan ke infrastruktur terkelola subquery. pada dasarnya sebuah server akan diputar sesuai permintaan dan disediakan untuk anda. ini akan memakan waktu selama beberapa menit, jadi waktunya minum kopi!\n\n\n\npenyebaran sekarang sedang berjalan.\n\n\n\n\n# langkah 6: menguji proyek anda\n\nuntuk menguji proyek anda, klik pada 3 elipsis dan pilihlah "lihat pada subquery explorer".\n\n\n\nini akan membawa anda ke "playground" yang sudah tidak asing lagi di mana anda dapat mengeklik tombol putar dan melihat hasil kueri.\n\n\n\n\n# langkah 7: langkah bonus\n\nbagi yang cerdik di antara kita, anda akan ingat bahwa di dalam tujuan pembelajaran, poin terakhirnya adalah menjalankan kueri get yang sederhana. untuk melakukan ini, kita perlu mengambil "query endpoint" yang ditampilkan pada detail penerapan.\n\n\n\nkemudian anda dapat mengirim permintaan get ke endpoint ini baik dengan menggunakan klien favorit anda seperti postman atau mockoon atau melalui curl pada terminal anda. untuk sederhananya, curl akan ditampilkan di bawah ini.\n\nperintah curl yang untuk dijalankan adalah:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\nmemberikan hasil dari:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nketerbacaan tidak menjadi perhatian di sini karena anda mungkin akan memiliki beberapa kode front-end untuk dipakai dan menguraikan respons json ini.\n\n\n# ringkasan\n\ndi dalam quick start yang dihosting subquery ini, kami menunjukkan betapa cepat dan mudahnya mengambil proyek subql dan menyebarkannya ke subquery projects di mana semua infrastruktur telah disediakan untuk kenyamanan anda. terdapat playground bawaan untuk menjalankan berbagai kueri serta endpoint api untuk integrasi kode anda.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Selamat datang di quick start SubQuery Hello World ini. Quick start ini bertujuan untuk menunjukkan kepada Anda cara menjalankan proyek starter def",meta:[{property:"og:url",content:"/id/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Selamat datang di quick start SubQuery Hello World ini. Quick start ini bertujuan untuk menunjukkan kepada Anda cara menjalankan proyek starter def"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/quickstart/helloworld-localhost.html",relativePath:"id/quickstart/helloworld-localhost.md",key:"v-79dd94fe",path:"/id/quickstart/helloworld-localhost/",headers:[{level:2,title:"Tujuan Pembelajaran",slug:"tujuan-pembelajaran",normalizedTitle:"tujuan pembelajaran",charIndex:237},{level:2,title:"Audiens yang dituju",slug:"audiens-yang-dituju",normalizedTitle:"audiens yang dituju",charIndex:515},{level:2,title:"Panduan video",slug:"panduan-video",normalizedTitle:"panduan video",charIndex:688},{level:2,title:"Prasyarat",slug:"prasyarat",normalizedTitle:"prasyarat",charIndex:706},{level:2,title:"Langkah 1: Inisialisasi proyek",slug:"langkah-1-inisialisasi-proyek",normalizedTitle:"langkah 1: inisialisasi proyek",charIndex:1551},{level:2,title:"Langkah 2: Instal dependencies",slug:"langkah-2-instal-dependencies",normalizedTitle:"langkah 2: instal dependencies",charIndex:2166},{level:2,title:"Langkah 3: Hasilkan kode",slug:"langkah-3-hasilkan-kode",normalizedTitle:"langkah 3: hasilkan kode",charIndex:2615},{level:2,title:"Langkah 4: Membuat kode",slug:"langkah-4-membuat-kode",normalizedTitle:"langkah 4: membuat kode",charIndex:3253},{level:2,title:"Langkah 5: Jalankan Docker",slug:"langkah-5-jalankan-docker",normalizedTitle:"langkah 5: jalankan docker",charIndex:3490},{level:2,title:"Langkah 6: Jelajahi playground",slug:"langkah-6-jelajahi-playground",normalizedTitle:"langkah 6: jelajahi playground",charIndex:4817},{level:2,title:"Ringkasan",slug:"ringkasan",normalizedTitle:"ringkasan",charIndex:5245}],readingTime:{minutes:2.7,words:811},headersStr:"Tujuan Pembelajaran Audiens yang dituju Panduan video Prasyarat Langkah 1: Inisialisasi proyek Langkah 2: Instal dependencies Langkah 3: Hasilkan kode Langkah 4: Membuat kode Langkah 5: Jalankan Docker Langkah 6: Jelajahi playground Ringkasan",content:'# Hello World (localhost + Docker)\n\nSelamat datang di quick start SubQuery Hello World ini. Quick start ini bertujuan untuk menunjukkan kepada Anda cara menjalankan proyek starter default di Docker dengan beberapa langkah sederhana.\n\n\n# Tujuan Pembelajaran\n\nDi akhir quick start ini, Anda harus:\n\n * memahami prasyarat yang diperlukan\n * memahami perintah umum dasar\n * dapat menavigasi ke localhost:3000 dan melihat playground\n * menjalankan kueri sederhana untuk mendapatkan tinggi blok dari mainnet Polkadot\n\n\n# Audiens yang dituju\n\nPanduan ini ditujukan bagi para pengembang baru yang memiliki pengalaman pengembangan dan tertarik untuk mempelajari lebih lanjut tentang SubQuery.\n\n\n# Panduan video\n\n\n# Prasyarat\n\nAnda akan memerlukan:\n\n * package manager yarn atau npm\n * SubQuery CLI (@subql/cli)\n * Docker\n\nAnda dapat menjalankan perintah berikut di terminal untuk melihat apakah Anda sudah memiliki salah satu prasyarat ini.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nUntuk pengguna yang lebih mahir, copy dan paste berikut ini:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nIni harus kembali: (untuk pengguna npm, ganti yarn dengan npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nJika Anda mendapatkan hal di atas, maka Anda siap untuk lanjut. Jika tidak, ikuti tautan ini untuk menginstalnya:\n\n * yarn atau npm\n * SubQuery CLI\n * Docker\n\n\n# Langkah 1: Inisialisasi proyek\n\nLangkah pertama saat memulai dengan SubQuery adalah menjalankan perintah subql init. Mari kita inisialisasi proyek awal dengan nama subqlHelloWorld. Perhatikan bahwa hanya author yang wajib diisi. Segala sesuatu yang lain dibiarkan kosong di bawah.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nJangan lupa untuk pindah ke direktori baru ini.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Langkah 2: Instal dependencies\n\nSekarang lakukan instal yarn atau node untuk menginstal berbagai dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nContoh yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Langkah 3: Hasilkan kode\n\nSekarang jalankan yarn codegen untuk menghasilkan TypeScript dari skema GraphQL.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nContoh yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nPeringatan Ketika perubahan dibuat pada file skema, harap ingat untuk menjalankan kembali yarn codegen untuk membuat ulang direktori jenis Anda.\n\n\n# Langkah 4: Membuat kode\n\nLangkah selanjutnya adalah membuat kode dengan yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nContoh yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Langkah 5: Jalankan Docker\n\nDengan menggunakan Docker memungkinkan Anda menjalankan contoh ini dengan sangat cepat karena semua infrastruktur yang diperlukan dapat tersediakan di dalam image Docker. Jalankan docker-compose pull && docker-compose up.\n\nIni akan menendang segalanya menjadi hidup di mana pada akhirnya Anda akan mendapatkan blok terambil.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Langkah 6: Jelajahi playground\n\nArahkan ke http://localhost:3000/ dan paste kueri di bawah ini ke sisi kiri layar lalu tekan tombol putar atau play.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nPlayground SubQuery pada localhost.\n\n\n\nJumlah blok pada playground harus sesuai dengan jumlah blok (secara teknis tinggi blok) di terminal juga.\n\n\n# Ringkasan\n\nDalam quick start ini, kami mendemonstrasikan langkah-langkah dasar untuk mengaktifkan dan menjalankan proyek pemula di dalam lingkungan Docker dan kemudian menavigasi ke localhost:3000 dan menjalankan kueri untuk mengembalikan nomor blok jaringan Polkadot mainnet.',normalizedContent:'# hello world (localhost + docker)\n\nselamat datang di quick start subquery hello world ini. quick start ini bertujuan untuk menunjukkan kepada anda cara menjalankan proyek starter default di docker dengan beberapa langkah sederhana.\n\n\n# tujuan pembelajaran\n\ndi akhir quick start ini, anda harus:\n\n * memahami prasyarat yang diperlukan\n * memahami perintah umum dasar\n * dapat menavigasi ke localhost:3000 dan melihat playground\n * menjalankan kueri sederhana untuk mendapatkan tinggi blok dari mainnet polkadot\n\n\n# audiens yang dituju\n\npanduan ini ditujukan bagi para pengembang baru yang memiliki pengalaman pengembangan dan tertarik untuk mempelajari lebih lanjut tentang subquery.\n\n\n# panduan video\n\n\n# prasyarat\n\nanda akan memerlukan:\n\n * package manager yarn atau npm\n * subquery cli (@subql/cli)\n * docker\n\nanda dapat menjalankan perintah berikut di terminal untuk melihat apakah anda sudah memiliki salah satu prasyarat ini.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nuntuk pengguna yang lebih mahir, copy dan paste berikut ini:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nini harus kembali: (untuk pengguna npm, ganti yarn dengan npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\njika anda mendapatkan hal di atas, maka anda siap untuk lanjut. jika tidak, ikuti tautan ini untuk menginstalnya:\n\n * yarn atau npm\n * subquery cli\n * docker\n\n\n# langkah 1: inisialisasi proyek\n\nlangkah pertama saat memulai dengan subquery adalah menjalankan perintah subql init. mari kita inisialisasi proyek awal dengan nama subqlhelloworld. perhatikan bahwa hanya author yang wajib diisi. segala sesuatu yang lain dibiarkan kosong di bawah.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\njangan lupa untuk pindah ke direktori baru ini.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# langkah 2: instal dependencies\n\nsekarang lakukan instal yarn atau node untuk menginstal berbagai dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\ncontoh yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# langkah 3: hasilkan kode\n\nsekarang jalankan yarn codegen untuk menghasilkan typescript dari skema graphql.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\ncontoh yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nperingatan ketika perubahan dibuat pada file skema, harap ingat untuk menjalankan kembali yarn codegen untuk membuat ulang direktori jenis anda.\n\n\n# langkah 4: membuat kode\n\nlangkah selanjutnya adalah membuat kode dengan yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\ncontoh yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# langkah 5: jalankan docker\n\ndengan menggunakan docker memungkinkan anda menjalankan contoh ini dengan sangat cepat karena semua infrastruktur yang diperlukan dapat tersediakan di dalam image docker. jalankan docker-compose pull && docker-compose up.\n\nini akan menendang segalanya menjadi hidup di mana pada akhirnya anda akan mendapatkan blok terambil.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# langkah 6: jelajahi playground\n\narahkan ke http://localhost:3000/ dan paste kueri di bawah ini ke sisi kiri layar lalu tekan tombol putar atau play.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nplayground subquery pada localhost.\n\n\n\njumlah blok pada playground harus sesuai dengan jumlah blok (secara teknis tinggi blok) di terminal juga.\n\n\n# ringkasan\n\ndalam quick start ini, kami mendemonstrasikan langkah-langkah dasar untuk mengaktifkan dan menjalankan proyek pemula di dalam lingkungan docker dan kemudian menavigasi ke localhost:3000 dan menjalankan kueri untuk mengembalikan nomor blok jaringan polkadot mainnet.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Panduan Memulai Cepat",frontmatter:{summary:"Panduan Memulai Cepat Dalam panduan Mulai Cepat ini, kita akan membuat proyek awal sederhana yang dapat Anda gunakan sebagai kerangka kerja untuk mengembangkan Proyek SubQuery Anda",meta:[{property:"og:url",content:"/id/quickstart/quickstart.html"},{property:"og:title",content:"Panduan Memulai Cepat"},{property:"og:description",content:"Panduan Memulai Cepat Dalam panduan Mulai Cepat ini, kita akan membuat proyek awal sederhana yang dapat Anda gunakan sebagai kerangka kerja untuk mengembangkan Proyek SubQuery Anda"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/quickstart/quickstart.html",relativePath:"id/quickstart/quickstart.md",key:"v-26e5d623",path:"/id/quickstart/quickstart/",headers:[{level:2,title:"Persiapan",slug:"persiapan",normalizedTitle:"persiapan",charIndex:470},{level:3,title:"Lingkungan Pengembangan Lokal",slug:"lingkungan-pengembangan-lokal",normalizedTitle:"lingkungan pengembangan lokal",charIndex:484},{level:3,title:"Pasang CLI SubQuery",slug:"pasang-cli-subquery",normalizedTitle:"pasang cli subquery",charIndex:727},{level:2,title:"Inisialisasi Proyek SubQuery Pemula",slug:"inisialisasi-proyek-subquery-pemula",normalizedTitle:"inisialisasi proyek subquery pemula",charIndex:1177},{level:2,title:"Konfigurasi dan Bangun Proyek Pemula",slug:"konfigurasi-dan-bangun-proyek-pemula",normalizedTitle:"konfigurasi dan bangun proyek pemula",charIndex:2771},{level:3,title:"Pembuatan Model GraphQL",slug:"pembuatan-model-graphql",normalizedTitle:"pembuatan model graphql",charIndex:3211},{level:2,title:"Bangun Proyek",slug:"bangun-proyek",normalizedTitle:"bangun proyek",charIndex:2787},{level:2,title:"Menjalankan dan Membuat database Proyek Pemula Anda",slug:"menjalankan-dan-membuat-database-proyek-pemula-anda",normalizedTitle:"menjalankan dan membuat database proyek pemula anda",charIndex:3857},{level:3,title:"Jalankan Proyek SubQuery Anda",slug:"jalankan-proyek-subquery-anda",normalizedTitle:"jalankan proyek subquery anda",charIndex:4269},{level:3,title:"Kueri Proyek Anda",slug:"kueri-proyek-anda",normalizedTitle:"kueri proyek anda",charIndex:4879},{level:2,title:"Langkah selanjutnya",slug:"langkah-selanjutnya",normalizedTitle:"langkah selanjutnya",charIndex:5572}],readingTime:{minutes:2.93,words:880},headersStr:"Persiapan Lingkungan Pengembangan Lokal Pasang CLI SubQuery Inisialisasi Proyek SubQuery Pemula Konfigurasi dan Bangun Proyek Pemula Pembuatan Model GraphQL Bangun Proyek Menjalankan dan Membuat database Proyek Pemula Anda Jalankan Proyek SubQuery Anda Kueri Proyek Anda Langkah selanjutnya",content:"# Panduan Memulai Cepat\n\nDalam panduan Mulai Cepat ini, kita akan membuat proyek awal sederhana yang dapat Anda gunakan sebagai kerangka kerja untuk mengembangkan Proyek SubQuery Anda sendiri.\n\nDi akhir panduan ini, Anda akan memiliki proyek SubQuery yang berjalan pada node SubQuery dengan titik akhir GraphQL tempat dimana Anda dapat membuat kueri data.\n\nJika Anda belum melakukannya, sebaiknya Anda membiasakan diri dengan terminologi yang digunakan di SubQuery.\n\n\n# Persiapan\n\n\n# Lingkungan Pengembangan Lokal\n\n * Naskah diperlukan untuk mengkompilasi proyek dan menentukan tipe.\n * Baik CLI SubQuery dan Project yang dihasilkan memiliki dependensi dan memerlukan versi modern Node.\n * Node SubQuery membutuhkan Docker\n\n\n# Pasang CLI SubQuery\n\nPasang SubQuery CLI secara global di terminal Anda dengan menggunakan NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nHarap dicatat bahwa kami JANGAN mendorong penggunaan global benang karena manajemen ketergantungannya yang buruk yang dapat menyebabkan kesalahan di masa mendatang.\n\nKemudian Anda dapat menjalankan bantuan untuk melihat perintah dan penggunaan yang tersedia yang telah disediakan oleh CLI\n\nbantuan subql\n\n\n1\n\n\n\n# Inisialisasi Proyek SubQuery Pemula\n\nDi dalam direktori tempat Anda ingin membuat proyek SubQuery, cukup ganti NAMA_PROYEK dengan milik Anda dan jalankan perintah:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nAnda akan ditanya pertanyaan tertentu saat proyek SubQuery diinisialisasi:\n\n * Repositori Git (Pilihan): Berikan URL Git ke repo tempat proyek SubQuery ini akan dihosting (saat dihosting di Penjelajah SubQuery)\n * Titik akhir RPC (Diperlukan): Menyediakan URL wss ke titik akhir RPC yang sedang berjalan yang mana akan digunakan secara default untuk proyek ini. Anda dapat dengan cepat mengakses titik akhir publik untuk jaringan Polkadot yang berbeda atau membuat simpul khusus Anda sendiri menggunakan OnFinality atau cukup gunakan titik akhir Polkadot default.\n * Penulis (Diperlukan): Masukkan pemilik proyek SubQuery ini di sini\n * Deskripsi (Pilihan): Anda dapat memberikan paragraf singkat tentang proyek Anda yang menjelaskan data apa yang ada di dalamnya dan apa yang dapat dilakukan pengguna dengannya\n * Versi (Diperlukan): Masukkan nomor versi khusus atau gunakan default (1.0.0)\n * Lisensi (Diperlukan): Berikan lisensi perangkat lunak untuk proyek ini atau terima default (Apache-2.0)\n\nSetelah proses inisialisasi selesai, Anda akan melihat folder anda dengan nama proyek yang telah dibuat di dalam direktori. Isi direktori ini harus identik dengan apa yang tercantum dalam Struktur Direktori.\n\nTerakhir, di bawah direktori proyek, jalankan perintah berikut untuk memasang dependensi proyek baru.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Konfigurasi dan Bangun Proyek Pemula\n\nDalam paket awal yang baru saja Anda inisialisasi, kami telah menyediakan konfigurasi standar untuk proyek baru Anda. Anda pastinya akan mengerjakan di file-file berikut:\n\n * Manifes di project.yaml\n * Skema GraphQL di schema.graphql\n * Fungsi Pemetaan di direktori src/mappings/\n\nUntuk informasi lebih lanjut tentang cara menulis SubQuery Anda sendiri, lihat dokumentasi kami di bawah Buat Proyek\n\n\n# Pembuatan Model GraphQL\n\nUntuk mengindeks proyek SubQuery Anda, Anda harus terlebih dahulu membuat model GraphQL yang diperlukan yang mana telah Anda tetapkan di file GraphQL Schema (schema.graphql). Jalankan perintah ini di root direktori proyek.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAnda akan menemukan model yang dihasilkan di direktori /src/types/models\n\n\n# Bangun Proyek\n\nUntuk menjalankan Proyek SubQuery Anda pada Node SubQuery yang dihosting secara lokal, Anda perlu membangun pekerjaan Anda.\n\nJalankan perintah build dari direktori root proyek.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Menjalankan dan Membuat database Proyek Pemula Anda\n\nMeskipun Anda dapat dengan cepat memublikasikan proyek baru Anda ke Proyek SubQuery dan menanyakannya menggunakan Penjelajah kami, cara termudah untuk menjalankan node SubQuery secara lokal adalah dalam wadah Docker, jika Anda belum memiliki Docker, Anda dapat memasangnya dari docker.com.\n\nLewati ini dan publikasikan proyek baru Anda ke Proyek SubQuery\n\n\n# Jalankan Proyek SubQuery Anda\n\nSemua konfigurasi yang mengontrol bagaimana node SubQuery dijalankan, didefinisikan dalam file docker-compose.yml ini. Untuk proyek baru yang baru saja diinisialisasi, Anda tidak perlu mengubah apa pun, tetapi Anda dapat membaca selengkapnya tentang file dan setelannya di bagian Jalankan Proyek\n\nDi bawah direktori proyek jalankan perintah berikut:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nMungkin perlu beberapa saat untuk mengunduh paket yang diperlukan (@subql/node, @subql/query, dan Postgres) untuk pertama kalinya tetapi segera Anda akan melihat Node subkueri.\n\n\n# Kueri Proyek Anda\n\nBuka browser Anda dan buka http://localhost:3000.\n\nAnda akan melihat taman bermain GraphQL ditampilkan di penjelajah dan skema yang siap untuk kueri. Di kanan atas taman bermain, Anda akan menemukan tombol Dokumen yang akan membuka undian dokumentasi. Dokumentasi ini dibuat secara otomatis dan membantu Anda menemukan entitas dan metode apa yang dapat Anda kuerikan.\n\nUntuk proyek SubQuery baru, Anda dapat mencoba kueri berikut untuk mengetahui cara kerjanya atau pelajari lebih lanjut tentang bahasa Kueri GraphQL.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Langkah selanjutnya\n\nSelamat, Anda sekarang memiliki proyek SubQuery yang berjalan secara lokal yang mana menerima permintaan GraphQL API untuk data sampel. Dalam panduan berikutnya, kami akan menunjukkan cara memublikasikan proyek baru Anda ke Proyek SubQuery dan menanyakannya menggunakan Penjelajah kami\n\nPublikasikan proyek baru Anda ke Proyek SubQuery",normalizedContent:"# panduan memulai cepat\n\ndalam panduan mulai cepat ini, kita akan membuat proyek awal sederhana yang dapat anda gunakan sebagai kerangka kerja untuk mengembangkan proyek subquery anda sendiri.\n\ndi akhir panduan ini, anda akan memiliki proyek subquery yang berjalan pada node subquery dengan titik akhir graphql tempat dimana anda dapat membuat kueri data.\n\njika anda belum melakukannya, sebaiknya anda membiasakan diri dengan terminologi yang digunakan di subquery.\n\n\n# persiapan\n\n\n# lingkungan pengembangan lokal\n\n * naskah diperlukan untuk mengkompilasi proyek dan menentukan tipe.\n * baik cli subquery dan project yang dihasilkan memiliki dependensi dan memerlukan versi modern node.\n * node subquery membutuhkan docker\n\n\n# pasang cli subquery\n\npasang subquery cli secara global di terminal anda dengan menggunakan npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nharap dicatat bahwa kami jangan mendorong penggunaan global benang karena manajemen ketergantungannya yang buruk yang dapat menyebabkan kesalahan di masa mendatang.\n\nkemudian anda dapat menjalankan bantuan untuk melihat perintah dan penggunaan yang tersedia yang telah disediakan oleh cli\n\nbantuan subql\n\n\n1\n\n\n\n# inisialisasi proyek subquery pemula\n\ndi dalam direktori tempat anda ingin membuat proyek subquery, cukup ganti nama_proyek dengan milik anda dan jalankan perintah:\n\nsubql init --starter project_name\n\n\n1\n\n\nanda akan ditanya pertanyaan tertentu saat proyek subquery diinisialisasi:\n\n * repositori git (pilihan): berikan url git ke repo tempat proyek subquery ini akan dihosting (saat dihosting di penjelajah subquery)\n * titik akhir rpc (diperlukan): menyediakan url wss ke titik akhir rpc yang sedang berjalan yang mana akan digunakan secara default untuk proyek ini. anda dapat dengan cepat mengakses titik akhir publik untuk jaringan polkadot yang berbeda atau membuat simpul khusus anda sendiri menggunakan onfinality atau cukup gunakan titik akhir polkadot default.\n * penulis (diperlukan): masukkan pemilik proyek subquery ini di sini\n * deskripsi (pilihan): anda dapat memberikan paragraf singkat tentang proyek anda yang menjelaskan data apa yang ada di dalamnya dan apa yang dapat dilakukan pengguna dengannya\n * versi (diperlukan): masukkan nomor versi khusus atau gunakan default (1.0.0)\n * lisensi (diperlukan): berikan lisensi perangkat lunak untuk proyek ini atau terima default (apache-2.0)\n\nsetelah proses inisialisasi selesai, anda akan melihat folder anda dengan nama proyek yang telah dibuat di dalam direktori. isi direktori ini harus identik dengan apa yang tercantum dalam struktur direktori.\n\nterakhir, di bawah direktori proyek, jalankan perintah berikut untuk memasang dependensi proyek baru.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# konfigurasi dan bangun proyek pemula\n\ndalam paket awal yang baru saja anda inisialisasi, kami telah menyediakan konfigurasi standar untuk proyek baru anda. anda pastinya akan mengerjakan di file-file berikut:\n\n * manifes di project.yaml\n * skema graphql di schema.graphql\n * fungsi pemetaan di direktori src/mappings/\n\nuntuk informasi lebih lanjut tentang cara menulis subquery anda sendiri, lihat dokumentasi kami di bawah buat proyek\n\n\n# pembuatan model graphql\n\nuntuk mengindeks proyek subquery anda, anda harus terlebih dahulu membuat model graphql yang diperlukan yang mana telah anda tetapkan di file graphql schema (schema.graphql). jalankan perintah ini di root direktori proyek.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nanda akan menemukan model yang dihasilkan di direktori /src/types/models\n\n\n# bangun proyek\n\nuntuk menjalankan proyek subquery anda pada node subquery yang dihosting secara lokal, anda perlu membangun pekerjaan anda.\n\njalankan perintah build dari direktori root proyek.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# menjalankan dan membuat database proyek pemula anda\n\nmeskipun anda dapat dengan cepat memublikasikan proyek baru anda ke proyek subquery dan menanyakannya menggunakan penjelajah kami, cara termudah untuk menjalankan node subquery secara lokal adalah dalam wadah docker, jika anda belum memiliki docker, anda dapat memasangnya dari docker.com.\n\nlewati ini dan publikasikan proyek baru anda ke proyek subquery\n\n\n# jalankan proyek subquery anda\n\nsemua konfigurasi yang mengontrol bagaimana node subquery dijalankan, didefinisikan dalam file docker-compose.yml ini. untuk proyek baru yang baru saja diinisialisasi, anda tidak perlu mengubah apa pun, tetapi anda dapat membaca selengkapnya tentang file dan setelannya di bagian jalankan proyek\n\ndi bawah direktori proyek jalankan perintah berikut:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nmungkin perlu beberapa saat untuk mengunduh paket yang diperlukan (@subql/node, @subql/query, dan postgres) untuk pertama kalinya tetapi segera anda akan melihat node subkueri.\n\n\n# kueri proyek anda\n\nbuka browser anda dan buka http://localhost:3000.\n\nanda akan melihat taman bermain graphql ditampilkan di penjelajah dan skema yang siap untuk kueri. di kanan atas taman bermain, anda akan menemukan tombol dokumen yang akan membuka undian dokumentasi. dokumentasi ini dibuat secara otomatis dan membantu anda menemukan entitas dan metode apa yang dapat anda kuerikan.\n\nuntuk proyek subquery baru, anda dapat mencoba kueri berikut untuk mengetahui cara kerjanya atau pelajari lebih lanjut tentang bahasa kueri graphql.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# langkah selanjutnya\n\nselamat, anda sekarang memiliki proyek subquery yang berjalan secara lokal yang mana menerima permintaan graphql api untuk data sampel. dalam panduan berikutnya, kami akan menunjukkan cara memublikasikan proyek baru anda ke proyek subquery dan menanyakannya menggunakan penjelajah kami\n\npublikasikan proyek baru anda ke proyek subquery",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Halo Dunia",frontmatter:{summary:"Halo Dunia Dalam panduan memulai cepat Halo Dunia, kami menjalankan beberapa perintah sederhana dan dengan sangat cepat mendapatkan contoh dan menjalankannya. Ini memungkinkan Anda",meta:[{property:"og:url",content:"/id/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Halo Dunia"},{property:"og:description",content:"Halo Dunia Dalam panduan memulai cepat Halo Dunia, kami menjalankan beberapa perintah sederhana dan dengan sangat cepat mendapatkan contoh dan menjalankannya. Ini memungkinkan Anda"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/quickstart/understanding-helloworld.html",relativePath:"id/quickstart/understanding-helloworld.md",key:"v-3977c37b",path:"/id/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:426},{level:2,title:"pemasangan yarn",slug:"pemasangan-yarn",normalizedTitle:"pemasangan yarn",charIndex:1205},{level:2,title:"kodegen yarn",slug:"kodegen-yarn",normalizedTitle:"kodegen yarn",charIndex:2084},{level:2,title:"pembuatan yarn",slug:"pembuatan-yarn",normalizedTitle:"pembuatan yarn",charIndex:2437},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2679},{level:2,title:"Ringkasan",slug:"ringkasan",normalizedTitle:"ringkasan",charIndex:3354}],readingTime:{minutes:2.01,words:603},headersStr:"subql init pemasangan yarn kodegen yarn pembuatan yarn docker-compose Ringkasan",content:'# Halo Dunia\n\nDalam panduan memulai cepat Halo Dunia, kami menjalankan beberapa perintah sederhana dan dengan sangat cepat mendapatkan contoh dan menjalankannya. Ini memungkinkan Anda untuk memastikan bahwa Anda memiliki semua prasyarat dan dapat menggunakan taman bermain lokal untuk membuat kueri sederhana guna mendapatkan data pertama Anda dari SubQuery. Di sini, kita melihat lebih dekat apa arti semua perintah itu.\n\n\n# subql init\n\nPerintah pertama yang kami jalankan adalah subql init --starter subqlHelloWorld.\n\nIni melakukan pekerjaan berat dan membuat banyak file untuk Anda. Seperti disebutkan dalam dokumentasi resmi, Anda pastinya akan mengerjakan file-file berikut:\n\n * Manifes di project.yaml\n * Skema GraphQL di schema.graphql\n * Fungsi Pemetaan di direktori src/mappings/\n\n\n\nFile-file ini adalah inti dari semua yang kita lakukan. Karena itu, kami akan mendedikasikan lebih banyak waktu untuk file-file ini di artikel lain. Untuk saat ini, ketahuilah bahwa skema berisi deskripsi data yang dapat diminta pengguna dari SubQuery API, file yaml proyek yang berisi parameter tipe "konfigurasi" dan tentu saja mappingHandlers yang berisi Naskah yang mana berisi fungsi yang mengubah data.\n\n\n# pemasangan yarn\n\nHal berikutnya yang kami lakukan adalah yarn install. npm install dapat digunakan juga.\n\n> Pelajaran sejarah singkat. Node Package Manager atau npm awalnya dirilis pada tahun 2010 dan merupakan manajer paket yang sangat populer di kalangan pengembang JavaScript. Ini adalah paket default yang dipasang secara otomatis setiap kali Anda memasang Node.js di sistem Anda. Yarn awalnya dirilis oleh Facebook pada tahun 2016 dengan maksud untuk mengatasi beberapa kekurangan kinerja dan keamanan bekerja dengan npm (pada waktu itu).\n\nApa yang dilakukan yarn adalah melihat file package.json dan mengunduh berbagai dependensi lainnya. Melihat file package.json, sepertinya tidak ada banyak dependensi, tetapi ketika Anda menjalankan perintah, Anda akan melihat bahwa 18.983 file ditambahkan. Ini karena setiap dependensi juga akan memiliki dependensinya sendiri.\n\n\n\n\n# kodegen yarn\n\nKemudian kita menjalankan codegen yarn atau npm run-script codegen. Apa yang dilakukan adalah mengambil skema GraphQL (dalam schema.graphql) dan menghasilkan file model TypeScript terkait (Oleh karena itu file output akan memiliki ekstensi .ts). Anda tidak boleh mengubah file yang dihasilkan, cukup ubah file schema.graphql sumber.\n\n\n\n\n# pembuatan yarn\n\nyarn build atau npm run-script build kemudian dieksekusi. Hal Ini pasti akrab bagi programmer berpengalaman. Itu membuat folder distribusi yang melakukan hal-hal seperti pengoptimalan kode yang mempersiapkan penyebaran.\n\n\n\n\n# docker-compose\n\nLangkah terakhir adalah perintah docker gabungan docker-compose pull && docker-compose up (dapat dijalankan secara terpisah juga). Perintah pull mengambil semua gambar yang diperlukan dari Docker Hub dan perintah up memulai container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nSaat kontainer dimulai, Anda akan melihat terminal mengeluarkan banyak teks yang menunjukkan status node dan mesin GraphQL. Saat itulah Anda melihat:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nanda tahu bahwa node SubQuery telah disinkronkan.\n\n\n# Ringkasan\n\nSekarang setelah Anda memiliki wawasan tentang apa yang terjadi di balik selimut, pertanyaannya adalah mau kemana mana setelah dari sini? Jika Anda merasa percaya diri, Anda dapat langsung mempelajari cara membuat proyek dan mempelajari lebih lanjut tentang tiga file utama. File manifes, skema GraphQL, dan file pemetaan.\n\nJika tidak, lanjutkan ke bagian tutorial kami di mana kami dapat menjalankan contoh Halo Dunia ini pada infrastruktur yang dihosting SubQuery, kami akan memodifikasi blok awal, dan kami akan menyelam lebih dalam di dalam menjalankan proyek SubQuery dengan menjalankan dan proyek sumber terbuka yang tersedia.',normalizedContent:'# halo dunia\n\ndalam panduan memulai cepat halo dunia, kami menjalankan beberapa perintah sederhana dan dengan sangat cepat mendapatkan contoh dan menjalankannya. ini memungkinkan anda untuk memastikan bahwa anda memiliki semua prasyarat dan dapat menggunakan taman bermain lokal untuk membuat kueri sederhana guna mendapatkan data pertama anda dari subquery. di sini, kita melihat lebih dekat apa arti semua perintah itu.\n\n\n# subql init\n\nperintah pertama yang kami jalankan adalah subql init --starter subqlhelloworld.\n\nini melakukan pekerjaan berat dan membuat banyak file untuk anda. seperti disebutkan dalam dokumentasi resmi, anda pastinya akan mengerjakan file-file berikut:\n\n * manifes di project.yaml\n * skema graphql di schema.graphql\n * fungsi pemetaan di direktori src/mappings/\n\n\n\nfile-file ini adalah inti dari semua yang kita lakukan. karena itu, kami akan mendedikasikan lebih banyak waktu untuk file-file ini di artikel lain. untuk saat ini, ketahuilah bahwa skema berisi deskripsi data yang dapat diminta pengguna dari subquery api, file yaml proyek yang berisi parameter tipe "konfigurasi" dan tentu saja mappinghandlers yang berisi naskah yang mana berisi fungsi yang mengubah data.\n\n\n# pemasangan yarn\n\nhal berikutnya yang kami lakukan adalah yarn install. npm install dapat digunakan juga.\n\n> pelajaran sejarah singkat. node package manager atau npm awalnya dirilis pada tahun 2010 dan merupakan manajer paket yang sangat populer di kalangan pengembang javascript. ini adalah paket default yang dipasang secara otomatis setiap kali anda memasang node.js di sistem anda. yarn awalnya dirilis oleh facebook pada tahun 2016 dengan maksud untuk mengatasi beberapa kekurangan kinerja dan keamanan bekerja dengan npm (pada waktu itu).\n\napa yang dilakukan yarn adalah melihat file package.json dan mengunduh berbagai dependensi lainnya. melihat file package.json, sepertinya tidak ada banyak dependensi, tetapi ketika anda menjalankan perintah, anda akan melihat bahwa 18.983 file ditambahkan. ini karena setiap dependensi juga akan memiliki dependensinya sendiri.\n\n\n\n\n# kodegen yarn\n\nkemudian kita menjalankan codegen yarn atau npm run-script codegen. apa yang dilakukan adalah mengambil skema graphql (dalam schema.graphql) dan menghasilkan file model typescript terkait (oleh karena itu file output akan memiliki ekstensi .ts). anda tidak boleh mengubah file yang dihasilkan, cukup ubah file schema.graphql sumber.\n\n\n\n\n# pembuatan yarn\n\nyarn build atau npm run-script build kemudian dieksekusi. hal ini pasti akrab bagi programmer berpengalaman. itu membuat folder distribusi yang melakukan hal-hal seperti pengoptimalan kode yang mempersiapkan penyebaran.\n\n\n\n\n# docker-compose\n\nlangkah terakhir adalah perintah docker gabungan docker-compose pull && docker-compose up (dapat dijalankan secara terpisah juga). perintah pull mengambil semua gambar yang diperlukan dari docker hub dan perintah up memulai container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nsaat kontainer dimulai, anda akan melihat terminal mengeluarkan banyak teks yang menunjukkan status node dan mesin graphql. saat itulah anda melihat:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nanda tahu bahwa node subquery telah disinkronkan.\n\n\n# ringkasan\n\nsekarang setelah anda memiliki wawasan tentang apa yang terjadi di balik selimut, pertanyaannya adalah mau kemana mana setelah dari sini? jika anda merasa percaya diri, anda dapat langsung mempelajari cara membuat proyek dan mempelajari lebih lanjut tentang tiga file utama. file manifes, skema graphql, dan file pemetaan.\n\njika tidak, lanjutkan ke bagian tutorial kami di mana kami dapat menjalankan contoh halo dunia ini pada infrastruktur yang dihosting subquery, kami akan memodifikasi blok awal, dan kami akan menyelam lebih dalam di dalam menjalankan proyek subquery dengan menjalankan dan proyek sumber terbuka yang tersedia.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Menjalankan SubQuery Secara Lokal",frontmatter:{summary:"Menjalankan SubQuery Secara Lokal Panduan ini bekerja melalui cara menjalankan node SubQuery lokal pada infrastruktur Anda, yang mencakup pengindeks dan layanan kueri. Tidak ingin ",meta:[{property:"og:url",content:"/id/run/run.html"},{property:"og:title",content:"Menjalankan SubQuery Secara Lokal"},{property:"og:description",content:"Menjalankan SubQuery Secara Lokal Panduan ini bekerja melalui cara menjalankan node SubQuery lokal pada infrastruktur Anda, yang mencakup pengindeks dan layanan kueri. Tidak ingin "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/run/run.html",relativePath:"id/run/run.md",key:"v-5ee434f3",path:"/id/run/run/",headers:[{level:2,title:"Gunakan Docker",slug:"gunakan-docker",normalizedTitle:"gunakan docker",charIndex:442},{level:2,title:"Menjalankan Pengindeks (subql/node)",slug:"menjalankan-pengindeks-subql-node",normalizedTitle:"menjalankan pengindeks (subql/node)",charIndex:935},{level:3,title:"Instalasi",slug:"instalasi",normalizedTitle:"instalasi",charIndex:1305},{level:3,title:"Perintah Utama",slug:"perintah-utama",normalizedTitle:"perintah utama",charIndex:1620},{level:2,title:"Menjalankan Layanan Kueri (subql/query)",slug:"menjalankan-layanan-kueri-subql-query",normalizedTitle:"menjalankan layanan kueri (subql/query)",charIndex:4152},{level:3,title:"Instalasi",slug:"instalasi-2",normalizedTitle:"instalasi",charIndex:1305},{level:3,title:"Menjalankan layanan Kueri",slug:"menjalankan-layanan-kueri",normalizedTitle:"menjalankan layanan kueri",charIndex:4414}],readingTime:{minutes:2.3,words:689},headersStr:"Gunakan Docker Menjalankan Pengindeks (subql/node) Instalasi Perintah Utama Menjalankan Layanan Kueri (subql/query) Instalasi Menjalankan layanan Kueri",content:"# Menjalankan SubQuery Secara Lokal\n\nPanduan ini bekerja melalui cara menjalankan node SubQuery lokal pada infrastruktur Anda, yang mencakup pengindeks dan layanan kueri. Tidak ingin khawatir saat menjalankan infrastruktur SubQuery Anda sendiri? SubQuery menyediakan layanan hosting yang terkelola kepada komunitas secara gratis. Ikuti panduan penerbitan kami untuk melihat bagaimana Anda dapat mengunggah proyek Anda ke Proyek SubQuery.\n\n\n# Gunakan Docker\n\nSolusi alternatif adalah menjalankan Docker Container, yang ditentukan oleh file docker-compose.yml. Untuk proyek baru yang baru saja diinisialisasi, Anda tidak perlu mengubah apa pun di sini.\n\nDi bawah direktori proyek jalankan perintah berikut:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nMungkin perlu beberapa saat untuk mengunduh paket yang diperlukan (@subql/node, @subql/query, dan Postgres) untuk pertama kalinya, tetapi segera Anda akan melihat Node subkueri.\n\n\n# Menjalankan Pengindeks (subql/node)\n\nPersyaratan:\n\n * Postgres database (versi 12 atau lebih tinggi). Ketika Node SubQuery mengindeks blockchain, data yang diekstrak akan disimpan dalam instance database eksternal.\n\nNode SubQuery adalah implementasi yang mengekstrak data blockchain berbasis substrat per proyek SubQuery dan menyimpannya ke dalam database Postgres.\n\n\n# Instalasi\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nHarap diperhatikan bahwa kami TIDAK mendukung penggunaan yarn global karena manajemen ketergantungannya yang buruk yang dapat menyebabkan error di masa mendatang.\n\nSetelah terinstal, Anda dapat memulai node dengan perintah berikut:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Perintah Utama\n\nPerintah berikut akan membantu Anda menyelesaikan konfigurasi node SubQuery dan memulai proses pengindeksan. Untuk mengetahui lebih lanjut, Anda dapat menjalankan perintah --help.\n\n# Arahkan ke jalur proyek lokal\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Gunakan Kamus\n\nMenggunakan kamus full chain dapat mempercepat pemrosesan proyek SubQuery selama pengujian atau selama indeks pertama Anda secara drastis. Dalam beberapa kasus, kami telah melihat peningkatan kinerja pengindeksan hingga 10x dibanding sebelumnya.\n\nKamus full chain dapat melakukan pra-indeks lokasi semua peristiwa dan ekstrinsik dalam chain tertentu dan memungkinkan layanan node Anda untuk melompat ke lokasi yang relevan saat melakukan proses indeks daripada memeriksa setiap blok.\n\nAnda dapat menambahkan titik akhir kamus di file project.yaml Anda (lihat File Manifes), atau tentukan saat dijalankan menggunakan perintah berikut:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Hubungkan ke database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\nBergantung pada konfigurasi database Postgres Anda (misalnya kata sandi database yang berbeda), harap pastikan juga bahwa pengindeks (subql/node) dan layanan kueri (subql/query) dapat membuat koneksi ke sana.\n\n# Tentukan file konfigurasi\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nIni akan mengarahkan node kueri ke file konfigurasi yang bisa dalam format YAML atau JSON. Lihat contoh di bawah ini.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Ubah ukuran batch pengambilan blok\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nSaat pengindeks pertama kali mengindeks chain, mengambil blok tunggal akan menurunkan kinerja secara signifikan. Meningkatkan ukuran batch untuk menyesuaikan jumlah blok yang diambil akan mengurangi waktu pemrosesan secara keseluruhan. Ukuran batch default saat ini adalah 100.\n\n# Mode lokal\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nUntuk tujuan debugging, pengguna dapat menjalankan node dalam mode lokal. Beralih ke model lokal akan membuat tabel Postgres dalam skema publik default.\n\nJika mode lokal tidak digunakan, skema Postgres baru dengan subquery_ awal dan tabel proyek yang sesuai akan dibuat.\n\n\n# Menjalankan Layanan Kueri (subql/query)\n\n\n# Instalasi\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nHarap perhatikan bahwa kami TIDAK mendukung penggunaan yarn global karena manajemen ketergantungannya yang buruk yang dapat menyebabkan error di masa mendatang.\n\n\n# Menjalankan layanan Kueri\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nPastikan nama proyek sama dengan nama proyek saat Anda menginisialisasi proyek. Periksa juga variabel lingkungan sudah benar.\n\nSetelah menjalankan layanan subql-query dengan sukses, buka browser Anda dan buka http://localhost:3000. Anda akan melihat playground GraphQL muncul di Explorer dan skema yang siap untuk kueri.",normalizedContent:"# menjalankan subquery secara lokal\n\npanduan ini bekerja melalui cara menjalankan node subquery lokal pada infrastruktur anda, yang mencakup pengindeks dan layanan kueri. tidak ingin khawatir saat menjalankan infrastruktur subquery anda sendiri? subquery menyediakan layanan hosting yang terkelola kepada komunitas secara gratis. ikuti panduan penerbitan kami untuk melihat bagaimana anda dapat mengunggah proyek anda ke proyek subquery.\n\n\n# gunakan docker\n\nsolusi alternatif adalah menjalankan docker container, yang ditentukan oleh file docker-compose.yml. untuk proyek baru yang baru saja diinisialisasi, anda tidak perlu mengubah apa pun di sini.\n\ndi bawah direktori proyek jalankan perintah berikut:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nmungkin perlu beberapa saat untuk mengunduh paket yang diperlukan (@subql/node, @subql/query, dan postgres) untuk pertama kalinya, tetapi segera anda akan melihat node subkueri.\n\n\n# menjalankan pengindeks (subql/node)\n\npersyaratan:\n\n * postgres database (versi 12 atau lebih tinggi). ketika node subquery mengindeks blockchain, data yang diekstrak akan disimpan dalam instance database eksternal.\n\nnode subquery adalah implementasi yang mengekstrak data blockchain berbasis substrat per proyek subquery dan menyimpannya ke dalam database postgres.\n\n\n# instalasi\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nharap diperhatikan bahwa kami tidak mendukung penggunaan yarn global karena manajemen ketergantungannya yang buruk yang dapat menyebabkan error di masa mendatang.\n\nsetelah terinstal, anda dapat memulai node dengan perintah berikut:\n\nsubql-node <command>\n\n\n1\n\n\n\n# perintah utama\n\nperintah berikut akan membantu anda menyelesaikan konfigurasi node subquery dan memulai proses pengindeksan. untuk mengetahui lebih lanjut, anda dapat menjalankan perintah --help.\n\n# arahkan ke jalur proyek lokal\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# gunakan kamus\n\nmenggunakan kamus full chain dapat mempercepat pemrosesan proyek subquery selama pengujian atau selama indeks pertama anda secara drastis. dalam beberapa kasus, kami telah melihat peningkatan kinerja pengindeksan hingga 10x dibanding sebelumnya.\n\nkamus full chain dapat melakukan pra-indeks lokasi semua peristiwa dan ekstrinsik dalam chain tertentu dan memungkinkan layanan node anda untuk melompat ke lokasi yang relevan saat melakukan proses indeks daripada memeriksa setiap blok.\n\nanda dapat menambahkan titik akhir kamus di file project.yaml anda (lihat file manifes), atau tentukan saat dijalankan menggunakan perintah berikut:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# hubungkan ke database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\nbergantung pada konfigurasi database postgres anda (misalnya kata sandi database yang berbeda), harap pastikan juga bahwa pengindeks (subql/node) dan layanan kueri (subql/query) dapat membuat koneksi ke sana.\n\n# tentukan file konfigurasi\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nini akan mengarahkan node kueri ke file konfigurasi yang bisa dalam format yaml atau json. lihat contoh di bawah ini.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# ubah ukuran batch pengambilan blok\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nsaat pengindeks pertama kali mengindeks chain, mengambil blok tunggal akan menurunkan kinerja secara signifikan. meningkatkan ukuran batch untuk menyesuaikan jumlah blok yang diambil akan mengurangi waktu pemrosesan secara keseluruhan. ukuran batch default saat ini adalah 100.\n\n# mode lokal\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nuntuk tujuan debugging, pengguna dapat menjalankan node dalam mode lokal. beralih ke model lokal akan membuat tabel postgres dalam skema publik default.\n\njika mode lokal tidak digunakan, skema postgres baru dengan subquery_ awal dan tabel proyek yang sesuai akan dibuat.\n\n\n# menjalankan layanan kueri (subql/query)\n\n\n# instalasi\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nharap perhatikan bahwa kami tidak mendukung penggunaan yarn global karena manajemen ketergantungannya yang buruk yang dapat menyebabkan error di masa mendatang.\n\n\n# menjalankan layanan kueri\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\npastikan nama proyek sama dengan nama proyek saat anda menginisialisasi proyek. periksa juga variabel lingkungan sudah benar.\n\nsetelah menjalankan layanan subql-query dengan sukses, buka browser anda dan buka http://localhost:3000. anda akan melihat playground graphql muncul di explorer dan skema yang siap untuk kueri.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Sandbox",frontmatter:{summary:"Sandbox Dalam skenario penggunaan yang kami bayangkan, node SubQuery biasanya dijalankan oleh host tepercaya, dan kode proyek SubQuery yang dikirimkan oleh pengguna ke node yang ti",meta:[{property:"og:url",content:"/id/run/sandbox.html"},{property:"og:title",content:"Sandbox"},{property:"og:description",content:"Sandbox Dalam skenario penggunaan yang kami bayangkan, node SubQuery biasanya dijalankan oleh host tepercaya, dan kode proyek SubQuery yang dikirimkan oleh pengguna ke node yang ti"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/run/sandbox.html",relativePath:"id/run/sandbox.md",key:"v-ec4d1a0a",path:"/id/run/sandbox/",headers:[{level:2,title:"Larangan",slug:"larangan",normalizedTitle:"larangan",charIndex:831}],readingTime:{minutes:.57,words:170},headersStr:"Larangan",content:"# Sandbox\n\nDalam skenario penggunaan yang kami bayangkan, node SubQuery biasanya dijalankan oleh host tepercaya, dan kode proyek SubQuery yang dikirimkan oleh pengguna ke node yang tidak sepenuhnya dapat dipercaya.\n\nBeberapa kode berbahaya kemungkinan akan menyerang host atau bahkan membahayakannya, dan menyebabkan kerusakan pada data proyek lain di host yang sama. Oleh karena itu, kami menggunakan mekanisme keamanan sandbox VM2 untuk mengurangi risiko. Yaitu:\n\n * Menjalankan kode tidak tepercaya dengan aman dalam konteks yang terisolasi dan kode berbahaya tidak akan mengakses jaringan dan sistem file host kecuali melalui interface terbuka yang kami masukkan ke dalam sandbox.\n\n * Meminta metode dengan aman dan bertukar data dan panggilan balik antar sandbox.\n\n * Kebal terhadap banyak metode serangan yang diketahui.\n\n\n# Larangan\n\n * Untuk membatasi akses ke modul bawaan tertentu, hanya nyatakan, buffer, crypto,util dan jalur dimasukkan dalam whitelist.\n\n * Kami mendukung modul pihak ketiga yang ditulis di CommonJS dan hybrid library seperti @polkadot/* yang menggunakan ESM sebagai default.\n\n * Semua modul yang menggunakan HTTP dan WebSocket dilarang.",normalizedContent:"# sandbox\n\ndalam skenario penggunaan yang kami bayangkan, node subquery biasanya dijalankan oleh host tepercaya, dan kode proyek subquery yang dikirimkan oleh pengguna ke node yang tidak sepenuhnya dapat dipercaya.\n\nbeberapa kode berbahaya kemungkinan akan menyerang host atau bahkan membahayakannya, dan menyebabkan kerusakan pada data proyek lain di host yang sama. oleh karena itu, kami menggunakan mekanisme keamanan sandbox vm2 untuk mengurangi risiko. yaitu:\n\n * menjalankan kode tidak tepercaya dengan aman dalam konteks yang terisolasi dan kode berbahaya tidak akan mengakses jaringan dan sistem file host kecuali melalui interface terbuka yang kami masukkan ke dalam sandbox.\n\n * meminta metode dengan aman dan bertukar data dan panggilan balik antar sandbox.\n\n * kebal terhadap banyak metode serangan yang diketahui.\n\n\n# larangan\n\n * untuk membatasi akses ke modul bawaan tertentu, hanya nyatakan, buffer, crypto,util dan jalur dimasukkan dalam whitelist.\n\n * kami mendukung modul pihak ketiga yang ditulis di commonjs dan hybrid library seperti @polkadot/* yang menggunakan esm sebagai default.\n\n * semua modul yang menggunakan http dan websocket dilarang.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Bagaimana cara mengubah ukuran blockchain fetching batch?",frontmatter:{summary:"Bagaimana cara mengubah ukuran blockchain fetching batch? Panduan video Pengenalan Ukuran batch default adalah 100, tapi ini bisa diubah menggunakan perintah ekstra --batch-size=xx",meta:[{property:"og:url",content:"/id/tutorials_examples/batch-size.html"},{property:"og:title",content:"Bagaimana cara mengubah ukuran blockchain fetching batch?"},{property:"og:description",content:"Bagaimana cara mengubah ukuran blockchain fetching batch? Panduan video Pengenalan Ukuran batch default adalah 100, tapi ini bisa diubah menggunakan perintah ekstra --batch-size=xx"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/tutorials_examples/batch-size.html",relativePath:"id/tutorials_examples/batch-size.md",key:"v-b00c343e",path:"/id/tutorials_examples/batch-size/",headers:[{level:2,title:"Panduan video",slug:"panduan-video",normalizedTitle:"panduan video",charIndex:64},{level:2,title:"Pengenalan",slug:"pengenalan",normalizedTitle:"pengenalan",charIndex:82},{level:2,title:"Kenapa mengubah ukuran batch?",slug:"kenapa-mengubah-ukuran-batch",normalizedTitle:"kenapa mengubah ukuran batch?",charIndex:782}],readingTime:{minutes:.45,words:134},headersStr:"Panduan video Pengenalan Kenapa mengubah ukuran batch?",content:'# Bagaimana cara mengubah ukuran blockchain fetching batch?\n\n\n# Panduan video\n\n\n# Pengenalan\n\nUkuran batch default adalah 100, tapi ini bisa diubah menggunakan perintah ekstra --batch-size=xx.\n\nAnda perlu memasukkannya ke garis perintah sebagai extra flag atau jika menggunakan Docker, modifikasi file docker-compose.yml dengan:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nContoh ini mengatur ukuran batch (batch size) ke 50.\n\n\n# Kenapa mengubah ukuran batch?\n\nMenggunakan ukuran batch yang lebih kecil bisa mengurangi penggunaan memori dan tidak membuat pengguna menunggu untuk query yang besar. Dengan kata lain, aplikasi anda bisa jadi lebih responsif.',normalizedContent:'# bagaimana cara mengubah ukuran blockchain fetching batch?\n\n\n# panduan video\n\n\n# pengenalan\n\nukuran batch default adalah 100, tapi ini bisa diubah menggunakan perintah ekstra --batch-size=xx.\n\nanda perlu memasukkannya ke garis perintah sebagai extra flag atau jika menggunakan docker, modifikasi file docker-compose.yml dengan:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\ncontoh ini mengatur ukuran batch (batch size) ke 50.\n\n\n# kenapa mengubah ukuran batch?\n\nmenggunakan ukuran batch yang lebih kecil bisa mengurangi penggunaan memori dan tidak membuat pengguna menunggu untuk query yang besar. dengan kata lain, aplikasi anda bisa jadi lebih responsif.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Bagaimana cara mulai di tinggi block berbeda?",frontmatter:{summary:"Bagaimana cara mulai di tinggi block berbeda? Panduan video Pengenalan Secara otomatis, semua proyek starter memulai sinkronisasi blockchain dari block genesis. Dengan kata lain, d",meta:[{property:"og:url",content:"/id/tutorials_examples/block-height.html"},{property:"og:title",content:"Bagaimana cara mulai di tinggi block berbeda?"},{property:"og:description",content:"Bagaimana cara mulai di tinggi block berbeda? Panduan video Pengenalan Secara otomatis, semua proyek starter memulai sinkronisasi blockchain dari block genesis. Dengan kata lain, d"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/tutorials_examples/block-height.html",relativePath:"id/tutorials_examples/block-height.md",key:"v-9fcf860a",path:"/id/tutorials_examples/block-height/",headers:[{level:2,title:"Panduan video",slug:"panduan-video",normalizedTitle:"panduan video",charIndex:52},{level:2,title:"Pengenalan",slug:"pengenalan",normalizedTitle:"pengenalan",charIndex:70},{level:2,title:"Kenapa tidak mulai dari nol?",slug:"kenapa-tidak-mulai-dari-nol",normalizedTitle:"kenapa tidak mulai dari nol?",charIndex:992},{level:2,title:"Apa kekurangan tidak memulai dari nol?",slug:"apa-kekurangan-tidak-memulai-dari-nol",normalizedTitle:"apa kekurangan tidak memulai dari nol?",charIndex:1319},{level:2,title:"Bagaimana cara mengetahui tinggi blockchain saat ini?",slug:"bagaimana-cara-mengetahui-tinggi-blockchain-saat-ini",normalizedTitle:"bagaimana cara mengetahui tinggi blockchain saat ini?",charIndex:1486},{level:2,title:"Apa saya harus membangun ulang atau codegen?",slug:"apa-saya-harus-membangun-ulang-atau-codegen",normalizedTitle:"apa saya harus membangun ulang atau codegen?",charIndex:1674}],readingTime:{minutes:.88,words:263},headersStr:"Panduan video Pengenalan Kenapa tidak mulai dari nol? Apa kekurangan tidak memulai dari nol? Bagaimana cara mengetahui tinggi blockchain saat ini? Apa saya harus membangun ulang atau codegen?",content:'# Bagaimana cara mulai di tinggi block berbeda?\n\n\n# Panduan video\n\n\n# Pengenalan\n\nSecara otomatis, semua proyek starter memulai sinkronisasi blockchain dari block genesis. Dengan kata lain, dari block 1. Untuk blockchain besar, ini biasanya membutuhkan beberapa hari atau bahkan minggu untuk sepenuhnya sinkronisasi.\n\nUntuk mulai sinkronisasi node SubQuery dari tinggi bukan-nol, yang perlu dilakukan hanyalah memodifikasi file project.yaml dan mengubah kunci startBlock.\n\nBerikut adalah file project.yaml di mana block mulainya sudah diatur ke 1.000.000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Kenapa tidak mulai dari nol?\n\nAlasan utamanya adalah karena ini bisa mengurangi waktu sinkronisasi blockchain. Artinya jika anda hanya tertarik pada transaksi di 3 bulan terakhir, anda bisa hanya mengsinkronisasi hasil 3 bulan terakhir, dengan begitu mengurangi waktu menunggu dan anda bisa mulai pengembangan lebih cepat.\n\n\n# Apa kekurangan tidak memulai dari nol?\n\nKekurangan paling jelas adalah anda tidak akan bisa melakukan query data di blockchain untuk block yang tidak anda miliki.\n\n\n# Bagaimana cara mengetahui tinggi blockchain saat ini?\n\nJika menggunakan jaringan Polkadot, anda bisa mengunjungi https://polkascan.io/, pilih jaringannya, dan lihat "Finalised Block".\n\n\n# Apa saya harus membangun ulang atau codegen?\n\nTidak. Karena anda memodifikasi file project.yaml, yang merupakan file konfigurasi, anda tidak perlu membangun ulang atau menghasilkan lagi kode typescript-nya.',normalizedContent:'# bagaimana cara mulai di tinggi block berbeda?\n\n\n# panduan video\n\n\n# pengenalan\n\nsecara otomatis, semua proyek starter memulai sinkronisasi blockchain dari block genesis. dengan kata lain, dari block 1. untuk blockchain besar, ini biasanya membutuhkan beberapa hari atau bahkan minggu untuk sepenuhnya sinkronisasi.\n\nuntuk mulai sinkronisasi node subquery dari tinggi bukan-nol, yang perlu dilakukan hanyalah memodifikasi file project.yaml dan mengubah kunci startblock.\n\nberikut adalah file project.yaml di mana block mulainya sudah diatur ke 1.000.000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# kenapa tidak mulai dari nol?\n\nalasan utamanya adalah karena ini bisa mengurangi waktu sinkronisasi blockchain. artinya jika anda hanya tertarik pada transaksi di 3 bulan terakhir, anda bisa hanya mengsinkronisasi hasil 3 bulan terakhir, dengan begitu mengurangi waktu menunggu dan anda bisa mulai pengembangan lebih cepat.\n\n\n# apa kekurangan tidak memulai dari nol?\n\nkekurangan paling jelas adalah anda tidak akan bisa melakukan query data di blockchain untuk block yang tidak anda miliki.\n\n\n# bagaimana cara mengetahui tinggi blockchain saat ini?\n\njika menggunakan jaringan polkadot, anda bisa mengunjungi https://polkascan.io/, pilih jaringannya, dan lihat "finalised block".\n\n\n# apa saya harus membangun ulang atau codegen?\n\ntidak. karena anda memodifikasi file project.yaml, yang merupakan file konfigurasi, anda tidak perlu membangun ulang atau menghasilkan lagi kode typescript-nya.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Bagaimana cara men-debug proyek SubQuery?",frontmatter:{summary:"Bagaimana cara men-debug proyek SubQuery? Panduan Video Pengantar Untuk men-debug proyek SubQuery seperti menelusuri kode, menyetel titik henti sementara, dan memeriksa variabel, A",meta:[{property:"og:url",content:"/id/tutorials_examples/debug-projects.html"},{property:"og:title",content:"Bagaimana cara men-debug proyek SubQuery?"},{property:"og:description",content:"Bagaimana cara men-debug proyek SubQuery? Panduan Video Pengantar Untuk men-debug proyek SubQuery seperti menelusuri kode, menyetel titik henti sementara, dan memeriksa variabel, A"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/tutorials_examples/debug-projects.html",relativePath:"id/tutorials_examples/debug-projects.md",key:"v-0fc2023e",path:"/id/tutorials_examples/debug-projects/",headers:[{level:2,title:"Panduan Video",slug:"panduan-video",normalizedTitle:"panduan video",charIndex:48},{level:2,title:"Pengantar",slug:"pengantar",normalizedTitle:"pengantar",charIndex:66},{level:2,title:"Node Inspeksi",slug:"node-inspeksi",normalizedTitle:"node inspeksi",charIndex:280},{level:2,title:"Alat Pengembang Chrome",slug:"alat-pengembang-chrome",normalizedTitle:"alat pengembang chrome",charIndex:702}],readingTime:{minutes:.61,words:182},headersStr:"Panduan Video Pengantar Node Inspeksi Alat Pengembang Chrome",content:"# Bagaimana cara men-debug proyek SubQuery?\n\n\n# Panduan Video\n\n\n# Pengantar\n\nUntuk men-debug proyek SubQuery seperti menelusuri kode, menyetel titik henti sementara, dan memeriksa variabel, Anda harus menggunakan pemeriksa Node.js bersama dengan alat Pencarian Google Chrome.\n\n\n# Node Inspeksi\n\nJalankan perintah berikut di layar terminal.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nContoh:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nUntuk bantuan, klik link berikut: https://nodejs.org/en/docs/inspector\nDebugger Terpasang.\n\n\n1\n2\n3\n4\n\n\n\n# Alat Pengembang Chrome\n\nBuka alat pengembang Chrome dan arahkan ke tab Sumber. Perhatikan bahwa mengklik ikon hijau akan membuka jendela baru.\n\n\n\nArahkan ke Filesystem dan tambahkan folder proyek Anda ke ruang kerja. Kemudian buka folder dist > mappings dan pilih kode yang ingin Anda debug. Kemudian ikuti kode seperti halnya alat debugging standar.\n\n",normalizedContent:"# bagaimana cara men-debug proyek subquery?\n\n\n# panduan video\n\n\n# pengantar\n\nuntuk men-debug proyek subquery seperti menelusuri kode, menyetel titik henti sementara, dan memeriksa variabel, anda harus menggunakan pemeriksa node.js bersama dengan alat pencarian google chrome.\n\n\n# node inspeksi\n\njalankan perintah berikut di layar terminal.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\ncontoh:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nuntuk bantuan, klik link berikut: https://nodejs.org/en/docs/inspector\ndebugger terpasang.\n\n\n1\n2\n3\n4\n\n\n\n# alat pengembang chrome\n\nbuka alat pengembang chrome dan arahkan ke tab sumber. perhatikan bahwa mengklik ikon hijau akan membuka jendela baru.\n\n\n\narahkan ke filesystem dan tambahkan folder proyek anda ke ruang kerja. kemudian buka folder dist > mappings dan pilih kode yang ingin anda debug. kemudian ikuti kode seperti halnya alat debugging standar.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Bagaimana cara kerja kamus SubQuery?",frontmatter:{summary:"Bagaimana cara kerja kamus SubQuery? Seluruh ide dari proyek kamus generik adalah untuk mengindeks semua data dari blockchain dan merekam peristiwa, ekstrinsik, dan jenisnya (modul",meta:[{property:"og:url",content:"/id/tutorials_examples/dictionary.html"},{property:"og:title",content:"Bagaimana cara kerja kamus SubQuery?"},{property:"og:description",content:"Bagaimana cara kerja kamus SubQuery? Seluruh ide dari proyek kamus generik adalah untuk mengindeks semua data dari blockchain dan merekam peristiwa, ekstrinsik, dan jenisnya (modul"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/tutorials_examples/dictionary.html",relativePath:"id/tutorials_examples/dictionary.md",key:"v-f91bb4c6",path:"/id/tutorials_examples/dictionary/",headers:[{level:2,title:"Bagaimana cara memasukkan kamus ke dalam proyek Anda?",slug:"bagaimana-cara-memasukkan-kamus-ke-dalam-proyek-anda",normalizedTitle:"bagaimana cara memasukkan kamus ke dalam proyek anda?",charIndex:1032},{level:2,title:"Apa yang terjadi jika kamus TIDAK digunakan?",slug:"apa-yang-terjadi-jika-kamus-tidak-digunakan",normalizedTitle:"apa yang terjadi jika kamus tidak digunakan?",charIndex:1352},{level:2,title:"Apa yang terjadi ketika kamus IS digunakan?",slug:"apa-yang-terjadi-ketika-kamus-is-digunakan",normalizedTitle:"apa yang terjadi ketika kamus is digunakan?",charIndex:1796},{level:2,title:"Kapan kamus TIDAK berguna?",slug:"kapan-kamus-tidak-berguna",normalizedTitle:"kapan kamus tidak berguna?",charIndex:2955}],readingTime:{minutes:1.69,words:506},headersStr:"Bagaimana cara memasukkan kamus ke dalam proyek Anda? Apa yang terjadi jika kamus TIDAK digunakan? Apa yang terjadi ketika kamus IS digunakan? Kapan kamus TIDAK berguna?",content:'# Bagaimana cara kerja kamus SubQuery?\n\nSeluruh ide dari proyek kamus generik adalah untuk mengindeks semua data dari blockchain dan merekam peristiwa, ekstrinsik, dan jenisnya (modul dan metode) dalam database dalam urutan tinggi blok. Proyek lain kemudian dapat menanyakan titik akhir network.dictionary ini alih-alih network.dictionary default yang ditentukan dalam file manifes.\n\nTitik akhir network.dictionary adalah parameter opsional yang jika ada, SDK akan secara otomatis mendeteksi dan menggunakannya. network.endpoint adalah wajib dan tidak akan dikompilasi jika tidak ada.\n\nMengambil proyek kamus SubQuery sebagai contoh, file skema mendefinisikan 3 entitas; ekstrinsik, peristiwa, specVersion. 3 entitas ini masing-masing berisi 6, 4, dan 2 bidang. Ketika proyek ini dijalankan, bidang ini tercermin dalam tabel database.\n\n\n\nData dari blockchain kemudian disimpan dalam tabel ini dan diindeks untuk kinerja. Proyek kemudian di-host di Proyek SubQuery dan titik akhir API tersedia untuk ditambahkan ke file manifes.\n\n\n# Bagaimana cara memasukkan kamus ke dalam proyek Anda?\n\nTambah kamus: https://api.subquery.network/sq/subquery/dictionary-polkadot ke bagian jaringan manifes. Misalnya:\n\njaringan:\n  titik akhir: wss://polkadot.api.onfinality.io/public-ws\n  kamus: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# Apa yang terjadi jika kamus TIDAK digunakan?\n\nKetika kamus TIDAK digunakan, pengindeks akan mengambil setiap blok data melalui api polkadot sesuai dengan ukuran batch bendera yang 100 secara default, dan menempatkan ini dalam buffer untuk diproses. Kemudian, pengindeks mengambil semua blok ini dari buffer dan saat memproses data blok, memeriksa apakah peristiwa dan ekstrinsik dalam blok ini cocok dengan filter yang ditentukan pengguna.\n\n\n# Apa yang terjadi ketika kamus IS digunakan?\n\nKetika kamus IS digunakan, pengindeks pertama-tama akan mengambil panggilan dan filter peristiwa sebagai parameter dan menggabungkannya ke dalam kueri GraphQL. Kemudian menggunakan API kamus untuk mendapatkan daftar ketinggian blok yang relevan saja yang berisi peristiwa dan ekstrinsik tertentu. Seringkali ini secara substansial kurang dari 100 jika default digunakan.\n\nMisalnya, bayangkan situasi di mana Anda mengindeks peristiwa transfer. Tidak semua blok memiliki event ini (pada gambar di bawah tidak ada event transfer di blok 3 dan 4).\n\n\n\nKamus memungkinkan proyek Anda untuk melewati ini jadi daripada mencari di setiap blok untuk acara transfer, itu melompat ke hanya blok 1, 2, dan 5. Ini karena kamus adalah referensi pra-komputasi untuk semua panggilan dan acara di masing-masing memblokir.\n\nIni berarti bahwa menggunakan kamus dapat mengurangi jumlah data yang diperoleh pengindeks dari rantai dan mengurangi jumlah blok "yang tidak diinginkan" yang disimpan di buffer lokal. Tetapi dibandingkan dengan metode tradisional, ini menambahkan langkah tambahan untuk mendapatkan data dari API kamus.\n\n\n# Kapan kamus TIDAK berguna?\n\nKetika penangan blok digunakan untuk mengambil data dari rantai, setiap blok perlu diproses. Oleh karena itu, menggunakan kamus dalam hal ini tidak memberikan keuntungan apa pun dan pengindeks akan secara otomatis beralih ke pendekatan non-kamus default.\n\nJuga, ketika berhadapan dengan peristiwa atau ekstrinsik yang terjadi atau ada di setiap blok seperti timestamp.set, menggunakan kamus tidak akan menawarkan keuntungan tambahan.',normalizedContent:'# bagaimana cara kerja kamus subquery?\n\nseluruh ide dari proyek kamus generik adalah untuk mengindeks semua data dari blockchain dan merekam peristiwa, ekstrinsik, dan jenisnya (modul dan metode) dalam database dalam urutan tinggi blok. proyek lain kemudian dapat menanyakan titik akhir network.dictionary ini alih-alih network.dictionary default yang ditentukan dalam file manifes.\n\ntitik akhir network.dictionary adalah parameter opsional yang jika ada, sdk akan secara otomatis mendeteksi dan menggunakannya. network.endpoint adalah wajib dan tidak akan dikompilasi jika tidak ada.\n\nmengambil proyek kamus subquery sebagai contoh, file skema mendefinisikan 3 entitas; ekstrinsik, peristiwa, specversion. 3 entitas ini masing-masing berisi 6, 4, dan 2 bidang. ketika proyek ini dijalankan, bidang ini tercermin dalam tabel database.\n\n\n\ndata dari blockchain kemudian disimpan dalam tabel ini dan diindeks untuk kinerja. proyek kemudian di-host di proyek subquery dan titik akhir api tersedia untuk ditambahkan ke file manifes.\n\n\n# bagaimana cara memasukkan kamus ke dalam proyek anda?\n\ntambah kamus: https://api.subquery.network/sq/subquery/dictionary-polkadot ke bagian jaringan manifes. misalnya:\n\njaringan:\n  titik akhir: wss://polkadot.api.onfinality.io/public-ws\n  kamus: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# apa yang terjadi jika kamus tidak digunakan?\n\nketika kamus tidak digunakan, pengindeks akan mengambil setiap blok data melalui api polkadot sesuai dengan ukuran batch bendera yang 100 secara default, dan menempatkan ini dalam buffer untuk diproses. kemudian, pengindeks mengambil semua blok ini dari buffer dan saat memproses data blok, memeriksa apakah peristiwa dan ekstrinsik dalam blok ini cocok dengan filter yang ditentukan pengguna.\n\n\n# apa yang terjadi ketika kamus is digunakan?\n\nketika kamus is digunakan, pengindeks pertama-tama akan mengambil panggilan dan filter peristiwa sebagai parameter dan menggabungkannya ke dalam kueri graphql. kemudian menggunakan api kamus untuk mendapatkan daftar ketinggian blok yang relevan saja yang berisi peristiwa dan ekstrinsik tertentu. seringkali ini secara substansial kurang dari 100 jika default digunakan.\n\nmisalnya, bayangkan situasi di mana anda mengindeks peristiwa transfer. tidak semua blok memiliki event ini (pada gambar di bawah tidak ada event transfer di blok 3 dan 4).\n\n\n\nkamus memungkinkan proyek anda untuk melewati ini jadi daripada mencari di setiap blok untuk acara transfer, itu melompat ke hanya blok 1, 2, dan 5. ini karena kamus adalah referensi pra-komputasi untuk semua panggilan dan acara di masing-masing memblokir.\n\nini berarti bahwa menggunakan kamus dapat mengurangi jumlah data yang diperoleh pengindeks dari rantai dan mengurangi jumlah blok "yang tidak diinginkan" yang disimpan di buffer lokal. tetapi dibandingkan dengan metode tradisional, ini menambahkan langkah tambahan untuk mendapatkan data dari api kamus.\n\n\n# kapan kamus tidak berguna?\n\nketika penangan blok digunakan untuk mengambil data dari rantai, setiap blok perlu diproses. oleh karena itu, menggunakan kamus dalam hal ini tidak memberikan keuntungan apa pun dan pengindeks akan secara otomatis beralih ke pendekatan non-kamus default.\n\njuga, ketika berhadapan dengan peristiwa atau ekstrinsik yang terjadi atau ada di setiap blok seperti timestamp.set, menggunakan kamus tidak akan menawarkan keuntungan tambahan.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorial",frontmatter:{summary:"Tutorial Bagaimana cara mulai di tinggi block berbeda? Panduan video Pengenalan Secara otomatis, semua proyek starter memulai sinkronisasi blockchain dari block genesis. Dengan kat",meta:[{property:"og:url",content:"/id/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorial"},{property:"og:description",content:"Tutorial Bagaimana cara mulai di tinggi block berbeda? Panduan video Pengenalan Secara otomatis, semua proyek starter memulai sinkronisasi blockchain dari block genesis. Dengan kat"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/tutorials_examples/howto.html",relativePath:"id/tutorials_examples/howto.md",key:"v-7c9e504d",path:"/id/tutorials_examples/howto/",headers:[{level:2,title:"Bagaimana cara mulai di tinggi block berbeda?",slug:"bagaimana-cara-mulai-di-tinggi-block-berbeda",normalizedTitle:"bagaimana cara mulai di tinggi block berbeda?",charIndex:15},{level:3,title:"Panduan video",slug:"panduan-video",normalizedTitle:"panduan video",charIndex:65},{level:3,title:"Pengenalan",slug:"pengenalan",normalizedTitle:"pengenalan",charIndex:83},{level:3,title:"Kenapa tidak mulai dari nol?",slug:"kenapa-tidak-mulai-dari-nol",normalizedTitle:"kenapa tidak mulai dari nol?",charIndex:1005},{level:3,title:"Apa kekurangan tidak memulai dari nol?",slug:"apa-kekurangan-tidak-memulai-dari-nol",normalizedTitle:"apa kekurangan tidak memulai dari nol?",charIndex:1332},{level:3,title:"Bagaimana cara mengetahui tinggi blockchain saat ini?",slug:"bagaimana-cara-mengetahui-tinggi-blockchain-saat-ini",normalizedTitle:"bagaimana cara mengetahui tinggi blockchain saat ini?",charIndex:1499},{level:3,title:"Apa saya harus membangun ulang atau codegen?",slug:"apa-saya-harus-membangun-ulang-atau-codegen",normalizedTitle:"apa saya harus membangun ulang atau codegen?",charIndex:1687},{level:2,title:"Bagaimana cara mengubah ukuran blockchain fetching batch?",slug:"bagaimana-cara-mengubah-ukuran-blockchain-fetching-batch",normalizedTitle:"bagaimana cara mengubah ukuran blockchain fetching batch?",charIndex:1898},{level:3,title:"Panduan video",slug:"panduan-video-2",normalizedTitle:"panduan video",charIndex:65},{level:3,title:"Pengenalan",slug:"pengenalan-2",normalizedTitle:"pengenalan",charIndex:83},{level:3,title:"Kenapa mengubah ukuran batch?",slug:"kenapa-mengubah-ukuran-batch",normalizedTitle:"kenapa mengubah ukuran batch?",charIndex:2678}],readingTime:{minutes:1.43,words:430},headersStr:"Bagaimana cara mulai di tinggi block berbeda? Panduan video Pengenalan Kenapa tidak mulai dari nol? Apa kekurangan tidak memulai dari nol? Bagaimana cara mengetahui tinggi blockchain saat ini? Apa saya harus membangun ulang atau codegen? Bagaimana cara mengubah ukuran blockchain fetching batch? Panduan video Pengenalan Kenapa mengubah ukuran batch?",content:'# Tutorial\n\n\n# Bagaimana cara mulai di tinggi block berbeda?\n\n\n# Panduan video\n\n\n# Pengenalan\n\nSecara otomatis, semua proyek starter memulai sinkronisasi blockchain dari block genesis. Dengan kata lain, dari block 1. Untuk blockchain besar, ini biasanya membutuhkan beberapa hari atau bahkan minggu untuk sepenuhnya sinkronisasi.\n\nUntuk mulai sinkronisasi node SubQuery dari tinggi bukan-nol, yang perlu dilakukan hanyalah memodifikasi file project.yaml dan mengubah kunci startBlock.\n\nBerikut adalah file project.yaml di mana block mulainya sudah diatur ke 1.000.000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Kenapa tidak mulai dari nol?\n\nAlasan utamanya adalah karena ini bisa mengurangi waktu sinkronisasi blockchain. Artinya jika anda hanya tertarik pada transaksi di 3 bulan terakhir, anda bisa hanya mengsinkronisasi hasil 3 bulan terakhir, dengan begitu mengurangi waktu menunggu dan anda bisa mulai pengembangan lebih cepat.\n\n\n# Apa kekurangan tidak memulai dari nol?\n\nKekurangan paling jelas adalah anda tidak akan bisa melakukan query data di blockchain untuk block yang tidak anda miliki.\n\n\n# Bagaimana cara mengetahui tinggi blockchain saat ini?\n\nJika menggunakan jaringan Polkadot, anda bisa mengunjungi https://polkascan.io/, pilih jaringannya, dan lihat "Finalised Block".\n\n\n# Apa saya harus membangun ulang atau codegen?\n\nTidak. Karena anda memodifikasi file project.yaml, yang merupakan file konfigurasi, anda tidak perlu membangun ulang atau menghasilkan lagi kode typescript-nya.\n\n\n# Bagaimana cara mengubah ukuran blockchain fetching batch?\n\n\n# Panduan video\n\n\n# Pengenalan\n\nUkuran batch default adalah 100, tapi ini bisa diubah menggunakan perintah ekstra --batch-size=xx.\n\nAnda perlu memasukkannya ke garis perintah sebagai extra flag atau jika menggunakan Docker, modifikasi file docker-compose.yml dengan:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nContoh ini mengatur ukuran batch (batch size) ke 50.\n\n\n# Kenapa mengubah ukuran batch?\n\nMenggunakan ukuran batch yang lebih kecil bisa mengurangi penggunaan memori dan tidak membuat pengguna menunggu untuk query yang besar. Dengan kata lain, aplikasi anda bisa jadi lebih responsif. Namun, akan ada lebih banyak panggilan API yang dilakukan jadi jika anda dikenakan biaya dengan basis I/O atau jika anda memiliki batasan API di chain anda, ini bisa menjadi sebuah kekurangan.',normalizedContent:'# tutorial\n\n\n# bagaimana cara mulai di tinggi block berbeda?\n\n\n# panduan video\n\n\n# pengenalan\n\nsecara otomatis, semua proyek starter memulai sinkronisasi blockchain dari block genesis. dengan kata lain, dari block 1. untuk blockchain besar, ini biasanya membutuhkan beberapa hari atau bahkan minggu untuk sepenuhnya sinkronisasi.\n\nuntuk mulai sinkronisasi node subquery dari tinggi bukan-nol, yang perlu dilakukan hanyalah memodifikasi file project.yaml dan mengubah kunci startblock.\n\nberikut adalah file project.yaml di mana block mulainya sudah diatur ke 1.000.000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# kenapa tidak mulai dari nol?\n\nalasan utamanya adalah karena ini bisa mengurangi waktu sinkronisasi blockchain. artinya jika anda hanya tertarik pada transaksi di 3 bulan terakhir, anda bisa hanya mengsinkronisasi hasil 3 bulan terakhir, dengan begitu mengurangi waktu menunggu dan anda bisa mulai pengembangan lebih cepat.\n\n\n# apa kekurangan tidak memulai dari nol?\n\nkekurangan paling jelas adalah anda tidak akan bisa melakukan query data di blockchain untuk block yang tidak anda miliki.\n\n\n# bagaimana cara mengetahui tinggi blockchain saat ini?\n\njika menggunakan jaringan polkadot, anda bisa mengunjungi https://polkascan.io/, pilih jaringannya, dan lihat "finalised block".\n\n\n# apa saya harus membangun ulang atau codegen?\n\ntidak. karena anda memodifikasi file project.yaml, yang merupakan file konfigurasi, anda tidak perlu membangun ulang atau menghasilkan lagi kode typescript-nya.\n\n\n# bagaimana cara mengubah ukuran blockchain fetching batch?\n\n\n# panduan video\n\n\n# pengenalan\n\nukuran batch default adalah 100, tapi ini bisa diubah menggunakan perintah ekstra --batch-size=xx.\n\nanda perlu memasukkannya ke garis perintah sebagai extra flag atau jika menggunakan docker, modifikasi file docker-compose.yml dengan:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\ncontoh ini mengatur ukuran batch (batch size) ke 50.\n\n\n# kenapa mengubah ukuran batch?\n\nmenggunakan ukuran batch yang lebih kecil bisa mengurangi penggunaan memori dan tidak membuat pengguna menunggu untuk query yang besar. dengan kata lain, aplikasi anda bisa jadi lebih responsif. namun, akan ada lebih banyak panggilan api yang dilakukan jadi jika anda dikenakan biaya dengan basis i/o atau jika anda memiliki batasan api di chain anda, ini bisa menjadi sebuah kekurangan.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorial & Contoh",frontmatter:{summary:"Tutorial & Contoh Di sini kami akan memberikan daftar tutorial dan menunjukkan berbagai contoh untuk membantu anda memulai secara cepat dan mudah. Contoh SubQuery Contoh Deskripsi ",meta:[{property:"og:url",content:"/id/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorial & Contoh"},{property:"og:description",content:"Tutorial & Contoh Di sini kami akan memberikan daftar tutorial dan menunjukkan berbagai contoh untuk membantu anda memulai secara cepat dan mudah. Contoh SubQuery Contoh Deskripsi "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/tutorials_examples/introduction.html",relativePath:"id/tutorials_examples/introduction.md",key:"v-98d0e0d6",path:"/id/tutorials_examples/introduction/",headers:[{level:2,title:"Contoh SubQuery",slug:"contoh-subquery",normalizedTitle:"contoh subquery",charIndex:154}],readingTime:{minutes:.73,words:220},headersStr:"Contoh SubQuery",content:"# Tutorial & Contoh\n\nDi sini kami akan memberikan daftar tutorial dan menunjukkan berbagai contoh untuk membantu anda memulai secara cepat dan mudah.\n\n\n# Contoh SubQuery\n\nCONTOH                      DESKRIPSI                                                    TOPIK\nextrinsic-finalized-block   Mengindeks ekstrinsik sehingga itu bisa di-query dengan      Contoh paling simpel dengan fungsi block handler\n                            hash-nya\nblock-timestamp             Mengindeks catatan waktu untuk setiap block yang selesai     Fungsi call handler sederhana\nvalidator-threshold         Mengindeks jumlah staking (jaminan) minimum agar validator   Fungsi block handler lebih rumit yang membuat external calls\n                            dapat dipilih.                                               ke @polkadot/api untuk data on-chain tambahan\nsum-reward                  Mengindeks staking bond, hadiah, dan slash dari terjadinya   event handlers lebih rumit dengan hubungan one-to-many\n                            block yang selesai\nentity-relation             Mengindeks transfer saldo antara akun, juga mengindeks       Hubungan One-to-many dan many-to-many dan extrinsic handling\n                            utilitas batchAll untuk mencari tahu isi dari panggilan      yang rumit\n                            ekstrinsik (extrinsic calls)\nkitty                       Mengindeks info kelahiran Kitty.                             call handlers kompleks dan event handlers, dengan data\n                                                                                         diindeks dari custom chain",normalizedContent:"# tutorial & contoh\n\ndi sini kami akan memberikan daftar tutorial dan menunjukkan berbagai contoh untuk membantu anda memulai secara cepat dan mudah.\n\n\n# contoh subquery\n\ncontoh                      deskripsi                                                    topik\nextrinsic-finalized-block   mengindeks ekstrinsik sehingga itu bisa di-query dengan      contoh paling simpel dengan fungsi block handler\n                            hash-nya\nblock-timestamp             mengindeks catatan waktu untuk setiap block yang selesai     fungsi call handler sederhana\nvalidator-threshold         mengindeks jumlah staking (jaminan) minimum agar validator   fungsi block handler lebih rumit yang membuat external calls\n                            dapat dipilih.                                               ke @polkadot/api untuk data on-chain tambahan\nsum-reward                  mengindeks staking bond, hadiah, dan slash dari terjadinya   event handlers lebih rumit dengan hubungan one-to-many\n                            block yang selesai\nentity-relation             mengindeks transfer saldo antara akun, juga mengindeks       hubungan one-to-many dan many-to-many dan extrinsic handling\n                            utilitas batchall untuk mencari tahu isi dari panggilan      yang rumit\n                            ekstrinsik (extrinsic calls)\nkitty                       mengindeks info kelahiran kitty.                             call handlers kompleks dan event handlers, dengan data\n                                                                                         diindeks dari custom chain",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Bagaimana cara menjalankan node pengindeks?",frontmatter:{summary:"Bagaimana cara menjalankan node pengindeks? Video Pengantar Pengantar Menjalankan node pengindeks adalah opsi lain selain menggunakan Docker atau memiliki proyek yang dihosting unt",meta:[{property:"og:url",content:"/id/tutorials_examples/run-indexer.html"},{property:"og:title",content:"Bagaimana cara menjalankan node pengindeks?"},{property:"og:description",content:"Bagaimana cara menjalankan node pengindeks? Video Pengantar Pengantar Menjalankan node pengindeks adalah opsi lain selain menggunakan Docker atau memiliki proyek yang dihosting unt"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/tutorials_examples/run-indexer.html",relativePath:"id/tutorials_examples/run-indexer.md",key:"v-23ca544d",path:"/id/tutorials_examples/run-indexer/",headers:[{level:2,title:"Video Pengantar",slug:"video-pengantar",normalizedTitle:"video pengantar",charIndex:50},{level:2,title:"Pengantar",slug:"pengantar",normalizedTitle:"pengantar",charIndex:56},{level:2,title:"Postgres",slug:"postgres",normalizedTitle:"postgres",charIndex:363},{level:2,title:"Install subql/node",slug:"install-subql-node",normalizedTitle:"install subql/node",charIndex:562},{level:2,title:"Mengatur konfigurasi DB",slug:"mengatur-konfigurasi-db",normalizedTitle:"mengatur konfigurasi db",charIndex:903},{level:2,title:"Mengindeks proyek",slug:"mengindeks-proyek",normalizedTitle:"mengindeks proyek",charIndex:1477},{level:2,title:"Memeriksa Postgres",slug:"memeriksa-postgres",normalizedTitle:"memeriksa postgres",charIndex:1781}],readingTime:{minutes:1.04,words:312},headersStr:"Video Pengantar Pengantar Postgres Install subql/node Mengatur konfigurasi DB Mengindeks proyek Memeriksa Postgres",content:'# Bagaimana cara menjalankan node pengindeks?\n\n\n# Video Pengantar\n\n\n# Pengantar\n\nMenjalankan node pengindeks adalah opsi lain selain menggunakan Docker atau memiliki proyek yang dihosting untuk Anda di SubQuery Projects. Ini membutuhkan lebih banyak waktu dan usaha tetapi akan meningkatkan pemahaman Anda tentang bagaimana SubQuery bekerja di bawah selimut.\n\n\n# Postgres\n\nMenjalankan node pengindeks pada infrastruktur Anda akan memerlukan pengaturan database Postgres. Anda dapat menginstal Postgres dari sini dan memastikan versinya 12 atau lebih tinggi.\n\n\n# Install subql/node\n\nKemudian untuk menjalankan node SubQuery, jalankan perintah berikut:\n\nnpm install -g @subql/node\n\n\n1\n\n\nFlag-g berarti menginstalnya secara global yang berarti di OSX, lokasinya adalah /usr/local/lib/node_modules.\n\nSetelah diinstal, Anda dapat memeriksa versi dengan menjalankan:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# Mengatur konfigurasi DB\n\nSelanjutnya, Anda perlu mengatur variabel lingkungan berikut:\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\n\n\n1\n2\n3\n4\n5\n\n\nTentu saja, jika Anda memiliki nilai yang berbeda untuk kunci di atas, harap sesuaikan. Perhatikan bahwa perintah env akan menampilkan variabel lingkungan saat ini dan proses ini hanya menetapkan nilai-nilai ini untuk sementara. Artinya, mereka hanya berlaku selama sesi terminal. Untuk mengaturnya secara permanen, simpan di ~/bash_profile Anda.\n\n\n# Mengindeks proyek\n\nUntuk mulai mengindeks proyek, navigasikan ke folder proyek Anda dan jalankan perintah berikut:\n\nsubql-node -f .\n\n\n1\n\n\nJika Anda tidak memiliki proyek, git clone https://github.com/subquery/subql-helloworld. Anda akan melihat node pengindeks mulai aktif dan mulai mengindeks blok.\n\n\n# Memeriksa Postgres\n\nJika Anda menavigasi ke Postgres, Anda akan melihat dua tabel dibuat. public.subqueries dan subquery_1.starter_entities.\n\npublic.subqueries hanya berisi 1 baris yang diperiksa oleh pengindeks saat memulai untuk "memahami keadaan saat ini" sehingga ia tahu dari mana harus melanjutkan. Abel starter_entities berisi indeks. Untuk melihat data, jalankan select (*) from subquery_1.starter_entities.',normalizedContent:'# bagaimana cara menjalankan node pengindeks?\n\n\n# video pengantar\n\n\n# pengantar\n\nmenjalankan node pengindeks adalah opsi lain selain menggunakan docker atau memiliki proyek yang dihosting untuk anda di subquery projects. ini membutuhkan lebih banyak waktu dan usaha tetapi akan meningkatkan pemahaman anda tentang bagaimana subquery bekerja di bawah selimut.\n\n\n# postgres\n\nmenjalankan node pengindeks pada infrastruktur anda akan memerlukan pengaturan database postgres. anda dapat menginstal postgres dari sini dan memastikan versinya 12 atau lebih tinggi.\n\n\n# install subql/node\n\nkemudian untuk menjalankan node subquery, jalankan perintah berikut:\n\nnpm install -g @subql/node\n\n\n1\n\n\nflag-g berarti menginstalnya secara global yang berarti di osx, lokasinya adalah /usr/local/lib/node_modules.\n\nsetelah diinstal, anda dapat memeriksa versi dengan menjalankan:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# mengatur konfigurasi db\n\nselanjutnya, anda perlu mengatur variabel lingkungan berikut:\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\n\n\n1\n2\n3\n4\n5\n\n\ntentu saja, jika anda memiliki nilai yang berbeda untuk kunci di atas, harap sesuaikan. perhatikan bahwa perintah env akan menampilkan variabel lingkungan saat ini dan proses ini hanya menetapkan nilai-nilai ini untuk sementara. artinya, mereka hanya berlaku selama sesi terminal. untuk mengaturnya secara permanen, simpan di ~/bash_profile anda.\n\n\n# mengindeks proyek\n\nuntuk mulai mengindeks proyek, navigasikan ke folder proyek anda dan jalankan perintah berikut:\n\nsubql-node -f .\n\n\n1\n\n\njika anda tidak memiliki proyek, git clone https://github.com/subquery/subql-helloworld. anda akan melihat node pengindeks mulai aktif dan mulai mengindeks blok.\n\n\n# memeriksa postgres\n\njika anda menavigasi ke postgres, anda akan melihat dua tabel dibuat. public.subqueries dan subquery_1.starter_entities.\n\npublic.subqueries hanya berisi 1 baris yang diperiksa oleh pengindeks saat memulai untuk "memahami keadaan saat ini" sehingga ia tahu dari mana harus melanjutkan. abel starter_entities berisi indeks. untuk melihat data, jalankan select (*) from subquery_1.starter_entities.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Terminologi",frontmatter:{summary:"Terminologi SubQuery Project (tempat sihirnya terjadi): Sebuah definisi (@subql/cli) tentang bagaimana SubQuery Node perlu melintasi dan menyatukan jaringan proyek dan bagaimana da",meta:[{property:"og:url",content:"/id/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminologi"},{property:"og:description",content:"Terminologi SubQuery Project (tempat sihirnya terjadi): Sebuah definisi (@subql/cli) tentang bagaimana SubQuery Node perlu melintasi dan menyatukan jaringan proyek dan bagaimana da"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/id/tutorials_examples/terminology.html",relativePath:"id/tutorials_examples/terminology.md",key:"v-0765aae6",path:"/id/tutorials_examples/terminology/",headers:[{level:2,title:"Terminologi",slug:"terminologi",normalizedTitle:"terminologi",charIndex:2}],readingTime:{minutes:.46,words:137},headersStr:"Terminologi",content:"# Terminologi\n\n * SubQuery Project (tempat sihirnya terjadi): Sebuah definisi (@subql/cli) tentang bagaimana SubQuery Node perlu melintasi dan menyatukan jaringan proyek dan bagaimana datanya ditransformasi dan disimpan untuk menghasilkan query GraphQL yang berguna\n * SubQuery Node (tempat kerjanya dilakukan): Sebuah paket (@subql/node) yang akan menerima definisi proyek SubQuery, dan menjalankan node yang secara konstan mengindeks jaringan yang terhubung ke basis data\n * SubQuery Query Service (tempat kami mendapatkan datanya): Sebuah paket (@subql/query) yang berinteraksi dengan GraphQL API dari node SubQuery yang dikeluarkan untuk melakukan query dan melihat data yang sudah diindeks\n * GraphQL (bagaimana kami melakukan query data): Bahasa Query untuk API yang secara khusus diperuntukkan data berbasis grafik yang fleksibel - lihat graphql.org",normalizedContent:"# terminologi\n\n * subquery project (tempat sihirnya terjadi): sebuah definisi (@subql/cli) tentang bagaimana subquery node perlu melintasi dan menyatukan jaringan proyek dan bagaimana datanya ditransformasi dan disimpan untuk menghasilkan query graphql yang berguna\n * subquery node (tempat kerjanya dilakukan): sebuah paket (@subql/node) yang akan menerima definisi proyek subquery, dan menjalankan node yang secara konstan mengindeks jaringan yang terhubung ke basis data\n * subquery query service (tempat kami mendapatkan datanya): sebuah paket (@subql/query) yang berinteraksi dengan graphql api dari node subquery yang dikeluarkan untuk melakukan query dan melihat data yang sudah diindeks\n * graphql (bagaimana kami melakukan query data): bahasa query untuk api yang secara khusus diperuntukkan data berbasis grafik yang fleksibel - lihat graphql.org",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/cli tool is used to create SubQuery projects. The @subql/node component is re",meta:[{property:"og:url",content:"/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/cli tool is used to create SubQuery projects. The @subql/node component is re"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/install/install.html",relativePath:"install/install.md",key:"v-2680104d",path:"/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:271},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:636},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1237}],readingTime:{minutes:1.22,words:367},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/cli tool is used to create SubQuery projects. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli tool helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\nyarn global add @subql/cli\n\n\n1\n\n\nnpm install -g @subql/cli\n\n\n1\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\nyarn global add @subql/node\n\n\n1\n\n\nnpm install -g @subql/node\n\n\n1\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\nyarn global add @subql/query\n\n\n1\n\n\nnpm install -g @subql/query\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/cli tool is used to create subquery projects. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli tool helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\nyarn global add @subql/cli\n\n\n1\n\n\nnpm install -g @subql/cli\n\n\n1\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\nyarn global add @subql/node\n\n\n1\n\n\nnpm install -g @subql/node\n\n\n1\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\nyarn global add @subql/query\n\n\n1\n\n\nnpm install -g @subql/query\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{frontmatter:{summary:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello",meta:[{property:"og:url",content:"/it/"},{property:"og:description",content:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/",relativePath:"it/README.md",key:"v-188a7204",path:"/it/",readingTime:{minutes:2.99,words:896},headersStr:null,content:"Welcome to SubQuery’s Docs\n\nExplore and transform your chain data to build intuitive dApps faster!\n\n\nQuick Start Guide\n\nUnderstand SubQuery by getting hands on with a traditional Hello World example. Using a template project within a Docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * The SubQuery Network\n   \n   SubQuery’s decentralised future. Read more about how indexers and consumers are rewarded.\n\n\nFAQ\n\n * What is SubQuery?\n   \n   SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n   \n   READ MORE\n * What is the best way to get started with SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n * How can I contribute or give feedback to SubQuery?\n   \n   We love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guidelines (coming soon).\n   \n   READ MORE\n * How much does it cost to host my project in SubQuery Projects?\n   \n   Hosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nIntegrating with your Custom Chain?\n\nWhether you're building a new parachain or an entirely new blockchain on Substrate - SubQuery can help you index and troubleshoot your chain's data. SubQuery is designed to easily integrate with a custom Substrate based chain.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nSupport and Contribute\n\nHave a question or interested to know more or how you can contribute? We’d love to hear from you. Please contact us via email or social media from the links below. Need technical expertise? Join our Discord community and receive support from our passionate community members.\n\nJOIN THE CONVERSATION ON DISCORD\nContact us hello@subquery.network\nFollow us on social\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"welcome to subquery’s docs\n\nexplore and transform your chain data to build intuitive dapps faster!\n\n\nquick start guide\n\nunderstand subquery by getting hands on with a traditional hello world example. using a template project within a docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * the subquery network\n   \n   subquery’s decentralised future. read more about how indexers and consumers are rewarded.\n\n\nfaq\n\n * what is subquery?\n   \n   subquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n   \n   read more\n * what is the best way to get started with subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n * how can i contribute or give feedback to subquery?\n   \n   we love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guidelines (coming soon).\n   \n   read more\n * how much does it cost to host my project in subquery projects?\n   \n   hosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nintegrating with your custom chain?\n\nwhether you're building a new parachain or an entirely new blockchain on substrate - subquery can help you index and troubleshoot your chain's data. subquery is designed to easily integrate with a custom substrate based chain.\n\nlearn how to integrate with your chain\n\nsupport and contribute\n\nhave a question or interested to know more or how you can contribute? we’d love to hear from you. please contact us via email or social media from the links below. need technical expertise? join our discord community and receive support from our passionate community members.\n\njoin the conversation on discord\ncontact us hello@subquery.network\nfollow us on social\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"GraphQL Schema",frontmatter:{summary:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict",meta:[{property:"og:url",content:"/it/create/graphql.html"},{property:"og:title",content:"GraphQL Schema"},{property:"og:description",content:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/create/graphql.html",relativePath:"it/create/graphql.md",key:"v-1466252d",path:"/it/create/graphql/",headers:[{level:2,title:"Defining Entities",slug:"defining-entities",normalizedTitle:"defining entities",charIndex:21},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:30},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:931},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1282},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1186},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3290},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3759},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:4062},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5096},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1268},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6445},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7144}],readingTime:{minutes:3.9,words:1170},headersStr:"Defining Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL Schema\n\n\n# Defining Entities\n\nThe schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates the shape of your data from SubQuery. To learn more about how to write in GraphQL schema language, we recommend checking out Schemas and Types.\n\nImportant: When you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# Entities\n\nEach entity must define its required fields id with the type of ID!. It is used as the primary key and unique among all entities of the same type.\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field\n}\n\ntype Title @entity {\n  id: ID!\n  name: String! @index(unique: true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nWhen code generation is run, this will automatically create a getByName under the User model, and the foreign key field title will create a getByTitleId method, which both can directly be accessed in the mapping function.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from '../types/models/User';\nimport {Title} from '../types/models/Title';\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account]\n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID!\n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery {\n  user(first: 5, filter: {contactCard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",normalizedContent:"# graphql schema\n\n\n# defining entities\n\nthe schema.graphql file defines the various graphql schemas. due to the way that the graphql query language works, the schema file essentially dictates the shape of your data from subquery. to learn more about how to write in graphql schema language, we recommend checking out schemas and types.\n\nimportant: when you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# entities\n\neach entity must define its required fields id with the type of id!. it is used as the primary key and unique among all entities of the same type.\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field\n}\n\ntype title @entity {\n  id: id!\n  name: string! @index(unique: true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nwhen code generation is run, this will automatically create a getbyname under the user model, and the foreign key field title will create a getbytitleid method, which both can directly be accessed in the mapping function.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from '../types/models/user';\nimport {title} from '../types/models/title';\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account]\n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id!\n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery {\n  user(first: 5, filter: {contactcard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/it/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/create/introduction.html",relativePath:"it/create/introduction.md",key:"v-73c98272",path:"/it/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2327}],readingTime:{minutes:1.76,words:527},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/it/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/create/manifest.html",relativePath:"it/create/manifest.md",key:"v-1553fc1d",path:"/it/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:1998},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3223},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4540}],readingTime:{minutes:2.51,words:752},headersStr:"Network Filters Mapping Filters Custom Chains",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - see Running an Indexer\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - see running an indexer\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/it/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/create/mapping.html",relativePath:"it/create/mapping.md",key:"v-6bcd2fe6",path:"/it/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3141},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4151},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5111},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5541},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6209},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5061},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6926},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10271},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11506},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11728}],readingTime:{minutes:6.93,words:2080},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from "@subql/types";\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n    // Create a new StarterEntity with the block hash as it\'s ID\n    const record = new starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from "ethers/lib/utils"; //Good way\nimport {utils} from "ethers" //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api.query.kitties.nextKittyId();\n    // return the Kitty type, input parameters types are AccountId and KittyIndex\n    const allKitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`Next kitty id ${nextKittyId}`)\n    //Custom rpc, set undefined to blockhash\n    const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined,nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from "@subql/types";\n\nexport async function handleblock(block: substrateblock): promise<void> {\n    // create a new starterentity with the block hash as it\'s id\n    const record = new starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from "ethers/lib/utils"; //good way\nimport {utils} from "ethers" //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api.query.kitties.nextkittyid();\n    // return the kitty type, input parameters types are accountid and kittyindex\n    const allkitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`next kitty id ${nextkittyid}`)\n    //custom rpc, set undefined to blockhash\n    const kittyprice = await api.rpc.kitties.getkittyprice(undefined,nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/it/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/faqs/faqs.html",relativePath:"it/faqs/faqs.md",key:"v-784c5b83",path:"/it/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/it/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/install/install.html",relativePath:"it/install/install.md",key:"v-0bd47593",path:"/it/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/it/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/miscellaneous/ambassadors.html",relativePath:"it/miscellaneous/ambassadors.md",key:"v-a8374142",path:"/it/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/it/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/miscellaneous/branding.html",relativePath:"it/miscellaneous/branding.md",key:"v-2a342b6d",path:"/it/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/it/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/miscellaneous/contributing.html",relativePath:"it/miscellaneous/contributing.md",key:"v-36e11e8d",path:"/it/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/it/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/publish/publish.html",relativePath:"it/publish/publish.md",key:"v-0b86ffc3",path:"/it/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1134},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. _We're almost there! We just need to deploy a new version of it. _\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. _we're almost there! we just need to deploy a new version of it. _\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/it/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/publish/upgrade.html",relativePath:"it/publish/upgrade.md",key:"v-6b9934ae",path:"/it/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/it/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/query/graphql.html",relativePath:"it/query/graphql.md",key:"v-a188fcc6",path:"/it/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/it/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/query/query.html",relativePath:"it/query/query.md",key:"v-296dfe42",path:"/it/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/it/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/quickstart/helloworld-hosted.html",relativePath:"it/quickstart/helloworld-hosted.md",key:"v-f39834a6",path:"/it/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/it/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/quickstart/helloworld-localhost.html",relativePath:"it/quickstart/helloworld-localhost.md",key:"v-0ca4553e",path:"/it/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"Step 1: Initialise project",slug:"step-1-initialise-project",normalizedTitle:"step 1: initialise project",charIndex:1455},{level:2,title:"Step 2: Install dependencies",slug:"step-2-install-dependencies",normalizedTitle:"step 2: install dependencies",charIndex:2035},{level:2,title:"Step 3: Generate code",slug:"step-3-generate-code",normalizedTitle:"step 3: generate code",charIndex:2477},{level:2,title:"Step 4: Build code",slug:"step-4-build-code",normalizedTitle:"step 4: build code",charIndex:3087},{level:2,title:"Step 5: Run Docker",slug:"step-5-run-docker",normalizedTitle:"step 5: run docker",charIndex:3319},{level:2,title:"Step 6: Browse playground",slug:"step-6-browse-playground",normalizedTitle:"step 6: browse playground",charIndex:4586},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:5027}],readingTime:{minutes:2.85,words:855},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Initialise project Step 2: Install dependencies Step 3: Generate code Step 4: Build code Step 5: Run Docker Step 6: Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Step 5: Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Step 6: Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# step 5: run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# step 6: browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/it/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/quickstart/quickstart.html",relativePath:"it/quickstart/quickstart.md",key:"v-475b7a03",path:"/it/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2566},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3009},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3388},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3628},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3981},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4548},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5235}],readingTime:{minutes:3.22,words:967},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/it/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/quickstart/understanding-helloworld.html",relativePath:"it/quickstart/understanding-helloworld.md",key:"v-2fc0fb5b",path:"/it/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/it/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/run/run.html",relativePath:"it/run/run.md",key:"v-ec5d765a",path:"/it/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3939},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4182}],readingTime:{minutes:2.57,words:772},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/it/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/run/sandbox.html",relativePath:"it/run/sandbox.md",key:"v-16eb1adb",path:"/it/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to change the blockchain fetching batch size?",frontmatter:{summary:"How to change the blockchain fetching batch size? Video guide Introduction The default batch size is 100, but this can be changed by using the extra command --batch-size=xx. You ne",meta:[{property:"og:url",content:"/it/tutorials_examples/batch-size.html"},{property:"og:title",content:"How to change the blockchain fetching batch size?"},{property:"og:description",content:"How to change the blockchain fetching batch size? Video guide Introduction The default batch size is 100, but this can be changed by using the extra command --batch-size=xx. You ne"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/tutorials_examples/batch-size.html",relativePath:"it/tutorials_examples/batch-size.md",key:"v-1098b9c1",path:"/it/tutorials_examples/batch-size/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:56},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:72},{level:2,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:744}],readingTime:{minutes:.47,words:141},headersStr:"Video guide Introduction Why change the batch size?",content:'# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive.',normalizedContent:'# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to start at a different block height?",frontmatter:{summary:"How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from b",meta:[{property:"og:url",content:"/it/tutorials_examples/block-height.html"},{property:"og:title",content:"How to start at a different block height?"},{property:"og:description",content:"How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from b"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/tutorials_examples/block-height.html",relativePath:"it/tutorials_examples/block-height.md",key:"v-3296464a",path:"/it/tutorials_examples/block-height/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:48},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:64},{level:2,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:952},{level:2,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1259},{level:2,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1439},{level:2,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1633}],readingTime:{minutes:1.02,words:307},headersStr:"Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen?",content:'# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.',normalizedContent:'# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to debug a SubQuery project?",frontmatter:{summary:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will",meta:[{property:"og:url",content:"/it/tutorials_examples/debug-projects.html"},{property:"og:title",content:"How to debug a SubQuery project?"},{property:"og:description",content:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/tutorials_examples/debug-projects.html",relativePath:"it/tutorials_examples/debug-projects.md",key:"v-49346ac1",path:"/it/tutorials_examples/debug-projects/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:39},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:55},{level:2,title:"Node inspector",slug:"node-inspector",normalizedTitle:"node inspector",charIndex:272},{level:2,title:"Chrome devtools",slug:"chrome-devtools",normalizedTitle:"chrome devtools",charIndex:683}],readingTime:{minutes:.65,words:196},headersStr:"Video guide Introduction Node inspector Chrome devtools",content:"# How to debug a SubQuery project?\n\n\n# Video guide\n\n\n# Introduction\n\nIn order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a Node.js inspector in conjunction with Chrome developer tools.\n\n\n# Node inspector\n\nRun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nFor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# Chrome devtools\n\nOpen up Chrome DevTools and navigate to the Sources tab. Note that clicking on the green icon will open up a new window.\n\n\n\nNavigate to Filesystem and add your project folder to the workspace. Then open the dist > mappings folder and select the code you wish to debug. Then step through the code as with any standard debugging tool.\n\n",normalizedContent:"# how to debug a subquery project?\n\n\n# video guide\n\n\n# introduction\n\nin order to debug subquery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a node.js inspector in conjunction with chrome developer tools.\n\n\n# node inspector\n\nrun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nfor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# chrome devtools\n\nopen up chrome devtools and navigate to the sources tab. note that clicking on the green icon will open up a new window.\n\n\n\nnavigate to filesystem and add your project folder to the workspace. then open the dist > mappings folder and select the code you wish to debug. then step through the code as with any standard debugging tool.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How does a SubQuery dictionary work?",frontmatter:{summary:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod",meta:[{property:"og:url",content:"/it/tutorials_examples/dictionary.html"},{property:"og:title",content:"How does a SubQuery dictionary work?"},{property:"og:description",content:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/tutorials_examples/dictionary.html",relativePath:"it/tutorials_examples/dictionary.md",key:"v-27de0d06",path:"/it/tutorials_examples/dictionary/",headers:[{level:2,title:"How to incorporate a dictionary into your project?",slug:"how-to-incorporate-a-dictionary-into-your-project",normalizedTitle:"how to incorporate a dictionary into your project?",charIndex:1024},{level:2,title:"What happens when a dictionary IS NOT used?",slug:"what-happens-when-a-dictionary-is-not-used",normalizedTitle:"what happens when a dictionary is not used?",charIndex:1350},{level:2,title:"What happens when a dictionary IS used?",slug:"what-happens-when-a-dictionary-is-used",normalizedTitle:"what happens when a dictionary is used?",charIndex:1772},{level:2,title:"When is a dictionary NOT useful?",slug:"when-is-a-dictionary-not-useful",normalizedTitle:"when is a dictionary not useful?",charIndex:2849}],readingTime:{minutes:2,words:601},headersStr:"How to incorporate a dictionary into your project? What happens when a dictionary IS NOT used? What happens when a dictionary IS used? When is a dictionary NOT useful?",content:"# How does a SubQuery dictionary work?\n\nThe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. Another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nThe network.dictionary endpoint is an optional parameter that if present, the SDK will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\nTaking the SubQuery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specVersion. These 3 entities contain 6, 4, and 2 fields respectively. When this project is run, these fields are reflected in the database tables.\n\n\n\nData from the blockchain is then stored in these tables and indexed for performance. The project is then hosted in SubQuery Projects and the API endpoint is available to be added to the manifest file.\n\n\n# How to incorporate a dictionary into your project?\n\nAdd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. Eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# What happens when a dictionary IS NOT used?\n\nWhen a dictionary is NOT used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. Later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# What happens when a dictionary IS used?\n\nWhen a dictionary IS used, the indexer will first take the call and event filters as parameters and merge this into a GraphQL query. It then uses the dictionary's API to obtain a list of relevant block heights only that contains the specific events and extrinsics. Often this is substantially less than 100 if the default is used.\n\nFor example, imagine a situation where you're indexing transfer events. Not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nThe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. This is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nThis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. But compared to the traditional method, it adds an additional step to get data from the dictionary’s API.\n\n\n# When is a dictionary NOT useful?\n\nWhen block handlers are used to grab data from a chain, every block needs to be processed. Therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nAlso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",normalizedContent:"# how does a subquery dictionary work?\n\nthe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nthe network.dictionary endpoint is an optional parameter that if present, the sdk will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\ntaking the subquery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specversion. these 3 entities contain 6, 4, and 2 fields respectively. when this project is run, these fields are reflected in the database tables.\n\n\n\ndata from the blockchain is then stored in these tables and indexed for performance. the project is then hosted in subquery projects and the api endpoint is available to be added to the manifest file.\n\n\n# how to incorporate a dictionary into your project?\n\nadd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# what happens when a dictionary is not used?\n\nwhen a dictionary is not used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# what happens when a dictionary is used?\n\nwhen a dictionary is used, the indexer will first take the call and event filters as parameters and merge this into a graphql query. it then uses the dictionary's api to obtain a list of relevant block heights only that contains the specific events and extrinsics. often this is substantially less than 100 if the default is used.\n\nfor example, imagine a situation where you're indexing transfer events. not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nthe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. this is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nthis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. but compared to the traditional method, it adds an additional step to get data from the dictionary’s api.\n\n\n# when is a dictionary not useful?\n\nwhen block handlers are used to grab data from a chain, every block needs to be processed. therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nalso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri",meta:[{property:"og:url",content:"/it/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/tutorials_examples/introduction.html",relativePath:"it/tutorials_examples/introduction.md",key:"v-2b97a116",path:"/it/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:155}],readingTime:{minutes:.77,words:231},headersStr:"SubQuery Examples",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# SubQuery Examples\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# subquery examples\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/it/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/tutorials_examples/howto.html",relativePath:"it/tutorials_examples/howto.md",key:"v-0f11ce4d",path:"/it/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to run an indexer node?",frontmatter:{summary:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r",meta:[{property:"og:url",content:"/it/tutorials_examples/run-indexer.html"},{property:"og:title",content:"How to run an indexer node?"},{property:"og:description",content:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/tutorials_examples/run-indexer.html",relativePath:"it/tutorials_examples/run-indexer.md",key:"v-05571e4d",path:"/it/tutorials_examples/run-indexer/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:34},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:50},{level:2,title:"Postgres",slug:"postgres",normalizedTitle:"postgres",charIndex:300},{level:2,title:"Install subql/node",slug:"install-subql-node",normalizedTitle:"install subql/node",charIndex:484},{level:2,title:"Setting DB configs",slug:"setting-db-configs",normalizedTitle:"setting db configs",charIndex:802},{level:2,title:"Indexing a project",slug:"indexing-a-project",normalizedTitle:"indexing a project",charIndex:1380},{level:2,title:"Inspecting Postgres",slug:"inspecting-postgres",normalizedTitle:"inspecting postgres",charIndex:1687}],readingTime:{minutes:1.18,words:353},headersStr:"Video guide Introduction Postgres Install subql/node Setting DB configs Indexing a project Inspecting Postgres",content:"# How to run an indexer node?\n\n\n# Video guide\n\n\n# Introduction\n\nRunning an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It requires more time and effort but will enhance your understanding of how SubQuery works under the covers.\n\n\n# Postgres\n\nRunning an indexer node on your infrastructure will require the setup of a Postgres database. You can install Postgres from here and ensure the version is 12 or greater.\n\n\n# Install subql/node\n\nThen to run a SubQuery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nThe -g flag means to install it globally which means on OSX, the location will be /usr/local/lib/node_modules.\n\nOnce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# Setting DB configs\n\nNext, you need to set the following environmental variables:\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\n\n\n1\n2\n3\n4\n5\n\n\nOf course, if you have different values for the above keys, please adjust accordingly. Note that the env command will display the current environment variables and that this process only sets these values temporarily. That is, they are only valid for the duration of the terminal session. To set them permanently, store them in your ~/bash_profile instead.\n\n\n# Indexing a project\n\nTo start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nIf you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. You should see the indexer node kick into life and start indexing blocks.\n\n\n# Inspecting Postgres\n\nIf you navigate to Postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. The starter_entities table contains the indexes. To view the data, run select (*) from subquery_1.starter_entities.",normalizedContent:"# how to run an indexer node?\n\n\n# video guide\n\n\n# introduction\n\nrunning an indexer node is another option outside of using docker or having a project hosted for you at subquery projects. it requires more time and effort but will enhance your understanding of how subquery works under the covers.\n\n\n# postgres\n\nrunning an indexer node on your infrastructure will require the setup of a postgres database. you can install postgres from here and ensure the version is 12 or greater.\n\n\n# install subql/node\n\nthen to run a subquery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nthe -g flag means to install it globally which means on osx, the location will be /usr/local/lib/node_modules.\n\nonce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# setting db configs\n\nnext, you need to set the following environmental variables:\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\n\n\n1\n2\n3\n4\n5\n\n\nof course, if you have different values for the above keys, please adjust accordingly. note that the env command will display the current environment variables and that this process only sets these values temporarily. that is, they are only valid for the duration of the terminal session. to set them permanently, store them in your ~/bash_profile instead.\n\n\n# indexing a project\n\nto start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nif you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. you should see the indexer node kick into life and start indexing blocks.\n\n\n# inspecting postgres\n\nif you navigate to postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. the starter_entities table contains the indexes. to view the data, run select (*) from subquery_1.starter_entities.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/it/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/tutorials_examples/terminology.html",relativePath:"it/tutorials_examples/terminology.md",key:"v-444c16e6",path:"/it/tutorials_examples/terminology/",headers:[{level:2,title:"Terminology",slug:"terminology",normalizedTitle:"terminology",charIndex:2}],readingTime:{minutes:.49,words:147},headersStr:"Terminology",content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{frontmatter:{summary:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello",meta:[{property:"og:url",content:"/ja/"},{property:"og:description",content:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/",relativePath:"ja/README.md",key:"v-2a03c37e",path:"/ja/",readingTime:{minutes:2.99,words:896},headersStr:null,content:"Welcome to SubQuery’s Docs\n\nExplore and transform your chain data to build intuitive dApps faster!\n\n\nQuick Start Guide\n\nUnderstand SubQuery by getting hands on with a traditional Hello World example. Using a template project within a Docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * The SubQuery Network\n   \n   SubQuery’s decentralised future. Read more about how indexers and consumers are rewarded.\n\n\nFAQ\n\n * What is SubQuery?\n   \n   SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n   \n   READ MORE\n * What is the best way to get started with SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n * How can I contribute or give feedback to SubQuery?\n   \n   We love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guidelines (coming soon).\n   \n   READ MORE\n * How much does it cost to host my project in SubQuery Projects?\n   \n   Hosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nIntegrating with your Custom Chain?\n\nWhether you're building a new parachain or an entirely new blockchain on Substrate - SubQuery can help you index and troubleshoot your chain's data. SubQuery is designed to easily integrate with a custom Substrate based chain.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nSupport and Contribute\n\nHave a question or interested to know more or how you can contribute? We’d love to hear from you. Please contact us via email or social media from the links below. Need technical expertise? Join our Discord community and receive support from our passionate community members.\n\nJOIN THE CONVERSATION ON DISCORD\nContact us hello@subquery.network\nFollow us on social\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"welcome to subquery’s docs\n\nexplore and transform your chain data to build intuitive dapps faster!\n\n\nquick start guide\n\nunderstand subquery by getting hands on with a traditional hello world example. using a template project within a docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * the subquery network\n   \n   subquery’s decentralised future. read more about how indexers and consumers are rewarded.\n\n\nfaq\n\n * what is subquery?\n   \n   subquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n   \n   read more\n * what is the best way to get started with subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n * how can i contribute or give feedback to subquery?\n   \n   we love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guidelines (coming soon).\n   \n   read more\n * how much does it cost to host my project in subquery projects?\n   \n   hosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nintegrating with your custom chain?\n\nwhether you're building a new parachain or an entirely new blockchain on substrate - subquery can help you index and troubleshoot your chain's data. subquery is designed to easily integrate with a custom substrate based chain.\n\nlearn how to integrate with your chain\n\nsupport and contribute\n\nhave a question or interested to know more or how you can contribute? we’d love to hear from you. please contact us via email or social media from the links below. need technical expertise? join our discord community and receive support from our passionate community members.\n\njoin the conversation on discord\ncontact us hello@subquery.network\nfollow us on social\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"GraphQL Schema",frontmatter:{summary:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict",meta:[{property:"og:url",content:"/ja/create/graphql.html"},{property:"og:title",content:"GraphQL Schema"},{property:"og:description",content:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/create/graphql.html",relativePath:"ja/create/graphql.md",key:"v-045024ad",path:"/ja/create/graphql/",headers:[{level:2,title:"Defining Entities",slug:"defining-entities",normalizedTitle:"defining entities",charIndex:21},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:30},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:931},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1282},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1186},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3290},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3759},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:4062},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5096},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1268},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6445},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7144}],readingTime:{minutes:3.9,words:1170},headersStr:"Defining Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL Schema\n\n\n# Defining Entities\n\nThe schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates the shape of your data from SubQuery. To learn more about how to write in GraphQL schema language, we recommend checking out Schemas and Types.\n\nImportant: When you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# Entities\n\nEach entity must define its required fields id with the type of ID!. It is used as the primary key and unique among all entities of the same type.\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field\n}\n\ntype Title @entity {\n  id: ID!\n  name: String! @index(unique: true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nWhen code generation is run, this will automatically create a getByName under the User model, and the foreign key field title will create a getByTitleId method, which both can directly be accessed in the mapping function.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from '../types/models/User';\nimport {Title} from '../types/models/Title';\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account]\n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID!\n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery {\n  user(first: 5, filter: {contactCard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",normalizedContent:"# graphql schema\n\n\n# defining entities\n\nthe schema.graphql file defines the various graphql schemas. due to the way that the graphql query language works, the schema file essentially dictates the shape of your data from subquery. to learn more about how to write in graphql schema language, we recommend checking out schemas and types.\n\nimportant: when you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# entities\n\neach entity must define its required fields id with the type of id!. it is used as the primary key and unique among all entities of the same type.\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field\n}\n\ntype title @entity {\n  id: id!\n  name: string! @index(unique: true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nwhen code generation is run, this will automatically create a getbyname under the user model, and the foreign key field title will create a getbytitleid method, which both can directly be accessed in the mapping function.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from '../types/models/user';\nimport {title} from '../types/models/title';\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account]\n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id!\n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery {\n  user(first: 5, filter: {contactcard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/ja/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/create/introduction.html",relativePath:"ja/create/introduction.md",key:"v-027260af",path:"/ja/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2327}],readingTime:{minutes:1.76,words:527},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/ja/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/create/manifest.html",relativePath:"ja/create/manifest.md",key:"v-f2a4a7f6",path:"/ja/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:1998},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3223},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4540}],readingTime:{minutes:2.51,words:752},headersStr:"Network Filters Mapping Filters Custom Chains",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - see Running an Indexer\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - see running an indexer\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/ja/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/create/mapping.html",relativePath:"ja/create/mapping.md",key:"v-8bf930e6",path:"/ja/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3141},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4151},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5111},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5541},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6209},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5061},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6926},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10271},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11506},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11728}],readingTime:{minutes:6.93,words:2080},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from "@subql/types";\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n    // Create a new StarterEntity with the block hash as it\'s ID\n    const record = new starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from "ethers/lib/utils"; //Good way\nimport {utils} from "ethers" //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api.query.kitties.nextKittyId();\n    // return the Kitty type, input parameters types are AccountId and KittyIndex\n    const allKitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`Next kitty id ${nextKittyId}`)\n    //Custom rpc, set undefined to blockhash\n    const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined,nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from "@subql/types";\n\nexport async function handleblock(block: substrateblock): promise<void> {\n    // create a new starterentity with the block hash as it\'s id\n    const record = new starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from "ethers/lib/utils"; //good way\nimport {utils} from "ethers" //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api.query.kitties.nextkittyid();\n    // return the kitty type, input parameters types are accountid and kittyindex\n    const allkitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`next kitty id ${nextkittyid}`)\n    //custom rpc, set undefined to blockhash\n    const kittyprice = await api.rpc.kitties.getkittyprice(undefined,nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/ja/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/faqs/faqs.html",relativePath:"ja/faqs/faqs.md",key:"v-6d65c06b",path:"/ja/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/ja/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/install/install.html",relativePath:"ja/install/install.md",key:"v-7d2e257b",path:"/ja/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/ja/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/miscellaneous/ambassadors.html",relativePath:"ja/miscellaneous/ambassadors.md",key:"v-0a98e772",path:"/ja/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/ja/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/miscellaneous/branding.html",relativePath:"ja/miscellaneous/branding.md",key:"v-95e01226",path:"/ja/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/ja/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/miscellaneous/contributing.html",relativePath:"ja/miscellaneous/contributing.md",key:"v-1738500d",path:"/ja/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/ja/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/miscellaneous/social_media.html",relativePath:"ja/miscellaneous/social_media.md",key:"v-a57e89e6",path:"/ja/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/ja/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/publish/connect.html",relativePath:"ja/publish/connect.md",key:"v-e2e0d016",path:"/ja/publish/connect/",readingTime:{minutes:.61,words:182},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/ja/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/publish/publish.html",relativePath:"ja/publish/publish.md",key:"v-7ce0afab",path:"/ja/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1134},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. _We're almost there! We just need to deploy a new version of it. _\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. _we're almost there! we just need to deploy a new version of it. _\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/ja/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/publish/upgrade.html",relativePath:"ja/publish/upgrade.md",key:"v-3b8d1591",path:"/ja/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/ja/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/query/graphql.html",relativePath:"ja/query/graphql.md",key:"v-bf8e4ef6",path:"/ja/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/ja/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/query/query.html",relativePath:"ja/query/query.md",key:"v-d5d38272",path:"/ja/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/ja/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/quickstart/helloworld-hosted.html",relativePath:"ja/quickstart/helloworld-hosted.md",key:"v-02e16a2d",path:"/ja/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/ja/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/quickstart/helloworld-localhost.html",relativePath:"ja/quickstart/helloworld-localhost.md",key:"v-bab9656e",path:"/ja/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"Step 1: Initialise project",slug:"step-1-initialise-project",normalizedTitle:"step 1: initialise project",charIndex:1455},{level:2,title:"Step 2: Install dependencies",slug:"step-2-install-dependencies",normalizedTitle:"step 2: install dependencies",charIndex:2035},{level:2,title:"Step 3: Generate code",slug:"step-3-generate-code",normalizedTitle:"step 3: generate code",charIndex:2477},{level:2,title:"Step 4: Build code",slug:"step-4-build-code",normalizedTitle:"step 4: build code",charIndex:3087},{level:2,title:"Step 5: Run Docker",slug:"step-5-run-docker",normalizedTitle:"step 5: run docker",charIndex:3319},{level:2,title:"Step 6: Browse playground",slug:"step-6-browse-playground",normalizedTitle:"step 6: browse playground",charIndex:4586},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:5027}],readingTime:{minutes:2.85,words:855},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Initialise project Step 2: Install dependencies Step 3: Generate code Step 4: Build code Step 5: Run Docker Step 6: Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Step 5: Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Step 6: Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# step 5: run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# step 6: browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/ja/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/quickstart/quickstart.html",relativePath:"ja/quickstart/quickstart.md",key:"v-c098962a",path:"/ja/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2566},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3009},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3388},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3628},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3981},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4548},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5235}],readingTime:{minutes:3.22,words:967},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/ja/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/quickstart/understanding-helloworld.html",relativePath:"ja/quickstart/understanding-helloworld.md",key:"v-2f10357a",path:"/ja/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/ja/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/run/run.html",relativePath:"ja/run/run.md",key:"v-6a0310bb",path:"/ja/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3939},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4182}],readingTime:{minutes:2.57,words:772},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/ja/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/run/sandbox.html",relativePath:"ja/run/sandbox.md",key:"v-7e8f4e7a",path:"/ja/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to change the blockchain fetching batch size?",frontmatter:{summary:"How to change the blockchain fetching batch size? Video guide Introduction The default batch size is 100, but this can be changed by using the extra command --batch-size=xx. You ne",meta:[{property:"og:url",content:"/ja/tutorials_examples/batch-size.html"},{property:"og:title",content:"How to change the blockchain fetching batch size?"},{property:"og:description",content:"How to change the blockchain fetching batch size? Video guide Introduction The default batch size is 100, but this can be changed by using the extra command --batch-size=xx. You ne"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/tutorials_examples/batch-size.html",relativePath:"ja/tutorials_examples/batch-size.md",key:"v-c1e04eae",path:"/ja/tutorials_examples/batch-size/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:56},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:72},{level:2,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:744}],readingTime:{minutes:.47,words:141},headersStr:"Video guide Introduction Why change the batch size?",content:'# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive.',normalizedContent:'# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to start at a different block height?",frontmatter:{summary:"How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from b",meta:[{property:"og:url",content:"/ja/tutorials_examples/block-height.html"},{property:"og:title",content:"How to start at a different block height?"},{property:"og:description",content:"How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from b"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/tutorials_examples/block-height.html",relativePath:"ja/tutorials_examples/block-height.md",key:"v-e0ab567a",path:"/ja/tutorials_examples/block-height/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:48},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:64},{level:2,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:952},{level:2,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1259},{level:2,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1439},{level:2,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1633}],readingTime:{minutes:1.02,words:307},headersStr:"Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen?",content:'# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.',normalizedContent:'# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to debug a SubQuery project?",frontmatter:{summary:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will",meta:[{property:"og:url",content:"/ja/tutorials_examples/debug-projects.html"},{property:"og:title",content:"How to debug a SubQuery project?"},{property:"og:description",content:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/tutorials_examples/debug-projects.html",relativePath:"ja/tutorials_examples/debug-projects.md",key:"v-73f708ae",path:"/ja/tutorials_examples/debug-projects/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:39},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:55},{level:2,title:"Node inspector",slug:"node-inspector",normalizedTitle:"node inspector",charIndex:272},{level:2,title:"Chrome devtools",slug:"chrome-devtools",normalizedTitle:"chrome devtools",charIndex:683}],readingTime:{minutes:.65,words:196},headersStr:"Video guide Introduction Node inspector Chrome devtools",content:"# How to debug a SubQuery project?\n\n\n# Video guide\n\n\n# Introduction\n\nIn order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a Node.js inspector in conjunction with Chrome developer tools.\n\n\n# Node inspector\n\nRun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nFor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# Chrome devtools\n\nOpen up Chrome DevTools and navigate to the Sources tab. Note that clicking on the green icon will open up a new window.\n\n\n\nNavigate to Filesystem and add your project folder to the workspace. Then open the dist > mappings folder and select the code you wish to debug. Then step through the code as with any standard debugging tool.\n\n",normalizedContent:"# how to debug a subquery project?\n\n\n# video guide\n\n\n# introduction\n\nin order to debug subquery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a node.js inspector in conjunction with chrome developer tools.\n\n\n# node inspector\n\nrun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nfor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# chrome devtools\n\nopen up chrome devtools and navigate to the sources tab. note that clicking on the green icon will open up a new window.\n\n\n\nnavigate to filesystem and add your project folder to the workspace. then open the dist > mappings folder and select the code you wish to debug. then step through the code as with any standard debugging tool.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How does a SubQuery dictionary work?",frontmatter:{summary:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod",meta:[{property:"og:url",content:"/ja/tutorials_examples/dictionary.html"},{property:"og:title",content:"How does a SubQuery dictionary work?"},{property:"og:description",content:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/tutorials_examples/dictionary.html",relativePath:"ja/tutorials_examples/dictionary.md",key:"v-7a881865",path:"/ja/tutorials_examples/dictionary/",headers:[{level:2,title:"How to incorporate a dictionary into your project?",slug:"how-to-incorporate-a-dictionary-into-your-project",normalizedTitle:"how to incorporate a dictionary into your project?",charIndex:1024},{level:2,title:"What happens when a dictionary IS NOT used?",slug:"what-happens-when-a-dictionary-is-not-used",normalizedTitle:"what happens when a dictionary is not used?",charIndex:1350},{level:2,title:"What happens when a dictionary IS used?",slug:"what-happens-when-a-dictionary-is-used",normalizedTitle:"what happens when a dictionary is used?",charIndex:1772},{level:2,title:"When is a dictionary NOT useful?",slug:"when-is-a-dictionary-not-useful",normalizedTitle:"when is a dictionary not useful?",charIndex:2849}],readingTime:{minutes:2,words:601},headersStr:"How to incorporate a dictionary into your project? What happens when a dictionary IS NOT used? What happens when a dictionary IS used? When is a dictionary NOT useful?",content:"# How does a SubQuery dictionary work?\n\nThe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. Another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nThe network.dictionary endpoint is an optional parameter that if present, the SDK will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\nTaking the SubQuery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specVersion. These 3 entities contain 6, 4, and 2 fields respectively. When this project is run, these fields are reflected in the database tables.\n\n\n\nData from the blockchain is then stored in these tables and indexed for performance. The project is then hosted in SubQuery Projects and the API endpoint is available to be added to the manifest file.\n\n\n# How to incorporate a dictionary into your project?\n\nAdd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. Eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# What happens when a dictionary IS NOT used?\n\nWhen a dictionary is NOT used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. Later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# What happens when a dictionary IS used?\n\nWhen a dictionary IS used, the indexer will first take the call and event filters as parameters and merge this into a GraphQL query. It then uses the dictionary's API to obtain a list of relevant block heights only that contains the specific events and extrinsics. Often this is substantially less than 100 if the default is used.\n\nFor example, imagine a situation where you're indexing transfer events. Not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nThe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. This is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nThis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. But compared to the traditional method, it adds an additional step to get data from the dictionary’s API.\n\n\n# When is a dictionary NOT useful?\n\nWhen block handlers are used to grab data from a chain, every block needs to be processed. Therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nAlso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",normalizedContent:"# how does a subquery dictionary work?\n\nthe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nthe network.dictionary endpoint is an optional parameter that if present, the sdk will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\ntaking the subquery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specversion. these 3 entities contain 6, 4, and 2 fields respectively. when this project is run, these fields are reflected in the database tables.\n\n\n\ndata from the blockchain is then stored in these tables and indexed for performance. the project is then hosted in subquery projects and the api endpoint is available to be added to the manifest file.\n\n\n# how to incorporate a dictionary into your project?\n\nadd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# what happens when a dictionary is not used?\n\nwhen a dictionary is not used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# what happens when a dictionary is used?\n\nwhen a dictionary is used, the indexer will first take the call and event filters as parameters and merge this into a graphql query. it then uses the dictionary's api to obtain a list of relevant block heights only that contains the specific events and extrinsics. often this is substantially less than 100 if the default is used.\n\nfor example, imagine a situation where you're indexing transfer events. not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nthe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. this is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nthis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. but compared to the traditional method, it adds an additional step to get data from the dictionary’s api.\n\n\n# when is a dictionary not useful?\n\nwhen block handlers are used to grab data from a chain, every block needs to be processed. therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nalso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/ja/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/tutorials_examples/howto.html",relativePath:"ja/tutorials_examples/howto.md",key:"v-062f2666",path:"/ja/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri",meta:[{property:"og:url",content:"/ja/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/tutorials_examples/introduction.html",relativePath:"ja/tutorials_examples/introduction.md",key:"v-d9acb146",path:"/ja/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:155}],readingTime:{minutes:.77,words:231},headersStr:"SubQuery Examples",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# SubQuery Examples\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# subquery examples\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to run an indexer node?",frontmatter:{summary:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r",meta:[{property:"og:url",content:"/ja/tutorials_examples/run-indexer.html"},{property:"og:title",content:"How to run an indexer node?"},{property:"og:description",content:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/tutorials_examples/run-indexer.html",relativePath:"ja/tutorials_examples/run-indexer.md",key:"v-2e80b5cd",path:"/ja/tutorials_examples/run-indexer/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:34},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:50},{level:2,title:"Postgres",slug:"postgres",normalizedTitle:"postgres",charIndex:300},{level:2,title:"Install subql/node",slug:"install-subql-node",normalizedTitle:"install subql/node",charIndex:484},{level:2,title:"Setting DB configs",slug:"setting-db-configs",normalizedTitle:"setting db configs",charIndex:802},{level:2,title:"Indexing a project",slug:"indexing-a-project",normalizedTitle:"indexing a project",charIndex:1380},{level:2,title:"Inspecting Postgres",slug:"inspecting-postgres",normalizedTitle:"inspecting postgres",charIndex:1687}],readingTime:{minutes:1.18,words:353},headersStr:"Video guide Introduction Postgres Install subql/node Setting DB configs Indexing a project Inspecting Postgres",content:"# How to run an indexer node?\n\n\n# Video guide\n\n\n# Introduction\n\nRunning an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It requires more time and effort but will enhance your understanding of how SubQuery works under the covers.\n\n\n# Postgres\n\nRunning an indexer node on your infrastructure will require the setup of a Postgres database. You can install Postgres from here and ensure the version is 12 or greater.\n\n\n# Install subql/node\n\nThen to run a SubQuery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nThe -g flag means to install it globally which means on OSX, the location will be /usr/local/lib/node_modules.\n\nOnce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# Setting DB configs\n\nNext, you need to set the following environmental variables:\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\n\n\n1\n2\n3\n4\n5\n\n\nOf course, if you have different values for the above keys, please adjust accordingly. Note that the env command will display the current environment variables and that this process only sets these values temporarily. That is, they are only valid for the duration of the terminal session. To set them permanently, store them in your ~/bash_profile instead.\n\n\n# Indexing a project\n\nTo start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nIf you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. You should see the indexer node kick into life and start indexing blocks.\n\n\n# Inspecting Postgres\n\nIf you navigate to Postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. The starter_entities table contains the indexes. To view the data, run select (*) from subquery_1.starter_entities.",normalizedContent:"# how to run an indexer node?\n\n\n# video guide\n\n\n# introduction\n\nrunning an indexer node is another option outside of using docker or having a project hosted for you at subquery projects. it requires more time and effort but will enhance your understanding of how subquery works under the covers.\n\n\n# postgres\n\nrunning an indexer node on your infrastructure will require the setup of a postgres database. you can install postgres from here and ensure the version is 12 or greater.\n\n\n# install subql/node\n\nthen to run a subquery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nthe -g flag means to install it globally which means on osx, the location will be /usr/local/lib/node_modules.\n\nonce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# setting db configs\n\nnext, you need to set the following environmental variables:\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\n\n\n1\n2\n3\n4\n5\n\n\nof course, if you have different values for the above keys, please adjust accordingly. note that the env command will display the current environment variables and that this process only sets these values temporarily. that is, they are only valid for the duration of the terminal session. to set them permanently, store them in your ~/bash_profile instead.\n\n\n# indexing a project\n\nto start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nif you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. you should see the indexer node kick into life and start indexing blocks.\n\n\n# inspecting postgres\n\nif you navigate to postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. the starter_entities table contains the indexes. to view the data, run select (*) from subquery_1.starter_entities.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/ja/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ja/tutorials_examples/terminology.html",relativePath:"ja/tutorials_examples/terminology.md",key:"v-07038c0d",path:"/ja/tutorials_examples/terminology/",headers:[{level:2,title:"Terminology",slug:"terminology",normalizedTitle:"terminology",charIndex:2}],readingTime:{minutes:.49,words:147},headersStr:"Terminology",content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{frontmatter:{summary:"서브쿼리의 문서에 오신 것을 환영합니다. 체인 데이터를 탐색하고 변환하여 직관적인 디앱을 더 빠르게 구축해보십시오! 빠른시작 가이드 가장 쉬운 Hello World 예제를 통해 서브쿼리를 이해해보세요. Docker 환경 내에서 템플릿 프로젝트를 사용하면 몇 가지 간단한 커맨드로 단 몇 분 만에 노드를 신속하게 시작, 실행",meta:[{property:"og:url",content:"/ko/"},{property:"og:description",content:"서브쿼리의 문서에 오신 것을 환영합니다. 체인 데이터를 탐색하고 변환하여 직관적인 디앱을 더 빠르게 구축해보십시오! 빠른시작 가이드 가장 쉬운 Hello World 예제를 통해 서브쿼리를 이해해보세요. Docker 환경 내에서 템플릿 프로젝트를 사용하면 몇 가지 간단한 커맨드로 단 몇 분 만에 노드를 신속하게 시작, 실행"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/",relativePath:"ko/README.md",key:"v-14d51344",path:"/ko/",readingTime:{minutes:1.87,words:562},headersStr:null,content:"서브쿼리의 문서에 오신 것을 환영합니다.\n\n체인 데이터를 탐색하고 변환하여 직관적인 디앱을 더 빠르게 구축해보십시오!\n\n\n빠른시작 가이드\n\n가장 쉬운 Hello World 예제를 통해 서브쿼리를 이해해보세요. Docker 환경 내에서 템플릿 프로젝트를 사용하면 몇 가지 간단한 커맨드로 단 몇 분 만에 노드를 신속하게 시작, 실행하고 블록체인 쿼리를 시작할 수 있습니다.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * 서브쿼리 네트워크\n   \n   서브쿼리의 탈중앙화된 미래. 인덱서와 소비자가 보상을 받는 방식에 대해서 자세히 알아보세요.\n\n\nFAQ\n\n * 서브쿼리란?\n   \n   서브쿼리는 개발자가 서브스트레이트 체인 데이터를 인덱싱, 변환 및 쿼리하여 애플리케이션을 구동할 수 있도록 하는 오픈 소스 프로젝트입니다.\n   \n   READ MORE\n * 서브쿼리를 시작하는 가장 좋은 방법은 무엇입니까?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. 쿼리를 실행하는 과정을 5분 만에 쉽게 구동할 수 있습니다. 일단 스타트 템플릿을 다운로드하고 프로젝트를 빌드한 다음, Docker를 이용하여 로컬 호스트에서 노드를 실행합니다.\n\n * 서브쿼리에 기여하거나 피드백을 어떻게 제공하나요?\n   \n   우리는 언제나 커뮤니티의 기여와 피드백을 환영합니다. 코드를 피드백을 하려면 관심 있는 레포지토리를 포크하고 변경합니다. 그런 다음 PR 또는 풀 리퀘스트를 통해 제출해주세요. 맞다! 테스트도 잊지 마시구요! 또한 기여를위한 가이드(곧 제공될 예정입니다) 도 확인해주세요.\n   \n   READ MORE\n * 서브쿼리 프로젝트에서 내 프로젝트를 호스팅하는 데 비용이 얼마나 듭니까?\n   \n   서브쿼리 프로젝트에서 프로젝트를 호스팅하는 비용은 무료입니다! 이것이 저희가 커뮤니티에 보답하는 방법입니다! To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\n커스텀 체인과 통합하시겠습니까?\n\n새로운 파라체인을 구축하든, 서브스트레이트에 완전히 새로운 블록체인을 구축하든 서브쿼리는 체인 데이터를 색인화하고 문제를 해결하는 데 큰 도움이 됩니다. 또한 서브쿼리는 서브스트레이트 기반의 커스텀 체인과 쉽게 통합되도록 설계되었습니다.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\n지원 및 기여\n\n어떠한 질문이 있거나, 더 자세히 알고 싶거나 또는 기여하고 싶다면 어떻게 해아하나요? 저희는 여러분의 의견을 듣고 싶습니다. 아래에 게시된 링크에서 이메일이나 소셜 미디어를 통해 문의해주세요. 전문적인 기술 지원이 필요하십니까? 디스코드 커뮤니티에 가입하고 열정적인 커뮤니티 구성원들에게 지원을 받아보세요.\n\n디스코드 커뮤니티에 참여하세요\n문의 메일 hello@subquery.network\n소셜미디어\n디스코드 트위터 미디움 텔레그램 깃허브 매트릭스 링크드인\n서브쿼리 © 2021",normalizedContent:"서브쿼리의 문서에 오신 것을 환영합니다.\n\n체인 데이터를 탐색하고 변환하여 직관적인 디앱을 더 빠르게 구축해보십시오!\n\n\n빠른시작 가이드\n\n가장 쉬운 hello world 예제를 통해 서브쿼리를 이해해보세요. docker 환경 내에서 템플릿 프로젝트를 사용하면 몇 가지 간단한 커맨드로 단 몇 분 만에 노드를 신속하게 시작, 실행하고 블록체인 쿼리를 시작할 수 있습니다.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * 서브쿼리 네트워크\n   \n   서브쿼리의 탈중앙화된 미래. 인덱서와 소비자가 보상을 받는 방식에 대해서 자세히 알아보세요.\n\n\nfaq\n\n * 서브쿼리란?\n   \n   서브쿼리는 개발자가 서브스트레이트 체인 데이터를 인덱싱, 변환 및 쿼리하여 애플리케이션을 구동할 수 있도록 하는 오픈 소스 프로젝트입니다.\n   \n   read more\n * 서브쿼리를 시작하는 가장 좋은 방법은 무엇입니까?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. 쿼리를 실행하는 과정을 5분 만에 쉽게 구동할 수 있습니다. 일단 스타트 템플릿을 다운로드하고 프로젝트를 빌드한 다음, docker를 이용하여 로컬 호스트에서 노드를 실행합니다.\n\n * 서브쿼리에 기여하거나 피드백을 어떻게 제공하나요?\n   \n   우리는 언제나 커뮤니티의 기여와 피드백을 환영합니다. 코드를 피드백을 하려면 관심 있는 레포지토리를 포크하고 변경합니다. 그런 다음 pr 또는 풀 리퀘스트를 통해 제출해주세요. 맞다! 테스트도 잊지 마시구요! 또한 기여를위한 가이드(곧 제공될 예정입니다) 도 확인해주세요.\n   \n   read more\n * 서브쿼리 프로젝트에서 내 프로젝트를 호스팅하는 데 비용이 얼마나 듭니까?\n   \n   서브쿼리 프로젝트에서 프로젝트를 호스팅하는 비용은 무료입니다! 이것이 저희가 커뮤니티에 보답하는 방법입니다! to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\n커스텀 체인과 통합하시겠습니까?\n\n새로운 파라체인을 구축하든, 서브스트레이트에 완전히 새로운 블록체인을 구축하든 서브쿼리는 체인 데이터를 색인화하고 문제를 해결하는 데 큰 도움이 됩니다. 또한 서브쿼리는 서브스트레이트 기반의 커스텀 체인과 쉽게 통합되도록 설계되었습니다.\n\nlearn how to integrate with your chain\n\n지원 및 기여\n\n어떠한 질문이 있거나, 더 자세히 알고 싶거나 또는 기여하고 싶다면 어떻게 해아하나요? 저희는 여러분의 의견을 듣고 싶습니다. 아래에 게시된 링크에서 이메일이나 소셜 미디어를 통해 문의해주세요. 전문적인 기술 지원이 필요하십니까? 디스코드 커뮤니티에 가입하고 열정적인 커뮤니티 구성원들에게 지원을 받아보세요.\n\n디스코드 커뮤니티에 참여하세요\n문의 메일 hello@subquery.network\n소셜미디어\n디스코드 트위터 미디움 텔레그램 깃허브 매트릭스 링크드인\n서브쿼리 © 2021",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL 엔티티 정의 schema.graphql 파일은 다양한 GraphQL 스키마를 정의합니다. GraphQL 쿼리 언어가 작동하는 방식으로 인해 스키마 파일은 본질적으로 서브쿼리의 데이터 모양을 결정합니다. There are libraries to help you implement ",meta:[{property:"og:url",content:"/ko/create/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL 엔티티 정의 schema.graphql 파일은 다양한 GraphQL 스키마를 정의합니다. GraphQL 쿼리 언어가 작동하는 방식으로 인해 스키마 파일은 본질적으로 서브쿼리의 데이터 모양을 결정합니다. There are libraries to help you implement "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/create/graphql.html",relativePath:"ko/create/graphql.md",key:"v-f004ba66",path:"/ko/create/graphql/",headers:[{level:2,title:"엔티티 정의",slug:"엔티티-정의",normalizedTitle:"엔티티 정의",charIndex:31},{level:3,title:"엔티티",slug:"엔티티",normalizedTitle:"엔티티",charIndex:31},{level:3,title:"지원되는 스칼라 및 유형",slug:"지원되는-스칼라-및-유형",normalizedTitle:"지원되는 스칼라 및 유형",charIndex:559},{level:2,title:"기본 키가 아닌 필드별 인덱싱",slug:"기본-키가-아닌-필드별-인덱싱",normalizedTitle:"기본 키가 아닌 필드별 인덱싱",charIndex:773},{level:2,title:"엔티티 관계",slug:"엔티티-관계",normalizedTitle:"엔티티 관계",charIndex:1894},{level:3,title:"일대일 관계",slug:"일대일-관계",normalizedTitle:"일대일 관계",charIndex:1970},{level:3,title:"일대다 관계",slug:"일대다-관계",normalizedTitle:"일대다 관계",charIndex:2316},{level:3,title:"다대다 관계",slug:"다대다-관계",normalizedTitle:"다대다 관계",charIndex:2521},{level:3,title:"역방향 조회",slug:"역방향-조회",normalizedTitle:"역방향 조회",charIndex:3175},{level:2,title:"JSON 타입",slug:"json-타입",normalizedTitle:"json 타입",charIndex:3616},{level:3,title:"JSON 지시어 정의",slug:"json-지시어-정의",normalizedTitle:"json 지시어 정의",charIndex:3974},{level:3,title:"Querying JSON 필드",slug:"querying-json-필드",normalizedTitle:"querying json 필드",charIndex:4451}],readingTime:{minutes:.98,words:294},headersStr:"엔티티 정의 엔티티 지원되는 스칼라 및 유형 기본 키가 아닌 필드별 인덱싱 엔티티 관계 일대일 관계 일대다 관계 다대다 관계 역방향 조회 JSON 타입 JSON 지시어 정의 Querying JSON 필드",content:"# Learn more about GraphQL\n\n\n# 엔티티 정의\n\nschema.graphql 파일은 다양한 GraphQL 스키마를 정의합니다. GraphQL 쿼리 언어가 작동하는 방식으로 인해 스키마 파일은 본질적으로 서브쿼리의 데이터 모양을 결정합니다. There are libraries to help you implement GraphQL in many different languages\n\n주요: schema 파일을 변경할 때, 다음 명령 yarn codegen을 사용하여 디렉토리 타입을 재생성하여서 사용하세요.\n\n\n# 엔티티\n\n각 엔터티는 ID! 형식의 필수 필드 id 를 정의해야 합니다. 이 키는 기본 키로 사용되며 동일한 유형의 모든 엔티티에서 고유합니다.\n\n엔티티의 Null 할 수 없는 필드는 ! 으로 표시됩니다. 아래 예제를 참조하세요:\n\n예시 입력 @entity {\n  id: ID! # id 필드는 항상 필수이며 다음과 같아야 합니다.\n  name: String! # 필수 필드입니다.\n  주소: String # 이것은 옵션 필드입니다\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 지원되는 스칼라 및 유형\n\n현재 유동 스칼라 유형 지원:\n\n * 아이디\n * Int\n * String\n * BigInt\n * 날짜\n * Boolean\n * <EntityName> 중첩된 관계 엔터티의 경우 정의된 엔터티 이름을 필드 중 하나로 사용할 수 있습니다. 엔티 관계를 참조하세요.\n * JSON가 구조화된 데이터를 저장할 수 있습니다, JSON type을 참조하세요\n\n\n# 기본 키가 아닌 필드별 인덱싱\n\nQuery 성능을 향상시키려면 기본 키가 아닌 필드에 @index 주석을 구현하여 엔터티 필드를 인덱싱하세요.\n\n그러나 사용자가 JSON 개체에 @index 주석을 추가할 수는 없다. 기본적으로 인덱스는 데이터베이스의 JSON 필드 및 외래 키에만 자동으로 추가되지만 Query 서비스 성능만 향상시킵니다.\n\n여기 예가 있습니다.\n\n사용자 @entity { 입력\n  id: ID!\n  이름: String! @index(unique: true) # 고유 항목을 참 또는 거짓으로 설정할 수 있습니다.\n  title: Title! # 인덱스는 외부 키 필드에 자동으로 추가됩니다. \n}  \n  이름: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n이 사용자의 이름은 알고 있지만 정확한 id 값은 모른다고 가정하면 모든 사용자를 추출한 다음 이름으로 필터링하는 대신 이름 필드 뒤에 @index 을 추가할 수 있습니다. 이렇게 하면 Query가 훨씬 빨라지고 unique: true를 추가로 전달하여 고유성을 보장할 수 있다.\n\n필드가 고유하지 않은 경우 최대 결과 집합 크기는 100입니다.\n\n코드 생성을 실행하면 User 모델 아래에getByName 이 자동으로 생성되고, 외래 키 필드 title이 getByTitleId 방법을 사용함으로, 두 가지 모두 매핑 기능에서 직접 사용 할 수 있습니다.\n\n/* 제목 엔터티에 대한 레코드 준비 */\n제목 삽입 (id, name) 값 ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from \"../types/models/User\"\nimport {Title} from \"../types/models/Title\"\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 엔티티 관계\n\n엔터티는 종종 다른 엔터티와 중첩된 관계를 가집니다. 필드 값을 다른 엔터티 이름으로 설정하면 기본적으로 두 엔터티 간의 일대일 관계가 정의됩니다.\n\n아래 예제를 사용하여 서로 다른 엔티티 관계(일대일, 일대다, 다대다) 를 구성할 수 있습니다.\n\n\n# 일대일 관계\n\n일대일 관계는 하나의 엔터티만 다른 엔터티에 매핑된 경우 기본값입니다.\n\n예시: 패스포트은 한 사람의 소유이고 한 사람은 한 사람의 패스포트만 가지고 있습니다(이 예에서는):\n\ntype Person @entity {\n  id: ID!\n}\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n\n\n또는\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 일대다 관계\n\n대괄호를 사용하여 필드 유형에 여러 개의 도면요소가 포함됨을 나타낼 수 있습니다.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account] \n}\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 다대다 관계\n\n다대다 관계는 매핑 엔터티를 구현하여 다른 두 엔터티를 연결함으로써 달성될 수 있습니다.\n\n예: 각 사용자는 여러 그룹(사용자 그룹) 의 일부이며 그룹에는 여러 다른 사용자(사용자 그룹) 가 있습니다.\n\n유형 사람 @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n또한 중간 도면요소의 여러 필드에 동일한 도면요소의 연결을 만들 수 있습니다.\n\n예를 들어, 계정에는 여러 개의 전송이 있을 수 있으며 각 전송에는 소스 및 대상 계정이 있습니다.\n\n이렇게 하면 양도 표를 통해 두 계정(출처 및 도착처) 간에 양방향 관계가 설정됩니다.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 역방향 조회\n\n엔터티에 대한 역방향 조회를 활성화하려면@derivedFrom 을 필드에 첨부하고 다른 엔터티의 역방향 조회 필드를 가리킵니다.\n\n이렇게 하면 Query할 수 있는 가상 필드가 엔티티에 생성됩니다.\n\n계정 \"에서\" 계정 엔티티에서 발신 전송 또는 발신 받기를 각각 필드에서 파생된 값으로 설정하여 액세스할 수 있습니다.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# JSON 타입\n\n저희는 구조화된 데이터를 저장하는 빠른 방법인 JSON 유형으로 데이터 저장을 지원하고 있습니다. 이 데이터를 Query하는 데 필요한 해당 JSON 인터페이스를 자동으로 생성하여 엔터티를 정의하고 관리하는 시간을 절약해 드립니다.\n\n다음 시나리오에서는 사용자가 JSON 유형을 사용하는 것이 좋습니다.\n\n * 구조화된 데이터를 단일 필드에 저장하는 것이 여러 개의 개별 엔터티를 만드는 것보다 관리 용이함.\n * 임의의 키/값 사용자 기본 설정 저장(여기서 값은 부울, 텍스트 또는 숫자일 수 있으며 다른 데이터 유형에 대해 별도의 열을 사용하지 않을 수 있습니다).\n * Schema가 휘발성이며 자주 변경됩니다\n\n\n# JSON 지시어 정의\n\n엔터티에 jsonField 주석을 추가하여 속성을 JSON 유형으로 정의합니다. 이렇게 하면 프로젝트의 모든 JSON 개체에 대한 인터페이스가 types/interfaces.ts에 자동으로 생성되며 매핑 기능에서 액세스할 수 있습니다.\n\n엔티티와 달리 jsonField 지시문 개체에는 id 필드가 필요하지 않습니다. JSON 개체는 다른 JSON 개체와 중첩할 수도 있습니다.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n} \n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Querying JSON 필드\n\nJSON 유형을 사용할 경우 텍스트 검색을 수행할 때마다 전체 엔티티에 영향을 미치기 때문에 필터링 시 Query 효율성에 약간의 영향이 있습니다.\n\n그러나, 그 영향은 여전히 저희의 질의 서비스에서 받아들여질 수 있습니다. 다음은 JSON 필드의 GraphQL Query에 contains 포함 연산자를 사용하여 '0064'가 포함된 전화번호를 소유한 처음 5명의 사용자를 찾는 방법의 예입니다.\n\n#처음 5명의 사용자를 찾으려면 '0064'가 포함되어 있습니다.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactCard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# learn more about graphql\n\n\n# 엔티티 정의\n\nschema.graphql 파일은 다양한 graphql 스키마를 정의합니다. graphql 쿼리 언어가 작동하는 방식으로 인해 스키마 파일은 본질적으로 서브쿼리의 데이터 모양을 결정합니다. there are libraries to help you implement graphql in many different languages\n\n주요: schema 파일을 변경할 때, 다음 명령 yarn codegen을 사용하여 디렉토리 타입을 재생성하여서 사용하세요.\n\n\n# 엔티티\n\n각 엔터티는 id! 형식의 필수 필드 id 를 정의해야 합니다. 이 키는 기본 키로 사용되며 동일한 유형의 모든 엔티티에서 고유합니다.\n\n엔티티의 null 할 수 없는 필드는 ! 으로 표시됩니다. 아래 예제를 참조하세요:\n\n예시 입력 @entity {\n  id: id! # id 필드는 항상 필수이며 다음과 같아야 합니다.\n  name: string! # 필수 필드입니다.\n  주소: string # 이것은 옵션 필드입니다\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 지원되는 스칼라 및 유형\n\n현재 유동 스칼라 유형 지원:\n\n * 아이디\n * int\n * string\n * bigint\n * 날짜\n * boolean\n * <entityname> 중첩된 관계 엔터티의 경우 정의된 엔터티 이름을 필드 중 하나로 사용할 수 있습니다. 엔티 관계를 참조하세요.\n * json가 구조화된 데이터를 저장할 수 있습니다, json type을 참조하세요\n\n\n# 기본 키가 아닌 필드별 인덱싱\n\nquery 성능을 향상시키려면 기본 키가 아닌 필드에 @index 주석을 구현하여 엔터티 필드를 인덱싱하세요.\n\n그러나 사용자가 json 개체에 @index 주석을 추가할 수는 없다. 기본적으로 인덱스는 데이터베이스의 json 필드 및 외래 키에만 자동으로 추가되지만 query 서비스 성능만 향상시킵니다.\n\n여기 예가 있습니다.\n\n사용자 @entity { 입력\n  id: id!\n  이름: string! @index(unique: true) # 고유 항목을 참 또는 거짓으로 설정할 수 있습니다.\n  title: title! # 인덱스는 외부 키 필드에 자동으로 추가됩니다. \n}  \n  이름: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n이 사용자의 이름은 알고 있지만 정확한 id 값은 모른다고 가정하면 모든 사용자를 추출한 다음 이름으로 필터링하는 대신 이름 필드 뒤에 @index 을 추가할 수 있습니다. 이렇게 하면 query가 훨씬 빨라지고 unique: true를 추가로 전달하여 고유성을 보장할 수 있다.\n\n필드가 고유하지 않은 경우 최대 결과 집합 크기는 100입니다.\n\n코드 생성을 실행하면 user 모델 아래에getbyname 이 자동으로 생성되고, 외래 키 필드 title이 getbytitleid 방법을 사용함으로, 두 가지 모두 매핑 기능에서 직접 사용 할 수 있습니다.\n\n/* 제목 엔터티에 대한 레코드 준비 */\n제목 삽입 (id, name) 값 ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from \"../types/models/user\"\nimport {title} from \"../types/models/title\"\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 엔티티 관계\n\n엔터티는 종종 다른 엔터티와 중첩된 관계를 가집니다. 필드 값을 다른 엔터티 이름으로 설정하면 기본적으로 두 엔터티 간의 일대일 관계가 정의됩니다.\n\n아래 예제를 사용하여 서로 다른 엔티티 관계(일대일, 일대다, 다대다) 를 구성할 수 있습니다.\n\n\n# 일대일 관계\n\n일대일 관계는 하나의 엔터티만 다른 엔터티에 매핑된 경우 기본값입니다.\n\n예시: 패스포트은 한 사람의 소유이고 한 사람은 한 사람의 패스포트만 가지고 있습니다(이 예에서는):\n\ntype person @entity {\n  id: id!\n}\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n\n\n또는\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 일대다 관계\n\n대괄호를 사용하여 필드 유형에 여러 개의 도면요소가 포함됨을 나타낼 수 있습니다.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account] \n}\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 다대다 관계\n\n다대다 관계는 매핑 엔터티를 구현하여 다른 두 엔터티를 연결함으로써 달성될 수 있습니다.\n\n예: 각 사용자는 여러 그룹(사용자 그룹) 의 일부이며 그룹에는 여러 다른 사용자(사용자 그룹) 가 있습니다.\n\n유형 사람 @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n또한 중간 도면요소의 여러 필드에 동일한 도면요소의 연결을 만들 수 있습니다.\n\n예를 들어, 계정에는 여러 개의 전송이 있을 수 있으며 각 전송에는 소스 및 대상 계정이 있습니다.\n\n이렇게 하면 양도 표를 통해 두 계정(출처 및 도착처) 간에 양방향 관계가 설정됩니다.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 역방향 조회\n\n엔터티에 대한 역방향 조회를 활성화하려면@derivedfrom 을 필드에 첨부하고 다른 엔터티의 역방향 조회 필드를 가리킵니다.\n\n이렇게 하면 query할 수 있는 가상 필드가 엔티티에 생성됩니다.\n\n계정 \"에서\" 계정 엔티티에서 발신 전송 또는 발신 받기를 각각 필드에서 파생된 값으로 설정하여 액세스할 수 있습니다.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# json 타입\n\n저희는 구조화된 데이터를 저장하는 빠른 방법인 json 유형으로 데이터 저장을 지원하고 있습니다. 이 데이터를 query하는 데 필요한 해당 json 인터페이스를 자동으로 생성하여 엔터티를 정의하고 관리하는 시간을 절약해 드립니다.\n\n다음 시나리오에서는 사용자가 json 유형을 사용하는 것이 좋습니다.\n\n * 구조화된 데이터를 단일 필드에 저장하는 것이 여러 개의 개별 엔터티를 만드는 것보다 관리 용이함.\n * 임의의 키/값 사용자 기본 설정 저장(여기서 값은 부울, 텍스트 또는 숫자일 수 있으며 다른 데이터 유형에 대해 별도의 열을 사용하지 않을 수 있습니다).\n * schema가 휘발성이며 자주 변경됩니다\n\n\n# json 지시어 정의\n\n엔터티에 jsonfield 주석을 추가하여 속성을 json 유형으로 정의합니다. 이렇게 하면 프로젝트의 모든 json 개체에 대한 인터페이스가 types/interfaces.ts에 자동으로 생성되며 매핑 기능에서 액세스할 수 있습니다.\n\n엔티티와 달리 jsonfield 지시문 개체에는 id 필드가 필요하지 않습니다. json 개체는 다른 json 개체와 중첩할 수도 있습니다.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n} \n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# querying json 필드\n\njson 유형을 사용할 경우 텍스트 검색을 수행할 때마다 전체 엔티티에 영향을 미치기 때문에 필터링 시 query 효율성에 약간의 영향이 있습니다.\n\n그러나, 그 영향은 여전히 저희의 질의 서비스에서 받아들여질 수 있습니다. 다음은 json 필드의 graphql query에 contains 포함 연산자를 사용하여 '0064'가 포함된 전화번호를 소유한 처음 5명의 사용자를 찾는 방법의 예입니다.\n\n#처음 5명의 사용자를 찾으려면 '0064'가 포함되어 있습니다.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactcard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/ko/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/create/introduction.html",relativePath:"ko/create/introduction.md",key:"v-64b91fd5",path:"/ko/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2327}],readingTime:{minutes:1.76,words:527},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Manifest 파일",frontmatter:{summary:"Manifest 파일 Manifest project.yaml 파일은 프로젝트의 시작점으로 볼 수 있으며 서브쿼리가 가 체인 데이터를 인덱스화 및 변환하는 방법에 대한 대부분의 세부사항에 대한 부분을 정의하게 됩니다. 매니페스트는 YAML 또는 JSON 형식일 수 있습니다. 이 문서에서는 모든 예제에서 YAML을 사용합니다",meta:[{property:"og:url",content:"/ko/create/manifest.html"},{property:"og:title",content:"Manifest 파일"},{property:"og:description",content:"Manifest 파일 Manifest project.yaml 파일은 프로젝트의 시작점으로 볼 수 있으며 서브쿼리가 가 체인 데이터를 인덱스화 및 변환하는 방법에 대한 대부분의 세부사항에 대한 부분을 정의하게 됩니다. 매니페스트는 YAML 또는 JSON 형식일 수 있습니다. 이 문서에서는 모든 예제에서 YAML을 사용합니다"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/create/manifest.html",relativePath:"ko/create/manifest.md",key:"v-6fbdffab",path:"/ko/create/manifest/",headers:[{level:2,title:"네트워크 필터",slug:"네트워크-필터",normalizedTitle:"네트워크 필터",charIndex:1617},{level:2,title:"매핑 필터",slug:"매핑-필터",normalizedTitle:"매핑 필터",charIndex:1599},{level:2,title:"커스텀 체인",slug:"커스텀-체인",normalizedTitle:"커스텀 체인",charIndex:3521}],readingTime:{minutes:1.22,words:365},headersStr:"네트워크 필터 매핑 필터 커스텀 체인",content:'# Manifest 파일\n\nManifest project.yaml 파일은 프로젝트의 시작점으로 볼 수 있으며 서브쿼리가 가 체인 데이터를 인덱스화 및 변환하는 방법에 대한 대부분의 세부사항에 대한 부분을 정의하게 됩니다.\n\n매니페스트는 YAML 또는 JSON 형식일 수 있습니다. 이 문서에서는 모든 예제에서 YAML을 사용합니다. 다음은 기본project.yaml의 표준 예시입니다.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint 은 인덱스화하는 블록체인의 wss 또는 ws 엔드포인트를 정의합니다. 완전한 아카이브 노드여야 합니다.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - see Running an Indexer\n * dataSources는, 필터링 및 추출하는 데이터와 적용하는 데이터 변환의 매핑 기능 핸들러의 장소를 정의합니다.\n   * kind은 현시점에서는 substrate/Runtime만 지원하고 있습니다.\n   * startBlock은, 인덱스 붙임을 개시하는 블록의 높이를 지정합니다.\n   * filter은, 실행하는 데이터 소스를 네트워크 엔드 포인트의 사양명으로 필터링 합니다, network filters참조\n   * mapping.handlers에는, 모든매핑 기능과 거기에 대응하는 핸들러 타입이 표시되어 매핑 필터가 추가됩니다.\n\n\n# 네트워크 필터\n\n일반적으로 사용자는 SubQuery를 생성하여 테스트넷 환경과 메인넷 환경 모두(Polkadot이나 Kusama)에서 재사용하기를 기대합니다. 네트워크간에서는 다양한 옵션(예. 인덱스 개시블록)이 다를 수 있습니다. 따라서 사용자가 각 데이터 원본에 대해 서로 다른 상세 정보를 정의할 수 있도록 하고 이는 하나의 SubQuery 프로젝트가 여전히 여러 네트워크에서 사용될 수 있음을 의미합니다.\n\n유저는 dataSources에filter을 추가하고, 각 네트워크에서 실행하는 데이터 소스를 결정할 수 있습니다.\n\n이제 Polkadot 네트워크와 Kusama 네트워크 모두에서 서로 다른 데이터 소스를 표시하는 예를 보여 줍니다.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# 매핑 필터\n\n매핑 필터는 매핑 핸들러를 트리거하는 블록, 이벤트 또는 외인성을 결정하는데 매우 편리한 기능입니다.\n\n매핑 기능에 의해서 처리되는 것은, 필터 조건을 채우는 착신 데이터 뿐입니다. 매핑 필터는 옵션이지만 SubQuery 프로젝트에서 처리되는 데이터 양이 대폭 줄어들고 인덱스 성능이 향상되므로 권장합니다.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\n다음 표에 다양한 핸들러로 지원되는 필터를 나타냅니다.\n\n핸들러           지원되는 필터\n블록 핸들러        specVersion\n이벤트 핸들러       module,method\nCallHandler   module,method ,success\n\n * 모듈 및 방법 필터는 임의의 Substrate 기반 체인으로 지원됩니다.\n * success 필터는 부울값을 취해, 성공 스테이터스에 의해서 외부의 것을 필터링 하기 위해서 사용할 수 있습니다.\n * specVersion 필터는 Substrate 블록의 스펙 버전 범위를 지정합니다. 다음으로 버전 범위를 설정하는 예를 제시하겠습니다.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# 커스텀 체인\n\nproject.yaml에 체인타입을 포함시키는 것으로 커스텀체인의 데이터를 인덱스화할 수도 있습니다. network.types으로, 이 블록체인으로 지원되는 특정 유형을 선언합니다. 저희는 Substrate 런타임 모듈에서 사용되는 추가 타입을 지원합니다.\n\ntypesAlias, typesBundle, typesChain 및 typesSpec도 지원됩니다.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest 파일\n\nmanifest project.yaml 파일은 프로젝트의 시작점으로 볼 수 있으며 서브쿼리가 가 체인 데이터를 인덱스화 및 변환하는 방법에 대한 대부분의 세부사항에 대한 부분을 정의하게 됩니다.\n\n매니페스트는 yaml 또는 json 형식일 수 있습니다. 이 문서에서는 모든 예제에서 yaml을 사용합니다. 다음은 기본project.yaml의 표준 예시입니다.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint 은 인덱스화하는 블록체인의 wss 또는 ws 엔드포인트를 정의합니다. 완전한 아카이브 노드여야 합니다.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - see running an indexer\n * datasources는, 필터링 및 추출하는 데이터와 적용하는 데이터 변환의 매핑 기능 핸들러의 장소를 정의합니다.\n   * kind은 현시점에서는 substrate/runtime만 지원하고 있습니다.\n   * startblock은, 인덱스 붙임을 개시하는 블록의 높이를 지정합니다.\n   * filter은, 실행하는 데이터 소스를 네트워크 엔드 포인트의 사양명으로 필터링 합니다, network filters참조\n   * mapping.handlers에는, 모든매핑 기능과 거기에 대응하는 핸들러 타입이 표시되어 매핑 필터가 추가됩니다.\n\n\n# 네트워크 필터\n\n일반적으로 사용자는 subquery를 생성하여 테스트넷 환경과 메인넷 환경 모두(polkadot이나 kusama)에서 재사용하기를 기대합니다. 네트워크간에서는 다양한 옵션(예. 인덱스 개시블록)이 다를 수 있습니다. 따라서 사용자가 각 데이터 원본에 대해 서로 다른 상세 정보를 정의할 수 있도록 하고 이는 하나의 subquery 프로젝트가 여전히 여러 네트워크에서 사용될 수 있음을 의미합니다.\n\n유저는 datasources에filter을 추가하고, 각 네트워크에서 실행하는 데이터 소스를 결정할 수 있습니다.\n\n이제 polkadot 네트워크와 kusama 네트워크 모두에서 서로 다른 데이터 소스를 표시하는 예를 보여 줍니다.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# 매핑 필터\n\n매핑 필터는 매핑 핸들러를 트리거하는 블록, 이벤트 또는 외인성을 결정하는데 매우 편리한 기능입니다.\n\n매핑 기능에 의해서 처리되는 것은, 필터 조건을 채우는 착신 데이터 뿐입니다. 매핑 필터는 옵션이지만 subquery 프로젝트에서 처리되는 데이터 양이 대폭 줄어들고 인덱스 성능이 향상되므로 권장합니다.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\n다음 표에 다양한 핸들러로 지원되는 필터를 나타냅니다.\n\n핸들러           지원되는 필터\n블록 핸들러        specversion\n이벤트 핸들러       module,method\ncallhandler   module,method ,success\n\n * 모듈 및 방법 필터는 임의의 substrate 기반 체인으로 지원됩니다.\n * success 필터는 부울값을 취해, 성공 스테이터스에 의해서 외부의 것을 필터링 하기 위해서 사용할 수 있습니다.\n * specversion 필터는 substrate 블록의 스펙 버전 범위를 지정합니다. 다음으로 버전 범위를 설정하는 예를 제시하겠습니다.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# 커스텀 체인\n\nproject.yaml에 체인타입을 포함시키는 것으로 커스텀체인의 데이터를 인덱스화할 수도 있습니다. network.types으로, 이 블록체인으로 지원되는 특정 유형을 선언합니다. 저희는 substrate 런타임 모듈에서 사용되는 추가 타입을 지원합니다.\n\ntypesalias, typesbundle, typeschain 및 typesspec도 지원됩니다.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/ko/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/create/mapping.html",relativePath:"ko/create/mapping.md",key:"v-3db0e5ad",path:"/ko/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3127},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4137},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5097},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5527},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6190},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5047},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6907},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10097},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11318},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11540}],readingTime:{minutes:6.93,words:2080},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from \'@subql/types\';\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n  // Create a new StarterEntity with the block hash as it\'s ID\n  const record = new starterEntity(block.block.header.hash.toString());\n  record.field1 = block.block.header.number.toNumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n  const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n  record.field4 = extrinsic.block.timestamp;\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from \'ethers/lib/utils\'; //Good way\nimport {utils} from \'ethers\'; //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n  const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n  record.field1 = hashMessage(\'Hello\');\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport {default as kitties} from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n  // custom types\n  types: {\n    Address: \'AccountId\',\n    LookupSource: \'AccountId\',\n    KittyIndex: \'u32\',\n    Kitty: \'[u8; 16]\',\n  },\n  // custom rpc : api.rpc.kitties.getKittyPrice\n  rpc: {\n    getKittyPrice: {\n      description: \'Get Kitty price\',\n      params: [\n        {\n          name: \'at\',\n          type: \'BlockHash\',\n          isHistoric: true,\n          isOptional: false,\n        },\n        {\n          name: \'kittyIndex\',\n          type: \'KittyIndex\',\n          isOptional: false,\n        },\n      ],\n      type: \'Balance\',\n    },\n  },\n};\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n    // this is the package name we use (in the interface imports, --package for generators) */\n    "kitty-birthinfo/*": ["src/*"],\n    // here we replace the @polkadot/api augmentation with our own, generated from chain\n    "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n    // replace the augmented types with our own, as generated from definitions\n    "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n  //return the KittyIndex type\n  const nextKittyId = await api.query.kitties.nextKittyId();\n  // return the Kitty type, input parameters types are AccountId and KittyIndex\n  const allKitties = await api.query.kitties.kitties(\'xxxxxxxxx\', 123);\n  logger.info(`Next kitty id ${nextKittyId}`);\n  //Custom rpc, set undefined to blockhash\n  const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined, nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from \'@subql/types\';\n\nexport async function handleblock(block: substrateblock): promise<void> {\n  // create a new starterentity with the block hash as it\'s id\n  const record = new starterentity(block.block.header.hash.tostring());\n  record.field1 = block.block.header.number.tonumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n  const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n  record.field4 = extrinsic.block.timestamp;\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from \'ethers/lib/utils\'; //good way\nimport {utils} from \'ethers\'; //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n  const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n  record.field1 = hashmessage(\'hello\');\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport {default as kitties} from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n  // custom types\n  types: {\n    address: \'accountid\',\n    lookupsource: \'accountid\',\n    kittyindex: \'u32\',\n    kitty: \'[u8; 16]\',\n  },\n  // custom rpc : api.rpc.kitties.getkittyprice\n  rpc: {\n    getkittyprice: {\n      description: \'get kitty price\',\n      params: [\n        {\n          name: \'at\',\n          type: \'blockhash\',\n          ishistoric: true,\n          isoptional: false,\n        },\n        {\n          name: \'kittyindex\',\n          type: \'kittyindex\',\n          isoptional: false,\n        },\n      ],\n      type: \'balance\',\n    },\n  },\n};\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n    // this is the package name we use (in the interface imports, --package for generators) */\n    "kitty-birthinfo/*": ["src/*"],\n    // here we replace the @polkadot/api augmentation with our own, generated from chain\n    "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n    // replace the augmented types with our own, as generated from definitions\n    "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n  //return the kittyindex type\n  const nextkittyid = await api.query.kitties.nextkittyid();\n  // return the kitty type, input parameters types are accountid and kittyindex\n  const allkitties = await api.query.kitties.kitties(\'xxxxxxxxx\', 123);\n  logger.info(`next kitty id ${nextkittyid}`);\n  //custom rpc, set undefined to blockhash\n  const kittyprice = await api.rpc.kitties.getkittyprice(undefined, nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/ko/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/faqs/faqs.html",relativePath:"ko/faqs/faqs.md",key:"v-0484fad1",path:"/ko/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/ko/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/install/install.html",relativePath:"ko/install/install.md",key:"v-663e7921",path:"/ko/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/ko/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/miscellaneous/ambassadors.html",relativePath:"ko/miscellaneous/ambassadors.md",key:"v-223c74ad",path:"/ko/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/ko/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/miscellaneous/branding.html",relativePath:"ko/miscellaneous/branding.md",key:"v-846f9be6",path:"/ko/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/ko/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/miscellaneous/contributing.html",relativePath:"ko/miscellaneous/contributing.md",key:"v-3f016ca6",path:"/ko/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/ko/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/miscellaneous/social_media.html",relativePath:"ko/miscellaneous/social_media.md",key:"v-7687b4ad",path:"/ko/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/ko/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/publish/publish.html",relativePath:"ko/publish/publish.md",key:"v-65f10351",path:"/ko/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1134},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. _We're almost there! We just need to deploy a new version of it. _\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. _we're almost there! we just need to deploy a new version of it. _\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project 배포가 성공적으로 완료되고 노드가 체인에서 데이터를 인덱스화하면 표시된 Query 엔드 포인트를 통해 프로젝트에 접속할 수 있습니다. 프로젝트 제목 옆에 있는 3개의 점을 클릭하여 SubQuery 탐색기로 표시할 수도 있습니다. 브라우저 내의 플레이그라운드를 사용하여 시작",meta:[{property:"og:url",content:"/ko/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project 배포가 성공적으로 완료되고 노드가 체인에서 데이터를 인덱스화하면 표시된 Query 엔드 포인트를 통해 프로젝트에 접속할 수 있습니다. 프로젝트 제목 옆에 있는 3개의 점을 클릭하여 SubQuery 탐색기로 표시할 수도 있습니다. 브라우저 내의 플레이그라운드를 사용하여 시작"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/publish/connect.html",relativePath:"ko/publish/connect.md",key:"v-779feb9b",path:"/ko/publish/connect/",readingTime:{minutes:.21,words:64},headersStr:null,content:"# Connect to your New Project\n\n배포가 성공적으로 완료되고 노드가 체인에서 데이터를 인덱스화하면 표시된 Query 엔드 포인트를 통해 프로젝트에 접속할 수 있습니다.\n\n\n\n프로젝트 제목 옆에 있는 3개의 점을 클릭하여 SubQuery 탐색기로 표시할 수도 있습니다. 브라우저 내의 플레이그라운드를 사용하여 시작할 수 있습니다.\n\n\n\n\n# GraphQL에 대해 더 알아보기\n\nofficial GraphQL guide here에 따라 GraphQL의 상세, 동작 방법 및 사용 방법을 확인할 수 있습니다.\n\n * many different languages로 GraphQL을 구현하는 데 도움이 되는 라이브러리가 있습니다.\n * 실제 튜토리얼을 사용한 자세한 학습 경험은 How to GraphQL을 참조해 주세요.\n * 무료 온라인 코스 Exploring GraphQL: A Query Language for APIs을 확인하시기 바랍니다.",normalizedContent:"# connect to your new project\n\n배포가 성공적으로 완료되고 노드가 체인에서 데이터를 인덱스화하면 표시된 query 엔드 포인트를 통해 프로젝트에 접속할 수 있습니다.\n\n\n\n프로젝트 제목 옆에 있는 3개의 점을 클릭하여 subquery 탐색기로 표시할 수도 있습니다. 브라우저 내의 플레이그라운드를 사용하여 시작할 수 있습니다.\n\n\n\n\n# graphql에 대해 더 알아보기\n\nofficial graphql guide here에 따라 graphql의 상세, 동작 방법 및 사용 방법을 확인할 수 있습니다.\n\n * many different languages로 graphql을 구현하는 데 도움이 되는 라이브러리가 있습니다.\n * 실제 튜토리얼을 사용한 자세한 학습 경험은 how to graphql을 참조해 주세요.\n * 무료 온라인 코스 exploring graphql: a query language for apis을 확인하시기 바랍니다.",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/ko/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/publish/upgrade.html",relativePath:"ko/publish/upgrade.md",key:"v-249d6937",path:"/ko/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/ko/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/query/graphql.html",relativePath:"ko/query/graphql.md",key:"v-b022432a",path:"/ko/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/ko/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/query/query.html",relativePath:"ko/query/query.md",key:"v-dc503226",path:"/ko/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (SubQuery 호스팅)",frontmatter:{summary:"Hello World (SubQuery 호스팅) 이 빠른 시작의 목적은 몇 가지 간단한 단계를 통해 SubQuery 프로젝트(우리의 관리 서비스)에서 기본 스타터 프로젝트를 실행하는 방법을 보여주는 것입니다. 간단한 스타터 프로젝트(그리고 지금까지 배운 모든 것)를 사용하지만 Docker 내에서 로컬로 실행하는 대신 Su",meta:[{property:"og:url",content:"/ko/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery 호스팅)"},{property:"og:description",content:"Hello World (SubQuery 호스팅) 이 빠른 시작의 목적은 몇 가지 간단한 단계를 통해 SubQuery 프로젝트(우리의 관리 서비스)에서 기본 스타터 프로젝트를 실행하는 방법을 보여주는 것입니다. 간단한 스타터 프로젝트(그리고 지금까지 배운 모든 것)를 사용하지만 Docker 내에서 로컬로 실행하는 대신 Su"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/quickstart/helloworld-hosted.html",relativePath:"ko/quickstart/helloworld-hosted.md",key:"v-166c1b0d",path:"/ko/quickstart/helloworld-hosted/",headers:[{level:2,title:"학습 목표",slug:"학습-목표",normalizedTitle:"학습 목표",charIndex:274},{level:2,title:"대상자",slug:"대상자",normalizedTitle:"대상자",charIndex:487},{level:2,title:"비디오 가이드",slug:"비디오-가이드",normalizedTitle:"비디오 가이드",charIndex:559},{level:2,title:"전제조건",slug:"전제조건",normalizedTitle:"전제조건",charIndex:571},{level:2,title:"1. Step 1: Create your project",slug:"_1-step-1-create-your-project",normalizedTitle:"1. step 1: create your project",charIndex:609},{level:2,title:"2. Step 2: Create a GitHub repo",slug:"_2-step-2-create-a-github-repo",normalizedTitle:"2. step 2: create a github repo",charIndex:839},{level:2,title:"3. Step 3: Push to GitHub",slug:"_3-step-3-push-to-github",normalizedTitle:"3. step 3: push to github",charIndex:1013},{level:2,title:"4. Create your project",slug:"_4-create-your-project",normalizedTitle:"4. create your project",charIndex:2475},{level:2,title:"5. Step 5: Deploy your project",slug:"_5-step-5-deploy-your-project",normalizedTitle:"5. step 5: deploy your project",charIndex:3208},{level:2,title:"6. Step 6: Testing your project",slug:"_6-step-6-testing-your-project",normalizedTitle:"6. step 6: testing your project",charIndex:4018},{level:2,title:"7. Step 7: Bonus step",slug:"_7-step-7-bonus-step",normalizedTitle:"7. step 7: bonus step",charIndex:4178},{level:2,title:"요약",slug:"요약",normalizedTitle:"요약",charIndex:5397}],readingTime:{minutes:1.69,words:507},headersStr:"학습 목표 대상자 비디오 가이드 전제조건 1. Step 1: Create your project 2. Step 2: Create a GitHub repo 3. Step 3: Push to GitHub 4. Create your project 5. Step 5: Deploy your project 6. Step 6: Testing your project 7. Step 7: Bonus step 요약",content:'# Hello World (SubQuery 호스팅)\n\n이 빠른 시작의 목적은 몇 가지 간단한 단계를 통해 SubQuery 프로젝트(우리의 관리 서비스)에서 기본 스타터 프로젝트를 실행하는 방법을 보여주는 것입니다.\n\n간단한 스타터 프로젝트(그리고 지금까지 배운 모든 것)를 사용하지만 Docker 내에서 로컬로 실행하는 대신 SubQuery의 관리 호스팅 인프라를 활용합니다. 즉, 우리는 SubQuery가 프로덕션 인프라를 실행하고 관리하는 모든 무거운 작업을 수행하도록 합니다.\n\n\n# 학습 목표\n\n빠른 시작이 끝나면, 다음을 수행해야 합니다.\n\n * 필요한 전제 조건을 이해\n * SubQuery 프로젝트에서 프로젝트를 호스팅할 수 있습니다.\n * 플레이그라운드를 사용하여 Polkadot 메인넷의 블록 높이를 가져오는 간단한 쿼리를 실행합니다.\n * cURL을 사용하여 Polkadot 메인넷의 블록 높이를 가져오기 위해 간단한 GET 쿼리를 실행합니다.\n\n\n# 대상자\n\n이 가이드는 약간의 개발 경험이 있고 SubQuery에 대해 더 배우고자 하는 새로운 개발자를 대상으로 합니다.\n\n\n# 비디오 가이드\n\n\n# 전제조건\n\n다음이 필요할 것입니다:\n\n * gitHub 계정\n\n\n# 1. Step 1: Create your project\n\nsubql_hellowworld라는 프로젝트를 만들고 가장 선호하는 패키지 관리자로 필수 설치, codegen 및 빌드를 실행해 보겠습니다.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\n그러나 docker 명령을 실행하지 마십시오.\n\n\n# 2. Step 2: Create a GitHub repo\n\nGitHub에서 새 공용 저장소를 만듭니다. 이름을 부여하고 공개 여부를 설정합니다. 여기에서는 모든 것이 현재 기본값으로 유지됩니다.\n\n\n\nGitHub URL을 기록해 둡니다. SubQuery가 액세스하려면 이 URL이 공개되어야 합니다.\n\n\n\n\n# 3. Step 3: Push to GitHub\n\n프로젝트 디렉토리로 돌아가 git 디렉토리로 초기화합니다. 그렇지 않으면 "치명적인: git 저장소(또는 상위 디렉토리)가 아님: .git" 오류가 발생할 수 있습니다.\n\ngit init\n\n\n1\n\n\n그런 다음 다음 명령을 사용하여 원격 저장소를 추가합니다.\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\n이것은 기본적으로 원격 저장소를 "https://github.com/seandotau/subqlHelloWorld.git"으로 설정하고 GitHub의 원격 저장소에 대한 표준 명명법인 "origin"이라는 이름을 부여합니다.\n\n다음으로 다음 명령을 사용하여 저장소에 코드를 추가합니다.\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nPush 명령은 "내 코드를 내 마스터 로컬 저장소에서 원본 저장소로 푸시하세요"를 의미합니다 GitHub를 새로 고치면 GitHub의 모든 코드가 표시됩니다.\n\n\n\n이제 GitHub에 코드를 가져왔으므로 SubQuery 프로젝트에서 호스트하는 방법을 살펴보겠습니다.\n\n\n# 4. Create your project\n\nhttps://project.subquery.network로 이동하여 GitHub 계정으로 로그인합니다.\n\n\n\n그런 다음 새 프로젝트를 만들고,\n\n\n\n그리고 적절한 세부 정보로 다양한 필드를 채우십시오.\n\n * GitHub account:: GitHub 계정이 두 개 이상인 경우, 이 프로젝트가 생성될 계정을 선택합니다. GitHub 조직 계정에서 생성된 프로젝트는 해당 조직의 구성원 간에 공유됩니다.\n * **Project Name:**여기에 프로젝트 이름을 지정합니다.\n * Subtitle: 프로젝트에 자막을 제공합니다.\n * **Description:**SubQuery 프로젝트가 하는 일을 설명하십시오.\n * **GitHub Repository URL:**SubQuery 프로젝트가 포함된 공용 저장소에 대한 유효한 GitHub URL이어야 합니다. 이 schema.graphql 파일은 디렉토리의 루트에 있어야 합니다.\n * **Hide project:**선택하면, 공개 SubQuery 탐색기에서 프로젝트를 숨깁니다. 커뮤니티와 SubQuery를 공유하려면 이 항목을 선택하지 않은 상태로 유지하십시오!\n\n\n\n만들기를 클릭하면, 대시보드로 이동합니다.\n\n\n\n대시보드에는 사용 중인 네트워크, 실행 중인 소스 코드의 GitHub 저장소 URL, 생성 및 마지막 업데이트 시간, 특히 배포 세부 정보와 같은 유용한 정보가 많이 포함되어 있습니다.\n\n\n# 5. Step 5: Deploy your project\n\n이제 SubQuery 프로젝트 내에서 프로젝트를 만들고 표시 동작을 설정했으므로 다음 단계는 프로젝트를 작동하도록 배포하는 것입니다. 버전을 배포하면 새로운 SubQuery 인덱싱 작업이 시작되고 필요한 쿼리 서비스가 GraphQL 요청 수락을 시작하도록 설정됩니다. 여기에서 기존 프로젝트에 새 버전을 배포할 수도 있습니다.\n\n프로덕션 슬롯 또는 스테이징 슬롯과 같은 다양한 환경에 배포하도록 선택할 수 있습니다. 여기에서 프로덕션 슬롯에 배포합니다. "배포" 버튼을 클릭하면 다음 파일이 있는 화면이 나타납니다.\n\n\n\n * **Commit Hash of new Version:**GitHub에서 배포하려는 SubQuery 프로젝트 코드베이스의 올바른 커밋을 선택합니다.\n * **Indexer Version:**이 SubQuery를 실행하려는 SubQuery의 노드 서비스 버전입니다. @subql/node 참조\n * Query Version: 이 SubQuery를 실행하려는 SubQuery의 쿼리 서비스 버전입니다. @subql/query 참조\n\n커밋이 하나만 있기 때문에 드롭다운에 하나의 옵션만 있습니다. 또한 최신 버전의 인덱서 및 쿼리 버전으로 작업하여 기본값을 수락한 다음 "업데이트 배포"를 클릭합니다.\n\n그러면 "처리 중" 상태의 배포가 표시됩니다. 여기에서 코드가 SubQuery의 관리 인프라에 배포되고 있습니다. 기본적으로 서버는 요청 시 가동되고 공급됩니다. 이것은 몇 분 정도 걸릴 것이므로 커피를 마실 시간입니다!\n\n\n\n이제 배포가 실행 중입니다.\n\n\n\n\n# 6. Step 6: Testing your project\n\n프로젝트를 테스트하려면 3개의 줄임표를 클릭하고 "SubQuery Explorer에서 보기"를 선택합니다.\n\n\n\n이렇게 하면 재생 버튼을 클릭하고 쿼리 결과를 볼 수 있는 친숙한 "Playground"로 이동합니다.\n\n\n\n\n# 7. Step 7: Bonus step\n\n우리 중 똑똑한 사람들을 위해, 학습 목표에서 마지막 요점은 간단한 GET 쿼리를 실행하는 것이었음을 기억할 것입니다. 이렇게 하려면, 배포 세부 정보에 표시된 "쿼리 끝점"을 가져와야 합니다.\n\n\n\n그런 다음 Postman 또는 Mockoon과 같은 자주 사용하는 클라이언트를 사용하거나 터미널의 cURL을 통해 이 끝점에 GET 요청을 보낼 수 있습니다. 간단하게 cURL이 아래에 표시됩니다.\n\n실행할 curl 명령은 다음과 같습니다.\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\n다음과 같은 결과가 나옵니다.\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\n이 JSON 응답을 사용하고 구문 분석할 프런트 엔드 코드가 있을 수 있으므로 가독성은 여기에서 문제가 되지 않습니다.\n\n\n# 요약\n\n이 SubQuery에서 호스팅하는 빠른 시작에서 우리는 Subql 프로젝트를 가지고 모든 인프라가 귀하의 편의를 위해 제공되는 SubQuery 프로젝트에 배포하는 것이 얼마나 빠르고 쉬운지 보여주었습니다. 다양한 쿼리를 실행할 수 있는 내장형 플레이그라운드와 코드를 통합할 수 있는 API 엔드포인트가 있습니다.',normalizedContent:'# hello world (subquery 호스팅)\n\n이 빠른 시작의 목적은 몇 가지 간단한 단계를 통해 subquery 프로젝트(우리의 관리 서비스)에서 기본 스타터 프로젝트를 실행하는 방법을 보여주는 것입니다.\n\n간단한 스타터 프로젝트(그리고 지금까지 배운 모든 것)를 사용하지만 docker 내에서 로컬로 실행하는 대신 subquery의 관리 호스팅 인프라를 활용합니다. 즉, 우리는 subquery가 프로덕션 인프라를 실행하고 관리하는 모든 무거운 작업을 수행하도록 합니다.\n\n\n# 학습 목표\n\n빠른 시작이 끝나면, 다음을 수행해야 합니다.\n\n * 필요한 전제 조건을 이해\n * subquery 프로젝트에서 프로젝트를 호스팅할 수 있습니다.\n * 플레이그라운드를 사용하여 polkadot 메인넷의 블록 높이를 가져오는 간단한 쿼리를 실행합니다.\n * curl을 사용하여 polkadot 메인넷의 블록 높이를 가져오기 위해 간단한 get 쿼리를 실행합니다.\n\n\n# 대상자\n\n이 가이드는 약간의 개발 경험이 있고 subquery에 대해 더 배우고자 하는 새로운 개발자를 대상으로 합니다.\n\n\n# 비디오 가이드\n\n\n# 전제조건\n\n다음이 필요할 것입니다:\n\n * github 계정\n\n\n# 1. step 1: create your project\n\nsubql_hellowworld라는 프로젝트를 만들고 가장 선호하는 패키지 관리자로 필수 설치, codegen 및 빌드를 실행해 보겠습니다.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\n그러나 docker 명령을 실행하지 마십시오.\n\n\n# 2. step 2: create a github repo\n\ngithub에서 새 공용 저장소를 만듭니다. 이름을 부여하고 공개 여부를 설정합니다. 여기에서는 모든 것이 현재 기본값으로 유지됩니다.\n\n\n\ngithub url을 기록해 둡니다. subquery가 액세스하려면 이 url이 공개되어야 합니다.\n\n\n\n\n# 3. step 3: push to github\n\n프로젝트 디렉토리로 돌아가 git 디렉토리로 초기화합니다. 그렇지 않으면 "치명적인: git 저장소(또는 상위 디렉토리)가 아님: .git" 오류가 발생할 수 있습니다.\n\ngit init\n\n\n1\n\n\n그런 다음 다음 명령을 사용하여 원격 저장소를 추가합니다.\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\n이것은 기본적으로 원격 저장소를 "https://github.com/seandotau/subqlhelloworld.git"으로 설정하고 github의 원격 저장소에 대한 표준 명명법인 "origin"이라는 이름을 부여합니다.\n\n다음으로 다음 명령을 사용하여 저장소에 코드를 추가합니다.\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\npush 명령은 "내 코드를 내 마스터 로컬 저장소에서 원본 저장소로 푸시하세요"를 의미합니다 github를 새로 고치면 github의 모든 코드가 표시됩니다.\n\n\n\n이제 github에 코드를 가져왔으므로 subquery 프로젝트에서 호스트하는 방법을 살펴보겠습니다.\n\n\n# 4. create your project\n\nhttps://project.subquery.network로 이동하여 github 계정으로 로그인합니다.\n\n\n\n그런 다음 새 프로젝트를 만들고,\n\n\n\n그리고 적절한 세부 정보로 다양한 필드를 채우십시오.\n\n * github account:: github 계정이 두 개 이상인 경우, 이 프로젝트가 생성될 계정을 선택합니다. github 조직 계정에서 생성된 프로젝트는 해당 조직의 구성원 간에 공유됩니다.\n * **project name:**여기에 프로젝트 이름을 지정합니다.\n * subtitle: 프로젝트에 자막을 제공합니다.\n * **description:**subquery 프로젝트가 하는 일을 설명하십시오.\n * **github repository url:**subquery 프로젝트가 포함된 공용 저장소에 대한 유효한 github url이어야 합니다. 이 schema.graphql 파일은 디렉토리의 루트에 있어야 합니다.\n * **hide project:**선택하면, 공개 subquery 탐색기에서 프로젝트를 숨깁니다. 커뮤니티와 subquery를 공유하려면 이 항목을 선택하지 않은 상태로 유지하십시오!\n\n\n\n만들기를 클릭하면, 대시보드로 이동합니다.\n\n\n\n대시보드에는 사용 중인 네트워크, 실행 중인 소스 코드의 github 저장소 url, 생성 및 마지막 업데이트 시간, 특히 배포 세부 정보와 같은 유용한 정보가 많이 포함되어 있습니다.\n\n\n# 5. step 5: deploy your project\n\n이제 subquery 프로젝트 내에서 프로젝트를 만들고 표시 동작을 설정했으므로 다음 단계는 프로젝트를 작동하도록 배포하는 것입니다. 버전을 배포하면 새로운 subquery 인덱싱 작업이 시작되고 필요한 쿼리 서비스가 graphql 요청 수락을 시작하도록 설정됩니다. 여기에서 기존 프로젝트에 새 버전을 배포할 수도 있습니다.\n\n프로덕션 슬롯 또는 스테이징 슬롯과 같은 다양한 환경에 배포하도록 선택할 수 있습니다. 여기에서 프로덕션 슬롯에 배포합니다. "배포" 버튼을 클릭하면 다음 파일이 있는 화면이 나타납니다.\n\n\n\n * **commit hash of new version:**github에서 배포하려는 subquery 프로젝트 코드베이스의 올바른 커밋을 선택합니다.\n * **indexer version:**이 subquery를 실행하려는 subquery의 노드 서비스 버전입니다. @subql/node 참조\n * query version: 이 subquery를 실행하려는 subquery의 쿼리 서비스 버전입니다. @subql/query 참조\n\n커밋이 하나만 있기 때문에 드롭다운에 하나의 옵션만 있습니다. 또한 최신 버전의 인덱서 및 쿼리 버전으로 작업하여 기본값을 수락한 다음 "업데이트 배포"를 클릭합니다.\n\n그러면 "처리 중" 상태의 배포가 표시됩니다. 여기에서 코드가 subquery의 관리 인프라에 배포되고 있습니다. 기본적으로 서버는 요청 시 가동되고 공급됩니다. 이것은 몇 분 정도 걸릴 것이므로 커피를 마실 시간입니다!\n\n\n\n이제 배포가 실행 중입니다.\n\n\n\n\n# 6. step 6: testing your project\n\n프로젝트를 테스트하려면 3개의 줄임표를 클릭하고 "subquery explorer에서 보기"를 선택합니다.\n\n\n\n이렇게 하면 재생 버튼을 클릭하고 쿼리 결과를 볼 수 있는 친숙한 "playground"로 이동합니다.\n\n\n\n\n# 7. step 7: bonus step\n\n우리 중 똑똑한 사람들을 위해, 학습 목표에서 마지막 요점은 간단한 get 쿼리를 실행하는 것이었음을 기억할 것입니다. 이렇게 하려면, 배포 세부 정보에 표시된 "쿼리 끝점"을 가져와야 합니다.\n\n\n\n그런 다음 postman 또는 mockoon과 같은 자주 사용하는 클라이언트를 사용하거나 터미널의 curl을 통해 이 끝점에 get 요청을 보낼 수 있습니다. 간단하게 curl이 아래에 표시됩니다.\n\n실행할 curl 명령은 다음과 같습니다.\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\n다음과 같은 결과가 나옵니다.\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\n이 json 응답을 사용하고 구문 분석할 프런트 엔드 코드가 있을 수 있으므로 가독성은 여기에서 문제가 되지 않습니다.\n\n\n# 요약\n\n이 subquery에서 호스팅하는 빠른 시작에서 우리는 subql 프로젝트를 가지고 모든 인프라가 귀하의 편의를 위해 제공되는 subquery 프로젝트에 배포하는 것이 얼마나 빠르고 쉬운지 보여주었습니다. 다양한 쿼리를 실행할 수 있는 내장형 플레이그라운드와 코드를 통합할 수 있는 api 엔드포인트가 있습니다.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) SubQuery Hello World 빠른 시작에 오신 것을 환영합니다. 빠른 시작은 몇 가지 간단한 단계를 통해 Docker에서 기본 스타터 프로젝트를 실행하는 방법을 보여주는 것을 목표로 합니다. 학습 목표 이 빠른 시작이 끝나면 다음을 수행해야 합니다. 필요",meta:[{property:"og:url",content:"/ko/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) SubQuery Hello World 빠른 시작에 오신 것을 환영합니다. 빠른 시작은 몇 가지 간단한 단계를 통해 Docker에서 기본 스타터 프로젝트를 실행하는 방법을 보여주는 것을 목표로 합니다. 학습 목표 이 빠른 시작이 끝나면 다음을 수행해야 합니다. 필요"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/quickstart/helloworld-localhost.html",relativePath:"ko/quickstart/helloworld-localhost.md",key:"v-5c3bceef",path:"/ko/quickstart/helloworld-localhost/",headers:[{level:2,title:"학습 목표",slug:"학습-목표",normalizedTitle:"학습 목표",charIndex:152},{level:2,title:"대상자",slug:"대상자",normalizedTitle:"대상자",charIndex:311},{level:2,title:"비디오 가이드",slug:"비디오-가이드",normalizedTitle:"비디오 가이드",charIndex:383},{level:2,title:"전제 조건",slug:"전제-조건",normalizedTitle:"전제 조건",charIndex:194},{level:2,title:"1. Step 1: Initialise project",slug:"_1-step-1-initialise-project",normalizedTitle:"1. step 1: initialise project",charIndex:1034},{level:2,title:"2. Step 2: Install dependencies",slug:"_2-step-2-install-dependencies",normalizedTitle:"2. step 2: install dependencies",charIndex:1516},{level:2,title:"3. Step 3: Generate code",slug:"_3-step-3-generate-code",normalizedTitle:"3. step 3: generate code",charIndex:1892},{level:2,title:"4. Step 4: Build code",slug:"_4-step-4-build-code",normalizedTitle:"4. step 4: build code",charIndex:2389},{level:2,title:"5. Run Docker",slug:"_5-run-docker",normalizedTitle:"5. run docker",charIndex:2566},{level:2,title:"6. Browse playground",slug:"_6-browse-playground",normalizedTitle:"6. browse playground",charIndex:3721},{level:2,title:"요약",slug:"요약",normalizedTitle:"요약",charIndex:4017}],readingTime:{minutes:1.61,words:482},headersStr:"학습 목표 대상자 비디오 가이드 전제 조건 1. Step 1: Initialise project 2. Step 2: Install dependencies 3. Step 3: Generate code 4. Step 4: Build code 5. Run Docker 6. Browse playground 요약",content:'# Hello World (localhost + Docker)\n\nSubQuery Hello World 빠른 시작에 오신 것을 환영합니다. 빠른 시작은 몇 가지 간단한 단계를 통해 Docker에서 기본 스타터 프로젝트를 실행하는 방법을 보여주는 것을 목표로 합니다.\n\n\n# 학습 목표\n\n이 빠른 시작이 끝나면 다음을 수행해야 합니다.\n\n * 필요한 전제 조건을 이해\n * 기본 공통 명령 이해\n * localhost:3000으로 이동하여 플레이그라운드를 볼 수 있습니다.\n * 간단한 쿼리를 실행하여 Polkadot 메인넷의 블록 높이를 가져옵니다.\n\n\n# 대상자\n\n이 가이드는 약간의 개발 경험이 있고 SubQuery에 대해 더 배우고자 하는 새로운 개발자를 대상으로 합니다.\n\n\n# 비디오 가이드\n\n\n# 전제 조건\n\n다음이 필요합니다:\n\n * 원사 또는 npm 패키지 관리자\n * 서브쿼리 CLI(@subql/cli)\n * Docker\n\n터미널에서 다음 명령을 실행하여 이러한 전제 조건이 이미 있는지 확인할 수 있습니다.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\n보다 숙달된 사용자의 경우 다음을 복사하여 붙여넣습니다.\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\n이것은 다음을 반환해야 합니다: (npm 사용자의 경우 yarn을 npm으로 교체)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\n위의 내용이 나오면 올바른 길로 가고 있는 것입니다. 그렇지 않은 경우 다음 링크를 따라 설치하십시오.\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# 1. Step 1: Initialise project\n\nSubQuery를 시작할 때 첫 번째 단계는 subql init 명령을 실행하는 것입니다. subqlHelloWorld라는 이름으로 시작 프로젝트를 초기화합시다. 오로지 작성자만이 필수라는 것을 기억하세요. 다른 모든 것은 아래에 비어 있습니다.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n이 새 디렉토리로 변경하는 것을 잊지 마십시오.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# 2. Step 2: Install dependencies\n\n이제 다양한 종속성을 설치하기 위해 원사 또는 노드 설치를 수행합니다.\n\n# Yarn yarn install # NPM npm install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 3. Step 3: Generate code\n\n이제 yarn codegen을 실행하여 GraphQL 스키마에서 Typescript를 생성합니다.\n\n# Yarn yarn codegen # NPM npm run-script codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n경고 스키마 파일이 변경되면 yarn codegen을 다시 실행하여 유형 디렉토리를 재생성하는 것을 잊지 마십시오.\n\n\n# 4. Step 4: Build code\n\n다음 단계는 yarn build로 코드를 빌드하는 것입니다.\n\n# Yarn yarn build # NPM npm run-script build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# 5. Run Docker\n\nDocker를 사용하면 필요한 모든 인프라가 Docker 이미지 내에서 제공될 수 있기 때문에 이 예제를 매우 빠르게 실행할 수 있습니다. docker-compose pull && docker-compose up을 실행합니다.\n\n이것은 결국 불러온 블록들 속으로 모든 것을 걷어차게 될 것입니다.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 6. Browse playground\n\nhttp://localhost:3000/으로 이동하여 화면 왼쪽에 아래 쿼리를 붙여넣고 재생 버튼을 누릅니다.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nlocalhost의 SubQuery 플레이그라운드.\n\n\n\n놀이터의 블록 수는 터미널의 블록 수(기술적으로 블록 높이)와도 일치해야 합니다.\n\n\n# 요약\n\n이 빠른 시작에서는 Docker 환경 내에서 스타터 프로젝트를 시작하고 실행하는 기본 단계를 시연한 다음 localhost:3000으로 이동하고 메인넷 Polkadot 네트워크의 블록 번호를 반환하는 쿼리를 실행했습니다.',normalizedContent:'# hello world (localhost + docker)\n\nsubquery hello world 빠른 시작에 오신 것을 환영합니다. 빠른 시작은 몇 가지 간단한 단계를 통해 docker에서 기본 스타터 프로젝트를 실행하는 방법을 보여주는 것을 목표로 합니다.\n\n\n# 학습 목표\n\n이 빠른 시작이 끝나면 다음을 수행해야 합니다.\n\n * 필요한 전제 조건을 이해\n * 기본 공통 명령 이해\n * localhost:3000으로 이동하여 플레이그라운드를 볼 수 있습니다.\n * 간단한 쿼리를 실행하여 polkadot 메인넷의 블록 높이를 가져옵니다.\n\n\n# 대상자\n\n이 가이드는 약간의 개발 경험이 있고 subquery에 대해 더 배우고자 하는 새로운 개발자를 대상으로 합니다.\n\n\n# 비디오 가이드\n\n\n# 전제 조건\n\n다음이 필요합니다:\n\n * 원사 또는 npm 패키지 관리자\n * 서브쿼리 cli(@subql/cli)\n * docker\n\n터미널에서 다음 명령을 실행하여 이러한 전제 조건이 이미 있는지 확인할 수 있습니다.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\n보다 숙달된 사용자의 경우 다음을 복사하여 붙여넣습니다.\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\n이것은 다음을 반환해야 합니다: (npm 사용자의 경우 yarn을 npm으로 교체)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\n위의 내용이 나오면 올바른 길로 가고 있는 것입니다. 그렇지 않은 경우 다음 링크를 따라 설치하십시오.\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# 1. step 1: initialise project\n\nsubquery를 시작할 때 첫 번째 단계는 subql init 명령을 실행하는 것입니다. subqlhelloworld라는 이름으로 시작 프로젝트를 초기화합시다. 오로지 작성자만이 필수라는 것을 기억하세요. 다른 모든 것은 아래에 비어 있습니다.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n이 새 디렉토리로 변경하는 것을 잊지 마십시오.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# 2. step 2: install dependencies\n\n이제 다양한 종속성을 설치하기 위해 원사 또는 노드 설치를 수행합니다.\n\n# yarn yarn install # npm npm install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 3. step 3: generate code\n\n이제 yarn codegen을 실행하여 graphql 스키마에서 typescript를 생성합니다.\n\n# yarn yarn codegen # npm npm run-script codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n경고 스키마 파일이 변경되면 yarn codegen을 다시 실행하여 유형 디렉토리를 재생성하는 것을 잊지 마십시오.\n\n\n# 4. step 4: build code\n\n다음 단계는 yarn build로 코드를 빌드하는 것입니다.\n\n# yarn yarn build # npm npm run-script build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# 5. run docker\n\ndocker를 사용하면 필요한 모든 인프라가 docker 이미지 내에서 제공될 수 있기 때문에 이 예제를 매우 빠르게 실행할 수 있습니다. docker-compose pull && docker-compose up을 실행합니다.\n\n이것은 결국 불러온 블록들 속으로 모든 것을 걷어차게 될 것입니다.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 6. browse playground\n\nhttp://localhost:3000/으로 이동하여 화면 왼쪽에 아래 쿼리를 붙여넣고 재생 버튼을 누릅니다.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nlocalhost의 subquery 플레이그라운드.\n\n\n\n놀이터의 블록 수는 터미널의 블록 수(기술적으로 블록 높이)와도 일치해야 합니다.\n\n\n# 요약\n\n이 빠른 시작에서는 docker 환경 내에서 스타터 프로젝트를 시작하고 실행하는 기본 단계를 시연한 다음 localhost:3000으로 이동하고 메인넷 polkadot 네트워크의 블록 번호를 반환하는 쿼리를 실행했습니다.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"빠른 시작 가이드",frontmatter:{summary:"빠른 시작 가이드 이 빠른 시작 가이드에서는, 자체 SubQuery 프로젝트를 개발하기 위한 프레임워크로 사용할 수 있는 간단한 시작 프로젝트를 만들 것입니다. 이 가이드가 끝나면, 데이터를 쿼리할 수 있는 GraphQL 끝점이 있는 SubQuery 노드에서 실행 중인 SubQuery 프로젝트를 만들 수 있습니다. 아직 ",meta:[{property:"og:url",content:"/ko/quickstart/quickstart.html"},{property:"og:title",content:"빠른 시작 가이드"},{property:"og:description",content:"빠른 시작 가이드 이 빠른 시작 가이드에서는, 자체 SubQuery 프로젝트를 개발하기 위한 프레임워크로 사용할 수 있는 간단한 시작 프로젝트를 만들 것입니다. 이 가이드가 끝나면, 데이터를 쿼리할 수 있는 GraphQL 끝점이 있는 SubQuery 노드에서 실행 중인 SubQuery 프로젝트를 만들 수 있습니다. 아직 "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/quickstart/quickstart.html",relativePath:"ko/quickstart/quickstart.md",key:"v-2afe91d1",path:"/ko/quickstart/quickstart/",headers:[{level:2,title:"준비",slug:"준비",normalizedTitle:"준비",charIndex:243},{level:3,title:"Local 개발 환경",slug:"local-개발-환경",normalizedTitle:"local 개발 환경",charIndex:250},{level:3,title:"SubQuery CLI 설치",slug:"subquery-cli-설치",normalizedTitle:"subquery cli 설치",charIndex:404},{level:2,title:"스타터 SubQuery 프로젝트 초기화",slug:"스타터-subquery-프로젝트-초기화",normalizedTitle:"스타터 subquery 프로젝트 초기화",charIndex:637},{level:3,title:"GraphQL 모델 생성",slug:"graphql-모델-생성",normalizedTitle:"graphql 모델 생성",charIndex:1743},{level:2,title:"프로젝트 빌드하기",slug:"프로젝트-빌드하기",normalizedTitle:"프로젝트 빌드하기",charIndex:1932},{level:2,title:"스타터 프로젝트 실행 및 쿼리",slug:"스타터-프로젝트-실행-및-쿼리",normalizedTitle:"스타터 프로젝트 실행 및 쿼리",charIndex:2079},{level:3,title:"SubQuery 프로젝트 실행",slug:"subquery-프로젝트-실행",normalizedTitle:"subquery 프로젝트 실행",charIndex:2305},{level:3,title:"프로젝트 쿼리",slug:"프로젝트-쿼리",normalizedTitle:"프로젝트 쿼리",charIndex:2666},{level:2,title:"다음 단계",slug:"다음-단계",normalizedTitle:"다음 단계",charIndex:3101}],readingTime:{minutes:.8,words:239},headersStr:"준비 Local 개발 환경 SubQuery CLI 설치 스타터 SubQuery 프로젝트 초기화 GraphQL 모델 생성 프로젝트 빌드하기 스타터 프로젝트 실행 및 쿼리 SubQuery 프로젝트 실행 프로젝트 쿼리 다음 단계",content:"# 빠른 시작 가이드\n\n이 빠른 시작 가이드에서는, 자체 SubQuery 프로젝트를 개발하기 위한 프레임워크로 사용할 수 있는 간단한 시작 프로젝트를 만들 것입니다.\n\n이 가이드가 끝나면, 데이터를 쿼리할 수 있는 GraphQL 끝점이 있는 SubQuery 노드에서 실행 중인 SubQuery 프로젝트를 만들 수 있습니다.\n\n아직 익숙하지 않은 경우, 우리는 귀하가 SubQuery에서 사용되는 용어에 익숙해지기를 권장합니다.\n\n\n# 준비\n\n\n# Local 개발 환경\n\n * 프로젝트를 컴파일하고 유형을 정의하려면 Typescript가 필요합니다.\n * SubQuery CLI와 생성된 프로젝트 모두 종속성이 있으며 최신 버전의 Node.js가 필요합니다.\n * SubQuery 노드에는 Docker가 필요합니다.\n\n\n# SubQuery CLI 설치\n\nNPM을 사용하여 터미널에 전역적으로 SubQuery CLI를 설치합니다.\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\n잘못된 종속성 관리로 인해 오류가 발생할 수 있으므로 yarn global 사용을 권장하지 않습니다.\n\n그런 다음 도움말을 실행하여 CLI에서 제공하는 사용 가능한 명령 및 사용법을 볼 수 있습니다.\n\nsubql help\n\n\n1\n\n\n\n# 스타터 SubQuery 프로젝트 초기화\n\nSubQuery 프로젝트를 생성하려는 디렉터리 내에서 PROJECT_NAME을 자신의 것으로 바꾸고 다음 명령을 실행하기만 하면 됩니다.\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nSubQuery 프로젝트가 초기화되면 다음과 같은 특정 질문을 받게 됩니다.\n\n * Git 저장소 (선택 사항): 이 SubQuery 프로젝트가 호스팅될 리포지토리에 대한 Git URL을 제공합니다(SubQuery Explorer에서 호스팅되는 경우).\n * RPC 끝점 (필요시): 이 프로젝트에 기본적으로 사용될 실행 중인 RPC 끝점에 대한 wss URL을 제공합니다. 다양한 Polkadot 네트워크의 공용 엔드포인트에 빠르게 액세스하거나 OnFinality를 사용하여 자체 전용 전용 노드를 생성하거나 기본 Polkadot 엔드포인트를 사용할 수도 있습니다.\n * 작성자(필요시): 이 SubQuery 프로젝트의 소유자를 여기에 입력하십시오.\n * 설명(선택 사항): 프로젝트에 포함된 데이터와 사용자가 수행할 수 있는 작업을 설명하는 짧은 단락을 제공할 수 있습니다.\n * 버전(필요시): 사용자 정의 버전 번호를 입력하거나 기본값(1.0.0)을 사용합니다.\n * 라이선스(필요시): 이 프로젝트에 대한 소프트웨어 라이선스를 제공하거나 기본값(Apache-2.0)을 수락합니다.\n\n초기화 프로세스가 완료되면, 프로젝트 이름이 있는 폴더가 디렉터리 내에 생성된 것을 볼 수 있습니다. 이 디렉토리의 내용은 디렉토리 구조에 나열된 것과 동일해야 합니다.\n\n마지막으로, 프로젝트 디렉터리에서 다음 명령을 실행하여 새 프로젝트의 종속성을 설치합니다.\n\ncd PROJECT_NAME # Yarn yarn install # NPM npm install 주로 다음 파일에서 작업하게 됩니다.:\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n고유한 SubQuery를 작성하는 방법에 대한 자세한 내용은 프로젝트 만들기에서 설명서를 확인하세요.\n\n\n# GraphQL 모델 생성\n\n귀하의 SubQuery 프로젝트를 인덱싱하려면 먼저 GraphQL 스키마 파일(schema.graphql)에 정의한 필수 GraphQL 모델을 생성해야 합니다. 프로젝트 디렉토리의 루트에서 이 명령을 실행하십시오.\n\n# Yarn yarn codegen # NPM npm run-script codegen\n\n\n# 프로젝트 빌드하기\n\n로컬에서 호스팅되는 SubQuery 노드에서 SubQuery 프로젝트를 실행하려면 작업을 빌드해야 합니다.\n\n프로젝트의 루트 디렉터리에서 빌드 명령을 실행합니다.\n\n```쉘 원사 빌드 ``` ```배시 npm 실행 스크립트 빌드 ```\n\n\n# 스타터 프로젝트 실행 및 쿼리\n\n새 프로젝트를 SubQuery 프로젝트에 빠르게 게시하고 탐색기를 사용하여 쿼리할 수 있지만, SubQuery 노드를 로컬로 실행하는 가장 쉬운 방법은 다음과 같은 경우 Docker 컨테이너에서 실행하는 것입니다. Docker가 아직 없는 경우 docker.com에서 설치할 수 있습니다.\n\n이 단계를 건너뛰고 새 프로젝트를 SubQuery 프로젝트에 게시합니다.\n\n\n# SubQuery 프로젝트 실행\n\nSubQuery 노드가 실행되는 방식을 제어하는 모든 구성은 이 docker-compose.yml 파일에 정의되어 있습니다. 방금 초기화된 새 프로젝트의 경우 여기에서 아무 것도 변경할 필요가 없지만 프로젝트 실행 섹션에서 파일 및 설정에 대한 자세한 내용을 읽을 수 있습니다.\n\n프로젝트 디렉터리에서 다음 명령을 실행합니다:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\n필요한 패키지(@subql/node, @subql/query 및 Postgres)를 처음으로 다운로드하는 데 시간이 걸릴 수 있지만, 곧 SubQuery노드가 실행 중인 것을 볼 수 있습니다.\n\n\n# 프로젝트 쿼리\n\n브라우저를 열고 http://localhost:3000으로 이동합니다.\n\nGraphQL 플레이그라운드가 탐색기에 표시되고 쿼리할 준비가 된 스키마가 표시되어야 합니다. 플레이그라운드의 오른쪽 상단에는 문서 추첨을 여는 문서 버튼이 있습니다. 이 문서는 자동으로 생성되며 쿼리할 수 있는 엔터티와 메서드를 찾는 데 도움이 됩니다.\n\n새로운 SubQuery 스타터 프로젝트의 경우, 다음 쿼리를 시도하여 작동 방식을 맛보거나 GraphQL 쿼리 언어에 대해 자세히 알아볼 수 있습니다.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 다음 단계\n\n축하합니다. 이제 귀하는 샘플 데이터에 대한 GraphQL API 요청을 수락하는 로컬 실행 SubQuery 프로젝트가 있습니다. 다음 가이드에서는, 새 프로젝트를 SubQuery 프로젝트에 게시하고 Explorer를 사용하여 쿼리하는 방법을 보여줍니다.\n\n새 프로젝트를 SubQuery 프로젝트에 게시하세요.",normalizedContent:"# 빠른 시작 가이드\n\n이 빠른 시작 가이드에서는, 자체 subquery 프로젝트를 개발하기 위한 프레임워크로 사용할 수 있는 간단한 시작 프로젝트를 만들 것입니다.\n\n이 가이드가 끝나면, 데이터를 쿼리할 수 있는 graphql 끝점이 있는 subquery 노드에서 실행 중인 subquery 프로젝트를 만들 수 있습니다.\n\n아직 익숙하지 않은 경우, 우리는 귀하가 subquery에서 사용되는 용어에 익숙해지기를 권장합니다.\n\n\n# 준비\n\n\n# local 개발 환경\n\n * 프로젝트를 컴파일하고 유형을 정의하려면 typescript가 필요합니다.\n * subquery cli와 생성된 프로젝트 모두 종속성이 있으며 최신 버전의 node.js가 필요합니다.\n * subquery 노드에는 docker가 필요합니다.\n\n\n# subquery cli 설치\n\nnpm을 사용하여 터미널에 전역적으로 subquery cli를 설치합니다.\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\n잘못된 종속성 관리로 인해 오류가 발생할 수 있으므로 yarn global 사용을 권장하지 않습니다.\n\n그런 다음 도움말을 실행하여 cli에서 제공하는 사용 가능한 명령 및 사용법을 볼 수 있습니다.\n\nsubql help\n\n\n1\n\n\n\n# 스타터 subquery 프로젝트 초기화\n\nsubquery 프로젝트를 생성하려는 디렉터리 내에서 project_name을 자신의 것으로 바꾸고 다음 명령을 실행하기만 하면 됩니다.\n\nsubql init --starter project_name\n\n\n1\n\n\nsubquery 프로젝트가 초기화되면 다음과 같은 특정 질문을 받게 됩니다.\n\n * git 저장소 (선택 사항): 이 subquery 프로젝트가 호스팅될 리포지토리에 대한 git url을 제공합니다(subquery explorer에서 호스팅되는 경우).\n * rpc 끝점 (필요시): 이 프로젝트에 기본적으로 사용될 실행 중인 rpc 끝점에 대한 wss url을 제공합니다. 다양한 polkadot 네트워크의 공용 엔드포인트에 빠르게 액세스하거나 onfinality를 사용하여 자체 전용 전용 노드를 생성하거나 기본 polkadot 엔드포인트를 사용할 수도 있습니다.\n * 작성자(필요시): 이 subquery 프로젝트의 소유자를 여기에 입력하십시오.\n * 설명(선택 사항): 프로젝트에 포함된 데이터와 사용자가 수행할 수 있는 작업을 설명하는 짧은 단락을 제공할 수 있습니다.\n * 버전(필요시): 사용자 정의 버전 번호를 입력하거나 기본값(1.0.0)을 사용합니다.\n * 라이선스(필요시): 이 프로젝트에 대한 소프트웨어 라이선스를 제공하거나 기본값(apache-2.0)을 수락합니다.\n\n초기화 프로세스가 완료되면, 프로젝트 이름이 있는 폴더가 디렉터리 내에 생성된 것을 볼 수 있습니다. 이 디렉토리의 내용은 디렉토리 구조에 나열된 것과 동일해야 합니다.\n\n마지막으로, 프로젝트 디렉터리에서 다음 명령을 실행하여 새 프로젝트의 종속성을 설치합니다.\n\ncd project_name # yarn yarn install # npm npm install 주로 다음 파일에서 작업하게 됩니다.:\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n고유한 subquery를 작성하는 방법에 대한 자세한 내용은 프로젝트 만들기에서 설명서를 확인하세요.\n\n\n# graphql 모델 생성\n\n귀하의 subquery 프로젝트를 인덱싱하려면 먼저 graphql 스키마 파일(schema.graphql)에 정의한 필수 graphql 모델을 생성해야 합니다. 프로젝트 디렉토리의 루트에서 이 명령을 실행하십시오.\n\n# yarn yarn codegen # npm npm run-script codegen\n\n\n# 프로젝트 빌드하기\n\n로컬에서 호스팅되는 subquery 노드에서 subquery 프로젝트를 실행하려면 작업을 빌드해야 합니다.\n\n프로젝트의 루트 디렉터리에서 빌드 명령을 실행합니다.\n\n```쉘 원사 빌드 ``` ```배시 npm 실행 스크립트 빌드 ```\n\n\n# 스타터 프로젝트 실행 및 쿼리\n\n새 프로젝트를 subquery 프로젝트에 빠르게 게시하고 탐색기를 사용하여 쿼리할 수 있지만, subquery 노드를 로컬로 실행하는 가장 쉬운 방법은 다음과 같은 경우 docker 컨테이너에서 실행하는 것입니다. docker가 아직 없는 경우 docker.com에서 설치할 수 있습니다.\n\n이 단계를 건너뛰고 새 프로젝트를 subquery 프로젝트에 게시합니다.\n\n\n# subquery 프로젝트 실행\n\nsubquery 노드가 실행되는 방식을 제어하는 모든 구성은 이 docker-compose.yml 파일에 정의되어 있습니다. 방금 초기화된 새 프로젝트의 경우 여기에서 아무 것도 변경할 필요가 없지만 프로젝트 실행 섹션에서 파일 및 설정에 대한 자세한 내용을 읽을 수 있습니다.\n\n프로젝트 디렉터리에서 다음 명령을 실행합니다:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\n필요한 패키지(@subql/node, @subql/query 및 postgres)를 처음으로 다운로드하는 데 시간이 걸릴 수 있지만, 곧 subquery노드가 실행 중인 것을 볼 수 있습니다.\n\n\n# 프로젝트 쿼리\n\n브라우저를 열고 http://localhost:3000으로 이동합니다.\n\ngraphql 플레이그라운드가 탐색기에 표시되고 쿼리할 준비가 된 스키마가 표시되어야 합니다. 플레이그라운드의 오른쪽 상단에는 문서 추첨을 여는 문서 버튼이 있습니다. 이 문서는 자동으로 생성되며 쿼리할 수 있는 엔터티와 메서드를 찾는 데 도움이 됩니다.\n\n새로운 subquery 스타터 프로젝트의 경우, 다음 쿼리를 시도하여 작동 방식을 맛보거나 graphql 쿼리 언어에 대해 자세히 알아볼 수 있습니다.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 다음 단계\n\n축하합니다. 이제 귀하는 샘플 데이터에 대한 graphql api 요청을 수락하는 로컬 실행 subquery 프로젝트가 있습니다. 다음 가이드에서는, 새 프로젝트를 subquery 프로젝트에 게시하고 explorer를 사용하여 쿼리하는 방법을 보여줍니다.\n\n새 프로젝트를 subquery 프로젝트에 게시하세요.",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World 설명",frontmatter:{summary:"Hello World 설명 Hello World 빠른 시작 가이드에서 우리는 몇 가지 간단한 명령을 실행했고 매우 빠르게 예제를 실행했습니다. 이를 통해 모든 전제 조건이 준비되었는지 확인하고 로컬 플레이그라운드를 사용하여 간단한 쿼리를 만들어 SubQuery에서 첫 번째 데이터를 가져올 수 있습니다. 여기에서 모든 명령",meta:[{property:"og:url",content:"/ko/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World 설명"},{property:"og:description",content:"Hello World 설명 Hello World 빠른 시작 가이드에서 우리는 몇 가지 간단한 명령을 실행했고 매우 빠르게 예제를 실행했습니다. 이를 통해 모든 전제 조건이 준비되었는지 확인하고 로컬 플레이그라운드를 사용하여 간단한 쿼리를 만들어 SubQuery에서 첫 번째 데이터를 가져올 수 있습니다. 여기에서 모든 명령"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/quickstart/understanding-helloworld.html",relativePath:"ko/quickstart/understanding-helloworld.md",key:"v-45b45b2e",path:"/ko/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql 초기화",slug:"subql-초기화",normalizedTitle:"subql 초기화",charIndex:210},{level:2,title:"yarn 설치",slug:"yarn-설치",normalizedTitle:"yarn 설치",charIndex:674},{level:2,title:"yarn 코드젠",slug:"yarn-코드젠",normalizedTitle:"yarn 코드젠",charIndex:1126},{level:2,title:"yarn 빌드",slug:"yarn-빌드",normalizedTitle:"yarn 빌드",charIndex:1353},{level:2,title:"도커-작성",slug:"도커-작성",normalizedTitle:"도커-작성",charIndex:1487},{level:2,title:"요약",slug:"요약",normalizedTitle:"요약",charIndex:1971}],readingTime:{minutes:.52,words:156},headersStr:"subql 초기화 yarn 설치 yarn 코드젠 yarn 빌드 도커-작성 요약",content:'# Hello World 설명\n\nHello World 빠른 시작 가이드에서 우리는 몇 가지 간단한 명령을 실행했고 매우 빠르게 예제를 실행했습니다. 이를 통해 모든 전제 조건이 준비되었는지 확인하고 로컬 플레이그라운드를 사용하여 간단한 쿼리를 만들어 SubQuery에서 첫 번째 데이터를 가져올 수 있습니다. 여기에서 모든 명령이 의미하는 바를 자세히 살펴보겠습니다.\n\n\n# subql 초기화\n\n우리가 실행한 첫 번째 명령은 subql init --starter subqlHelloWorld였습니다.\n\n이것은 무거운 작업을 수행하고 많은 파일을 생성합니다. 공식 문서에 명시된 바와 같이 주로 다음 파일에 대해 작업하게 됩니다.\n\n * 매니페스트 인 project.yaml\n * GraphQL 스키마 schema.graphql\n * 매핑 기능 src/mappings/ 디렉토리\n\n\n\n이 파일은 우리가 하는 모든 일의 핵심입니다. 따라서 다른 기사에서 이러한 파일에 더 많은 시간을 할애할 것입니다. 하지만 지금은 스키마에 사용자가 SubQuery API에서 요청할 수 있는 데이터에 대한 설명, "구성" 유형 매개변수가 포함된 프로젝트 yaml 파일, 물론 데이터를 변환하는 함수가 포함된 typescript가 포함된 mappingHandlers에 대한 설명이 포함되어 있다는 점만 알아두십시오.\n\n\n# yarn 설치\n\n다음 작업은 yarn install이었습니다. npm install도 사용할 수 있습니다.\n\n> 짧은 역사 수업. Node Package Manager 또는 npm은 2010년에 처음 출시되었으며 JavaScript 개발자들 사이에서 엄청나게 인기 있는 패키지 관리자입니다. 시스템에 Node.js를 설치할 때마다 자동으로 설치되는 기본 패키지입니다. Yarn은 (당시) npm으로 작업할 때의 일부 성능 및 보안 단점을 해결하기 위해 2016년 Facebook에서 처음 출시했습니다.\n\nYarn 이 하는 일은 package.json 파일을 보고 다양한 다른 종속성을 다운로드하는 것입니다. package.json 파일을 보면 종속성이 별로 없어 보이지만 명령어를 실행하면 18,983개의 파일이 추가된 것을 알 수 있습니다. 이는 각 종속성에도 고유한 종속성이 있기 때문입니다.\n\n\n\n\n# yarn 코드젠\n\n그런 다음 yarn codegen 또는 npm run-script codegen을 실행했습니다. 이것이 하는 일은 GraphQL 스키마(schema.graphql에 있음)를 가져오고 관련 typescript 모델 파일을 생성하는 것입니다(따라서 출력 파일의 확장자는 .ts입니다). 이렇게 생성된 파일을 변경해서는 안 되며 소스 schema.graphql 파일만 변경하십시오.\n\n\n\n\n# yarn 빌드\n\n그런 다음 yarn build 또는 npm run-script build가 실행되었습니다. 이것은 노련한 프로그래머에게 친숙할 것입니다. 배포를 준비하는 코드 최적화와 같은 작업을 수행하는 배포 폴더를 만듭니다.\n\n\n\n\n# 도커-작성\n\n마지막 단계는 결합된 docker 명령 docker-compose pull && docker-compose up(별도로 실행할 수도 있음). pull 명령은 Docker Hub에서 필요한 모든 이미지를 가져오고 up 명령은 컨테이너를 시작합니다.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\n컨테이너가 시작되면 터미널이 노드와 GraphQL 엔진의 상태를 보여주는 많은 텍스트를 뱉어내는 것을 볼 수 있습니다. 다음을 볼 때입니다.\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nsubQuery 노드가 동기화를 시작했다는 것을 알고 있습니다.\n\n\n# 요약\n\n은밀히 일어나는 일에 대한 통찰력을 얻었으므로 이제 여기서부터 어디로 가야 합니까? 자신이 있다면 프로젝트 생성 방법과 세 가지 주요 파일에 대해 자세히 알아볼 수 있습니다. 매니페스트 파일, GraphQL 스키마 및 매핑 파일.\n\n그렇지 않으면 SubQuery의 호스팅된 인프라에서 이 Hello World 예제를 실행하는 방법을 살펴보는 자습서 섹션을 계속 진행하고 시작 블록을 수정하는 방법을 살펴보고 즉시 사용 가능한 실행을 통해 SubQuery 프로젝트를 실행하는 방법에 대해 자세히 알아보겠습니다. 및 오픈 소스 프로젝트.',normalizedContent:'# hello world 설명\n\nhello world 빠른 시작 가이드에서 우리는 몇 가지 간단한 명령을 실행했고 매우 빠르게 예제를 실행했습니다. 이를 통해 모든 전제 조건이 준비되었는지 확인하고 로컬 플레이그라운드를 사용하여 간단한 쿼리를 만들어 subquery에서 첫 번째 데이터를 가져올 수 있습니다. 여기에서 모든 명령이 의미하는 바를 자세히 살펴보겠습니다.\n\n\n# subql 초기화\n\n우리가 실행한 첫 번째 명령은 subql init --starter subqlhelloworld였습니다.\n\n이것은 무거운 작업을 수행하고 많은 파일을 생성합니다. 공식 문서에 명시된 바와 같이 주로 다음 파일에 대해 작업하게 됩니다.\n\n * 매니페스트 인 project.yaml\n * graphql 스키마 schema.graphql\n * 매핑 기능 src/mappings/ 디렉토리\n\n\n\n이 파일은 우리가 하는 모든 일의 핵심입니다. 따라서 다른 기사에서 이러한 파일에 더 많은 시간을 할애할 것입니다. 하지만 지금은 스키마에 사용자가 subquery api에서 요청할 수 있는 데이터에 대한 설명, "구성" 유형 매개변수가 포함된 프로젝트 yaml 파일, 물론 데이터를 변환하는 함수가 포함된 typescript가 포함된 mappinghandlers에 대한 설명이 포함되어 있다는 점만 알아두십시오.\n\n\n# yarn 설치\n\n다음 작업은 yarn install이었습니다. npm install도 사용할 수 있습니다.\n\n> 짧은 역사 수업. node package manager 또는 npm은 2010년에 처음 출시되었으며 javascript 개발자들 사이에서 엄청나게 인기 있는 패키지 관리자입니다. 시스템에 node.js를 설치할 때마다 자동으로 설치되는 기본 패키지입니다. yarn은 (당시) npm으로 작업할 때의 일부 성능 및 보안 단점을 해결하기 위해 2016년 facebook에서 처음 출시했습니다.\n\nyarn 이 하는 일은 package.json 파일을 보고 다양한 다른 종속성을 다운로드하는 것입니다. package.json 파일을 보면 종속성이 별로 없어 보이지만 명령어를 실행하면 18,983개의 파일이 추가된 것을 알 수 있습니다. 이는 각 종속성에도 고유한 종속성이 있기 때문입니다.\n\n\n\n\n# yarn 코드젠\n\n그런 다음 yarn codegen 또는 npm run-script codegen을 실행했습니다. 이것이 하는 일은 graphql 스키마(schema.graphql에 있음)를 가져오고 관련 typescript 모델 파일을 생성하는 것입니다(따라서 출력 파일의 확장자는 .ts입니다). 이렇게 생성된 파일을 변경해서는 안 되며 소스 schema.graphql 파일만 변경하십시오.\n\n\n\n\n# yarn 빌드\n\n그런 다음 yarn build 또는 npm run-script build가 실행되었습니다. 이것은 노련한 프로그래머에게 친숙할 것입니다. 배포를 준비하는 코드 최적화와 같은 작업을 수행하는 배포 폴더를 만듭니다.\n\n\n\n\n# 도커-작성\n\n마지막 단계는 결합된 docker 명령 docker-compose pull && docker-compose up(별도로 실행할 수도 있음). pull 명령은 docker hub에서 필요한 모든 이미지를 가져오고 up 명령은 컨테이너를 시작합니다.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\n컨테이너가 시작되면 터미널이 노드와 graphql 엔진의 상태를 보여주는 많은 텍스트를 뱉어내는 것을 볼 수 있습니다. 다음을 볼 때입니다.\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nsubquery 노드가 동기화를 시작했다는 것을 알고 있습니다.\n\n\n# 요약\n\n은밀히 일어나는 일에 대한 통찰력을 얻었으므로 이제 여기서부터 어디로 가야 합니까? 자신이 있다면 프로젝트 생성 방법과 세 가지 주요 파일에 대해 자세히 알아볼 수 있습니다. 매니페스트 파일, graphql 스키마 및 매핑 파일.\n\n그렇지 않으면 subquery의 호스팅된 인프라에서 이 hello world 예제를 실행하는 방법을 살펴보는 자습서 섹션을 계속 진행하고 시작 블록을 수정하는 방법을 살펴보고 즉시 사용 가능한 실행을 통해 subquery 프로젝트를 실행하는 방법에 대해 자세히 알아보겠습니다. 및 오픈 소스 프로젝트.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"로컬에서 하위 쿼리 실행",frontmatter:{summary:"로컬에서 하위 쿼리 실행 이 가이드는 인덱서와 쿼리 서비스를 모두 포함하는 인프라에서 로컬 SubQuery 노드를 실행하는 방법을 설명합니다. 자체 SubQuery 인프라를 실행하는 것에 대해 걱정하고 싶지 않으세요? SubQuery는 커뮤니티에 관리 호스팅 서비스를 무료로 제공합니다. 게시 가이드를 따라 프로젝트를 Su",meta:[{property:"og:url",content:"/ko/run/run.html"},{property:"og:title",content:"로컬에서 하위 쿼리 실행"},{property:"og:description",content:"로컬에서 하위 쿼리 실행 이 가이드는 인덱서와 쿼리 서비스를 모두 포함하는 인프라에서 로컬 SubQuery 노드를 실행하는 방법을 설명합니다. 자체 SubQuery 인프라를 실행하는 것에 대해 걱정하고 싶지 않으세요? SubQuery는 커뮤니티에 관리 호스팅 서비스를 무료로 제공합니다. 게시 가이드를 따라 프로젝트를 Su"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/run/run.html",relativePath:"ko/run/run.md",key:"v-72bdcd61",path:"/ko/run/run/",headers:[{level:2,title:"도커 사용",slug:"도커-사용",normalizedTitle:"도커 사용",charIndex:217},{level:2,title:"인덱서 실행 (subql/node)",slug:"인덱서-실행-subql-node",normalizedTitle:"인덱서 실행 (subql/node)",charIndex:514},{level:3,title:"설치",slug:"설치",normalizedTitle:"설치",charIndex:720},{level:3,title:"주요 명령",slug:"주요-명령",normalizedTitle:"주요 명령",charIndex:893},{level:2,title:"쿼리 서비스 실행(subql/query)",slug:"쿼리-서비스-실행-subql-query",normalizedTitle:"쿼리 서비스 실행(subql/query)",charIndex:4164},{level:3,title:"설치",slug:"설치-2",normalizedTitle:"설치",charIndex:720},{level:3,title:"쿼리 서비스 실행",slug:"쿼리-서비스-실행",normalizedTitle:"쿼리 서비스 실행",charIndex:4164}],readingTime:{minutes:1.22,words:365},headersStr:"도커 사용 인덱서 실행 (subql/node) 설치 주요 명령 쿼리 서비스 실행(subql/query) 설치 쿼리 서비스 실행",content:'# 로컬에서 하위 쿼리 실행\n\n이 가이드는 인덱서와 쿼리 서비스를 모두 포함하는 인프라에서 로컬 SubQuery 노드를 실행하는 방법을 설명합니다. 자체 SubQuery 인프라를 실행하는 것에 대해 걱정하고 싶지 않으세요? SubQuery는 커뮤니티에 관리 호스팅 서비스를 무료로 제공합니다. 게시 가이드를 따라 프로젝트를 SubQuery 프로젝트에 업로드하는 방법을 확인하세요.\n\n\n# 도커 사용\n\n다른 솔루션은 docker-compose.yml 파일로 정의된 Docker Container를 실행하는 것입니다. 방금 초기화된 새 프로젝트의 경우 여기에서 아무 것도 변경할 필요가 없습니다.\n\n프로젝트 디렉터리에서 다음 명령을 실행합니다.\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\n필요한 패키지(@subql/node, @subql/query 및 Postgres) 를 처음 다운로드하는 데 시간이 걸릴 수 있지만 곧 실행 중인 것을 볼 수 있습니다. 서브쿼리 노드.\n\n\n# 인덱서 실행 (subql/node)\n\n요구 사항:\n\n * Postgres 데이터베이스(버전 12 이상). SubQuery 노드가 블록체인을 인덱싱하는 동안 추출된 데이터는 외부 데이터베이스 인스턴스에 저장됩니다.\n\nSubQuery 노드는 SubQuery 프로젝트별로 기판 기반 블록체인 데이터를 추출하고 이를 Postgres 데이터베이스에 저장하는 구현입니다.\n\n\n# 설치\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nyarn global의 사용을 권장하지 않습니다. 잘못된 종속성 관리로 인해 오류가 발생할 수 있기 때문입니다.\n\n설치가 완료되면 다음 명령으로 노드를 시작할 수 있습니다.\n\nsubql-node <command>\n\n\n1\n\n\n\n# 주요 명령\n\n다음 명령은 SubQuery 노드 구성을 완료하고 인덱싱을 시작하는 데 도움이 됩니다. 자세히 알아보려면 언제든지 --help를 실행할 수 있습니다.\n\n# 로컬 프로젝트 경로를 가리킴\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\n전체 체인 사전을 사용하면 테스트 중 또는 첫 번째 색인 중에 SubQuery 프로젝트 처리 속도를 크게 높일 수 있습니다. 어떤 경우에는 인덱싱 성능이 최대 10배까지 향상되는 것을 보았습니다.\n\n전체 체인 사전은 특정 체인 내의 모든 이벤트 및 외부 요소의 위치를 미리 인덱싱하고 인덱싱할 때 노드 서비스가 각 블록을 검사하는 대신 관련 위치로 건너뛸 수 있도록 합니다.\n\nproject.yaml 파일(매니페스트 파일 참조)에 사전 끝점을 추가하거나 다음 명령을 사용하여 런타임에 지정할 수 있습니다.\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\nSubQuery 사전 작동 방식에 대해 자세히 알아보기\n\n# 데이터베이스에 연결\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\nPostgres 데이터베이스의 구성(예: 다른 데이터베이스 비밀번호)에 따라 인덱서(subql/node)와 쿼리 서비스(subql/query)가 모두 연결할 수 있는지 확인하십시오.\n\n# 구성 파일 지정\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\n그러면 쿼리 노드가 YAML 또는 JSON 형식일 수 있는 구성 파일을 가리킵니다. 아래의 예를 확인하세요.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# 블록 가져오기 배치 크기 변경\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\n인덱서가 체인을 처음 인덱싱할 때 단일 블록을 가져오면 성능이 크게 저하됩니다. 가져오는 블록 수를 조정하기 위해 배치 크기를 늘리면 전체 처리 시간이 줄어듭니다. 현재 기본 배치 크기는 100입니다.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\n디버깅을 위해 사용자는 로컬 모드에서 노드를 실행할 수 있습니다. 로컬 모델로 전환하면 기본 스키마 public에 Postgres 테이블이 생성됩니다.\n\n로컬 모드를 사용하지 않는 경우 초기 subquery_ 및 해당 프로젝트 테이블이 있는 새 Postgres 스키마가 생성됩니다.\n\n# 노드 상태 확인\n\n실행 중인 SubQuery 노드의 상태를 확인하고 모니터링하는 데 사용할 수 있는 2개의 엔드포인트가 있습니다.\n\n * 간단한 200 응답을 반환하는 상태 확인 엔드포인트\n * 실행 중인 SubQuery 노드에 대한 추가 분석을 포함하는 메타데이터 엔드포인트\n\n이것을 SubQuery 노드의 기본 URL에 추가합니다. 예를 들어 http://localhost:3000/meta는 다음을 반환합니다.\n\n{\n    "currentProcessingHeight": 1000699,\n    "currentProcessingTimestamp": 1631517883547,\n    "targetHeight": 6807295,\n    "bestHeight": 6807298,\n    "indexerNodeVersion": "0.19.1",\n    "lastProcessedHeight": 1000699,\n    "lastProcessedTimestamp": 1631517883555,\n    "uptime": 41.151789063,\n    "polkadotSdkVersion": "5.4.1",\n    "apiConnected": true,\n    "injectedApiConnected": true,\n    "usingDictionary": false,\n    "chain": "Polkadot",\n    "specName": "polkadot",\n    "genesisHash": "0x91b171bb158e2d3848fa23a9f1c25182fb8e20313b2c1eb49219da7a70ce90c3",\n    "blockTime": 6000\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nhttp://localhost:3000/health는 성공하면 HTTP 200을 반환합니다.\n\n인덱서가 정상이 아니면 500 오류가 반환됩니다. 인덱서가 정상이 아니면 500 오류가 반환됩니다.\n\n{\n    "status": 500,\n    "error": "Indexer is not healthy"\n}\n\n\n1\n2\n3\n4\n\n\n잘못된 URL을 사용하면 404 찾을 수 없음 오류가 반환됩니다.\n\n{\n"statusCode": 404,\n"message": "Cannot GET /healthy",\n"error": "Not Found"\n}\n\n\n1\n2\n3\n4\n5\n\n\n# 프로젝트 디버그\n\n노드 검사기를 사용하여 다음 명령어를 실행하세요.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\n예를 들어:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad에서 수신하는 디버거\n도움이 필요하면 https://nodejs.org/en/docs/inspector를 참조하세요.\n디버거가 연결되었습니다.\n\n\n1\n2\n3\n4\n\n\n그런 다음 Chrome 개발 도구를 열고 소스 > 파일 시스템을 만들고 프로젝트를 작업 공간에 추가하고 디버깅을 시작합니다. 자세한 내용은 다음을 확인하세요. SubQuery 프로젝트를 디버그하는 방법\n\n\n# 쿼리 서비스 실행(subql/query)\n\n\n# 설치\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nyarn global의 사용을 권장하지 않습니다. 잘못된 종속성 관리로 인해 오류가 발생할 수 있기 때문입니다.\n\n\n# 쿼리 서비스 실행\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\n프로젝트를 초기화할 때 프로젝트 이름이 프로젝트 이름과 동일한지 확인하세요. 또한 환경 변수가 올바른지 확인하십시오.\n\nSubql-query 서비스를 성공적으로 실행한 후 브라우저를 열고 http://localhost:3000으로 이동합니다. Explorer에 표시되는 GraphQL 플레이그라운드와 쿼리할 준비가 된 스키마가 표시되어야 합니다.',normalizedContent:'# 로컬에서 하위 쿼리 실행\n\n이 가이드는 인덱서와 쿼리 서비스를 모두 포함하는 인프라에서 로컬 subquery 노드를 실행하는 방법을 설명합니다. 자체 subquery 인프라를 실행하는 것에 대해 걱정하고 싶지 않으세요? subquery는 커뮤니티에 관리 호스팅 서비스를 무료로 제공합니다. 게시 가이드를 따라 프로젝트를 subquery 프로젝트에 업로드하는 방법을 확인하세요.\n\n\n# 도커 사용\n\n다른 솔루션은 docker-compose.yml 파일로 정의된 docker container를 실행하는 것입니다. 방금 초기화된 새 프로젝트의 경우 여기에서 아무 것도 변경할 필요가 없습니다.\n\n프로젝트 디렉터리에서 다음 명령을 실행합니다.\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\n필요한 패키지(@subql/node, @subql/query 및 postgres) 를 처음 다운로드하는 데 시간이 걸릴 수 있지만 곧 실행 중인 것을 볼 수 있습니다. 서브쿼리 노드.\n\n\n# 인덱서 실행 (subql/node)\n\n요구 사항:\n\n * postgres 데이터베이스(버전 12 이상). subquery 노드가 블록체인을 인덱싱하는 동안 추출된 데이터는 외부 데이터베이스 인스턴스에 저장됩니다.\n\nsubquery 노드는 subquery 프로젝트별로 기판 기반 블록체인 데이터를 추출하고 이를 postgres 데이터베이스에 저장하는 구현입니다.\n\n\n# 설치\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nyarn global의 사용을 권장하지 않습니다. 잘못된 종속성 관리로 인해 오류가 발생할 수 있기 때문입니다.\n\n설치가 완료되면 다음 명령으로 노드를 시작할 수 있습니다.\n\nsubql-node <command>\n\n\n1\n\n\n\n# 주요 명령\n\n다음 명령은 subquery 노드 구성을 완료하고 인덱싱을 시작하는 데 도움이 됩니다. 자세히 알아보려면 언제든지 --help를 실행할 수 있습니다.\n\n# 로컬 프로젝트 경로를 가리킴\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\n전체 체인 사전을 사용하면 테스트 중 또는 첫 번째 색인 중에 subquery 프로젝트 처리 속도를 크게 높일 수 있습니다. 어떤 경우에는 인덱싱 성능이 최대 10배까지 향상되는 것을 보았습니다.\n\n전체 체인 사전은 특정 체인 내의 모든 이벤트 및 외부 요소의 위치를 미리 인덱싱하고 인덱싱할 때 노드 서비스가 각 블록을 검사하는 대신 관련 위치로 건너뛸 수 있도록 합니다.\n\nproject.yaml 파일(매니페스트 파일 참조)에 사전 끝점을 추가하거나 다음 명령을 사용하여 런타임에 지정할 수 있습니다.\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\nsubquery 사전 작동 방식에 대해 자세히 알아보기\n\n# 데이터베이스에 연결\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\npostgres 데이터베이스의 구성(예: 다른 데이터베이스 비밀번호)에 따라 인덱서(subql/node)와 쿼리 서비스(subql/query)가 모두 연결할 수 있는지 확인하십시오.\n\n# 구성 파일 지정\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\n그러면 쿼리 노드가 yaml 또는 json 형식일 수 있는 구성 파일을 가리킵니다. 아래의 예를 확인하세요.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# 블록 가져오기 배치 크기 변경\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\n인덱서가 체인을 처음 인덱싱할 때 단일 블록을 가져오면 성능이 크게 저하됩니다. 가져오는 블록 수를 조정하기 위해 배치 크기를 늘리면 전체 처리 시간이 줄어듭니다. 현재 기본 배치 크기는 100입니다.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\n디버깅을 위해 사용자는 로컬 모드에서 노드를 실행할 수 있습니다. 로컬 모델로 전환하면 기본 스키마 public에 postgres 테이블이 생성됩니다.\n\n로컬 모드를 사용하지 않는 경우 초기 subquery_ 및 해당 프로젝트 테이블이 있는 새 postgres 스키마가 생성됩니다.\n\n# 노드 상태 확인\n\n실행 중인 subquery 노드의 상태를 확인하고 모니터링하는 데 사용할 수 있는 2개의 엔드포인트가 있습니다.\n\n * 간단한 200 응답을 반환하는 상태 확인 엔드포인트\n * 실행 중인 subquery 노드에 대한 추가 분석을 포함하는 메타데이터 엔드포인트\n\n이것을 subquery 노드의 기본 url에 추가합니다. 예를 들어 http://localhost:3000/meta는 다음을 반환합니다.\n\n{\n    "currentprocessingheight": 1000699,\n    "currentprocessingtimestamp": 1631517883547,\n    "targetheight": 6807295,\n    "bestheight": 6807298,\n    "indexernodeversion": "0.19.1",\n    "lastprocessedheight": 1000699,\n    "lastprocessedtimestamp": 1631517883555,\n    "uptime": 41.151789063,\n    "polkadotsdkversion": "5.4.1",\n    "apiconnected": true,\n    "injectedapiconnected": true,\n    "usingdictionary": false,\n    "chain": "polkadot",\n    "specname": "polkadot",\n    "genesishash": "0x91b171bb158e2d3848fa23a9f1c25182fb8e20313b2c1eb49219da7a70ce90c3",\n    "blocktime": 6000\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nhttp://localhost:3000/health는 성공하면 http 200을 반환합니다.\n\n인덱서가 정상이 아니면 500 오류가 반환됩니다. 인덱서가 정상이 아니면 500 오류가 반환됩니다.\n\n{\n    "status": 500,\n    "error": "indexer is not healthy"\n}\n\n\n1\n2\n3\n4\n\n\n잘못된 url을 사용하면 404 찾을 수 없음 오류가 반환됩니다.\n\n{\n"statuscode": 404,\n"message": "cannot get /healthy",\n"error": "not found"\n}\n\n\n1\n2\n3\n4\n5\n\n\n# 프로젝트 디버그\n\n노드 검사기를 사용하여 다음 명령어를 실행하세요.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\n예를 들어:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\nws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad에서 수신하는 디버거\n도움이 필요하면 https://nodejs.org/en/docs/inspector를 참조하세요.\n디버거가 연결되었습니다.\n\n\n1\n2\n3\n4\n\n\n그런 다음 chrome 개발 도구를 열고 소스 > 파일 시스템을 만들고 프로젝트를 작업 공간에 추가하고 디버깅을 시작합니다. 자세한 내용은 다음을 확인하세요. subquery 프로젝트를 디버그하는 방법\n\n\n# 쿼리 서비스 실행(subql/query)\n\n\n# 설치\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nyarn global의 사용을 권장하지 않습니다. 잘못된 종속성 관리로 인해 오류가 발생할 수 있기 때문입니다.\n\n\n# 쿼리 서비스 실행\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\n프로젝트를 초기화할 때 프로젝트 이름이 프로젝트 이름과 동일한지 확인하세요. 또한 환경 변수가 올바른지 확인하십시오.\n\nsubql-query 서비스를 성공적으로 실행한 후 브라우저를 열고 http://localhost:3000으로 이동합니다. explorer에 표시되는 graphql 플레이그라운드와 쿼리할 준비가 된 스키마가 표시되어야 합니다.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"샌드박스",frontmatter:{summary:"샌드박스 되는 사용 시나리오에서 SubQuery 노드는 일반적으로 신뢰할 수 있는 호스트에 의해 실행되며, 사용자가 노드에 제출한 SubQuery 프로젝트의 코드는 완전히 신뢰할 수 있는 것은 아닙니다. 일부 악의적인 코드는 호스트를 공격하거나 침해할 수 있으며 같은 호스트 내 다른 프로젝트의 데이터에 손상을 줄 수 있습",meta:[{property:"og:url",content:"/ko/run/sandbox.html"},{property:"og:title",content:"샌드박스"},{property:"og:description",content:"샌드박스 되는 사용 시나리오에서 SubQuery 노드는 일반적으로 신뢰할 수 있는 호스트에 의해 실행되며, 사용자가 노드에 제출한 SubQuery 프로젝트의 코드는 완전히 신뢰할 수 있는 것은 아닙니다. 일부 악의적인 코드는 호스트를 공격하거나 침해할 수 있으며 같은 호스트 내 다른 프로젝트의 데이터에 손상을 줄 수 있습"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/run/sandbox.html",relativePath:"ko/run/sandbox.md",key:"v-850bfe2e",path:"/ko/run/sandbox/",headers:[{level:2,title:"제한 사항",slug:"제한-사항",normalizedTitle:"제한 사항",charIndex:414}],readingTime:{minutes:.1,words:29},headersStr:"제한 사항",content:"# 샌드박스\n\n되는 사용 시나리오에서 SubQuery 노드는 일반적으로 신뢰할 수 있는 호스트에 의해 실행되며, 사용자가 노드에 제출한 SubQuery 프로젝트의 코드는 완전히 신뢰할 수 있는 것은 아닙니다.\n\n일부 악의적인 코드는 호스트를 공격하거나 침해할 수 있으며 같은 호스트 내 다른 프로젝트의 데이터에 손상을 줄 수 있습니다. 따라서, 위험을 줄이기 위해 VM2 샌드박스 보안 메커니즘을 사용합니다. 이는:\n\n * 신뢰할 수 없는 코드를 격리된 콘텍스트에서 안전하게 실행하고 악의적인 코드는 공개된 인터페이스를 통해 샌드박스에 주입하지 않는 한 호스트의 네트워크와 파일 시스템에 접근하지 않습니다.\n\n * 샌드박스 간에 메소드를 안전하게 호출하여 데이터와 콜백을 교환합니다.\n\n * 많은 기존의 공격방법에 면역이 있습니다.\n\n\n# 제한 사항\n\n * 특정 임베디드 모듈에 대한 액세스를 제한하기 위해 assert, buffer, crypto,util 와 path 만이 화이트 리스트에 표시됩니다.\n\n * 저희는 ESM 를 디폴트로서 사용하는CommonJS 과 hybrid등의 라이브러리, @polkadot/* 와 같은 기술된 3rd party modules 을 지원 합니다.\n\n * HTTP 을 사용하는 임의의 모듈 및 WebSocket 은 금지되어 있습니다.",normalizedContent:"# 샌드박스\n\n되는 사용 시나리오에서 subquery 노드는 일반적으로 신뢰할 수 있는 호스트에 의해 실행되며, 사용자가 노드에 제출한 subquery 프로젝트의 코드는 완전히 신뢰할 수 있는 것은 아닙니다.\n\n일부 악의적인 코드는 호스트를 공격하거나 침해할 수 있으며 같은 호스트 내 다른 프로젝트의 데이터에 손상을 줄 수 있습니다. 따라서, 위험을 줄이기 위해 vm2 샌드박스 보안 메커니즘을 사용합니다. 이는:\n\n * 신뢰할 수 없는 코드를 격리된 콘텍스트에서 안전하게 실행하고 악의적인 코드는 공개된 인터페이스를 통해 샌드박스에 주입하지 않는 한 호스트의 네트워크와 파일 시스템에 접근하지 않습니다.\n\n * 샌드박스 간에 메소드를 안전하게 호출하여 데이터와 콜백을 교환합니다.\n\n * 많은 기존의 공격방법에 면역이 있습니다.\n\n\n# 제한 사항\n\n * 특정 임베디드 모듈에 대한 액세스를 제한하기 위해 assert, buffer, crypto,util 와 path 만이 화이트 리스트에 표시됩니다.\n\n * 저희는 esm 를 디폴트로서 사용하는commonjs 과 hybrid등의 라이브러리, @polkadot/* 와 같은 기술된 3rd party modules 을 지원 합니다.\n\n * http 을 사용하는 임의의 모듈 및 websocket 은 금지되어 있습니다.",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"블록체인의 설치 뱃지 크기를 변경하려면 어떻게 해야 합니까?",frontmatter:{summary:"블록체인의 설치 뱃지 크기를 변경하려면 어떻게 해야 합니까? 비디오 가이드 소개 기본 뱃지 사이즈는 100 이지만, 이는 추가 명령어 --batch-size=xx를 사용하여 변경할 수 있습니다. 이는 추가 플래그로 명령줄에 대해 수행해야 합니다. 도커를 사용하는 경우에는 docker-compose.yml을 다음과 같이 변",meta:[{property:"og:url",content:"/ko/tutorials_examples/batch-size.html"},{property:"og:title",content:"블록체인의 설치 뱃지 크기를 변경하려면 어떻게 해야 합니까?"},{property:"og:description",content:"블록체인의 설치 뱃지 크기를 변경하려면 어떻게 해야 합니까? 비디오 가이드 소개 기본 뱃지 사이즈는 100 이지만, 이는 추가 명령어 --batch-size=xx를 사용하여 변경할 수 있습니다. 이는 추가 플래그로 명령줄에 대해 수행해야 합니다. 도커를 사용하는 경우에는 docker-compose.yml을 다음과 같이 변"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/tutorials_examples/batch-size.html",relativePath:"ko/tutorials_examples/batch-size.md",key:"v-1562e6e2",path:"/ko/tutorials_examples/batch-size/",headers:[{level:2,title:"비디오 가이드",slug:"비디오-가이드",normalizedTitle:"비디오 가이드",charIndex:40},{level:2,title:"소개",slug:"소개",normalizedTitle:"소개",charIndex:52},{level:2,title:"왜 뱃지 크기를 변경하나요?",slug:"왜-뱃지-크기를-변경하나요",normalizedTitle:"왜 뱃지 크기를 변경하나요?",charIndex:625}],readingTime:{minutes:.19,words:58},headersStr:"비디오 가이드 소개 왜 뱃지 크기를 변경하나요?",content:'# 블록체인의 설치 뱃지 크기를 변경하려면 어떻게 해야 합니까?\n\n\n# 비디오 가이드\n\n\n# 소개\n\n기본 뱃지 사이즈는 100 이지만, 이는 추가 명령어 --batch-size=xx를 사용하여 변경할 수 있습니다.\n\n이는 추가 플래그로 명령줄에 대해 수행해야 합니다. 도커를 사용하는 경우에는 docker-compose.yml을 다음과 같이 변경합니다:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n본 예에서는 배치 사이즈를 50으로 설정합니다.\n\n\n# 왜 뱃지 크기를 변경하나요?\n\n배치 크기를 작게 하면 메모리 사용량이 줄어들어 사용자가 큰 query를 받지 않게 됩니다. 즉, 애플리케이션의 응답성이 향상됩니다.',normalizedContent:'# 블록체인의 설치 뱃지 크기를 변경하려면 어떻게 해야 합니까?\n\n\n# 비디오 가이드\n\n\n# 소개\n\n기본 뱃지 사이즈는 100 이지만, 이는 추가 명령어 --batch-size=xx를 사용하여 변경할 수 있습니다.\n\n이는 추가 플래그로 명령줄에 대해 수행해야 합니다. 도커를 사용하는 경우에는 docker-compose.yml을 다음과 같이 변경합니다:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n본 예에서는 배치 사이즈를 50으로 설정합니다.\n\n\n# 왜 뱃지 크기를 변경하나요?\n\n배치 크기를 작게 하면 메모리 사용량이 줄어들어 사용자가 큰 query를 받지 않게 됩니다. 즉, 애플리케이션의 응답성이 향상됩니다.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"다른 블록의 높이부터 시작하려면 어떻게 해야 하죠?",frontmatter:{summary:"다른 블록의 높이부터 시작하려면 어떻게 해야 하죠? 비디오 가이드 소개 기본적으로 모든 스타터 프로젝트는 제네시스 블록에서 블록체인의 동기를 시작합니다. 즉, 블록1부터. 대규모 블록체인의 경우 완전히 동기화하는데 보통 며칠 또는 몇 주가 걸릴 수 있습니다. SubQuery 서브 쿼리 노드를 제로 이외 의 높이 에서 동기",meta:[{property:"og:url",content:"/ko/tutorials_examples/block-height.html"},{property:"og:title",content:"다른 블록의 높이부터 시작하려면 어떻게 해야 하죠?"},{property:"og:description",content:"다른 블록의 높이부터 시작하려면 어떻게 해야 하죠? 비디오 가이드 소개 기본적으로 모든 스타터 프로젝트는 제네시스 블록에서 블록체인의 동기를 시작합니다. 즉, 블록1부터. 대규모 블록체인의 경우 완전히 동기화하는데 보통 며칠 또는 몇 주가 걸릴 수 있습니다. SubQuery 서브 쿼리 노드를 제로 이외 의 높이 에서 동기"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/tutorials_examples/block-height.html",relativePath:"ko/tutorials_examples/block-height.md",key:"v-4942d669",path:"/ko/tutorials_examples/block-height/",headers:[{level:2,title:"비디오 가이드",slug:"비디오-가이드",normalizedTitle:"비디오 가이드",charIndex:35},{level:2,title:"소개",slug:"소개",normalizedTitle:"소개",charIndex:47},{level:2,title:"제로부터 시작해보는 게 어떤가요?",slug:"제로부터-시작해보는-게-어떤가요",normalizedTitle:"제로부터 시작해보는 게 어떤가요?",charIndex:742},{level:2,title:"처음부터 시작하지 않는 것의 단점은 무엇인가요?",slug:"처음부터-시작하지-않는-것의-단점은-무엇인가요",normalizedTitle:"처음부터 시작하지 않는 것의 단점은 무엇인가요?",charIndex:872},{level:2,title:"현재 블록체인의 높이를 어떻게 계산하나요?",slug:"현재-블록체인의-높이를-어떻게-계산하나요",normalizedTitle:"현재 블록체인의 높이를 어떻게 계산하나요?",charIndex:952},{level:2,title:"재구축이나 코드 생성을 해야 하나요?",slug:"재구축이나-코드-생성을-해야-하나요",normalizedTitle:"재구축이나 코드 생성을 해야 하나요?",charIndex:1060}],readingTime:{minutes:.27,words:81},headersStr:"비디오 가이드 소개 제로부터 시작해보는 게 어떤가요? 처음부터 시작하지 않는 것의 단점은 무엇인가요? 현재 블록체인의 높이를 어떻게 계산하나요? 재구축이나 코드 생성을 해야 하나요?",content:'# 다른 블록의 높이부터 시작하려면 어떻게 해야 하죠?\n\n\n# 비디오 가이드\n\n\n# 소개\n\n기본적으로 모든 스타터 프로젝트는 제네시스 블록에서 블록체인의 동기를 시작합니다. 즉, 블록1부터. 대규모 블록체인의 경우 완전히 동기화하는데 보통 며칠 또는 몇 주가 걸릴 수 있습니다.\n\nSubQuery 서브 쿼리 노드를 제로 이외 의 높이 에서 동기화 를 시작 하려면 project.yaml 파일 을 수정 하고 startBlock 키를 변경 하기 만 하면 됩니다.\n\n은 시작블록이 1,000,000으로 설정되어 있는 project.yaml 파일입니다\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# 제로부터 시작해보는 게 어떤가요?\n\n블록체인의 동기화 시간을 줄일 수 있다는 게 주된 이유입니다. 즉, 지난 3개월간의 거래에만 관심이 있는 경우 대기 시간이 적고 개발을 보다 빨리 시작할 수 있는 것은 지난 3개월뿐입니다.\n\n\n# 처음부터 시작하지 않는 것의 단점은 무엇인가요?\n\n가장 분명한 단점은 가지고 있지 않은 블록체인의 데이터를 조회할 수 없다는 것입니다.\n\n\n# 현재 블록체인의 높이를 어떻게 계산하나요?\n\nPolkadot 네트워크를 사용하고 있는 경우는,https://polkascan.io/에 액세스 해, "최종 블록"도를 표시할 수 있습니다.\n\n\n# 재구축이나 코드 생성을 해야 하나요?\n\n아니요. Project.yaml 파일은 기본적으로 구성 파일이므로 유형 스크립트 코드를 재구축 또는 재생성 할 필요가 없습니다.',normalizedContent:'# 다른 블록의 높이부터 시작하려면 어떻게 해야 하죠?\n\n\n# 비디오 가이드\n\n\n# 소개\n\n기본적으로 모든 스타터 프로젝트는 제네시스 블록에서 블록체인의 동기를 시작합니다. 즉, 블록1부터. 대규모 블록체인의 경우 완전히 동기화하는데 보통 며칠 또는 몇 주가 걸릴 수 있습니다.\n\nsubquery 서브 쿼리 노드를 제로 이외 의 높이 에서 동기화 를 시작 하려면 project.yaml 파일 을 수정 하고 startblock 키를 변경 하기 만 하면 됩니다.\n\n은 시작블록이 1,000,000으로 설정되어 있는 project.yaml 파일입니다\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# 제로부터 시작해보는 게 어떤가요?\n\n블록체인의 동기화 시간을 줄일 수 있다는 게 주된 이유입니다. 즉, 지난 3개월간의 거래에만 관심이 있는 경우 대기 시간이 적고 개발을 보다 빨리 시작할 수 있는 것은 지난 3개월뿐입니다.\n\n\n# 처음부터 시작하지 않는 것의 단점은 무엇인가요?\n\n가장 분명한 단점은 가지고 있지 않은 블록체인의 데이터를 조회할 수 없다는 것입니다.\n\n\n# 현재 블록체인의 높이를 어떻게 계산하나요?\n\npolkadot 네트워크를 사용하고 있는 경우는,https://polkascan.io/에 액세스 해, "최종 블록"도를 표시할 수 있습니다.\n\n\n# 재구축이나 코드 생성을 해야 하나요?\n\n아니요. project.yaml 파일은 기본적으로 구성 파일이므로 유형 스크립트 코드를 재구축 또는 재생성 할 필요가 없습니다.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"SubQuery 프로젝트를 어떻게 디버그할 수 있을까요?",frontmatter:{summary:"SubQuery 프로젝트를 어떻게 디버그할 수 있을까요? 비디오 가이드 소개 단계별 코드 실행, 중단점 설정, 변수 검사와 같은 SubQuery 프로젝트를 디버그하려면, Chrome 개발자 도구와 함께 Node.js 검사기를 사용해야 합니다. 노드 검사기 터미널 화면에서 다음 명령어를 실행합니다. 예시 Chrome 개발도",meta:[{property:"og:url",content:"/ko/tutorials_examples/debug-projects.html"},{property:"og:title",content:"SubQuery 프로젝트를 어떻게 디버그할 수 있을까요?"},{property:"og:description",content:"SubQuery 프로젝트를 어떻게 디버그할 수 있을까요? 비디오 가이드 소개 단계별 코드 실행, 중단점 설정, 변수 검사와 같은 SubQuery 프로젝트를 디버그하려면, Chrome 개발자 도구와 함께 Node.js 검사기를 사용해야 합니다. 노드 검사기 터미널 화면에서 다음 명령어를 실행합니다. 예시 Chrome 개발도"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/tutorials_examples/debug-projects.html",relativePath:"ko/tutorials_examples/debug-projects.md",key:"v-1a10bb0f",path:"/ko/tutorials_examples/debug-projects/",headers:[{level:2,title:"비디오 가이드",slug:"비디오-가이드",normalizedTitle:"비디오 가이드",charIndex:38},{level:2,title:"소개",slug:"소개",normalizedTitle:"소개",charIndex:50},{level:2,title:"노드 검사기",slug:"노드-검사기",normalizedTitle:"노드 검사기",charIndex:151},{level:2,title:"Chrome 개발도구",slug:"chrome-개발도구",normalizedTitle:"chrome 개발도구",charIndex:520}],readingTime:{minutes:.31,words:93},headersStr:"비디오 가이드 소개 노드 검사기 Chrome 개발도구",content:"# SubQuery 프로젝트를 어떻게 디버그할 수 있을까요?\n\n\n# 비디오 가이드\n\n\n# 소개\n\n단계별 코드 실행, 중단점 설정, 변수 검사와 같은 SubQuery 프로젝트를 디버그하려면, Chrome 개발자 도구와 함께 Node.js 검사기를 사용해야 합니다.\n\n\n# 노드 검사기\n\n터미널 화면에서 다음 명령어를 실행합니다.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\n예시\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# Chrome 개발도구\n\nChrome DevTools를 열고 소스 탭으로 이동합니다. 녹색 아이콘을 클릭하면 새 창이 열립니다.\n\n\n\n파일 시스템으로 이동하여 프로젝트 폴더를 작업 공간에 추가하십시오. 그런 다음 dist > mappings 폴더를 열고 디버그할 코드를 선택합니다. 이후 표준 디버깅 도구와 마찬가지로 코드를 단계별로 실행합니다.\n\n",normalizedContent:"# subquery 프로젝트를 어떻게 디버그할 수 있을까요?\n\n\n# 비디오 가이드\n\n\n# 소개\n\n단계별 코드 실행, 중단점 설정, 변수 검사와 같은 subquery 프로젝트를 디버그하려면, chrome 개발자 도구와 함께 node.js 검사기를 사용해야 합니다.\n\n\n# 노드 검사기\n\n터미널 화면에서 다음 명령어를 실행합니다.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\n예시\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# chrome 개발도구\n\nchrome devtools를 열고 소스 탭으로 이동합니다. 녹색 아이콘을 클릭하면 새 창이 열립니다.\n\n\n\n파일 시스템으로 이동하여 프로젝트 폴더를 작업 공간에 추가하십시오. 그런 다음 dist > mappings 폴더를 열고 디버그할 코드를 선택합니다. 이후 표준 디버깅 도구와 마찬가지로 코드를 단계별로 실행합니다.\n\n",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"SubQuery 사전은 어떻게 작동하나요?",frontmatter:{summary:"SubQuery 사전은 어떻게 작동하나요? 일반 사전 프로젝트의 모든 아이디어는 블록체인의 모든 데이터를 인덱싱하고 이벤트, 외부요인 및 해당 유형(모듈 및 메서드)을 블록 높이 순서대로 데이터베이스에 기록하는 것입니다. 그러면, 다른 프로젝트에서 network.dictionary 끝점을 매니페스트 파일에 정의된 기본 n",meta:[{property:"og:url",content:"/ko/tutorials_examples/dictionary.html"},{property:"og:title",content:"SubQuery 사전은 어떻게 작동하나요?"},{property:"og:description",content:"SubQuery 사전은 어떻게 작동하나요? 일반 사전 프로젝트의 모든 아이디어는 블록체인의 모든 데이터를 인덱싱하고 이벤트, 외부요인 및 해당 유형(모듈 및 메서드)을 블록 높이 순서대로 데이터베이스에 기록하는 것입니다. 그러면, 다른 프로젝트에서 network.dictionary 끝점을 매니페스트 파일에 정의된 기본 n"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/tutorials_examples/dictionary.html",relativePath:"ko/tutorials_examples/dictionary.md",key:"v-5e72676a",path:"/ko/tutorials_examples/dictionary/",headers:[{level:2,title:"프로젝트에 사전을 통합하는 방법은 무엇입니까?",slug:"프로젝트에-사전을-통합하는-방법은-무엇입니까",normalizedTitle:"프로젝트에 사전을 통합하는 방법은 무엇입니까?",charIndex:595},{level:2,title:"사전을 사용하지 않으면 어떻게 됩니까?",slug:"사전을-사용하지-않으면-어떻게-됩니까",normalizedTitle:"사전을 사용하지 않으면 어떻게 됩니까?",charIndex:875},{level:2,title:"사전이 사용되면 어떻게 됩니까?",slug:"사전이-사용되면-어떻게-됩니까",normalizedTitle:"사전이 사용되면 어떻게 됩니까?",charIndex:1088},{level:2,title:"사전이 유용하지 않은 경우는 언제입니까?",slug:"사전이-유용하지-않은-경우는-언제입니까",normalizedTitle:"사전이 유용하지 않은 경우는 언제입니까?",charIndex:1616}],readingTime:{minutes:.37,words:110},headersStr:"프로젝트에 사전을 통합하는 방법은 무엇입니까? 사전을 사용하지 않으면 어떻게 됩니까? 사전이 사용되면 어떻게 됩니까? 사전이 유용하지 않은 경우는 언제입니까?",content:'# SubQuery 사전은 어떻게 작동하나요?\n\n일반 사전 프로젝트의 모든 아이디어는 블록체인의 모든 데이터를 인덱싱하고 이벤트, 외부요인 및 해당 유형(모듈 및 메서드)을 블록 높이 순서대로 데이터베이스에 기록하는 것입니다. 그러면, 다른 프로젝트에서 network.dictionary 끝점을 매니페스트 파일에 정의된 기본 network.endpoint 을 대신하여 쿼리할 수 있습니다.\n\nnetwork.dictionary 끝점은 존재하는 경우에 SDK가 자동으로 감지하고 사용하는 선택적 매개변수입니다. network.endpoint는 필수이지만, 존재하지 않는다면 컴파일되지 않습니다.\n\nSubQuery 사전 프로젝트를 예로 들면, 스키마 파일은 3개의 엔티티; 외부, 이벤트, specVersion를 정의합니다. 이 3개의 엔터티에는 각각 6, 4, 2개의 필드가 있습니다. 이 프로젝트를 실행하면, 이러한 필드들이 데이터베이스 테이블에 반영됩니다.\n\n\n\n그런 다음 블록체인의 데이터는 이 테이블들에 저장되고 성능을 위해 인덱싱됩니다. 그러면 프로젝트가 SubQuery 프로젝트에서 호스팅되고, API 끝점을 매니페스트 파일에 추가할 수 있습니다.\n\n\n# 프로젝트에 사전을 통합하는 방법은 무엇입니까?\n\n메니페스트 네트워크 부분에 dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot를 추가하세요. 예시:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# 사전을 사용하지 않으면 어떻게 됩니까?\n\n사전을 사용하지 않는 경우, 인덱서는 기본적으로 100인 배치 크기 플래그에 따라 polkadot API를 통해 모든 블록 데이터를 가져와 처리를 위해 버퍼에 배치합니다. 나중에, 인덱서는 버퍼에서 이러한 모든 블록을 가져오고 블록 데이터를 처리하는 동안, 이러한 블록의 이벤트 및 외부가 사용자 정의 필터와 일치하는지 확인합니다.\n\n\n# 사전이 사용되면 어떻게 됩니까?\n\n사전이 사용되면, 인덱서는 먼저 호출 및 이벤트 필터를 매개변수로 사용하고 이를 GraphQL 쿼리에 병합합니다. 그런 다음 사전의 API를 사용하여 특정 이벤트 및 외부 요소만 포함하는 관련 블록 높이 목록을 얻습니다. 기본값이 사용되는 경우 종종 이 값은 100보다 훨씬 작습니다.\n\n예를 들어, 전송 이벤트를 인덱싱하는 상황을 상상해 보십시오. 모든 블록에 이 이벤트가 있는 것은 아닙니다(아래 이미지에서 블록 3과 4에는 전송 이벤트가 없습니다).\n\n\n\n사전을 사용하면 각 블록에서 전송 이벤트를 찾는 대신 프로젝트가 이를 건너뛸 수 있으므로, 블록 1, 2, 5만 건너뜁니다. 사전이 각 블록의 모든 호출 및 이벤트에 대한 미리 계산된 참조이기 때문입니다.\n\n이것은 사전을 사용하면 인덱서가 체인에서 얻는 데이터의 양을 줄이고 로컬 버퍼에 저장된 "원치 않는" 블록의 수를 줄일 수 있음을 의미합니다. 그러나 기존 방법과 비교하여, 사전의 API에서 데이터를 가져오는 추가 단계가 추가됩니다.\n\n\n# 사전이 유용하지 않은 경우는 언제입니까?\n\n블록 처리자를 사용하여 체인에서 데이터를 가져오면, 모든 블록을 처리해야 합니다. 따라서, 이 경우에 사전을 사용하는 것은 어떠한 이점도 제공하지 않으며 인덱서는 자동으로 기본 비사전 접근 방식으로 전환합니다.\n\n또한, timestamp.set과 같이 모든 블록에서 발생하거나 존재하는 이벤트 또는 외부를 처리할 때, 사전을 사용하는 것은 추가적인 이점을 제공하지 않습니다.',normalizedContent:'# subquery 사전은 어떻게 작동하나요?\n\n일반 사전 프로젝트의 모든 아이디어는 블록체인의 모든 데이터를 인덱싱하고 이벤트, 외부요인 및 해당 유형(모듈 및 메서드)을 블록 높이 순서대로 데이터베이스에 기록하는 것입니다. 그러면, 다른 프로젝트에서 network.dictionary 끝점을 매니페스트 파일에 정의된 기본 network.endpoint 을 대신하여 쿼리할 수 있습니다.\n\nnetwork.dictionary 끝점은 존재하는 경우에 sdk가 자동으로 감지하고 사용하는 선택적 매개변수입니다. network.endpoint는 필수이지만, 존재하지 않는다면 컴파일되지 않습니다.\n\nsubquery 사전 프로젝트를 예로 들면, 스키마 파일은 3개의 엔티티; 외부, 이벤트, specversion를 정의합니다. 이 3개의 엔터티에는 각각 6, 4, 2개의 필드가 있습니다. 이 프로젝트를 실행하면, 이러한 필드들이 데이터베이스 테이블에 반영됩니다.\n\n\n\n그런 다음 블록체인의 데이터는 이 테이블들에 저장되고 성능을 위해 인덱싱됩니다. 그러면 프로젝트가 subquery 프로젝트에서 호스팅되고, api 끝점을 매니페스트 파일에 추가할 수 있습니다.\n\n\n# 프로젝트에 사전을 통합하는 방법은 무엇입니까?\n\n메니페스트 네트워크 부분에 dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot를 추가하세요. 예시:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# 사전을 사용하지 않으면 어떻게 됩니까?\n\n사전을 사용하지 않는 경우, 인덱서는 기본적으로 100인 배치 크기 플래그에 따라 polkadot api를 통해 모든 블록 데이터를 가져와 처리를 위해 버퍼에 배치합니다. 나중에, 인덱서는 버퍼에서 이러한 모든 블록을 가져오고 블록 데이터를 처리하는 동안, 이러한 블록의 이벤트 및 외부가 사용자 정의 필터와 일치하는지 확인합니다.\n\n\n# 사전이 사용되면 어떻게 됩니까?\n\n사전이 사용되면, 인덱서는 먼저 호출 및 이벤트 필터를 매개변수로 사용하고 이를 graphql 쿼리에 병합합니다. 그런 다음 사전의 api를 사용하여 특정 이벤트 및 외부 요소만 포함하는 관련 블록 높이 목록을 얻습니다. 기본값이 사용되는 경우 종종 이 값은 100보다 훨씬 작습니다.\n\n예를 들어, 전송 이벤트를 인덱싱하는 상황을 상상해 보십시오. 모든 블록에 이 이벤트가 있는 것은 아닙니다(아래 이미지에서 블록 3과 4에는 전송 이벤트가 없습니다).\n\n\n\n사전을 사용하면 각 블록에서 전송 이벤트를 찾는 대신 프로젝트가 이를 건너뛸 수 있으므로, 블록 1, 2, 5만 건너뜁니다. 사전이 각 블록의 모든 호출 및 이벤트에 대한 미리 계산된 참조이기 때문입니다.\n\n이것은 사전을 사용하면 인덱서가 체인에서 얻는 데이터의 양을 줄이고 로컬 버퍼에 저장된 "원치 않는" 블록의 수를 줄일 수 있음을 의미합니다. 그러나 기존 방법과 비교하여, 사전의 api에서 데이터를 가져오는 추가 단계가 추가됩니다.\n\n\n# 사전이 유용하지 않은 경우는 언제입니까?\n\n블록 처리자를 사용하여 체인에서 데이터를 가져오면, 모든 블록을 처리해야 합니다. 따라서, 이 경우에 사전을 사용하는 것은 어떠한 이점도 제공하지 않으며 인덱서는 자동으로 기본 비사전 접근 방식으로 전환합니다.\n\n또한, timestamp.set과 같이 모든 블록에서 발생하거나 존재하는 이벤트 또는 외부를 처리할 때, 사전을 사용하는 것은 추가적인 이점을 제공하지 않습니다.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/ko/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/tutorials_examples/howto.html",relativePath:"ko/tutorials_examples/howto.md",key:"v-8e6581a6",path:"/ko/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"튜토리얼 & 예",frontmatter:{summary:"튜토리얼 & 예 여기에서 튜토리얼을 나열하고 가장 쉽고 빠른 방법으로 시작하고 실행하는 데 도움이 되는 다양한 예를 살펴보겠습니다. SubQuery Examples SubQuery 예들 예시 설명 주제 -------------------------------------------------------------------",meta:[{property:"og:url",content:"/ko/tutorials_examples/introduction.html"},{property:"og:title",content:"튜토리얼 & 예"},{property:"og:description",content:"튜토리얼 & 예 여기에서 튜토리얼을 나열하고 가장 쉽고 빠른 방법으로 시작하고 실행하는 데 도움이 되는 다양한 예를 살펴보겠습니다. SubQuery Examples SubQuery 예들 예시 설명 주제 -------------------------------------------------------------------"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/tutorials_examples/introduction.html",relativePath:"ko/tutorials_examples/introduction.md",key:"v-4cc22903",path:"/ko/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:81},{level:2,title:"SubQuery 예들",slug:"subquery-예들",normalizedTitle:"subquery 예들",charIndex:103}],readingTime:{minutes:.3,words:91},headersStr:"SubQuery Examples SubQuery 예들",content:"# 튜토리얼 & 예\n\n여기에서 튜토리얼을 나열하고 가장 쉽고 빠른 방법으로 시작하고 실행하는 데 도움이 되는 다양한 예를 살펴보겠습니다.\n\n\n# SubQuery Examples\n\n\n# SubQuery 예들\n\n예시                          설명                                                          주제\nextrinsic-finalized-block   해시로 query를 할 수 있도록 외부 항목을 인덱싱합니다.                           block handler 기능가 있는 가장 간단한 예\nblock-timestamp             각 최종 블록의 인덱스 타임스탬프                                          또 다른 간단한 call handler 기능\nvalidator-threshold         검증인을 선출하는 데 필요한 최소 스테이킹 금액을 인덱싱합니다.                         추가 온체인 데이터를 위해 @polkadot/api에 대한 __external calls__을 수행하는 보다\n                                                                                        복잡한 block handler 기능이 있습니다\nsum-reward                  스테이킹 본드, 보상, 블록 완료 이벤트 슬래시 인덱스                              event handlers 관계가 있는 보다 복잡한 one-to-many\nentity-relation             계정 간의 균형 전송을 색인화하고, 유틸리티 batchAll을 색인화하여 외부 호출의 내용을 찾습니다.   One-to-many 및 many-to-many 관계 및 복잡한 extrinsic handling\nKitty Chain                 Kitties의 인덱스 출생 정보.                                         __call handlers__에서 인덱싱된 데이터가 있는 복잡한 event handlers 및 custom\n                                                                                        chain",normalizedContent:"# 튜토리얼 & 예\n\n여기에서 튜토리얼을 나열하고 가장 쉽고 빠른 방법으로 시작하고 실행하는 데 도움이 되는 다양한 예를 살펴보겠습니다.\n\n\n# subquery examples\n\n\n# subquery 예들\n\n예시                          설명                                                          주제\nextrinsic-finalized-block   해시로 query를 할 수 있도록 외부 항목을 인덱싱합니다.                           block handler 기능가 있는 가장 간단한 예\nblock-timestamp             각 최종 블록의 인덱스 타임스탬프                                          또 다른 간단한 call handler 기능\nvalidator-threshold         검증인을 선출하는 데 필요한 최소 스테이킹 금액을 인덱싱합니다.                         추가 온체인 데이터를 위해 @polkadot/api에 대한 __external calls__을 수행하는 보다\n                                                                                        복잡한 block handler 기능이 있습니다\nsum-reward                  스테이킹 본드, 보상, 블록 완료 이벤트 슬래시 인덱스                              event handlers 관계가 있는 보다 복잡한 one-to-many\nentity-relation             계정 간의 균형 전송을 색인화하고, 유틸리티 batchall을 색인화하여 외부 호출의 내용을 찾습니다.   one-to-many 및 many-to-many 관계 및 복잡한 extrinsic handling\nkitty chain                 kitties의 인덱스 출생 정보.                                         __call handlers__에서 인덱싱된 데이터가 있는 복잡한 event handlers 및 custom\n                                                                                        chain",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"인덱서 노드를 실행하는 방법은 무엇인가요?",frontmatter:{summary:"인덱서 노드를 실행하는 방법은 무엇인가요? 비디오 가이드 소개 인덱서 노드를 실행하는 것은 Docker를 사용하거나 SubQuery 프로젝트에서 프로젝트를 호스팅하는 것 외에 다른 옵션입니다. 더 많은 시간과 노력이 필요하지만 SubQuery가 어떻게 작동하는지 이해하는 데 도움이 됩니다. Postgres 인프라에서 인덱",meta:[{property:"og:url",content:"/ko/tutorials_examples/run-indexer.html"},{property:"og:title",content:"인덱서 노드를 실행하는 방법은 무엇인가요?"},{property:"og:description",content:"인덱서 노드를 실행하는 방법은 무엇인가요? 비디오 가이드 소개 인덱서 노드를 실행하는 것은 Docker를 사용하거나 SubQuery 프로젝트에서 프로젝트를 호스팅하는 것 외에 다른 옵션입니다. 더 많은 시간과 노력이 필요하지만 SubQuery가 어떻게 작동하는지 이해하는 데 도움이 됩니다. Postgres 인프라에서 인덱"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/tutorials_examples/run-indexer.html",relativePath:"ko/tutorials_examples/run-indexer.md",key:"v-48dcaded",path:"/ko/tutorials_examples/run-indexer/",headers:[{level:2,title:"비디오 가이드",slug:"비디오-가이드",normalizedTitle:"비디오 가이드",charIndex:30},{level:2,title:"소개",slug:"소개",normalizedTitle:"소개",charIndex:42},{level:2,title:"Postgres",slug:"postgres",normalizedTitle:"postgres",charIndex:178},{level:2,title:"Subql/노드 설치",slug:"subql-노드-설치",normalizedTitle:"subql/노드 설치",charIndex:283},{level:2,title:"DB 구성 설정",slug:"db-구성-설정",normalizedTitle:"db 구성 설정",charIndex:514},{level:2,title:"프로젝트 인덱싱",slug:"프로젝트-인덱싱",normalizedTitle:"프로젝트 인덱싱",charIndex:839},{level:2,title:"Postgres 검사",slug:"postgres-검사",normalizedTitle:"postgres 검사",charIndex:1034}],readingTime:{minutes:.33,words:98},headersStr:"비디오 가이드 소개 Postgres Subql/노드 설치 DB 구성 설정 프로젝트 인덱싱 Postgres 검사",content:'# 인덱서 노드를 실행하는 방법은 무엇인가요?\n\n\n# 비디오 가이드\n\n\n# 소개\n\n인덱서 노드를 실행하는 것은 Docker를 사용하거나 SubQuery 프로젝트에서 프로젝트를 호스팅하는 것 외에 다른 옵션입니다. 더 많은 시간과 노력이 필요하지만 SubQuery가 어떻게 작동하는지 이해하는 데 도움이 됩니다.\n\n\n# Postgres\n\n인프라에서 인덱서 노드를 실행하려면 Postgres 데이터베이스를 설정해야 합니다. 여기에서 Postgres를 설치하고 버전이 12 이상인지 확인할 수 있습니다.\n\n\n# Subql/노드 설치\n\nSubQuery 노드를 실행하려면, 다음 명령을 실행합니다.\n\nnpm install -g @subql/node\n\n\n1\n\n\n-g 플래그는 OSX에서 위치가 /usr/local/lib/node_modules가 됨을 의미하는 전역적으로 설치함을 의미합니다.\n\n설치가 완료되면 다음을 실행하여 버전을 확인할 수 있습니다.\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# DB 구성 설정\n\n다음으로, 다음 환경 변수를 설정해야 합니다.\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\n\n\n1\n2\n3\n4\n5\n\n\n물론, 위의 키들이 다른 값이 있는 경우, 그에 따라 조정하십시오. env 명령은 현재 환경 변수를 표시하며 이 프로세스는 이러한 값만 임시로 설정합니다. 즉, 터미널 세션 동안에만 유효합니다. 영구적으로 설정하려면, 대신 ~/bash_profile에 저장하십시오.\n\n\n# 프로젝트 인덱싱\n\n프로젝트 인덱싱을 시작하려면, 프로젝트 폴더로 이동하여 다음 명령을 실행합니다.\n\nsubql-node -f .\n\n\n1\n\n\n편한 프로젝트가 없다면, git clone https://github.com/subquery/subql-helloworld하십시오. 인덱서 노드가 작동하고 블록 인덱싱을 시작하는 것을 볼 수 있습니다.\n\n\n# Postgres 검사\n\nPostgres로 이동하면, 두 개의 테이블이 생성된 것을 볼 수 있습니다. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries는 시작 시 "현재 상태를 이해"하기 위해 인덱서가 확인하는 행을 하나만 포함하므로 계속되는 위치를 알 수 있습니다. starter_entities 테이블에는 인덱스가 포함되어 있습니다. 데이터를 보려면 subquery_1.starter_entities에서 select(*)를 실행합니다.',normalizedContent:'# 인덱서 노드를 실행하는 방법은 무엇인가요?\n\n\n# 비디오 가이드\n\n\n# 소개\n\n인덱서 노드를 실행하는 것은 docker를 사용하거나 subquery 프로젝트에서 프로젝트를 호스팅하는 것 외에 다른 옵션입니다. 더 많은 시간과 노력이 필요하지만 subquery가 어떻게 작동하는지 이해하는 데 도움이 됩니다.\n\n\n# postgres\n\n인프라에서 인덱서 노드를 실행하려면 postgres 데이터베이스를 설정해야 합니다. 여기에서 postgres를 설치하고 버전이 12 이상인지 확인할 수 있습니다.\n\n\n# subql/노드 설치\n\nsubquery 노드를 실행하려면, 다음 명령을 실행합니다.\n\nnpm install -g @subql/node\n\n\n1\n\n\n-g 플래그는 osx에서 위치가 /usr/local/lib/node_modules가 됨을 의미하는 전역적으로 설치함을 의미합니다.\n\n설치가 완료되면 다음을 실행하여 버전을 확인할 수 있습니다.\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# db 구성 설정\n\n다음으로, 다음 환경 변수를 설정해야 합니다.\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\n\n\n1\n2\n3\n4\n5\n\n\n물론, 위의 키들이 다른 값이 있는 경우, 그에 따라 조정하십시오. env 명령은 현재 환경 변수를 표시하며 이 프로세스는 이러한 값만 임시로 설정합니다. 즉, 터미널 세션 동안에만 유효합니다. 영구적으로 설정하려면, 대신 ~/bash_profile에 저장하십시오.\n\n\n# 프로젝트 인덱싱\n\n프로젝트 인덱싱을 시작하려면, 프로젝트 폴더로 이동하여 다음 명령을 실행합니다.\n\nsubql-node -f .\n\n\n1\n\n\n편한 프로젝트가 없다면, git clone https://github.com/subquery/subql-helloworld하십시오. 인덱서 노드가 작동하고 블록 인덱싱을 시작하는 것을 볼 수 있습니다.\n\n\n# postgres 검사\n\npostgres로 이동하면, 두 개의 테이블이 생성된 것을 볼 수 있습니다. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries는 시작 시 "현재 상태를 이해"하기 위해 인덱서가 확인하는 행을 하나만 포함하므로 계속되는 위치를 알 수 있습니다. starter_entities 테이블에는 인덱스가 포함되어 있습니다. 데이터를 보려면 subquery_1.starter_entities에서 select(*)를 실행합니다.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"술어",frontmatter:{summary:"술어 SubQuery 프로젝트(마법이 일어나는 곳): SubQuery 노드가 프로젝트 네트워크를 순회하고 집계하는 방법과 데이터가 변환되는 방법에 대한 정의(@subql/cli) 유용한 GraphQL 쿼리를 활성화하기 위해 저장; SubQuery 노드(작업이 완료된 곳): SubQuery 프로젝트 정의를 수락하고 연결된 ",meta:[{property:"og:url",content:"/ko/tutorials_examples/terminology.html"},{property:"og:title",content:"술어"},{property:"og:description",content:"술어 SubQuery 프로젝트(마법이 일어나는 곳): SubQuery 노드가 프로젝트 네트워크를 순회하고 집계하는 방법과 데이터가 변환되는 방법에 대한 정의(@subql/cli) 유용한 GraphQL 쿼리를 활성화하기 위해 저장; SubQuery 노드(작업이 완료된 곳): SubQuery 프로젝트 정의를 수락하고 연결된 "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ko/tutorials_examples/terminology.html",relativePath:"ko/tutorials_examples/terminology.md",key:"v-215f842d",path:"/ko/tutorials_examples/terminology/",readingTime:{minutes:.16,words:49},headersStr:null,content:"# 술어\n\n * SubQuery 프로젝트(마법이 일어나는 곳): SubQuery 노드가 프로젝트 네트워크를 순회하고 집계하는 방법과 데이터가 변환되는 방법에 대한 정의(@subql/cli) 유용한 GraphQL 쿼리를 활성화하기 위해 저장\n * SubQuery 노드(작업이 완료된 곳): SubQuery 프로젝트 정의를 수락하고 연결된 네트워크를 지속적으로 인덱싱하는 노드를 실행하는 패키지(@subql/node) 데이터베이스에\n * SubQuery 쿼리 서비스(데이터를 가져오는 위치): 배포된 SubQuery 노드의 GraphQL API와 상호 작용하여 쿼리하고 확인하는 패키지(@subql/query) 인덱싱된 데이터\n * GraphQL (how we query the data): 유연한 그래프 기반 데이터에 특히 적합한 API 쿼리 언어 - graphql.org를 참조",normalizedContent:"# 술어\n\n * subquery 프로젝트(마법이 일어나는 곳): subquery 노드가 프로젝트 네트워크를 순회하고 집계하는 방법과 데이터가 변환되는 방법에 대한 정의(@subql/cli) 유용한 graphql 쿼리를 활성화하기 위해 저장\n * subquery 노드(작업이 완료된 곳): subquery 프로젝트 정의를 수락하고 연결된 네트워크를 지속적으로 인덱싱하는 노드를 실행하는 패키지(@subql/node) 데이터베이스에\n * subquery 쿼리 서비스(데이터를 가져오는 위치): 배포된 subquery 노드의 graphql api와 상호 작용하여 쿼리하고 확인하는 패키지(@subql/query) 인덱싱된 데이터\n * graphql (how we query the data): 유연한 그래프 기반 데이터에 특히 적합한 api 쿼리 언어 - graphql.org를 참조",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/miscellaneous/ambassadors.html",relativePath:"miscellaneous/ambassadors.md",key:"v-ae40a866",path:"/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/miscellaneous/branding.html",relativePath:"miscellaneous/branding.md",key:"v-a45391be",path:"/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/miscellaneous/contributing.html",relativePath:"miscellaneous/contributing.md",key:"v-6d299e43",path:"/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/miscellaneous/social_media.html",relativePath:"miscellaneous/social_media.md",key:"v-034044f3",path:"/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:531}],readingTime:{minutes:.62,words:187},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Linktree\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.\n\n * Telegram (Chinese)\n * Telegram (Russian)\n * Telegram (Spanish)\n * Telegram (Thai)\n * Telegram (Turkish)\n * Telegram (Vietnamese)\n * Telegram (Vietnamese Announcement)",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * linktree\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.\n\n * telegram (chinese)\n * telegram (russian)\n * telegram (spanish)\n * telegram (thai)\n * telegram (turkish)\n * telegram (vietnamese)\n * telegram (vietnamese announcement)",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Connect to your new project",frontmatter:{summary:"Connect to your new project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/publish/connect.html"},{property:"og:title",content:"Connect to your new project"},{property:"og:description",content:"Connect to your new project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/publish/connect.html",relativePath:"publish/connect.md",key:"v-b6710da6",path:"/publish/connect/",readingTime:{minutes:.58,words:174},headersStr:null,content:"# Connect to your new project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Publish your SubQuery project",frontmatter:{summary:"Publish your SubQuery project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery project"},{property:"og:description",content:"Publish your SubQuery project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/publish/publish.html",relativePath:"publish/publish.md",key:"v-529f2d66",path:"/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3805},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4260}],readingTime:{minutes:3.68,words:1105},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. We're almost there! We just need to deploy a new version of it.\n\n\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. we're almost there! we just need to deploy a new version of it.\n\n\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Deploy a new version of your SubQuery project",frontmatter:{summary:"Deploy a new version of your SubQuery project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/publish/upgrade.html"},{property:"og:title",content:"Deploy a new version of your SubQuery project"},{property:"og:description",content:"Deploy a new version of your SubQuery project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/publish/upgrade.html",relativePath:"publish/upgrade.md",key:"v-5be2726d",path:"/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:2306}],readingTime:{minutes:1.69,words:506},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a new version of your SubQuery project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLog into SubQuery Project and select the project you want to deploy a new version of. You can choose to either deploy to the production or staging slot. These two slots are isolated environments and each has their own databases and synchronise independently.\n\nWe recommend deploying to your staging slot only for final staging testing or when you need to resync your project data. You can then promote it to production with zero downtime. You will find testing is faster when running a project locally as you can more easily debug issues.\n\nThe staging slot is perfect for:\n\n * Final validation of changes to your SubQuery Project in a separate environment. The staging slot has a different URL to production that you can use in your dApps.\n * Warming up and indexing data for an updated SubQuery project to eliminate downtime in your dApp\n * Preparing a new release for your SubQuery Project without exposing it publicly. The staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlog into subquery project and select the project you want to deploy a new version of. you can choose to either deploy to the production or staging slot. these two slots are isolated environments and each has their own databases and synchronise independently.\n\nwe recommend deploying to your staging slot only for final staging testing or when you need to resync your project data. you can then promote it to production with zero downtime. you will find testing is faster when running a project locally as you can more easily debug issues.\n\nthe staging slot is perfect for:\n\n * final validation of changes to your subquery project in a separate environment. the staging slot has a different url to production that you can use in your dapps.\n * warming up and indexing data for an updated subquery project to eliminate downtime in your dapp\n * preparing a new release for your subquery project without exposing it publicly. the staging slot is not shown to the public in the explorer and has a unique url that is visible only to you.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/query/graphql.html",relativePath:"query/graphql.md",key:"v-31c257a6",path:"/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/query/query.html",relativePath:"query/query.md",key:"v-ecedcbe6",path:"/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/quickstart/helloworld-hosted.html",relativePath:"quickstart/helloworld-hosted.md",key:"v-562bf2a5",path:"/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"1. Create your project",slug:"_1-create-your-project",normalizedTitle:"1. create your project",charIndex:1058},{level:2,title:"2. Create a GitHub repo",slug:"_2-create-a-github-repo",normalizedTitle:"2. create a github repo",charIndex:1349},{level:2,title:"3. Push to GitHub",slug:"_3-push-to-github",normalizedTitle:"3. push to github",charIndex:1602},{level:2,title:"4. Create your project",slug:"_4-create-your-project",normalizedTitle:"4. create your project",charIndex:3346},{level:2,title:"5. Deploy your project",slug:"_5-deploy-your-project",normalizedTitle:"5. deploy your project",charIndex:4559},{level:2,title:"6. Testing your project",slug:"_6-testing-your-project",normalizedTitle:"6. testing your project",charIndex:6068},{level:2,title:"7. Bonus step",slug:"_7-bonus-step",normalizedTitle:"7. bonus step",charIndex:6311},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7763}],readingTime:{minutes:4.66,words:1398},headersStr:"Learning objectives Intended audience Video guide Pre-requisites 1. Create your project 2. Create a GitHub repo 3. Push to GitHub 4. Create your project 5. Deploy your project 6. Testing your project 7. Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# 1. Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# 2. Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# 3. Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# 4. Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# 5. Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# 6. Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# 7. Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# 1. create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# 2. create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# 3. push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# 4. create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# 5. deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# 6. testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# 7. bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/quickstart/helloworld-localhost.html",relativePath:"quickstart/helloworld-localhost.md",key:"v-bc9cfe26",path:"/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"1. Initialise project",slug:"_1-initialise-project",normalizedTitle:"1. initialise project",charIndex:1455},{level:2,title:"2. Install dependencies",slug:"_2-install-dependencies",normalizedTitle:"2. install dependencies",charIndex:2030},{level:2,title:"3. Generate code",slug:"_3-generate-code",normalizedTitle:"3. generate code",charIndex:2451},{level:2,title:"4. Build code",slug:"_4-build-code",normalizedTitle:"4. build code",charIndex:3040},{level:2,title:"5. Run Docker",slug:"_5-run-docker",normalizedTitle:"5. run docker",charIndex:3251},{level:2,title:"6. Browse playground",slug:"_6-browse-playground",normalizedTitle:"6. browse playground",charIndex:4513},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:4949}],readingTime:{minutes:2.93,words:879},headersStr:"Learning objectives Intended audience Video guide Pre-requisites 1. Initialise project 2. Install dependencies 3. Generate code 4. Build code 5. Run Docker 6. Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# 1. Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# 2. Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\nyarn install\n\n\n1\n\n\nnpm install\n\n\n1\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 3. Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\nyarn codegen\n\n\n1\n\n\nnpm run-script codegen\n\n\n1\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# 4. Build code\n\nThe next step is to build the code with yarn build.\n\nyarn build\n\n\n1\n\n\nnpm run-script build\n\n\n1\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# 5. Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 6. Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# 1. initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# 2. install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\nyarn install\n\n\n1\n\n\nnpm install\n\n\n1\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 3. generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\nyarn codegen\n\n\n1\n\n\nnpm run-script codegen\n\n\n1\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# 4. build code\n\nthe next step is to build the code with yarn build.\n\nyarn build\n\n\n1\n\n\nnpm run-script build\n\n\n1\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# 5. run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 6. browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/quickstart/quickstart.html",relativePath:"quickstart/quickstart.md",key:"v-867568e6",path:"/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2565},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3008},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3371},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3595},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3948},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4515},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5202}],readingTime:{minutes:3.33,words:999},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\nyarn install\n\n\n1\n2\n\n\ncd PROJECT_NAME\nnpm install\n\n\n1\n2\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\nyarn codegen\n\n\n1\n\n\nnpm run-script codegen\n\n\n1\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\nyarn build\n\n\n1\n\n\nnpm run-script build\n\n\n1\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\nyarn install\n\n\n1\n2\n\n\ncd project_name\nnpm install\n\n\n1\n2\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\nyarn codegen\n\n\n1\n\n\nnpm run-script codegen\n\n\n1\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\nyarn build\n\n\n1\n\n\nnpm run-script build\n\n\n1\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/quickstart/understanding-helloworld.html",relativePath:"quickstart/understanding-helloworld.md",key:"v-d4874966",path:"/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Command Line Flags",frontmatter:{summary:"Command Line Flags subql-node --help This shows the help options. --version This displays the current version. -f, --subquery Use this flag to start the SubQuery project. --subquer",meta:[{property:"og:url",content:"/references/references.html"},{property:"og:title",content:"Command Line Flags"},{property:"og:description",content:"Command Line Flags subql-node --help This shows the help options. --version This displays the current version. -f, --subquery Use this flag to start the SubQuery project. --subquer"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/references/references.html",relativePath:"references/references.md",key:"v-b4ffb0e6",path:"/references/references/",headers:[{level:2,title:"subql-node",slug:"subql-node",normalizedTitle:"subql-node",charIndex:25},{level:3,title:"--help",slug:"help",normalizedTitle:"--help",charIndex:40},{level:3,title:"--version",slug:"version",normalizedTitle:"--version",charIndex:194},{level:3,title:"-f, --subquery",slug:"f-subquery",normalizedTitle:"-f, --subquery",charIndex:271},{level:3,title:"--subquery-name",slug:"subquery-name",normalizedTitle:"--subquery-name",charIndex:356},{level:3,title:"-c, --config",slug:"c-config",normalizedTitle:"-c, --config",charIndex:433},{level:3,title:"--local",slug:"local",normalizedTitle:"--local",charIndex:518},{level:3,title:"--batch-size",slug:"batch-size",normalizedTitle:"--batch-size",charIndex:599},{level:3,title:"--debug",slug:"debug",normalizedTitle:"--debug",charIndex:840},{level:3,title:"--profiler",slug:"profiler",normalizedTitle:"--profiler",charIndex:1058},{level:3,title:"--network-endpoint",slug:"network-endpoint",normalizedTitle:"--network-endpoint",charIndex:1211},{level:3,title:"--output-fmt",slug:"output-fmt",normalizedTitle:"--output-fmt",charIndex:1292},{level:3,title:"--log-level",slug:"log-level",normalizedTitle:"--log-level",charIndex:1433},{level:3,title:"--timestamp-field",slug:"timestamp-field",normalizedTitle:"--timestamp-field",charIndex:1864},{level:3,title:"-d, --network-dictionary",slug:"d-network-dictionary",normalizedTitle:"-d, --network-dictionary",charIndex:2020},{level:2,title:"subql-query",slug:"subql-query",normalizedTitle:"subql-query",charIndex:9120},{level:3,title:"--help",slug:"help-2",normalizedTitle:"--help",charIndex:40},{level:3,title:"--version",slug:"version-2",normalizedTitle:"--version",charIndex:194},{level:3,title:"-n, --name",slug:"n-name",normalizedTitle:"-n, --name",charIndex:9342},{level:3,title:"--playground",slug:"playground",normalizedTitle:"--playground",charIndex:9427},{level:3,title:"--output-fmt",slug:"output-fmt-2",normalizedTitle:"--output-fmt",charIndex:1292},{level:3,title:"--log-level",slug:"log-level-2",normalizedTitle:"--log-level",charIndex:1433}],readingTime:{minutes:4.86,words:1457},headersStr:"subql-node --help --version -f, --subquery --subquery-name -c, --config --local --batch-size --debug --profiler --network-endpoint --output-fmt --log-level --timestamp-field -d, --network-dictionary subql-query --help --version -n, --name --playground --output-fmt --log-level",content:'# Command Line Flags\n\n\n# subql-node\n\n\n# --help\n\nThis shows the help options.\n\n> subql-node --help\nOptions:\n      --help                Show help                                  [boolean]\n      --version             Show version number                        [boolean]\n  -f, --subquery            Local path of the subquery project          [string]\n      --subquery-name       Name of the subquery project                [string]\n  -c, --config              Specify configuration file                  [string]\n      --local               Use local mode                             [boolean]\n      --batch-size          Batch size of blocks to fetch in one round  [number]\n      --timeout             Timeout for indexer sandbox to execute the mapping\n                            functions                                   [number]\n      --debug               Show debug information to console output. will\n                            forcefully set log level to debug\n                                                      [boolean] [default: false]\n      --profiler            Show profiler information to console output\n                                                      [boolean] [default: false]\n      --network-endpoint    Blockchain network endpoint to connect      [string]\n      --output-fmt          Print log as json or plain text\n                                           [string] [choices: "json", "colored"]\n      --log-level           Specify log level to print. Ignored when --debug is\n                            used\n          [string] [choices: "fatal", "error", "warn", "info", "debug", "trace",\n                                                                       "silent"]\n      --migrate             Migrate db schema (for management tables only)\n                                                      [boolean] [default: false]\n      --timestamp-field     Enable/disable created_at and updated_at in schema\n                                                       [boolean] [default: true]\n  -d, --network-dictionary  Specify the dictionary api for this network [string]\n      --proof-of-index      Enable/disable proof of index\n                                                      [boolean] [default: false]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n\n# --version\n\nThis displays the current version.\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# -f, --subquery\n\nUse this flag to start the SubQuery project.\n\nsubql-node -f . // OR\nsubql-node --subquery .\n\n\n1\n2\n\n\n\n# --subquery-name\n\nThis flag allows you to provide a name for your project which acts as if it creates an instance of your project. Upon providing a new name, a new database schema is created and block synchronisation starts from zero.\n\nsubql-node -f . --subquery-name=test2\n\n\n1\n\n\n\n# -c, --config\n\nAll these various configurations can be placed into a .yml or .json file and then referenced with the config flag.\n\nSample subquery_config.yml file:\n\nsubquery: . // Mandatory. This is the local path of the project. The period here means the current local directory.\nsubqueryName: hello // Optional name\nbatchSize: 55 // Optional config\n\n\n1\n2\n3\n\n\nPlace this file in the same directory as the project. Then in the current project directory, run:\n\n> subql-node -c ./subquery_config.yml\n\n\n1\n\n\n\n# --local\n\nThis flag is primarily used for debugging purposes where it creates the default starter_entity table in the default "postgres" schema.\n\nsubql-node -f . --local\n\n\n1\n\n\nNote that once you use this flag, removing it won\'t mean that it will point to another database. To repoint to another database you will have to create a NEW database and change the env settings to this new database. In other words, "export DB_DATABASE=<new_db_here>"\n\n\n# --batch-size\n\nThis flag allows you to set the batch size in the command line. If batch size is also set in the config file, this takes precedent.\n\n> subql-node -f . --batch-size=20\n2021-08-09T23:24:43.775Z <fetch> INFO fetch block [6601,6620], total 20 blocks\n2021-08-09T23:24:45.606Z <fetch> INFO fetch block [6621,6640], total 20 blocks\n2021-08-09T23:24:47.415Z <fetch> INFO fetch block [6641,6660], total 20 blocks\n2021-08-09T23:24:49.235Z <fetch> INFO fetch block [6661,6680], total 20 blocks\n\n\n1\n2\n3\n4\n5\n\n\n\n# --debug\n\nThis outputs debug information to the console output and forcefully sets the log level to debug.\n\n> subql-node -f . --debug\n2021-08-10T11:45:39.471Z <db> DEBUG Executing (1b0d0c23-d7c7-4adb-a703-e4e5c414e035): INSERT INTO "subquery_1"."starter_entities" ("id","block_height","created_at","updated_at") VALUES ($1,$2,$3,$4) ON CONFLICT ("id") DO UPDATE SET "id"=EXCLUDED."id","block_height"=EXCLUDED."block_height","updated_at"=EXCLUDED."updated_at" RETURNING "id","block_height","created_at","updated_at";\n2021-08-10T11:45:39.472Z <db> DEBUG Executing (default): UPDATE "subqueries" SET "next_block_height"=$1,"updated_at"=$2 WHERE "id" = $3\n2021-08-10T11:45:39.472Z <db> DEBUG Executing (1b0d0c23-d7c7-4adb-a703-e4e5c414e035): COMMIT;\n\n\n1\n2\n3\n4\n\n\n\n# --profiler\n\nThis shows profiler information.\n\nsubql-node -f . --local --profiler\n2021-08-10T10:57:07.234Z <profiler> INFO FetchService, fetchMeta, 3876 ms\n2021-08-10T10:57:08.095Z <profiler> INFO FetchService, fetchMeta, 774 ms\n2021-08-10T10:57:10.361Z <profiler> INFO SubstrateUtil, fetchBlocksBatches, 2265 ms\n2021-08-10T10:57:10.361Z <fetch> INFO fetch block [3801,3900], total 100 blocks\n\n\n1\n2\n3\n4\n5\n\n\n\n# --network-endpoint\n\nThis flag allows users to override the network endpoint configuration from the manifest file.\n\nsubql-node -f . --network-endpoint="wss://polkadot.api.onfinality.io/public-ws"\n\n\n1\n\n\nNote that this must also be set in the manifest file, otherwise you\'ll get:\n\nERROR Create Subquery project from given path failed! Error: failed to parse project.yaml.\nAn instance of ProjectManifestImpl has failed the validation:\n - property network has failed the following constraints: isObject\n - property network.network has failed the following constraints: nestedValidation\n\n\n1\n2\n3\n4\n\n\n\n# --output-fmt\n\nThere are two different terminal output formats. JSON or colored. Colored is the default and contains colored text.\n\n> subql-node -f . --output-fmt=json\n{"level":"info","timestamp":"2021-08-10T11:58:18.087Z","pid":24714,"hostname":"P.local","category":"fetch","message":"fetch block [10501,10600], total 100 blocks"}\n\n\n1\n2\n\n\n> subql-node -f . --output-fmt=colored\n2021-08-10T11:57:41.480Z <subql-node> INFO node started\n(node:24707) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n2021-08-10T11:57:48.981Z <fetch> INFO fetch block [10201,10300], total 100 blocks\n2021-08-10T11:57:51.862Z <fetch> INFO fetch block [10301,10400], total 100 blocks\n\n\n1\n2\n3\n4\n5\n\n\n\n# --log-level\n\nThere are 7 options to choose from. “fatal”, “error”, “warn”, “info”, “debug”, “trace”, “silent”. The example below shows silent. Nothing will be printed in the terminal so the only way to tell if the node is working or not is to query the database for row count (select count(*) from subquery_1.starter_entities) or query the block height.\n\n> subql-node -f . --log-level=silent\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(Use `node --trace-warnings ...` to show where the warning was created)\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [DEP0152] DeprecationWarning: Custom PerformanceEntry accessors are deprecated. Please use the detail property.\n(node:24686) [PINODEP007] Warning: bindings.level is deprecated, use options.level option instead\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# --timestamp-field\n\nBy default this is true. when set to false with:\n\n> subql-node -f . –timestamp-field=false\n\n\n1\n\n\nThis removes the created_at and updated_at columns in the starter_entities table.\n\n\n# -d, --network-dictionary\n\nThis allows you to specify a dictionary endpoint which is a free service that is provided and hosted at: https://explorer.subquery.network/ (search for dictionary) and presents an API endpoint of: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\nTypically this would be set in your manifest file but below shows an example of using it as an argument in the command line.\n\nsubql-node -f . -d "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\n\n1\n\n\nRead more about how a SubQuery Dictionary works.\n\n\n# subql-query\n\n\n# --help\n\nThis shows the help options.\n\nns:\n      --help        Show help                                          [boolean]\n      --version     Show version number                                [boolean]\n  -n, --name        project name                             [string] [required]\n      --playground  enable graphql playground                          [boolean]\n      --output-fmt  Print log as json or plain text\n                      [string] [choices: "json", "colored"] [default: "colored"]\n      --log-level   Specify log level to print.\n          [string] [choices: "fatal", "error", "warn", "info", "debug", "trace",\n                                                     "silent"] [default: "info"]\n      --indexer     Url that allow query to access indexer metadata     [string]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# --version\n\nThis displays the current version.\n\n> subql-query --version\n0.7.0\n\n\n1\n2\n\n\n\n# -n, --name\n\nThis flag is used to start the query service. If the --subquery-name flag is not provided when running an indexer, the name here will refer to the default project name. If --subquery-name is set, then the name here should match what was set.\n\n> subql-node -f . // --subquery-name not set\n\n> subql-query -n subql-helloworld  --playground // the name defaults to the project directory name\n\n\n1\n2\n3\n\n\n> subql-node -f . --subquery-name=hiworld // --subquery-name set\n\n> subql-query -n hiworld --playground  // the name points to the subql-helloworld project but with the name of hiworld\n\n\n1\n2\n3\n\n\n\n# --playground\n\nThis flag enables the graphql playground so should always be included by default to be of any use.\n\n\n# --output-fmt\n\nSee --output-fmt\n\n\n# --log-level\n\nSee --log-level',normalizedContent:'# command line flags\n\n\n# subql-node\n\n\n# --help\n\nthis shows the help options.\n\n> subql-node --help\noptions:\n      --help                show help                                  [boolean]\n      --version             show version number                        [boolean]\n  -f, --subquery            local path of the subquery project          [string]\n      --subquery-name       name of the subquery project                [string]\n  -c, --config              specify configuration file                  [string]\n      --local               use local mode                             [boolean]\n      --batch-size          batch size of blocks to fetch in one round  [number]\n      --timeout             timeout for indexer sandbox to execute the mapping\n                            functions                                   [number]\n      --debug               show debug information to console output. will\n                            forcefully set log level to debug\n                                                      [boolean] [default: false]\n      --profiler            show profiler information to console output\n                                                      [boolean] [default: false]\n      --network-endpoint    blockchain network endpoint to connect      [string]\n      --output-fmt          print log as json or plain text\n                                           [string] [choices: "json", "colored"]\n      --log-level           specify log level to print. ignored when --debug is\n                            used\n          [string] [choices: "fatal", "error", "warn", "info", "debug", "trace",\n                                                                       "silent"]\n      --migrate             migrate db schema (for management tables only)\n                                                      [boolean] [default: false]\n      --timestamp-field     enable/disable created_at and updated_at in schema\n                                                       [boolean] [default: true]\n  -d, --network-dictionary  specify the dictionary api for this network [string]\n      --proof-of-index      enable/disable proof of index\n                                                      [boolean] [default: false]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n\n# --version\n\nthis displays the current version.\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# -f, --subquery\n\nuse this flag to start the subquery project.\n\nsubql-node -f . // or\nsubql-node --subquery .\n\n\n1\n2\n\n\n\n# --subquery-name\n\nthis flag allows you to provide a name for your project which acts as if it creates an instance of your project. upon providing a new name, a new database schema is created and block synchronisation starts from zero.\n\nsubql-node -f . --subquery-name=test2\n\n\n1\n\n\n\n# -c, --config\n\nall these various configurations can be placed into a .yml or .json file and then referenced with the config flag.\n\nsample subquery_config.yml file:\n\nsubquery: . // mandatory. this is the local path of the project. the period here means the current local directory.\nsubqueryname: hello // optional name\nbatchsize: 55 // optional config\n\n\n1\n2\n3\n\n\nplace this file in the same directory as the project. then in the current project directory, run:\n\n> subql-node -c ./subquery_config.yml\n\n\n1\n\n\n\n# --local\n\nthis flag is primarily used for debugging purposes where it creates the default starter_entity table in the default "postgres" schema.\n\nsubql-node -f . --local\n\n\n1\n\n\nnote that once you use this flag, removing it won\'t mean that it will point to another database. to repoint to another database you will have to create a new database and change the env settings to this new database. in other words, "export db_database=<new_db_here>"\n\n\n# --batch-size\n\nthis flag allows you to set the batch size in the command line. if batch size is also set in the config file, this takes precedent.\n\n> subql-node -f . --batch-size=20\n2021-08-09t23:24:43.775z <fetch> info fetch block [6601,6620], total 20 blocks\n2021-08-09t23:24:45.606z <fetch> info fetch block [6621,6640], total 20 blocks\n2021-08-09t23:24:47.415z <fetch> info fetch block [6641,6660], total 20 blocks\n2021-08-09t23:24:49.235z <fetch> info fetch block [6661,6680], total 20 blocks\n\n\n1\n2\n3\n4\n5\n\n\n\n# --debug\n\nthis outputs debug information to the console output and forcefully sets the log level to debug.\n\n> subql-node -f . --debug\n2021-08-10t11:45:39.471z <db> debug executing (1b0d0c23-d7c7-4adb-a703-e4e5c414e035): insert into "subquery_1"."starter_entities" ("id","block_height","created_at","updated_at") values ($1,$2,$3,$4) on conflict ("id") do update set "id"=excluded."id","block_height"=excluded."block_height","updated_at"=excluded."updated_at" returning "id","block_height","created_at","updated_at";\n2021-08-10t11:45:39.472z <db> debug executing (default): update "subqueries" set "next_block_height"=$1,"updated_at"=$2 where "id" = $3\n2021-08-10t11:45:39.472z <db> debug executing (1b0d0c23-d7c7-4adb-a703-e4e5c414e035): commit;\n\n\n1\n2\n3\n4\n\n\n\n# --profiler\n\nthis shows profiler information.\n\nsubql-node -f . --local --profiler\n2021-08-10t10:57:07.234z <profiler> info fetchservice, fetchmeta, 3876 ms\n2021-08-10t10:57:08.095z <profiler> info fetchservice, fetchmeta, 774 ms\n2021-08-10t10:57:10.361z <profiler> info substrateutil, fetchblocksbatches, 2265 ms\n2021-08-10t10:57:10.361z <fetch> info fetch block [3801,3900], total 100 blocks\n\n\n1\n2\n3\n4\n5\n\n\n\n# --network-endpoint\n\nthis flag allows users to override the network endpoint configuration from the manifest file.\n\nsubql-node -f . --network-endpoint="wss://polkadot.api.onfinality.io/public-ws"\n\n\n1\n\n\nnote that this must also be set in the manifest file, otherwise you\'ll get:\n\nerror create subquery project from given path failed! error: failed to parse project.yaml.\nan instance of projectmanifestimpl has failed the validation:\n - property network has failed the following constraints: isobject\n - property network.network has failed the following constraints: nestedvalidation\n\n\n1\n2\n3\n4\n\n\n\n# --output-fmt\n\nthere are two different terminal output formats. json or colored. colored is the default and contains colored text.\n\n> subql-node -f . --output-fmt=json\n{"level":"info","timestamp":"2021-08-10t11:58:18.087z","pid":24714,"hostname":"p.local","category":"fetch","message":"fetch block [10501,10600], total 100 blocks"}\n\n\n1\n2\n\n\n> subql-node -f . --output-fmt=colored\n2021-08-10t11:57:41.480z <subql-node> info node started\n(node:24707) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n2021-08-10t11:57:48.981z <fetch> info fetch block [10201,10300], total 100 blocks\n2021-08-10t11:57:51.862z <fetch> info fetch block [10301,10400], total 100 blocks\n\n\n1\n2\n3\n4\n5\n\n\n\n# --log-level\n\nthere are 7 options to choose from. “fatal”, “error”, “warn”, “info”, “debug”, “trace”, “silent”. the example below shows silent. nothing will be printed in the terminal so the only way to tell if the node is working or not is to query the database for row count (select count(*) from subquery_1.starter_entities) or query the block height.\n\n> subql-node -f . --log-level=silent\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(use `node --trace-warnings ...` to show where the warning was created)\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n(node:24686) [dep0152] deprecationwarning: custom performanceentry accessors are deprecated. please use the detail property.\n(node:24686) [pinodep007] warning: bindings.level is deprecated, use options.level option instead\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# --timestamp-field\n\nby default this is true. when set to false with:\n\n> subql-node -f . –timestamp-field=false\n\n\n1\n\n\nthis removes the created_at and updated_at columns in the starter_entities table.\n\n\n# -d, --network-dictionary\n\nthis allows you to specify a dictionary endpoint which is a free service that is provided and hosted at: https://explorer.subquery.network/ (search for dictionary) and presents an api endpoint of: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\ntypically this would be set in your manifest file but below shows an example of using it as an argument in the command line.\n\nsubql-node -f . -d "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\n\n1\n\n\nread more about how a subquery dictionary works.\n\n\n# subql-query\n\n\n# --help\n\nthis shows the help options.\n\nns:\n      --help        show help                                          [boolean]\n      --version     show version number                                [boolean]\n  -n, --name        project name                             [string] [required]\n      --playground  enable graphql playground                          [boolean]\n      --output-fmt  print log as json or plain text\n                      [string] [choices: "json", "colored"] [default: "colored"]\n      --log-level   specify log level to print.\n          [string] [choices: "fatal", "error", "warn", "info", "debug", "trace",\n                                                     "silent"] [default: "info"]\n      --indexer     url that allow query to access indexer metadata     [string]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# --version\n\nthis displays the current version.\n\n> subql-query --version\n0.7.0\n\n\n1\n2\n\n\n\n# -n, --name\n\nthis flag is used to start the query service. if the --subquery-name flag is not provided when running an indexer, the name here will refer to the default project name. if --subquery-name is set, then the name here should match what was set.\n\n> subql-node -f . // --subquery-name not set\n\n> subql-query -n subql-helloworld  --playground // the name defaults to the project directory name\n\n\n1\n2\n3\n\n\n> subql-node -f . --subquery-name=hiworld // --subquery-name set\n\n> subql-query -n hiworld --playground  // the name points to the subql-helloworld project but with the name of hiworld\n\n\n1\n2\n3\n\n\n\n# --playground\n\nthis flag enables the graphql playground so should always be included by default to be of any use.\n\n\n# --output-fmt\n\nsee --output-fmt\n\n\n# --log-level\n\nsee --log-level',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{frontmatter:{summary:"Добро пожаловать в SubQuery’s Docs Изучите и преобразуйте свои ончейн данные, чтобы быстрее создавать интуитивно понятные приложения! Быстрый старт руководства Понимайте SubQuery, ",meta:[{property:"og:url",content:"/ru/"},{property:"og:description",content:"Добро пожаловать в SubQuery’s Docs Изучите и преобразуйте свои ончейн данные, чтобы быстрее создавать интуитивно понятные приложения! Быстрый старт руководства Понимайте SubQuery, "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/",relativePath:"ru/README.md",key:"v-3bb71ffe",path:"/ru/",readingTime:{minutes:1.97,words:592},headersStr:null,content:"Добро пожаловать в SubQuery’s Docs\n\nИзучите и преобразуйте свои ончейн данные, чтобы быстрее создавать интуитивно понятные приложения!\n\n\nБыстрый старт руководства\n\nПонимайте SubQuery, используя традиционный пример Hello World. Использование шаблона проекта с помощью Докера , вы можете быстро запустить узел и начать искать данные в блокчейне всего за несколько минут с помощью нескольких простых команд.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * The SubQuery Network\n   \n   Децентрализованное будущее SubQuery. Подробнее о вознаграждении индексаторов и потребителей.\n\n\nFAQ\n\n * Что такое SubQuery?\n   \n   SubQuery - это проект с открытым исходным кодом, который позволяет разработчикам индексировать, преобразовывать и запрашивать данные блокчейна Substrate для своих приложений.\n   \n   READ MORE\n * Какой лучший способ начать работу с SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. Это простая 5-минутка по скачиванию стартового шаблона, созданию проекта, а затем запуска узла на локальном хосте и выполнения простого запроса с помощью Docker.\n\n * Как я могу внести свой вклад или оставить отзыв на SubQuery?\n   \n   Мы любим вносить свой вклад и получать обратную связь от сообщества. Чтобы дополнить код, форкните репозиторий интересов и внесите изменения. Затем отправьте PR или Pull Request. Кстати, не забудьте проверить! Также ознакомьтесь с нашими рекомендациями внесению дополнений (скоро).\n   \n   READ MORE\n * Сколько стоит разместить мой проект в SubQuery?\n   \n   Размещение вашего проекта в SubQuery Projects абсолютно бесплатно - это наш способ вернуть сообщество в будущем. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nИнтеграция с вашей собственной цепочкой?\n\nСоздаете ли вы новый парачейн или совершенно новый блокчейн в Substrate - SubQuery может помочь вам индексировать и диагностировать данные цепочки. SubQuery разработан для того, чтобы легко интегрироваться с пользовательской цепочкой Substrate.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nПоддержка и содействие\n\nУ Вас есть вопрос или интересно узнать больше или как Вы можете помочь? Мы будем рады услышать от вас. Пожалуйста, свяжитесь с нами по электронной почте или через социальные сети по ссылкам ниже. Нужна техническая экспертиза? Присоединяйтесь к нашему сообществу Discord и получите поддержку от наших членов сообщества.\n\nПРИСОЕДИНЯЙТЕСЬ К ОБСУЖДЕНИЮ В ДИСКОРДЕ\nСвяжитесь с нами hello@subquery.network\nПодпишитесь на нас в социальных сетях\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"добро пожаловать в subquery’s docs\n\nизучите и преобразуите свои ончеин данные, чтобы быстрее создавать интуитивно понятные приложения!\n\n\nбыстрыи старт руководства\n\nпонимаите subquery, используя традиционныи пример hello world. использование шаблона проекта с помощью докера , вы можете быстро запустить узел и начать искать данные в блокчеине всего за несколько минут с помощью нескольких простых команд.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * the subquery network\n   \n   децентрализованное будущее subquery. подробнее о вознаграждении индексаторов и потребителеи.\n\n\nfaq\n\n * что такое subquery?\n   \n   subquery - это проект с открытым исходным кодом, которыи позволяет разработчикам индексировать, преобразовывать и запрашивать данные блокчеина substrate для своих приложении.\n   \n   read more\n * какои лучшии способ начать работу с subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. это простая 5-минутка по скачиванию стартового шаблона, созданию проекта, а затем запуска узла на локальном хосте и выполнения простого запроса с помощью docker.\n\n * как я могу внести свои вклад или оставить отзыв на subquery?\n   \n   мы любим вносить свои вклад и получать обратную связь от сообщества. чтобы дополнить код, форкните репозитории интересов и внесите изменения. затем отправьте pr или pull request. кстати, не забудьте проверить! также ознакомьтесь с нашими рекомендациями внесению дополнении (скоро).\n   \n   read more\n * сколько стоит разместить мои проект в subquery?\n   \n   размещение вашего проекта в subquery projects абсолютно бесплатно - это наш способ вернуть сообщество в будущем. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nинтеграция с вашеи собственнои цепочкои?\n\nсоздаете ли вы новыи парачеин или совершенно новыи блокчеин в substrate - subquery может помочь вам индексировать и диагностировать данные цепочки. subquery разработан для того, чтобы легко интегрироваться с пользовательскои цепочкои substrate.\n\nlearn how to integrate with your chain\n\nподдержка и содеиствие\n\nу вас есть вопрос или интересно узнать больше или как вы можете помочь? мы будем рады услышать от вас. пожалуиста, свяжитесь с нами по электроннои почте или через социальные сети по ссылкам ниже. нужна техническая экспертиза? присоединяитесь к нашему сообществу discord и получите поддержку от наших членов сообщества.\n\nприсоединяитесь к обсуждению в дискорде\nсвяжитесь с нами hello@subquery.network\nподпишитесь на нас в социальных сетях\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Узнай больше о GraphQL",frontmatter:{summary:"Узнай больше о GraphQL Определение объектов Файл schema.graphql определяет различные схемы GraphQL. Из-за того, как работает язык запросов GraphQL, схема файлов по сути диктует фор",meta:[{property:"og:url",content:"/ru/create/graphql.html"},{property:"og:title",content:"Узнай больше о GraphQL"},{property:"og:description",content:"Узнай больше о GraphQL Определение объектов Файл schema.graphql определяет различные схемы GraphQL. Из-за того, как работает язык запросов GraphQL, схема файлов по сути диктует фор"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/create/graphql.html",relativePath:"ru/create/graphql.md",key:"v-1b3677a6",path:"/ru/create/graphql/",headers:[{level:2,title:"Определение объектов",slug:"определение-объектов",normalizedTitle:"определение объектов",charIndex:29},{level:3,title:"Сущности",slug:"сущности",normalizedTitle:"сущности",charIndex:439},{level:3,title:"Поддерживаемые скаляры и типы",slug:"поддерживаемые-скаляры-и-типы",normalizedTitle:"поддерживаемые скаляры и типы",charIndex:943},{level:2,title:"Индексирование с помощью не первичного ключа",slug:"индексирование-с-помощью-не-первичного-ключа",normalizedTitle:"индексирование с помощью не первичного ключа",charIndex:1331},{level:2,title:"Связи субъектов",slug:"связи-субъектов",normalizedTitle:"связи субъектов",charIndex:3008},{level:3,title:"Индивидуальные отношения",slug:"индивидуальные-отношения",normalizedTitle:"индивидуальные отношения",charIndex:3309},{level:3,title:"Отношения от одного до нескольких",slug:"отношения-от-одного-до-нескольких",normalizedTitle:"отношения от одного до нескольких",charIndex:3807},{level:3,title:'Отношения "многие ко многим"',slug:"отношения-многие-ко-многим",normalizedTitle:"отношения &quot;многие ко многим&quot;",charIndex:null},{level:3,title:"Обратные запросы",slug:"обратные-запросы",normalizedTitle:"обратные запросы",charIndex:5182},{level:2,title:"Тип JSON",slug:"тип-json",normalizedTitle:"тип json",charIndex:5881},{level:3,title:"Определить директиву JSON",slug:"определить-директиву-json",normalizedTitle:"определить директиву json",charIndex:6580},{level:3,title:"Запрос полей JSON",slug:"запрос-полеи-json",normalizedTitle:"запрос полеи json",charIndex:7275}],readingTime:{minutes:.89,words:266},headersStr:'Определение объектов Сущности Поддерживаемые скаляры и типы Индексирование с помощью не первичного ключа Связи субъектов Индивидуальные отношения Отношения от одного до нескольких Отношения "многие ко многим" Обратные запросы Тип JSON Определить директиву JSON Запрос полей JSON',content:"# Узнай больше о GraphQL\n\n\n# Определение объектов\n\nФайл schema.graphql определяет различные схемы GraphQL. Из-за того, как работает язык запросов GraphQL, схема файлов по сути диктует форму ваших данных из SubQuery. There are libraries to help you implement GraphQL in many different languages\n\nВажно: При внесении каких-либо изменений в файл, убедитесь, что вы регенерируете директорию типов, используя следующую команду yarn codegen\n\n\n# Сущности\n\nКаждая сущность должна определить свои требуемые поля id с типом ID!. Он используется в качестве первичного ключа и уникален между всеми сущностями одного типа.\n\nПоля, не допускающие значения NULL, в сущности обозначены !. Пожалуйста, смотрите пример ниже:\n\nнапечатайте Пример @entity {\n  id: ID! поле # id всегда необходимо заполнять и оно должно выглядеть следующим образом\n  name: String! # Это обязательное поле для заполнения\n  address: String # Это необязательное поле\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Поддерживаемые скаляры и типы\n\nВ настоящее время мы поддерживаем следующие скалярные типы:\n\n * ID\n * Int\n * Строка\n * BigInt\n * Дата\n * Логический\n * <EntityName> для вложенных сущностей связей вы можете использовать определенное имя сущности в качестве одного из полей. Пожалуйста, смотрите в Entity Relationships.\n * JSON может также хранить структурированные данные, см. JSON type\n\n\n# Индексирование с помощью не первичного ключа\n\nЧтобы улучшить производительность поисковых запросов, индексируйте выбранные области просто внедрив аннотацию @index в поле непервичного ключа.\n\nТем не менее, мы не позволяем пользователям добавлять аннотации @index к любому объекту JSON. По умолчанию, индексы автоматически добавляются к внешним ключам и для полей JSON в базе данных, но только для повышения производительности службы запросов.\n\nВот пример.\n\nтип пользователя @entity {\n  id: ID!\n  name: String! @index(unique: true) # уникальное может быть установлено в true или false\n  title: Title! # Индексы автоматически добавляются в поле внешнего ключа \n}\n\nтип Title @entity {\n  id: ID!  \n  name: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nПредполагая, что мы знали имя этого пользователя, но мы не знаем его точное значение id, вместо того, чтобы извлекать всех пользователей, а затем фильтровать их по имени, мы можем добавить @index за полем имени. Это делает поиск гораздо более быстрее, и мы можем дополнительно пройти unique: true для обеспечения уникальности.\n\nЕсли поле не уникальное, то максимальный размер набора результатов равен 100\n\nКогда выполняется генерация кода, автоматически создастся getByName в соответствии с моделью User , и внешний ключ title создаст метод `getByTitleId</0>, к которым оба могут быть напрямую доступны в функции сопоставления.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\netByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // Список всех капитанов\n\n\n1\n2\n3\n4\n5\n\n\n\n# Связи субъектов\n\nСущность часто имеет вложенные отношения с другими субъектами. Установка значения поля на другое имя объекта определит связь между этими двумя объектами по умолчанию.\n\nРазличные отношения объектов (один-на-один, и многие) могут быть настроены с помощью приведенных ниже примеров.\n\n\n# Индивидуальные отношения\n\nОтношения «один к одному» используются по умолчанию, когда только один объект сопоставляется с другим.\n\nПример: паспорт будет принадлежать только одному человеку, и у человека есть только один паспорт (в данном примере):\n\nтип Person @entity {\n  id: ID!\n}\n\nтип Passport @entity {\n  id: ID!\n  владелец: Человек!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nили\n\nтип Person @entity {\n  id: ID!\n  паспорт: Passport!\n}\n\nтип Passport @entity {\n  id: ID!\n  владелец: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Отношения от одного до нескольких\n\nВы можете использовать квадратные скобки, чтобы указать, что тип поля включает несколько сущностей.\n\nПример: Человек может иметь несколько учетных записей.\n\nтип Person @entity {\n  id: ID!\n  аккаунты: [Account] \n}\n\nтип аккаунта @entity {\n  id: ID!\n  публичный адрес: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Отношения \"многие ко многим\"\n\nОтношения «многие ко многим» могут быть достигнуты путем реализации объекта сопоставления для соединения двух других объектов.\n\nПример: каждый человек является частью нескольких групп (PersonGroup), а в группах есть несколько разных людей (PersonGroup).\n\nтип Person @entity {\n  id: ID!\n  name: String!\n  группы: [PersonGroup]\n}\n\nтип PersonGroup @entity {\n  id: ID!\n  человек: Person!\n  Группа: Group!\n}\n\nтип Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nКроме того, можно создать соединение одной и той же сущности в нескольких полях средней сущности.\n\nНапример, учетная запись может иметь несколько переводов, и каждая передача имеет исходную и целевую учетные записи.\n\nЭто установит двусторонние отношения между двумя аккаунтами (от и до) через таблицу передачи.\n\nтип Account @entity {\n  id: ID!\n  публичный адрес: String!\n}\n\nтип Transfer @entity {\n  id: ID!\n  сумма: BigInt\n  от: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Обратные запросы\n\nЧтобы разрешить обратный поиск объекта в отношении, присоедините @dehibitedFrom к полю и укажите на его поле обратного просмотра другого объекта.\n\nЭто создает виртуальное поле на объекте, который может быть запрошен.\n\nПередача «от» учетной записи доступна из объекта аккаунта путем установки значения sentTransfer или receiveTransfer, полученного из соответствующих полей from или to.\n\nтип Account @entity {\n  id: ID!\n  публичный адрес: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  сумма: BigInt\n  от: Account!\n  от: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Тип JSON\n\nМы поддерживаем сохранение данных в формате JSON, что является быстрым способом хранения структурированных данных. Мы автоматически сгенерируем соответствующие интерфейсы JSON для запроса данных и сэкономим время для определения и управления сущностями.\n\nМы рекомендуем пользователям использовать тип JSON в следующих сценариях:\n\n * Хранение структурированных данных в одном поле более управляемо, чем создание нескольких отдельных сущностей.\n * Сохранение произвольных пользовательских настроек ключа / значения (где значение может быть логическим, текстовым или числовым, и вы не хотите иметь отдельные столбцы для разных типов данных)\n * Схема является волатильной и часто меняется\n\n\n# Определить директиву JSON\n\nОпределите свойство как тип JSON файла, добавив аннотацию jsonField в объекте. Это автоматически создаст интерфейсы для всех JSON объектов в вашем проекте в types/interfaces.ts, и вы можете получить доступ к ним в функции сопоставления.\n\nВ отличие от объекта, директивный jsonField объект не требует поля id. Объект JSON также способен соединиться с другими объектами JSON.\n\nтип AddressDetail @jsonField {\n  улица: String!\n  округ: String!\n}\n\nвведите ContactCard @jsonField {\n  телефон: String!\n  адрес: AddressDetail # Вложенный JSON\n}\n\nтип User @entity {\n  id: ID! \n  контакт: [ContactCard] # Сохраните список JSON объектов\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Запрос полей JSON\n\nНедостатком использования файлов типа JSON является слабое влияние на эффективность запроса при фильтрации, поскольку каждый раз, когда выполняется текстовый поиск, он выполняется по всему объекту.\n\nТем не менее, влияние на нашу работу по поисковым запросам все еще приемлемо. Вот пример того, как использовать contains оператора в запросе GraphQL на JSON файл, чтобы найти пять первых пользователей, у которых есть номер телефона, содержащий '0064'.\n\n#Чтобы найти первых 5 пользователей телефоны которых содержат '0064'.\n\nquery{\n  пользователь (\n    первый: 5,\n    filter: {\n      contactCard: {\n        содержит : [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# узнаи больше о graphql\n\n\n# определение объектов\n\nфаил schema.graphql определяет различные схемы graphql. из-за того, как работает язык запросов graphql, схема фаилов по сути диктует форму ваших данных из subquery. there are libraries to help you implement graphql in many different languages\n\nважно: при внесении каких-либо изменении в фаил, убедитесь, что вы регенерируете директорию типов, используя следующую команду yarn codegen\n\n\n# сущности\n\nкаждая сущность должна определить свои требуемые поля id с типом id!. он используется в качестве первичного ключа и уникален между всеми сущностями одного типа.\n\nполя, не допускающие значения null, в сущности обозначены !. пожалуиста, смотрите пример ниже:\n\nнапечатаите пример @entity {\n  id: id! поле # id всегда необходимо заполнять и оно должно выглядеть следующим образом\n  name: string! # это обязательное поле для заполнения\n  address: string # это необязательное поле\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# поддерживаемые скаляры и типы\n\nв настоящее время мы поддерживаем следующие скалярные типы:\n\n * id\n * int\n * строка\n * bigint\n * дата\n * логическии\n * <entityname> для вложенных сущностеи связеи вы можете использовать определенное имя сущности в качестве одного из полеи. пожалуиста, смотрите в entity relationships.\n * json может также хранить структурированные данные, см. json type\n\n\n# индексирование с помощью не первичного ключа\n\nчтобы улучшить производительность поисковых запросов, индексируите выбранные области просто внедрив аннотацию @index в поле непервичного ключа.\n\nтем не менее, мы не позволяем пользователям добавлять аннотации @index к любому объекту json. по умолчанию, индексы автоматически добавляются к внешним ключам и для полеи json в базе данных, но только для повышения производительности службы запросов.\n\nвот пример.\n\nтип пользователя @entity {\n  id: id!\n  name: string! @index(unique: true) # уникальное может быть установлено в true или false\n  title: title! # индексы автоматически добавляются в поле внешнего ключа \n}\n\nтип title @entity {\n  id: id!  \n  name: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nпредполагая, что мы знали имя этого пользователя, но мы не знаем его точное значение id, вместо того, чтобы извлекать всех пользователеи, а затем фильтровать их по имени, мы можем добавить @index за полем имени. это делает поиск гораздо более быстрее, и мы можем дополнительно проити unique: true для обеспечения уникальности.\n\nесли поле не уникальное, то максимальныи размер набора результатов равен 100\n\nкогда выполняется генерация кода, автоматически создастся getbyname в соответствии с моделью user , и внешнии ключ title создаст метод `getbytitleid</0>, к которым оба могут быть напрямую доступны в функции сопоставления.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\netbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // список всех капитанов\n\n\n1\n2\n3\n4\n5\n\n\n\n# связи субъектов\n\nсущность часто имеет вложенные отношения с другими субъектами. установка значения поля на другое имя объекта определит связь между этими двумя объектами по умолчанию.\n\nразличные отношения объектов (один-на-один, и многие) могут быть настроены с помощью приведенных ниже примеров.\n\n\n# индивидуальные отношения\n\nотношения «один к одному» используются по умолчанию, когда только один объект сопоставляется с другим.\n\nпример: паспорт будет принадлежать только одному человеку, и у человека есть только один паспорт (в данном примере):\n\nтип person @entity {\n  id: id!\n}\n\nтип passport @entity {\n  id: id!\n  владелец: человек!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nили\n\nтип person @entity {\n  id: id!\n  паспорт: passport!\n}\n\nтип passport @entity {\n  id: id!\n  владелец: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# отношения от одного до нескольких\n\nвы можете использовать квадратные скобки, чтобы указать, что тип поля включает несколько сущностеи.\n\nпример: человек может иметь несколько учетных записеи.\n\nтип person @entity {\n  id: id!\n  аккаунты: [account] \n}\n\nтип аккаунта @entity {\n  id: id!\n  публичныи адрес: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# отношения \"многие ко многим\"\n\nотношения «многие ко многим» могут быть достигнуты путем реализации объекта сопоставления для соединения двух других объектов.\n\nпример: каждыи человек является частью нескольких групп (persongroup), а в группах есть несколько разных людеи (persongroup).\n\nтип person @entity {\n  id: id!\n  name: string!\n  группы: [persongroup]\n}\n\nтип persongroup @entity {\n  id: id!\n  человек: person!\n  группа: group!\n}\n\nтип group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nкроме того, можно создать соединение однои и тои же сущности в нескольких полях среднеи сущности.\n\nнапример, учетная запись может иметь несколько переводов, и каждая передача имеет исходную и целевую учетные записи.\n\nэто установит двусторонние отношения между двумя аккаунтами (от и до) через таблицу передачи.\n\nтип account @entity {\n  id: id!\n  публичныи адрес: string!\n}\n\nтип transfer @entity {\n  id: id!\n  сумма: bigint\n  от: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# обратные запросы\n\nчтобы разрешить обратныи поиск объекта в отношении, присоедините @dehibitedfrom к полю и укажите на его поле обратного просмотра другого объекта.\n\nэто создает виртуальное поле на объекте, которыи может быть запрошен.\n\nпередача «от» учетнои записи доступна из объекта аккаунта путем установки значения senttransfer или receivetransfer, полученного из соответствующих полеи from или to.\n\nтип account @entity {\n  id: id!\n  публичныи адрес: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  сумма: bigint\n  от: account!\n  от: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# тип json\n\nмы поддерживаем сохранение данных в формате json, что является быстрым способом хранения структурированных данных. мы автоматически сгенерируем соответствующие интерфеисы json для запроса данных и сэкономим время для определения и управления сущностями.\n\nмы рекомендуем пользователям использовать тип json в следующих сценариях:\n\n * хранение структурированных данных в одном поле более управляемо, чем создание нескольких отдельных сущностеи.\n * сохранение произвольных пользовательских настроек ключа / значения (где значение может быть логическим, текстовым или числовым, и вы не хотите иметь отдельные столбцы для разных типов данных)\n * схема является волатильнои и часто меняется\n\n\n# определить директиву json\n\nопределите своиство как тип json фаила, добавив аннотацию jsonfield в объекте. это автоматически создаст интерфеисы для всех json объектов в вашем проекте в types/interfaces.ts, и вы можете получить доступ к ним в функции сопоставления.\n\nв отличие от объекта, директивныи jsonfield объект не требует поля id. объект json также способен соединиться с другими объектами json.\n\nтип addressdetail @jsonfield {\n  улица: string!\n  округ: string!\n}\n\nвведите contactcard @jsonfield {\n  телефон: string!\n  адрес: addressdetail # вложенныи json\n}\n\nтип user @entity {\n  id: id! \n  контакт: [contactcard] # сохраните список json объектов\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# запрос полеи json\n\nнедостатком использования фаилов типа json является слабое влияние на эффективность запроса при фильтрации, поскольку каждыи раз, когда выполняется текстовыи поиск, он выполняется по всему объекту.\n\nтем не менее, влияние на нашу работу по поисковым запросам все еще приемлемо. вот пример того, как использовать contains оператора в запросе graphql на json фаил, чтобы наити пять первых пользователеи, у которых есть номер телефона, содержащии '0064'.\n\n#чтобы наити первых 5 пользователеи телефоны которых содержат '0064'.\n\nquery{\n  пользователь (\n    первыи: 5,\n    filter: {\n      contactcard: {\n        содержит : [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples В инструкции быстрого старта, мы очень быстро разобрали пример, чтобы показать Вам, что такое SubQuery и как он работает. В данной статье, мы более подробно ра",meta:[{property:"og:url",content:"/ru/create/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples В инструкции быстрого старта, мы очень быстро разобрали пример, чтобы показать Вам, что такое SubQuery и как он работает. В данной статье, мы более подробно ра"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/create/introduction.html",relativePath:"ru/create/introduction.md",key:"v-1e91fed2",path:"/ru/create/introduction/",headers:[{level:2,title:"Примеры SubQuery",slug:"примеры-subquery",normalizedTitle:"примеры subquery",charIndex:286},{level:2,title:"Структура каталогов",slug:"структура-каталогов",normalizedTitle:"структура каталогов",charIndex:1329},{level:2,title:"Генерирование кода",slug:"генерирование-кода",normalizedTitle:"генерирование кода",charIndex:1703},{level:2,title:"Сборка",slug:"сборка",normalizedTitle:"сборка",charIndex:2196}],readingTime:{minutes:.5,words:149},headersStr:"Примеры SubQuery Структура каталогов Генерирование кода Сборка",content:"# Tutorials & Examples\n\nВ инструкции быстрого старта, мы очень быстро разобрали пример, чтобы показать Вам, что такое SubQuery и как он работает. В данной статье, мы более подробно рассмотрим рабочий процесс создания вашего проекта и ключевых файлов, с которыми вы будете работать.\n\n\n# Примеры SubQuery\n\nНекоторые из следующих примеров предполагают, что вы успешно запустили стартовый пакет, описанный в разделе Быстрый старт. С этого стартового пакета мы рассмотрим стандартный процесс по настройке и внедрению вашего SubQuery проекта.\n\n 1. Инициализируйте ваш проект с помощью subql init PROJECT_NAME\n 2. Обновите файл манифеста (проект. aml), чтобы включить информацию о вашем блокчейне, и сущности, которые вы собираетесь сопоставить - см. Файл манифеста\n 3. Создайте GraphQL сущности в вашей схеме (schema.raphql), которые определяют форму ваших данных, которые вы будете извлекать и использовать для запроса - см. GraphQL Schema\n 4. Добавьте все функции сопоставления (например, mappingHandlers.ts), которые вы хотите использовать для преобразования данных цепи в GraphQL сущности, которые вы определили ранее - см. Mapping\n 5. Сгенерируйте, постройте, и опубликуйте ваш код в SubQuery Projects (или запустите на вашем локальном узле) - см. Запуск и запрос вашего стартового проекта в нашей инструкции быстрого старта.\n\n\n# Структура каталогов\n\nСледующая карта предоставляет обзор структуры директория SubQuery проекта при запуске команды init.\n\n- project-name\n  L package.json\n  L проект. aml\n  L README.md\n  L schema.graphql\n  L tsconfig. son\n  L docker-compose.yml\n  L src\n    L index. s\n    L сопоставления\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nExample\n\n\n\n\n# Генерирование кода\n\nКаждый раз, когда вы меняете сущности GraphQL, вы должны регенерировать типы каталогов следующей командой.\n\nyarn codegen\n\n\n1\n\n\nЭто команда создаст новый каталог (или обновит существующий) src/types, который содержит сгенерированные классы сущностей для каждого типа, который вы ранее задали в schema.graphql. Эти классы обеспечивают безопасную загрузку сущностей, доступ к чтению и записи на поле сущности - подробнее об этом процессе можно прочитать на GraphQL-схеме.\n\n\n# Сборка\n\nДля того, чтобы запустить свой проект SubQuery на локальном узле SubQuery Node, вам нужно сначала завершить свою работу.\n\nЗапустите команду сборки из корневого каталога проекта.\n\nМетод `console.log` **больше не поддерживается**. Вместо этого был введен `logger` модуль, что означает, что мы можем поддерживать логгер, который может принимать различные уровни логгеров.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nЧтобы использовать logger.info или logger.warn, просто поместите строку в файл сопоставления.\n\n\n\nДля использования logger.debugтребуется дополнительный шаг. Добавьте --log-level=debug в вашу командную строку.\n\nЕсли вы используете docker container, добавьте эту строку в ваш docker-compose.yaml файл.\n\n\n\nТеперь вы должны увидеть новые записи на экране терминала.\n\n",normalizedContent:"# tutorials & examples\n\nв инструкции быстрого старта, мы очень быстро разобрали пример, чтобы показать вам, что такое subquery и как он работает. в даннои статье, мы более подробно рассмотрим рабочии процесс создания вашего проекта и ключевых фаилов, с которыми вы будете работать.\n\n\n# примеры subquery\n\nнекоторые из следующих примеров предполагают, что вы успешно запустили стартовыи пакет, описанныи в разделе быстрыи старт. с этого стартового пакета мы рассмотрим стандартныи процесс по настроике и внедрению вашего subquery проекта.\n\n 1. инициализируите ваш проект с помощью subql init project_name\n 2. обновите фаил манифеста (проект. aml), чтобы включить информацию о вашем блокчеине, и сущности, которые вы собираетесь сопоставить - см. фаил манифеста\n 3. создаите graphql сущности в вашеи схеме (schema.raphql), которые определяют форму ваших данных, которые вы будете извлекать и использовать для запроса - см. graphql schema\n 4. добавьте все функции сопоставления (например, mappinghandlers.ts), которые вы хотите использовать для преобразования данных цепи в graphql сущности, которые вы определили ранее - см. mapping\n 5. сгенерируите, построите, и опубликуите ваш код в subquery projects (или запустите на вашем локальном узле) - см. запуск и запрос вашего стартового проекта в нашеи инструкции быстрого старта.\n\n\n# структура каталогов\n\nследующая карта предоставляет обзор структуры директория subquery проекта при запуске команды init.\n\n- project-name\n  l package.json\n  l проект. aml\n  l readme.md\n  l schema.graphql\n  l tsconfig. son\n  l docker-compose.yml\n  l src\n    l index. s\n    l сопоставления\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nexample\n\n\n\n\n# генерирование кода\n\nкаждыи раз, когда вы меняете сущности graphql, вы должны регенерировать типы каталогов следующеи командои.\n\nyarn codegen\n\n\n1\n\n\nэто команда создаст новыи каталог (или обновит существующии) src/types, которыи содержит сгенерированные классы сущностеи для каждого типа, которыи вы ранее задали в schema.graphql. эти классы обеспечивают безопасную загрузку сущностеи, доступ к чтению и записи на поле сущности - подробнее об этом процессе можно прочитать на graphql-схеме.\n\n\n# сборка\n\nдля того, чтобы запустить свои проект subquery на локальном узле subquery node, вам нужно сначала завершить свою работу.\n\nзапустите команду сборки из корневого каталога проекта.\n\nметод `console.log` **больше не поддерживается**. вместо этого был введен `logger` модуль, что означает, что мы можем поддерживать логгер, которыи может принимать различные уровни логгеров.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nчтобы использовать logger.info или logger.warn, просто поместите строку в фаил сопоставления.\n\n\n\nдля использования logger.debugтребуется дополнительныи шаг. добавьте --log-level=debug в вашу командную строку.\n\nесли вы используете docker container, добавьте эту строку в ваш docker-compose.yaml фаил.\n\n\n\nтеперь вы должны увидеть новые записи на экране терминала.\n\n",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Файл манифеста",frontmatter:{summary:"Файл манифеста Манифест файл project. amlможно рассматривать как входную точку вашего проекта, и он определяет большую часть деталей о том, как SubQuery будет индексировать и преоб",meta:[{property:"og:url",content:"/ru/create/manifest.html"},{property:"og:title",content:"Файл манифеста"},{property:"og:description",content:"Файл манифеста Манифест файл project. amlможно рассматривать как входную точку вашего проекта, и он определяет большую часть деталей о том, как SubQuery будет индексировать и преоб"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/create/manifest.html",relativePath:"ru/create/manifest.md",key:"v-6a2b59ed",path:"/ru/create/manifest/",headers:[{level:2,title:"Сетевые Фильтры",slug:"сетевые-фильтры",normalizedTitle:"сетевые фильтры",charIndex:2048},{level:2,title:"Фильтры сопоставления",slug:"фильтры-сопоставления",normalizedTitle:"фильтры сопоставления",charIndex:3336},{level:2,title:"Пользовательские цепочки",slug:"пользовательские-цепочки",normalizedTitle:"пользовательские цепочки",charIndex:4757}],readingTime:{minutes:1.09,words:327},headersStr:"Сетевые Фильтры Фильтры сопоставления Пользовательские цепочки",content:"# Файл манифеста\n\nМанифест файл project. amlможно рассматривать как входную точку вашего проекта, и он определяет большую часть деталей о том, как SubQuery будет индексировать и преобразовывать данные цепочки.\n\nМанифест может быть в формате YAML или JSON. В этом документе мы будем использовать YAML во всех примерах. Ниже приведен стандартный пример базового project.yaml.\n\nspecVersion: '0.0.1'\ndescription: ''\nrepository: 'https://github.com/subquery/subql-starter'\n\nschema: './schema.graphql'\n\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: 'https://api.subquery.network/sq/subquery/dictionary-polkadot'\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network. \\endpoint определяет конечную точку wss или ws для индексирования блокчейна - Это должно быть полный архивный узел.\n * network.dictionary при необходимости предоставляет HTTP конечную точку полного словаря для ускорения обработки - см. Running an Indexer\n * dataSources определяет данные, которые будут отфильтрованы и извлечены, а также расположение обработчика карты для применения преобразования данных.\n   * kind поддерживает только substrate/Runtime сейчас.\n   * startBlock определяет высоту блока для начала индексации.\n   * filter фильтрует источник данных для выполнения по сетевому имени спецификации конечной точки, см. сетевые фильтры\n   * mapping.handlers выведет список всех mapping functions и соответствующих типов обработчиков, с дополнительными mapping filters.\n\n\n# Сетевые Фильтры\n\nОбычно пользователь создаст SubQuery и будет повторно использовать его как для тестнетов, так и для майннет среды(например, Polkadot и Kusama). Между сетями различные опции, вероятно, отличаются (например, стартовый блок индекса). Поэтому мы позволяем пользователям определять различные детали для каждого источника данных, что означает, что один проект SubQuery по-прежнему может использоваться в нескольких сетях.\n\nПользователи могут добавить filter на dataSources для решения о том, какой источник данных запускать в каждой сети.\n\nНиже приведен пример, который показывает различные источники данных как для Polkadot так и для Kusama.\n\n\n---\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter: #Optional\n      specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter:\n      specName: kusama\n    startBlock: 12000\n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# Фильтры сопоставления\n\nФильтры сопоставления являются чрезвычайно полезной функцией, чтобы решить, что блок, событие или надпись вызовут обработчик сопоставления.\n\nТолько входящие данные, удовлетворяющие условия фильтра, будут обрабатываться функциями сопоставления. Фильтры сопоставления являются необязательными, но рекомендуются, поскольку они значительно уменьшают объем данных, обрабатываемых вашим проектом SubQuery и повышают производительность индексации.\n\n#Пример фильтра из callHandler\nfilter:\n  module: balances\n  method: Deposit\n  success: true\n\n\n1\n2\n3\n4\n5\n\n\nВ следующей таблице описываются фильтры поддерживаемые различными обработчиками.\n\nHANDLER             ПОДДЕРЖИВАЕМЫЙ ФИЛЬТР\nОбработчик блоков   специализация\nEventHandler        module,method\nCallHandler         module,method ,success\n\n * Фильтры модулей и методов поддерживаются в любой блокчейн цепи, построенной на Substrate.\n * success фильтр принимает логическое значение и может быть использован для фильтрации дополнительных по его статусу успеха.\n * specVersion определяет диапазон версии спецификации для блока substrate. Следующие примеры описывают, как установить диапазон версий.\n\nfilter:\n  specVersion: [23, 24] #Index блок с specVersion в диапазоне от 23 до 24 (включительно).\n  specVersion: [100]      #Index блок со спецификацией больше или равно 100.\n  specVersion: [null, 23] #Индекс блок со специализацией менее 23.\n\n\n1\n2\n3\n4\n\n\n\n# Пользовательские цепочки\n\nВы можете проиндексировать данные из пользовательских цепей, включив в project.yaml. Объявить конкретные типы, поддерживаемые блокчейном в network.types. Мы поддерживаем дополнительные типы, используемые модулями выполнения substrate.\n\nТакже поддерживаются typesAlias, typesBundle, typesChain, и typesSpec.\n\nspecVersion: \"0.0.1\"\ndescription: \"This subquery indexes kitty's birth info\"\nrepository: \"https://github.com/onfinality-io/subql-examples\"\nschema: \"./schema.graphql\"\nnetwork:\n  endpoint: \"ws://host.kittychain. o/public-ws\"\n  типы: {\n    \"KittyIndex\": \"u32\",\n    \"Kitty\": \"[u8; 16]\"\n  }\n# typesChain: { chain: { Type5: 'example' } }\n# typesSpec: { spec: { Type6: 'example' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter: #Optional\n      specName: kitty-chain\n    mapping:\n      handlers:\n        - handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n",normalizedContent:"# фаил манифеста\n\nманифест фаил project. amlможно рассматривать как входную точку вашего проекта, и он определяет большую часть деталеи о том, как subquery будет индексировать и преобразовывать данные цепочки.\n\nманифест может быть в формате yaml или json. в этом документе мы будем использовать yaml во всех примерах. ниже приведен стандартныи пример базового project.yaml.\n\nspecversion: '0.0.1'\ndescription: ''\nrepository: 'https://github.com/subquery/subql-starter'\n\nschema: './schema.graphql'\n\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: 'https://api.subquery.network/sq/subquery/dictionary-polkadot'\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network. \\endpoint определяет конечную точку wss или ws для индексирования блокчеина - это должно быть полныи архивныи узел.\n * network.dictionary при необходимости предоставляет http конечную точку полного словаря для ускорения обработки - см. running an indexer\n * datasources определяет данные, которые будут отфильтрованы и извлечены, а также расположение обработчика карты для применения преобразования данных.\n   * kind поддерживает только substrate/runtime сеичас.\n   * startblock определяет высоту блока для начала индексации.\n   * filter фильтрует источник данных для выполнения по сетевому имени спецификации конечнои точки, см. сетевые фильтры\n   * mapping.handlers выведет список всех mapping functions и соответствующих типов обработчиков, с дополнительными mapping filters.\n\n\n# сетевые фильтры\n\nобычно пользователь создаст subquery и будет повторно использовать его как для тестнетов, так и для маиннет среды(например, polkadot и kusama). между сетями различные опции, вероятно, отличаются (например, стартовыи блок индекса). поэтому мы позволяем пользователям определять различные детали для каждого источника данных, что означает, что один проект subquery по-прежнему может использоваться в нескольких сетях.\n\nпользователи могут добавить filter на datasources для решения о том, какои источник данных запускать в каждои сети.\n\nниже приведен пример, которыи показывает различные источники данных как для polkadot так и для kusama.\n\n\n---\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter: #optional\n      specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter:\n      specname: kusama\n    startblock: 12000\n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# фильтры сопоставления\n\nфильтры сопоставления являются чрезвычаино полезнои функциеи, чтобы решить, что блок, событие или надпись вызовут обработчик сопоставления.\n\nтолько входящие данные, удовлетворяющие условия фильтра, будут обрабатываться функциями сопоставления. фильтры сопоставления являются необязательными, но рекомендуются, поскольку они значительно уменьшают объем данных, обрабатываемых вашим проектом subquery и повышают производительность индексации.\n\n#пример фильтра из callhandler\nfilter:\n  module: balances\n  method: deposit\n  success: true\n\n\n1\n2\n3\n4\n5\n\n\nв следующеи таблице описываются фильтры поддерживаемые различными обработчиками.\n\nhandler             поддерживаемыи фильтр\nобработчик блоков   специализация\neventhandler        module,method\ncallhandler         module,method ,success\n\n * фильтры модулеи и методов поддерживаются в любои блокчеин цепи, построеннои на substrate.\n * success фильтр принимает логическое значение и может быть использован для фильтрации дополнительных по его статусу успеха.\n * specversion определяет диапазон версии спецификации для блока substrate. следующие примеры описывают, как установить диапазон версии.\n\nfilter:\n  specversion: [23, 24] #index блок с specversion в диапазоне от 23 до 24 (включительно).\n  specversion: [100]      #index блок со спецификациеи больше или равно 100.\n  specversion: [null, 23] #индекс блок со специализациеи менее 23.\n\n\n1\n2\n3\n4\n\n\n\n# пользовательские цепочки\n\nвы можете проиндексировать данные из пользовательских цепеи, включив в project.yaml. объявить конкретные типы, поддерживаемые блокчеином в network.types. мы поддерживаем дополнительные типы, используемые модулями выполнения substrate.\n\nтакже поддерживаются typesalias, typesbundle, typeschain, и typesspec.\n\nspecversion: \"0.0.1\"\ndescription: \"this subquery indexes kitty's birth info\"\nrepository: \"https://github.com/onfinality-io/subql-examples\"\nschema: \"./schema.graphql\"\nnetwork:\n  endpoint: \"ws://host.kittychain. o/public-ws\"\n  типы: {\n    \"kittyindex\": \"u32\",\n    \"kitty\": \"[u8; 16]\"\n  }\n# typeschain: { chain: { type5: 'example' } }\n# typesspec: { spec: { type6: 'example' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter: #optional\n      specname: kitty-chain\n    mapping:\n      handlers:\n        - handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Сопоставление",frontmatter:{summary:"Сопоставление Функции сопоставления определяют, как данные цепи преобразуются в оптимизированные GraphQL-сущности, которые мы ранее определили в файле schema.graphql. Сопоставления",meta:[{property:"og:url",content:"/ru/create/mapping.html"},{property:"og:title",content:"Сопоставление"},{property:"og:description",content:"Сопоставление Функции сопоставления определяют, как данные цепи преобразуются в оптимизированные GraphQL-сущности, которые мы ранее определили в файле schema.graphql. Сопоставления"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/create/mapping.html",relativePath:"ru/create/mapping.md",key:"v-afcff1e6",path:"/ru/create/mapping/",headers:[{level:2,title:"Обработчик блоков",slug:"обработчик-блоков",normalizedTitle:"обработчик блоков",charIndex:632},{level:2,title:"Обработчик событий",slug:"обработчик-событии",normalizedTitle:"обработчик событии",charIndex:1377},{level:2,title:"Обработчик вызовов",slug:"обработчик-вызовов",normalizedTitle:"обработчик вызовов",charIndex:2683},{level:2,title:"Состояния запроса",slug:"состояния-запроса",normalizedTitle:"состояния запроса",charIndex:3301},{level:2,title:"RPC-вызовы",slug:"rpc-вызовы",normalizedTitle:"rpc-вызовы",charIndex:4329},{level:2,title:"Модули и Библиотеки",slug:"модули-и-библиотеки",normalizedTitle:"модули и библиотеки",charIndex:5386},{level:3,title:"Встроенные модули",slug:"встроенные-модули",normalizedTitle:"встроенные модули",charIndex:5864},{level:3,title:"Сторонние библиотеки",slug:"сторонние-библиотеки",normalizedTitle:"сторонние библиотеки",charIndex:6558},{level:2,title:"Кастомные Substrate цепи",slug:"кастомные-substrate-цепи",normalizedTitle:"кастомные substrate цепи",charIndex:6921},{level:3,title:"Подготовка",slug:"подготовка",normalizedTitle:"подготовка",charIndex:7279},{level:3,title:"Генерация типов",slug:"генерация-типов",normalizedTitle:"генерация типов",charIndex:10400},{level:3,title:"Использование",slug:"использование",normalizedTitle:"использование",charIndex:11650},{level:3,title:"Пользовательские вызовы в цепочке rpc",slug:"пользовательские-вызовы-в-цепочке-rpc",normalizedTitle:"пользовательские вызовы в цепочке rpc",charIndex:12581}],readingTime:{minutes:2.85,words:855},headersStr:"Обработчик блоков Обработчик событий Обработчик вызовов Состояния запроса RPC-вызовы Модули и Библиотеки Встроенные модули Сторонние библиотеки Кастомные Substrate цепи Подготовка Генерация типов Использование Пользовательские вызовы в цепочке rpc",content:'# Сопоставление\n\nФункции сопоставления определяют, как данные цепи преобразуются в оптимизированные GraphQL-сущности, которые мы ранее определили в файле schema.graphql.\n\nСопоставления написаны в подгруппе TypeScript называется AssemblyScript, который может быть скомпилирован в WASM (WebAssembly).\n\n * Сопоставления определяются в директории src/mapappings и экспортируются как функция\n * Эти сопоставления также экспортированы в src/index.ts\n * Файлы сопоставлений являются ссылками в project.yaml под обработчиками сопоставлений.\n\nСуществует три класса функций сопоставления; Block handlers, Event Handlers, и Call Handlers.\n\n\n# Обработчик блоков\n\nВы можете использовать обработчики блоков для создания информации каждый раз, когда новый блок прикрепляется к цепочке Substrate, например номер блока. Для достижения этой цели, определенный BlockHandler будет вызываться один раз для каждого блока.\n\nimport {SubstrateBlock} from \'@subql/types\';\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n  // Create a new StarterEntity with the block hash as it\'s ID\n  const record = new starterEntity(block.block.header.hash.toString());\n  record.field1 = block.block.header.number.toNumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nSubstrateBlock является расширенным интерфейсом типа signedBlock, но также включает в себя specVersion и timestamp.\n\n\n# Обработчик событий\n\nВы можете использовать обработчики событий для сбора информации, когда определенные события включены в новый блок. События, входящие в стандартное время выполнения Substrate, и блок могут содержать несколько событий.\n\nВо время обработки события в качестве аргумента с напечатанными входами и выходами, обработчик событий будет получать подстрочное событие. Любой тип события запускает сопоставление, позволяя фиксировать действия с источником данных. Вы должны использовать Mapping Filters в вашем манифесте для фильтрации событий, чтобы сократить время, необходимое для индексирования данных и улучшения производительности сопоставления.\n\nимпортировать {SubstrateEvent} из "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Получение записи по ее ID\n    const запись = new starterEntity(event). xtrinsic.block.block.header.hash.toString());\n    record.field2 = account. oString();\n    record.field3 = (баланс как баланс).toBigInt();\n    ожидание record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nSubstrateEvent является расширенным интерфейсом типа EventRecord. Помимо данных события, он также включает в себя id (блок к которому принадлежит это событие) и дополнительным внутри этого блока.\n\n\n# Обработчик вызовов\n\nОбработчики вызовов используются, когда вы хотите запечатлеть информацию о некоторых substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n  const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n  record.field4 = extrinsic.block.timestamp;\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nSubstrateExtrinsic расширяет GenericExtrinsic. Назначенный id (блок, к которому принадлежит), и предоставляет дополнительное свойство, которое расширяет события среди этого блока. Кроме того, он регистрирует успешный статус этой надбавки.\n\n\n# Состояния запроса\n\nНаша цель - охватить все источники данных для пользователей для сопоставления обработчиков (более чем три типа событий интерфейса выше). Поэтому мы выставили некоторые из интерфейсов @polkadot/api для увеличения возможностей.\n\nЭто интерфейсы, которые мы поддерживаем в настоящее время:\n\n * api.query.<module>.<method>() будет запрашивать current блок.\n * api.query.<module>.<method>.multi() сделает несколько запросов типа same в текущем блоке.\n * api.queryMulti() сделает несколько запросов разных типов в текущем блоке.\n\nЭто интерфейсы, которые мы НЕ поддерживаем сейчас:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nСмотрите пример использования этого API в нашем validator-threshold варианте использования.\n\n\n# RPC-вызовы\n\nМы также поддерживаем некоторые методы API RPC, которые являются удалёнными вызовами, которые позволяют функции сопоставления взаимодействовать с реальным узлом, запросом и отправкой. Основной предпосылкой подзапроса является то, что он детерминирует и, следовательно, держать последовательные результаты мы разрешаем только исторические RPC-вызовы.\n\nДокументы в JSON-RPC предоставляют некоторые методы, которые используют BlockHash в качестве входного параметра (e. . в?: BlockHash), которые теперь разрешены. Мы также изменили эти методы, чтобы получить по умолчанию хэш текущего блока индексации.\n\n// Скажем, мы сейчас индексируем блок с этим хэшем номером\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Оригинальный метод имеет необязательный входной блок хэш\nconst b1 = ожидание api. pc.chain.getBlock(blockhash);\n\n// Он будет использовать текущий блок по умолчанию так:\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * Для Custom Substrate Chains RPC звонки смотрите usage.\n\n\n# Модули и Библиотеки\n\nДля улучшения возможностей обработки данных SubQuery, мы разрешили некоторые встроенные модули NodeJS для запущенных функций сопоставления в песочнице, и разрешили пользователям звонить в сторонние библиотеки.\n\nПожалуйста, обратите внимание, что это экспериментальная функция и вы можете столкнуться с ошибками или проблемами, которые могут негативно повлиять на ваши функции сопоставления. Пожалуйста, сообщите о любых ошибках, создав вопрос в GitHub.\n\n\n# Встроенные модули\n\nВ настоящее время мы разрешаем следующие модули NodeJS:assert, buffer, crypto, util, and path.\n\nВместо того, чтобы импортировать весь модуль, мы рекомендуем импортировать только нужный метод(ы). Некоторые методы в этих модулях могут иметь неподдерживаемые зависимости и не будут выполнены при импорте.\n\nимпортировать {hashMessage} из "ethers/lib/utils"; //Хороший способ\nимпорта {utils} из "ethers" //Некорректный\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic. lock.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    ожидание записи.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Сторонние библиотеки\n\nИз-за ограничений виртуальной машины в песочнице мы поддерживаем только сторонние библиотеки, написанные CommonJS.\n\nМы также поддерживаем гибридную библиотеку , такую как @polkadot/* , использующую ESM по умолчанию. Однако, если другие библиотеки зависят от модулей в формате ESM , виртуальная машина НЕ компилирует и возвращает ошибку.\n\n\n# Кастомные Substrate цепи\n\nSubquery может быть использован не только в Polkadot или Kusama.\n\nВы можете использовать кастомную Substrate цепь, и мы предоставляем инструменты для импорта типов, интерфейсов и дополнительных методов, автоматически используя @polkadot/typegen.\n\nВ следующих разделах мы используем наш набор для объяснения процесса интеграции.\n\n\n# Подготовка\n\nСоздайте новый каталог api-интерфейсов в папке проекта src для хранения всех необходимых и сгенерированных файлов. Мы также создаем каталог api-interfaces/kitties , так как хотим добавить декорирование в API из модуля наборов.\n\n# Метаданные\n\nНам нужны метаданные для создания реальных конечных точек API. В примере c котятами мы используем конечную точку из локальной тестовой сети, и она предоставляет дополнительные типы. Выполните шаги в настройках метаданных PolkadotJS , чтобы получить метаданные узла из конечной точки HTTP.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nили из его веб-сокета с помощью websocet:\n\n//Установить websocat\nbrew install websocat\n\n//Получить метаданные\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nДалее скопируйте и вставьте вывод в файл JSON. В нашем примере c котятами, мы создали api-interface/kitty.json.\n\n# Определения типов\n\nМы предполагаем, что пользователь знает конкретные типы и поддержку RPC из цепочки, и она определена в Манифесте.\n\nСледующие типа установки, мы создаем :\n\n * src/api-interfaces/definitions.ts - экспортирует все определения подпапок\n\nэкспортировать { default as kitties } из \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - определения типа для модуля котят\n\nэкспорт по умолчанию {\n    // пользовательские типы\n    : {\n        Адрес: "AccountId",\n        Справка: "ID клиента",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api. pc.kitties. etKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            параметр: [\n                {name: \'at\', тип: \'BlockHash\', История: правда, необязательно: false}, {name: \'kittyIndex\', тип: \'KittyIndex\', необязательно: ложно}], type: \'Баланс\'}}}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n# Пакеты\n\n * В пакете . son файл, не забудьте добавить @polkadot/typegen в качестве зависимостей для разработки и @polkadot/api как обычную зависимость (в идеале ту же версию). Нам также нужно ts-node в качестве зависимости для разработки, чтобы помочь нам запустить скрипты.\n * Мы добавляем скрипты для запуска обоих типов; generate:defs и метаданных generate:meta generators (в таком порядке, чтобы метаданные могли использовать типы).\n\nВот упрощённая версия package.json. Убедитесь, что в разделе скрипты имя пакета верно, и каталоги верны.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input . src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint . src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9. "\n  },\n  "devDependencies": {\n    "typescript": "^4.1. ",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Генерация типов\n\nТеперь, когда подготовка завершена, мы готовы генерировать типы и метаданные. Выполните следующие команды:\n\n# Для установки новых зависимостей\nyarn\n\n# Генерировать типы\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nВ каждой папке модулей (например, / kitties) теперь должен быть сгенерированный types.ts, который определяет все интерфейсы из определений этих модулей, а также файл index.ts, который их все экспортирует.\n\n# Сгенерировать метаданные\nyarn generate:meta\n\n\n1\n2\n\n\nЭта команда сгенерирует метаданные и новые api-дополнения к API. Поскольку мы не хотим использовать встроенный API, нам нужно будет заменить их, добавив явное переопределение в нашем tsconfig. сын. После обновления пути в конфигурации будут выглядеть следующим образом (без комментариев):\n\n{\n  "compilerOptions": {\n    // это имя пакета, которое мы используем (в импорте интерфейса, --пакет для генераторов)*/\n    "Информация о рождении/*": ["src/*"],\n    // здесь мы заменим добавление @polkadot/api своим генерируется из цепи\n    "@polkadot/api/augment": ["src/interfaces/augment-api. s"],\n    // заменить дополненные типы собственными, в соответствии с определениями\n    "@polkadot/types/augment": ["src/interfaces/augment-types. s"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Использование\n\nТеперь в функции сопоставления, мы можем показать, как метаданные и типы на самом деле украшают API. Конечная точка RPC будет поддерживать модули и методы, описанные выше. Для использования пользовательского вызова rpc см. раздел Пользовательские вызовы rpc цепи\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api. веер. itties. extKittyId();\n    // возвращаем тип Kitty, тип входных параметров: AccountId и KittyIndex\n    const allKitties = await api. uery.kitties.kitties(\'xxxxxxx\',123)\n    logger. nfo(`Следующий id котика ${nextKittyId}`)\n    //Другой rpc, установка не определена для blockhash\n    const kittyPrice = ожидание api. pc.kitties.getKittyPrice(неизвестно, nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nЕсли вы хотите опубликовать этот проект нашему исследователю, пожалуйста, включите сгенерированные файлы в src/api-интерфейсы.\n\n\n# Пользовательские вызовы в цепочке rpc\n\nДля поддержки пользовательских вызовов в цепочке RPC мы должны вручную вставить определения RPC для typesBundle, что позволяет конфигурацию для каждой точки. Вы можете определить typesBundle в project.yml. И пожалуйста, помните только isHistoric тип звонков поддерживается.\n\n...\n  типы: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                параметров: [\n                  {name: \'at\', тип: \'BlockHash\', История: правда, необязательно: false}, {name: \'kittyIndex\', тип: \'KittyIndex\', необязательно: ложно}], тип: "Баланс", }}}}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n',normalizedContent:'# сопоставление\n\nфункции сопоставления определяют, как данные цепи преобразуются в оптимизированные graphql-сущности, которые мы ранее определили в фаиле schema.graphql.\n\nсопоставления написаны в подгруппе typescript называется assemblyscript, которыи может быть скомпилирован в wasm (webassembly).\n\n * сопоставления определяются в директории src/mapappings и экспортируются как функция\n * эти сопоставления также экспортированы в src/index.ts\n * фаилы сопоставлении являются ссылками в project.yaml под обработчиками сопоставлении.\n\nсуществует три класса функции сопоставления; block handlers, event handlers, и call handlers.\n\n\n# обработчик блоков\n\nвы можете использовать обработчики блоков для создания информации каждыи раз, когда новыи блок прикрепляется к цепочке substrate, например номер блока. для достижения этои цели, определенныи blockhandler будет вызываться один раз для каждого блока.\n\nimport {substrateblock} from \'@subql/types\';\n\nexport async function handleblock(block: substrateblock): promise<void> {\n  // create a new starterentity with the block hash as it\'s id\n  const record = new starterentity(block.block.header.hash.tostring());\n  record.field1 = block.block.header.number.tonumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nsubstrateblock является расширенным интерфеисом типа signedblock, но также включает в себя specversion и timestamp.\n\n\n# обработчик событии\n\nвы можете использовать обработчики событии для сбора информации, когда определенные события включены в новыи блок. события, входящие в стандартное время выполнения substrate, и блок могут содержать несколько событии.\n\nво время обработки события в качестве аргумента с напечатанными входами и выходами, обработчик событии будет получать подстрочное событие. любои тип события запускает сопоставление, позволяя фиксировать деиствия с источником данных. вы должны использовать mapping filters в вашем манифесте для фильтрации событии, чтобы сократить время, необходимое для индексирования данных и улучшения производительности сопоставления.\n\nимпортировать {substrateevent} из "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // получение записи по ее id\n    const запись = new starterentity(event). xtrinsic.block.block.header.hash.tostring());\n    record.field2 = account. ostring();\n    record.field3 = (баланс как баланс).tobigint();\n    ожидание record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nsubstrateevent является расширенным интерфеисом типа eventrecord. помимо данных события, он также включает в себя id (блок к которому принадлежит это событие) и дополнительным внутри этого блока.\n\n\n# обработчик вызовов\n\nобработчики вызовов используются, когда вы хотите запечатлеть информацию о некоторых substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n  const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n  record.field4 = extrinsic.block.timestamp;\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nsubstrateextrinsic расширяет genericextrinsic. назначенныи id (блок, к которому принадлежит), и предоставляет дополнительное своиство, которое расширяет события среди этого блока. кроме того, он регистрирует успешныи статус этои надбавки.\n\n\n# состояния запроса\n\nнаша цель - охватить все источники данных для пользователеи для сопоставления обработчиков (более чем три типа событии интерфеиса выше). поэтому мы выставили некоторые из интерфеисов @polkadot/api для увеличения возможностеи.\n\nэто интерфеисы, которые мы поддерживаем в настоящее время:\n\n * api.query.<module>.<method>() будет запрашивать current блок.\n * api.query.<module>.<method>.multi() сделает несколько запросов типа same в текущем блоке.\n * api.querymulti() сделает несколько запросов разных типов в текущем блоке.\n\nэто интерфеисы, которые мы не поддерживаем сеичас:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nсмотрите пример использования этого api в нашем validator-threshold варианте использования.\n\n\n# rpc-вызовы\n\nмы также поддерживаем некоторые методы api rpc, которые являются удаленными вызовами, которые позволяют функции сопоставления взаимодеиствовать с реальным узлом, запросом и отправкои. основнои предпосылкои подзапроса является то, что он детерминирует и, следовательно, держать последовательные результаты мы разрешаем только исторические rpc-вызовы.\n\nдокументы в json-rpc предоставляют некоторые методы, которые используют blockhash в качестве входного параметра (e. . в?: blockhash), которые теперь разрешены. мы также изменили эти методы, чтобы получить по умолчанию хэш текущего блока индексации.\n\n// скажем, мы сеичас индексируем блок с этим хэшем номером\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// оригинальныи метод имеет необязательныи входнои блок хэш\nconst b1 = ожидание api. pc.chain.getblock(blockhash);\n\n// он будет использовать текущии блок по умолчанию так:\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * для custom substrate chains rpc звонки смотрите usage.\n\n\n# модули и библиотеки\n\nдля улучшения возможностеи обработки данных subquery, мы разрешили некоторые встроенные модули nodejs для запущенных функции сопоставления в песочнице, и разрешили пользователям звонить в сторонние библиотеки.\n\nпожалуиста, обратите внимание, что это экспериментальная функция и вы можете столкнуться с ошибками или проблемами, которые могут негативно повлиять на ваши функции сопоставления. пожалуиста, сообщите о любых ошибках, создав вопрос в github.\n\n\n# встроенные модули\n\nв настоящее время мы разрешаем следующие модули nodejs:assert, buffer, crypto, util, and path.\n\nвместо того, чтобы импортировать весь модуль, мы рекомендуем импортировать только нужныи метод(ы). некоторые методы в этих модулях могут иметь неподдерживаемые зависимости и не будут выполнены при импорте.\n\nимпортировать {hashmessage} из "ethers/lib/utils"; //хорошии способ\nимпорта {utils} из "ethers" //некорректныи\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic. lock.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    ожидание записи.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# сторонние библиотеки\n\nиз-за ограничении виртуальнои машины в песочнице мы поддерживаем только сторонние библиотеки, написанные commonjs.\n\nмы также поддерживаем гибридную библиотеку , такую как @polkadot/* , использующую esm по умолчанию. однако, если другие библиотеки зависят от модулеи в формате esm , виртуальная машина не компилирует и возвращает ошибку.\n\n\n# кастомные substrate цепи\n\nsubquery может быть использован не только в polkadot или kusama.\n\nвы можете использовать кастомную substrate цепь, и мы предоставляем инструменты для импорта типов, интерфеисов и дополнительных методов, автоматически используя @polkadot/typegen.\n\nв следующих разделах мы используем наш набор для объяснения процесса интеграции.\n\n\n# подготовка\n\nсоздаите новыи каталог api-интерфеисов в папке проекта src для хранения всех необходимых и сгенерированных фаилов. мы также создаем каталог api-interfaces/kitties , так как хотим добавить декорирование в api из модуля наборов.\n\n# метаданные\n\nнам нужны метаданные для создания реальных конечных точек api. в примере c котятами мы используем конечную точку из локальнои тестовои сети, и она предоставляет дополнительные типы. выполните шаги в настроиках метаданных polkadotjs , чтобы получить метаданные узла из конечнои точки http.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nили из его веб-сокета с помощью websocet:\n\n//установить websocat\nbrew install websocat\n\n//получить метаданные\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nдалее скопируите и вставьте вывод в фаил json. в нашем примере c котятами, мы создали api-interface/kitty.json.\n\n# определения типов\n\nмы предполагаем, что пользователь знает конкретные типы и поддержку rpc из цепочки, и она определена в манифесте.\n\nследующие типа установки, мы создаем :\n\n * src/api-interfaces/definitions.ts - экспортирует все определения подпапок\n\nэкспортировать { default as kitties } из \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - определения типа для модуля котят\n\nэкспорт по умолчанию {\n    // пользовательские типы\n    : {\n        адрес: "accountid",\n        справка: "id клиента",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api. pc.kitties. etkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            параметр: [\n                {name: \'at\', тип: \'blockhash\', история: правда, необязательно: false}, {name: \'kittyindex\', тип: \'kittyindex\', необязательно: ложно}], type: \'баланс\'}}}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n# пакеты\n\n * в пакете . son фаил, не забудьте добавить @polkadot/typegen в качестве зависимостеи для разработки и @polkadot/api как обычную зависимость (в идеале ту же версию). нам также нужно ts-node в качестве зависимости для разработки, чтобы помочь нам запустить скрипты.\n * мы добавляем скрипты для запуска обоих типов; generate:defs и метаданных generate:meta generators (в таком порядке, чтобы метаданные могли использовать типы).\n\nвот упрощенная версия package.json. убедитесь, что в разделе скрипты имя пакета верно, и каталоги верны.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input . src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint . src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9. "\n  },\n  "devdependencies": {\n    "typescript": "^4.1. ",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# генерация типов\n\nтеперь, когда подготовка завершена, мы готовы генерировать типы и метаданные. выполните следующие команды:\n\n# для установки новых зависимостеи\nyarn\n\n# генерировать типы\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nв каждои папке модулеи (например, / kitties) теперь должен быть сгенерированныи types.ts, которыи определяет все интерфеисы из определении этих модулеи, а также фаил index.ts, которыи их все экспортирует.\n\n# сгенерировать метаданные\nyarn generate:meta\n\n\n1\n2\n\n\nэта команда сгенерирует метаданные и новые api-дополнения к api. поскольку мы не хотим использовать встроенныи api, нам нужно будет заменить их, добавив явное переопределение в нашем tsconfig. сын. после обновления пути в конфигурации будут выглядеть следующим образом (без комментариев):\n\n{\n  "compileroptions": {\n    // это имя пакета, которое мы используем (в импорте интерфеиса, --пакет для генераторов)*/\n    "информация о рождении/*": ["src/*"],\n    // здесь мы заменим добавление @polkadot/api своим генерируется из цепи\n    "@polkadot/api/augment": ["src/interfaces/augment-api. s"],\n    // заменить дополненные типы собственными, в соответствии с определениями\n    "@polkadot/types/augment": ["src/interfaces/augment-types. s"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# использование\n\nтеперь в функции сопоставления, мы можем показать, как метаданные и типы на самом деле украшают api. конечная точка rpc будет поддерживать модули и методы, описанные выше. для использования пользовательского вызова rpc см. раздел пользовательские вызовы rpc цепи\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api. веер. itties. extkittyid();\n    // возвращаем тип kitty, тип входных параметров: accountid и kittyindex\n    const allkitties = await api. uery.kitties.kitties(\'xxxxxxx\',123)\n    logger. nfo(`следующии id котика ${nextkittyid}`)\n    //другои rpc, установка не определена для blockhash\n    const kittyprice = ожидание api. pc.kitties.getkittyprice(неизвестно, nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nесли вы хотите опубликовать этот проект нашему исследователю, пожалуиста, включите сгенерированные фаилы в src/api-интерфеисы.\n\n\n# пользовательские вызовы в цепочке rpc\n\nдля поддержки пользовательских вызовов в цепочке rpc мы должны вручную вставить определения rpc для typesbundle, что позволяет конфигурацию для каждои точки. вы можете определить typesbundle в project.yml. и пожалуиста, помните только ishistoric тип звонков поддерживается.\n\n...\n  типы: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                параметров: [\n                  {name: \'at\', тип: \'blockhash\', история: правда, необязательно: false}, {name: \'kittyindex\', тип: \'kittyindex\', необязательно: ложно}], тип: "баланс", }}}}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n',charsets:{cyrillic:!0,cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Часто задаваемые вопросы",frontmatter:{summary:"Часто задаваемые вопросы Что такое SubQuery? SubQuery - это проект с открытым исходным кодом, который позволяет разработчикам индексировать, преобразовывать и запрашивать данные це",meta:[{property:"og:url",content:"/ru/faqs/faqs.html"},{property:"og:title",content:"Часто задаваемые вопросы"},{property:"og:description",content:"Часто задаваемые вопросы Что такое SubQuery? SubQuery - это проект с открытым исходным кодом, который позволяет разработчикам индексировать, преобразовывать и запрашивать данные це"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/faqs/faqs.html",relativePath:"ru/faqs/faqs.md",key:"v-249ce353",path:"/ru/faqs/faqs/",headers:[{level:2,title:"Что такое SubQuery?",slug:"что-такое-subquery",normalizedTitle:"что такое subquery?",charIndex:31},{level:2,title:"Какой лучший способ начать работу с SubQuery?",slug:"какои-лучшии-способ-начать-работу-с-subquery",normalizedTitle:"какои лучшии способ начать работу с subquery?",charIndex:472},{level:2,title:"Как я могу внести свой вклад или оставить отзыв для SubQuery?",slug:"как-я-могу-внести-свои-вклад-или-оставить-отзыв-для-subquery",normalizedTitle:"как я могу внести свои вклад или оставить отзыв для subquery?",charIndex:801},{level:2,title:"Сколько стоит разместить мой проект в SubQuery?",slug:"сколько-стоит-разместить-мои-проект-в-subquery",normalizedTitle:"сколько стоит разместить мои проект в subquery?",charIndex:1248},{level:2,title:"Что такое слоты развертывания?",slug:"что-такое-слоты-развертывания",normalizedTitle:"что такое слоты развертывания?",charIndex:1538},{level:2,title:"В чем преимущество промежуточного слота?",slug:"в-чем-преимущество-промежуточного-слота",normalizedTitle:"в чем преимущество промежуточного слота?",charIndex:2225},{level:2,title:"Что такое надстройки?",slug:"что-такое-надстроики",normalizedTitle:"что такое надстроики?",charIndex:2752}],readingTime:{minutes:.22,words:66},headersStr:"Что такое SubQuery? Какой лучший способ начать работу с SubQuery? Как я могу внести свой вклад или оставить отзыв для SubQuery? Сколько стоит разместить мой проект в SubQuery? Что такое слоты развертывания? В чем преимущество промежуточного слота? Что такое надстройки?",content:'# Часто задаваемые вопросы\n\n\n# Что такое SubQuery?\n\nSubQuery - это проект с открытым исходным кодом, который позволяет разработчикам индексировать, преобразовывать и запрашивать данные цепи Substrate для питания своих приложений.\n\nSubQuery также предоставляет бесплатный хостинг проектов по производству для разработчиков, позволяя им снять ответственность за построение инфраструктуры, и также позволяет разработчикам делать то, что они делают лучше всего - строить.\n\n\n# Какой лучший способ начать работу с SubQuery?\n\nЛучший способ начать работу с SubQuery - попробовать наш Урок «Приветствуем мир». Это простая 5-минутная прогулка по загрузке начального шаблона, построению проекта, а затем с помощью использования Docker для запуска узла на вашем локальном хосте и выполнения простого запроса.\n\n\n# Как я могу внести свой вклад или оставить отзыв для SubQuery?\n\nНам нравится вклад и отзывы сообщества. Чтобы внести свой код, форкните интересующее вас хранилище и внесите свои изменения. Затем отправьте PR или Pull Request. Ах, не забудь еще и протестировать! Также ознакомьтесь с нашими рекомендациями внесению дополнений (скоро).\n\nЧтобы оставить отзыв, свяжитесь с нами по адресу hello@subquery.network или перейдите на наш discord channel\n\n\n# Сколько стоит разместить мой проект в SubQuery?\n\nРазмещение вашего проекта в SubQuery Projects абсолютно бесплатно - это наш способ отблагодарить сообщество. Чтобы научиться каким образом размещать ваш проект у нас, пожалуйста ознакомьтесь с руководством Hello World (SubQuery hosted).\n\n\n# Что такое слоты развертывания?\n\nСлоты развертывания - это функция в SubQuery Projects, которая является эквивалентом среды разработки. Например, в любой организации занимающейся программным обеспечением обычно есть как минимум среда разработки и производственная среда (без учета localhost). Обычно дополнительные условия, такие как постановка и пре-продакшен или даже QA, включаются в зависимости от потребностей организации и их разработки.\n\nSubQuery в настоящее время имеет два доступных слота. Промежуточный слот и производственный слот. Это позволяет разработчикам установить свой SubQuery в промежуточную среду и если все хорошо, "продвинуть в производство" щелчком по кнопке.\n\n\n# В чем преимущество промежуточного слота?\n\nОсновное преимущество использования промежуточного слота состоит в том, что он позволяет вам подготовить новую версию вашего проекта SubQuery, не раскрывая ее публично. Вы можете подождать, пока промежуточный слот переиндексирует все данные, не затрагивая рабочие приложения.\n\nПромежуточный слот не отображается публично в Explorer и имеет уникальный URL, который видим только вам. И, конечно же, отдельная среда позволяет вам тестировать новый код, не ущерба вашему производству.\n\n\n# Что такое надстройки?\n\nЕсли вы уже знакомы с понятиями блокчейна, вы можете подумать о дополнительных функциях, сопоставимых с транзакциями. Однако более формально надстройками является часть информации, которая поступает извне цепи и включена в блок. Есть три категории надстроек. Они являются неотъемлемыми элементами, подписанными транзакциями и неподписанными транзакциями.\n\nInherent Extrinsics - это части информации, которые не подписаны и вставляются в блок автором блока.\n\nВнешние подписанные транзакции - это транзакции, которые содержат подпись учетной записи, выданного транзакцией. Они должны заплатить комиссию за включение транзакции в цепочку.\n\nНеподписанные транзакции – это транзакции, которые не содержат подписи счета, который выдает транзакцию. Неподписанные транзакции должны использоваться с осторожностью, потому что никто не платит комиссию, так как она подписана. Из-за этого в очереди транзакций отсутствует экономическая логика для предотвращения спама.\n\nДля получения дополнительной информации нажмите here.',normalizedContent:'# часто задаваемые вопросы\n\n\n# что такое subquery?\n\nsubquery - это проект с открытым исходным кодом, которыи позволяет разработчикам индексировать, преобразовывать и запрашивать данные цепи substrate для питания своих приложении.\n\nsubquery также предоставляет бесплатныи хостинг проектов по производству для разработчиков, позволяя им снять ответственность за построение инфраструктуры, и также позволяет разработчикам делать то, что они делают лучше всего - строить.\n\n\n# какои лучшии способ начать работу с subquery?\n\nлучшии способ начать работу с subquery - попробовать наш урок «приветствуем мир». это простая 5-минутная прогулка по загрузке начального шаблона, построению проекта, а затем с помощью использования docker для запуска узла на вашем локальном хосте и выполнения простого запроса.\n\n\n# как я могу внести свои вклад или оставить отзыв для subquery?\n\nнам нравится вклад и отзывы сообщества. чтобы внести свои код, форкните интересующее вас хранилище и внесите свои изменения. затем отправьте pr или pull request. ах, не забудь еще и протестировать! также ознакомьтесь с нашими рекомендациями внесению дополнении (скоро).\n\nчтобы оставить отзыв, свяжитесь с нами по адресу hello@subquery.network или переидите на наш discord channel\n\n\n# сколько стоит разместить мои проект в subquery?\n\nразмещение вашего проекта в subquery projects абсолютно бесплатно - это наш способ отблагодарить сообщество. чтобы научиться каким образом размещать ваш проект у нас, пожалуиста ознакомьтесь с руководством hello world (subquery hosted).\n\n\n# что такое слоты развертывания?\n\nслоты развертывания - это функция в subquery projects, которая является эквивалентом среды разработки. например, в любои организации занимающеися программным обеспечением обычно есть как минимум среда разработки и производственная среда (без учета localhost). обычно дополнительные условия, такие как постановка и пре-продакшен или даже qa, включаются в зависимости от потребностеи организации и их разработки.\n\nsubquery в настоящее время имеет два доступных слота. промежуточныи слот и производственныи слот. это позволяет разработчикам установить свои subquery в промежуточную среду и если все хорошо, "продвинуть в производство" щелчком по кнопке.\n\n\n# в чем преимущество промежуточного слота?\n\nосновное преимущество использования промежуточного слота состоит в том, что он позволяет вам подготовить новую версию вашего проекта subquery, не раскрывая ее публично. вы можете подождать, пока промежуточныи слот переиндексирует все данные, не затрагивая рабочие приложения.\n\nпромежуточныи слот не отображается публично в explorer и имеет уникальныи url, которыи видим только вам. и, конечно же, отдельная среда позволяет вам тестировать новыи код, не ущерба вашему производству.\n\n\n# что такое надстроики?\n\nесли вы уже знакомы с понятиями блокчеина, вы можете подумать о дополнительных функциях, сопоставимых с транзакциями. однако более формально надстроиками является часть информации, которая поступает извне цепи и включена в блок. есть три категории надстроек. они являются неотъемлемыми элементами, подписанными транзакциями и неподписанными транзакциями.\n\ninherent extrinsics - это части информации, которые не подписаны и вставляются в блок автором блока.\n\nвнешние подписанные транзакции - это транзакции, которые содержат подпись учетнои записи, выданного транзакциеи. они должны заплатить комиссию за включение транзакции в цепочку.\n\nнеподписанные транзакции – это транзакции, которые не содержат подписи счета, которыи выдает транзакцию. неподписанные транзакции должны использоваться с осторожностью, потому что никто не платит комиссию, так как она подписана. из-за этого в очереди транзакции отсутствует экономическая логика для предотвращения спама.\n\nдля получения дополнительнои информации нажмите here.',charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Установка SubQuery",frontmatter:{summary:"Установка SubQuery Для создании проекта SubQuery требуются различные компоненты. Для запуска индексатора требуется компонент @subql/node. Для генерации запросов требуется библиотек",meta:[{property:"og:url",content:"/ru/install/install.html"},{property:"og:title",content:"Установка SubQuery"},{property:"og:description",content:"Установка SubQuery Для создании проекта SubQuery требуются различные компоненты. Для запуска индексатора требуется компонент @subql/node. Для генерации запросов требуется библиотек"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/install/install.html",relativePath:"ru/install/install.md",key:"v-60abd363",path:"/ru/install/install/",headers:[{level:2,title:"Установка @subql/cli",slug:"установка-subql-cli",normalizedTitle:"установка @subql/cli",charIndex:203},{level:2,title:"Установите @subql/node",slug:"установите-subql-node",normalizedTitle:"установите @subql/node",charIndex:591},{level:2,title:"Установите @subql/query",slug:"установите-subql-query",normalizedTitle:"установите @subql/query",charIndex:1210}],readingTime:{minutes:.38,words:115},headersStr:"Установка @subql/cli Установите @subql/node Установите @subql/query",content:'# Установка SubQuery\n\nДля создании проекта SubQuery требуются различные компоненты. Для запуска индексатора требуется компонент @subql/node. Для генерации запросов требуется библиотека @subql/query.\n\n\n# Установка @subql/cli\n\nБиблиотека @subql/cli помогает создать фреймворк проекта. Это означает, что вам не нужно начинать с нуля.\n\nУстановите SubQuery CLI на терминал, используя Yarn или NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nЗатем вы можете запустить справку, чтобы увидеть доступные команды и использовать их в CLI:\n\nсправка subql\n\n\n1\n\n\n\n# Установите @subql/node\n\nУзел SubQuery - это реализация, которая извлекает субстратегически данные блокчейна в рамках проекта SubQuery и сохраняет их в базу данных Postgres.\n\nУстановите ноду SubQuery на терминал, используя Yarn или NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nПосле установки вы можете запустить узел с:\n\nsubql-узел <command>\n\n\n1\n\n\n> Примечание: Если вы используете Docker или хостинг вашего проекта в проектах SubQuery вы можете пропустить этот шаг. Это происходит потому, что узел SubQuery уже находится в контейнере Docker и в инфраструктуре хостинга.\n\n\n# Установите @subql/query\n\nБиблиотека запросов SubQuery предоставляет сервис, который позволяет запускать ваш проект в среде "playground" через ваш браузер.\n\nУстановите запрос SubQuery на терминал с помощью Yarn или NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Примечание: Если вы используете Docker или хостинг вашего проекта в проектах SubQuery вы можете пропустить этот шаг. Это происходит потому, что узел SubQuery уже находится в контейнере Docker и в инфраструктуре хостинга.',normalizedContent:'# установка subquery\n\nдля создании проекта subquery требуются различные компоненты. для запуска индексатора требуется компонент @subql/node. для генерации запросов требуется библиотека @subql/query.\n\n\n# установка @subql/cli\n\nбиблиотека @subql/cli помогает создать фреимворк проекта. это означает, что вам не нужно начинать с нуля.\n\nустановите subquery cli на терминал, используя yarn или npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nзатем вы можете запустить справку, чтобы увидеть доступные команды и использовать их в cli:\n\nсправка subql\n\n\n1\n\n\n\n# установите @subql/node\n\nузел subquery - это реализация, которая извлекает субстратегически данные блокчеина в рамках проекта subquery и сохраняет их в базу данных postgres.\n\nустановите ноду subquery на терминал, используя yarn или npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nпосле установки вы можете запустить узел с:\n\nsubql-узел <command>\n\n\n1\n\n\n> примечание: если вы используете docker или хостинг вашего проекта в проектах subquery вы можете пропустить этот шаг. это происходит потому, что узел subquery уже находится в контеинере docker и в инфраструктуре хостинга.\n\n\n# установите @subql/query\n\nбиблиотека запросов subquery предоставляет сервис, которыи позволяет запускать ваш проект в среде "playground" через ваш браузер.\n\nустановите запрос subquery на терминал с помощью yarn или npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> примечание: если вы используете docker или хостинг вашего проекта в проектах subquery вы можете пропустить этот шаг. это происходит потому, что узел subquery уже находится в контеинере docker и в инфраструктуре хостинга.',charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Амбассадорская программа",frontmatter:{summary:"Амбассадорская программа Мы понимаем, что одна из наших самых сильных сторон - это наше сообщество, и с вашей помощью мы хотим расти и создавать локальных амбассадоров в сообщества",meta:[{property:"og:url",content:"/ru/miscellaneous/ambassadors.html"},{property:"og:title",content:"Амбассадорская программа"},{property:"og:description",content:"Амбассадорская программа Мы понимаем, что одна из наших самых сильных сторон - это наше сообщество, и с вашей помощью мы хотим расти и создавать локальных амбассадоров в сообщества"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/miscellaneous/ambassadors.html",relativePath:"ru/miscellaneous/ambassadors.md",key:"v-4a7311a2",path:"/ru/miscellaneous/ambassadors/",headers:[{level:2,title:"Во что мы верим",slug:"во-что-мы-верим",normalizedTitle:"во что мы верим",charIndex:228},{level:2,title:"Наша Амбассадорская программа",slug:"наша-амбассадорская-программа",normalizedTitle:"наша амбассадорская программа",charIndex:1452},{level:3,title:"Преимущества Амбассадоров",slug:"преимущества-амбассадоров",normalizedTitle:"преимущества амбассадоров",charIndex:1821},{level:2,title:"Как это работает",slug:"как-это-работает",normalizedTitle:"как это работает",charIndex:3191},{level:2,title:"Амбассадорские активности",slug:"амбассадорские-активности",normalizedTitle:"амбассадорские активности",charIndex:4209}],readingTime:{minutes:.16,words:49},headersStr:"Во что мы верим Наша Амбассадорская программа Преимущества Амбассадоров Как это работает Амбассадорские активности",content:"# Амбассадорская программа\n\n\n\nМы понимаем, что одна из наших самых сильных сторон - это наше сообщество, и с вашей помощью мы хотим расти и создавать локальных амбассадоров в сообществах по всему миру.\n\nПодай заявку сейчас!\n\n\n# Во что мы верим\n\nНаша команда собралась вместе, разделяя общие взгляды на создание основ гибкой и всеобъемлющей базы данных для экосистемы Polkadot.\n\nСоздано разработчиками, для разработчиков: SubQuery - растущее сообщество, фокусирующееся на предоставлении лучших продуктов и услуг для наших разработчиков, и разработчиков работающих в нашей экосистеме. SubQuery будет успешно функционировать только в том случае, если экосистема Polkadot будет успешно функционировать, поэтому все, что мы делаем, мы делаем с учетом интересов наших клиентов.\n\nЦелостность и подотчетность: У нас есть члены команды в Окленде, Шанхае и Сиднее, поэтому для нас важна удаленная работа. Мы надеемся, что наша сможет работать автономна для достижения наших совместных целей. Ключевым требованием для нашей команды является принятие ответственности за свои действия и за их добросовестность.\n\nСодержательное руководство и поддержка: Блокчейн - это сложно, и каждому иногда нужна помощь. В нашем сообществе не бывает глупых вопросов, и каждый в нашей команде обязательно будет поддерживать наших пользователей. Мы узнаем некоторые из самых ценных идей о нашем сервисе (и о том, как мы можем его улучшить) непосредственно от нашего сообщества.\n\n\n# Наша Амбассадорская программа\n\nНаша программа амбассадоров SubQuery нацелена на поиск лидеров сообщества с энтузиазмом о Polkadot и SubQuery. Мы ищем авторов, которые могут рассказать о SubQuery в своих локальных сообществах и оказывать поддержку новым разработчикам, которые хотят использовать SubQuery для создания удивительных приложений и сервисов на Polkadot.\n\n\n# Преимущества Амбассадоров\n\nВ SubQuery мы прилагаем все усилия для достижения того, что мы делаем. Аналогичным образом, амбассадоры должны выделить какое-то время при вступлении в нашу команду, но они будут вознаграждены преимуществами.\n\nФинансирование и поддержка: Вы можете быть вознаграждены за хорошую работу с ранними возможностями участия в частных продажах и получении наград. Кроме того, мы предоставим вам финансовые гранты для проведения встреч с сообществом.\n\nДоступ к команде SubQuery: Вы получите прямой доступ к команде SubQuery с возможностями практического обучения. Эксклюзивные AMAs с нашими лидерами и разработчиками, а также ознакомление с нашей «дорожной картой».\n\nРазвитие сети: Ожидайте рост вашей профессиональной деятельности, являясь послом одного из лучших проектов Polkadot. Познакомьтесь с другими послами по всему миру и получите доступ к локальным проектам Polkadot, которые нам необходимо поддерживать на местном уровне. Вы даже сможете получить свободный доступ для представления SubQuery в местных сообществах.\n\nSwag и другие бесплатные вещи: Каждый любит бесплатные вещи! Получайте ежегодное вознаграждение крутых вещей от SubQuery, что позволит вам выделяться в толпе. Плюс дополнительные вознаграждения, которые вы можете поделиться на общественных мероприятиях. Вы также получите эксклюзивный NFT для вашего статуса амбассадора.\n\n\n# Как это работает\n\nНаша программа амбассадоров имеет несколько уровней, каждый уровень имеет различные преимущества и возможности. Вы можете продвигаться вверх, участвуя в амбассадорских мероприятиях и упорно работая вместе с нами.\n\nКак только Вы отправите заявку, мы выберем кандидатов, которые соответствуют нашим ценностям. Если вас выберут, Вы будете размещены в нашей обучающей программе и получите информационный пакет, расширяющий Ваши знания о SubQuery. После этого вы можете начать работу по программе стажеров, выполнив определенные задания по адаптации. (например, создание SubQuery проекта). На протяжении всего этого процесса мы будем проводить семинары для того, чтобы поддержать вас.\n\nКак только вы пройдете программу стажировки, вы сможете назвать себя амбассадором SubQuery и будете приняты в нашу полную программу. После этого вы можете продолжить работать через программу и развиваться по категориям, чем выше вал ранг, тем больше привилегий и наград вы сможете получить.\n\nПодайте заявку сейчас!\n\n\n# Амбассадорские активности\n\nПослы SubQuery могут вносить свой вклад в четыре основные области, включая управление событиями, создание контента, перевод и модерацию сообществ. Вы можете принять участие во всех областях, в которых захотите, вы не привязаны ни к одной из них.\n\nУправление событиями: Создание местных сообществ путем хостинга, организации и создания различными мероприятий. Создание местного сообщества будет ключевой частью роста сообщества SubQuery . SubQuery поможет вам обеспечить финансирование событий, посылая уникальные вещи, которые будут выданы бесплатно, а также участие в «Q& В режиме реального времени в качестве спикеров или в сеансах АМА.\n\nСоздание контента: У нас есть большой список различного контента и поддерживающие материалы, с созданием которых нам нужна помощь. Помните, что наш успех зависит от способности наших клиентов строить удивительные вещи с помощью нашего сервиса, так что нам нужна ваша помощь, чтобы сделать это понятнее. Контент включает в себя видео, инфографики, обучающие материалы, анимацию или любые другие связанные материалы для информирования, обучения или воодушевление членов сообщества в рамках экосистемы SubQuery. SubQuery будет поддерживать создателей контента, предоставляя активы и опыт в области брендинга. Мы также будем использовать маркетинговые каналы SubQuery, чтобы повысить узнаваемость вашего контента (и вас самих).\n\nПереводы: Наши клиенты говорят не только по-английски! Нам нужна Ваша помощь, чтобы сделать SubQuery более доступным, переводя наш контент на ваш родной язык, а также помогая поделиться этим с нашим международным сообществом.\n\nМодератор сообщества: Модераторы будут способствовать развитию сообщества SubQuery, гарантируя, что официальные каналы сообщества будут активными и интересными. SubQuery будет поддерживать модераторов, продвигая каналы, которые они контролируют, а также давать рекомендации по нашим ожиданиям.\n\nПодайте заявку сейчас!",normalizedContent:"# амбассадорская программа\n\n\n\nмы понимаем, что одна из наших самых сильных сторон - это наше сообщество, и с вашеи помощью мы хотим расти и создавать локальных амбассадоров в сообществах по всему миру.\n\nподаи заявку сеичас!\n\n\n# во что мы верим\n\nнаша команда собралась вместе, разделяя общие взгляды на создание основ гибкои и всеобъемлющеи базы данных для экосистемы polkadot.\n\nсоздано разработчиками, для разработчиков: subquery - растущее сообщество, фокусирующееся на предоставлении лучших продуктов и услуг для наших разработчиков, и разработчиков работающих в нашеи экосистеме. subquery будет успешно функционировать только в том случае, если экосистема polkadot будет успешно функционировать, поэтому все, что мы делаем, мы делаем с учетом интересов наших клиентов.\n\nцелостность и подотчетность: у нас есть члены команды в окленде, шанхае и сиднее, поэтому для нас важна удаленная работа. мы надеемся, что наша сможет работать автономна для достижения наших совместных целеи. ключевым требованием для нашеи команды является принятие ответственности за свои деиствия и за их добросовестность.\n\nсодержательное руководство и поддержка: блокчеин - это сложно, и каждому иногда нужна помощь. в нашем сообществе не бывает глупых вопросов, и каждыи в нашеи команде обязательно будет поддерживать наших пользователеи. мы узнаем некоторые из самых ценных идеи о нашем сервисе (и о том, как мы можем его улучшить) непосредственно от нашего сообщества.\n\n\n# наша амбассадорская программа\n\nнаша программа амбассадоров subquery нацелена на поиск лидеров сообщества с энтузиазмом о polkadot и subquery. мы ищем авторов, которые могут рассказать о subquery в своих локальных сообществах и оказывать поддержку новым разработчикам, которые хотят использовать subquery для создания удивительных приложении и сервисов на polkadot.\n\n\n# преимущества амбассадоров\n\nв subquery мы прилагаем все усилия для достижения того, что мы делаем. аналогичным образом, амбассадоры должны выделить какое-то время при вступлении в нашу команду, но они будут вознаграждены преимуществами.\n\nфинансирование и поддержка: вы можете быть вознаграждены за хорошую работу с ранними возможностями участия в частных продажах и получении наград. кроме того, мы предоставим вам финансовые гранты для проведения встреч с сообществом.\n\nдоступ к команде subquery: вы получите прямои доступ к команде subquery с возможностями практического обучения. эксклюзивные amas с нашими лидерами и разработчиками, а также ознакомление с нашеи «дорожнои картои».\n\nразвитие сети: ожидаите рост вашеи профессиональнои деятельности, являясь послом одного из лучших проектов polkadot. познакомьтесь с другими послами по всему миру и получите доступ к локальным проектам polkadot, которые нам необходимо поддерживать на местном уровне. вы даже сможете получить свободныи доступ для представления subquery в местных сообществах.\n\nswag и другие бесплатные вещи: каждыи любит бесплатные вещи! получаите ежегодное вознаграждение крутых вещеи от subquery, что позволит вам выделяться в толпе. плюс дополнительные вознаграждения, которые вы можете поделиться на общественных мероприятиях. вы также получите эксклюзивныи nft для вашего статуса амбассадора.\n\n\n# как это работает\n\nнаша программа амбассадоров имеет несколько уровнеи, каждыи уровень имеет различные преимущества и возможности. вы можете продвигаться вверх, участвуя в амбассадорских мероприятиях и упорно работая вместе с нами.\n\nкак только вы отправите заявку, мы выберем кандидатов, которые соответствуют нашим ценностям. если вас выберут, вы будете размещены в нашеи обучающеи программе и получите информационныи пакет, расширяющии ваши знания о subquery. после этого вы можете начать работу по программе стажеров, выполнив определенные задания по адаптации. (например, создание subquery проекта). на протяжении всего этого процесса мы будем проводить семинары для того, чтобы поддержать вас.\n\nкак только вы проидете программу стажировки, вы сможете назвать себя амбассадором subquery и будете приняты в нашу полную программу. после этого вы можете продолжить работать через программу и развиваться по категориям, чем выше вал ранг, тем больше привилегии и наград вы сможете получить.\n\nподаите заявку сеичас!\n\n\n# амбассадорские активности\n\nпослы subquery могут вносить свои вклад в четыре основные области, включая управление событиями, создание контента, перевод и модерацию сообществ. вы можете принять участие во всех областях, в которых захотите, вы не привязаны ни к однои из них.\n\nуправление событиями: создание местных сообществ путем хостинга, организации и создания различными мероприятии. создание местного сообщества будет ключевои частью роста сообщества subquery . subquery поможет вам обеспечить финансирование событии, посылая уникальные вещи, которые будут выданы бесплатно, а также участие в «q& в режиме реального времени в качестве спикеров или в сеансах ама.\n\nсоздание контента: у нас есть большои список различного контента и поддерживающие материалы, с созданием которых нам нужна помощь. помните, что наш успех зависит от способности наших клиентов строить удивительные вещи с помощью нашего сервиса, так что нам нужна ваша помощь, чтобы сделать это понятнее. контент включает в себя видео, инфографики, обучающие материалы, анимацию или любые другие связанные материалы для информирования, обучения или воодушевление членов сообщества в рамках экосистемы subquery. subquery будет поддерживать создателеи контента, предоставляя активы и опыт в области брендинга. мы также будем использовать маркетинговые каналы subquery, чтобы повысить узнаваемость вашего контента (и вас самих).\n\nпереводы: наши клиенты говорят не только по-англииски! нам нужна ваша помощь, чтобы сделать subquery более доступным, переводя наш контент на ваш роднои язык, а также помогая поделиться этим с нашим международным сообществом.\n\nмодератор сообщества: модераторы будут способствовать развитию сообщества subquery, гарантируя, что официальные каналы сообщества будут активными и интересными. subquery будет поддерживать модераторов, продвигая каналы, которые они контролируют, а также давать рекомендации по нашим ожиданиям.\n\nподаите заявку сеичас!",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Брендинговые материалы",frontmatter:{summary:"Брендинговые материалы Все элементы бренда SubQuery являются собственностью, и мы очень серьезно относимся к нашему бренду. Если вы решили использовать любые торговые марки, логоти",meta:[{property:"og:url",content:"/ru/miscellaneous/branding.html"},{property:"og:title",content:"Брендинговые материалы"},{property:"og:description",content:"Брендинговые материалы Все элементы бренда SubQuery являются собственностью, и мы очень серьезно относимся к нашему бренду. Если вы решили использовать любые торговые марки, логоти"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/miscellaneous/branding.html",relativePath:"ru/miscellaneous/branding.md",key:"v-7ce7626d",path:"/ru/miscellaneous/branding/",headers:[{level:2,title:"Экспортируемый Figma File",slug:"экспортируемыи-figma-file",normalizedTitle:"экспортируемыи figma file",charIndex:372},{level:2,title:"Пакет брендовых активов",slug:"пакет-брендовых-активов",normalizedTitle:"пакет брендовых активов",charIndex:540}],readingTime:{minutes:.1,words:29},headersStr:"Экспортируемый Figma File Пакет брендовых активов",content:"# Брендинговые материалы\n\nВсе элементы бренда SubQuery являются собственностью, и мы очень серьезно относимся к нашему бренду.\n\nЕсли вы решили использовать любые торговые марки, логотипы, дизайны или другие функции бренда, внимательно следуйте руководящим принципам здесь или обращайтесь к нам через социальные сети для уточнения.\n\nЕсли у вас есть сомнения, спросите!\n\n\n# Экспортируемый Figma File\n\nНаш Figma File имеет полную коллекцию всех активов бренда (логотипы, шрифты, цвета, изображения и т.д.)\n\nFigma - ресурсы бренда SubQuery\n\n\n# Пакет брендовых активов\n\nУменьшенный ZIP файл бренда\n\npublic_branding.zip",normalizedContent:"# брендинговые материалы\n\nвсе элементы бренда subquery являются собственностью, и мы очень серьезно относимся к нашему бренду.\n\nесли вы решили использовать любые торговые марки, логотипы, дизаины или другие функции бренда, внимательно следуите руководящим принципам здесь или обращаитесь к нам через социальные сети для уточнения.\n\nесли у вас есть сомнения, спросите!\n\n\n# экспортируемыи figma file\n\nнаш figma file имеет полную коллекцию всех активов бренда (логотипы, шрифты, цвета, изображения и т.д.)\n\nfigma - ресурсы бренда subquery\n\n\n# пакет брендовых активов\n\nуменьшенныи zip фаил бренда\n\npublic_branding.zip",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Вклад в SubQuery",frontmatter:{summary:"Вклад в SubQuery Добро пожаловать и большое спасибо за то, что рассмотрели возможность внести свой вклад в этот проект SubQuery! Вместе мы сможем проложить путь к более децентрализ",meta:[{property:"og:url",content:"/ru/miscellaneous/contributing.html"},{property:"og:title",content:"Вклад в SubQuery"},{property:"og:description",content:"Вклад в SubQuery Добро пожаловать и большое спасибо за то, что рассмотрели возможность внести свой вклад в этот проект SubQuery! Вместе мы сможем проложить путь к более децентрализ"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/miscellaneous/contributing.html",relativePath:"ru/miscellaneous/contributing.md",key:"v-0258bce6",path:"/ru/miscellaneous/contributing/",headers:[{level:2,title:"Кодекс поведения",slug:"кодекс-поведения",normalizedTitle:"кодекс поведения",charIndex:892},{level:2,title:"Приступая к работе",slug:"приступая-к-работе",normalizedTitle:"приступая к работе",charIndex:1158},{level:2,title:"Как сделать вклад",slug:"как-сделать-вклад",normalizedTitle:"как сделать вклад",charIndex:1719},{level:3,title:"Сообщить об ошибках",slug:"сообщить-об-ошибках",normalizedTitle:"сообщить об ошибках",charIndex:1741},{level:3,title:"Отправка Pull Request'ов",slug:"отправка-pull-request-ов",normalizedTitle:"отправка pull request'ов",charIndex:2267},{level:2,title:"Контрагенты кодирования",slug:"контрагенты-кодирования",normalizedTitle:"контрагенты кодирования",charIndex:2728},{level:3,title:"Сообщения Git Commit",slug:"сообщения-git-commit",normalizedTitle:"сообщения git commit",charIndex:2756},{level:3,title:"Руководство по стилю JavaScript",slug:"руководство-по-стилю-javascript",normalizedTitle:"руководство по стилю javascript",charIndex:3011}],readingTime:{minutes:.13,words:38},headersStr:"Кодекс поведения Приступая к работе Как сделать вклад Сообщить об ошибках Отправка Pull Request'ов Контрагенты кодирования Сообщения Git Commit Руководство по стилю JavaScript",content:"# Вклад в SubQuery\n\nДобро пожаловать и большое спасибо за то, что рассмотрели возможность внести свой вклад в этот проект SubQuery! Вместе мы сможем проложить путь к более децентрализованному будущему.\n\n> Эта документация активно поддерживается командой SubQuery . Мы приветствуем ваш вклад, вы можете сделать это, форкнув наш проект GitHub и внеся изменения во все файлы markdown документации в каталоге docs.\n\nНиже приводится набор руководящих принципов (не правил) для внесения вклада в SubQuery. Следуя этим руководящим принципам, мы сделаем процесс внесения вклада простым и эффективным для всех заинтересованных сторон. Он также сообщает, что вы соглашаетесь уважать время управления и разработки этого проекта. В свою очередь, мы будем с уважением относиться к вашему вопросу, учитывая изменения, сотрудничаем с улучшениями и помогая вам окончательно оформлять запросы на слияние.\n\n\n# Кодекс поведения\n\nМы серьезно относимся к нашим проектам сообщества с открытым исходным кодом и к ответственности, и считаем, что мы и другие участники соблюдаем высокие стандарты общения. Участвуя в этом проекте, вы соглашаетесь соблюдать наш Кодекс поведения.\n\n\n# Приступая к работе\n\nВзносы в наши репозитории делаются через Issues и Pull requests (PR). Несколько общих руководящих принципов, которые охватывают и то и другое:\n\n * Ищите существующие Замечания и PR, прежде чем создавать собственные.\n * Мы прилагаем все усилия, чтобы обеспечить своевременное решение проблем, но, в зависимости от последствий, может потребоваться некоторое время, чтобы исследовать основную причину. Дружественное @ упоминание в ветке комментариев отправителю или участнику может помочь привлечь внимание, если ваша проблема блокируется.\n\n\n# Как сделать вклад\n\n\n# Сообщить об ошибках\n\nОшибки отслеживаются как проблемы в GitHub. При регистрации проблемы объясните проблему и включите дополнительные сведения, чтобы помочь специалистам по обслуживанию воспроизвести проблему:\n\n * Чтобы идентифицировать проблему, используйте понятное и описательное название.\n * Опишите точные шаги для воспроизведения проблемы.\n * Опишите поведение, которое вы наблюдали после выполнения шагов.\n * Объясните, какое поведение вы должны увидеть вместо этого и почему.\n * Если возможно, включите скриншоты\n\n\n# Отправка Pull Request'ов\n\nВ общем, мы следуем рабочему процессу Git, основанному на принципах «fork-and-pull»\n\n * Форкнуть репозиторий для вашей учетной записи на Github\n * Клонировать проект на вашу машину\n * Создать филиал локально с кратким, но описательным именем\n * Сохранить изменения в ветке\n * Следуя любым правилам форматирования и тестирования, специфичным для этого репозитория\n * Отправить изменения в ваш форк\n * Открыть PR в нашем репозитории\n\n\n# Контрагенты кодирования\n\n\n# Сообщения Git Commit\n\n * Используйте настоящее время («Добавить объект», а не «Добавлен объект»)\n * Используйте повелительное наклонение («Переместить курсор в...», а не «Переместить курсор в...»)\n * Ограничьте первую строку до 72 символов или меньше\n\n\n# Руководство по стилю JavaScript\n\n * Весь код JavaScript размещен на основе Prettier и ESLint",normalizedContent:"# вклад в subquery\n\nдобро пожаловать и большое спасибо за то, что рассмотрели возможность внести свои вклад в этот проект subquery! вместе мы сможем проложить путь к более децентрализованному будущему.\n\n> эта документация активно поддерживается командои subquery . мы приветствуем ваш вклад, вы можете сделать это, форкнув наш проект github и внеся изменения во все фаилы markdown документации в каталоге docs.\n\nниже приводится набор руководящих принципов (не правил) для внесения вклада в subquery. следуя этим руководящим принципам, мы сделаем процесс внесения вклада простым и эффективным для всех заинтересованных сторон. он также сообщает, что вы соглашаетесь уважать время управления и разработки этого проекта. в свою очередь, мы будем с уважением относиться к вашему вопросу, учитывая изменения, сотрудничаем с улучшениями и помогая вам окончательно оформлять запросы на слияние.\n\n\n# кодекс поведения\n\nмы серьезно относимся к нашим проектам сообщества с открытым исходным кодом и к ответственности, и считаем, что мы и другие участники соблюдаем высокие стандарты общения. участвуя в этом проекте, вы соглашаетесь соблюдать наш кодекс поведения.\n\n\n# приступая к работе\n\nвзносы в наши репозитории делаются через issues и pull requests (pr). несколько общих руководящих принципов, которые охватывают и то и другое:\n\n * ищите существующие замечания и pr, прежде чем создавать собственные.\n * мы прилагаем все усилия, чтобы обеспечить своевременное решение проблем, но, в зависимости от последствии, может потребоваться некоторое время, чтобы исследовать основную причину. дружественное @ упоминание в ветке комментариев отправителю или участнику может помочь привлечь внимание, если ваша проблема блокируется.\n\n\n# как сделать вклад\n\n\n# сообщить об ошибках\n\nошибки отслеживаются как проблемы в github. при регистрации проблемы объясните проблему и включите дополнительные сведения, чтобы помочь специалистам по обслуживанию воспроизвести проблему:\n\n * чтобы идентифицировать проблему, используите понятное и описательное название.\n * опишите точные шаги для воспроизведения проблемы.\n * опишите поведение, которое вы наблюдали после выполнения шагов.\n * объясните, какое поведение вы должны увидеть вместо этого и почему.\n * если возможно, включите скриншоты\n\n\n# отправка pull request'ов\n\nв общем, мы следуем рабочему процессу git, основанному на принципах «fork-and-pull»\n\n * форкнуть репозитории для вашеи учетнои записи на github\n * клонировать проект на вашу машину\n * создать филиал локально с кратким, но описательным именем\n * сохранить изменения в ветке\n * следуя любым правилам форматирования и тестирования, специфичным для этого репозитория\n * отправить изменения в ваш форк\n * открыть pr в нашем репозитории\n\n\n# контрагенты кодирования\n\n\n# сообщения git commit\n\n * используите настоящее время («добавить объект», а не «добавлен объект»)\n * используите повелительное наклонение («переместить курсор в...», а не «переместить курсор в...»)\n * ограничьте первую строку до 72 символов или меньше\n\n\n# руководство по стилю javascript\n\n * весь код javascript размещен на основе prettier и eslint",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Ссылки в социальных сетях",frontmatter:{summary:"Ссылки в социальных сетях SubQuery - это активный проект, который поддерживает и общается с нашими последователями через множество социальных сетей. Наша цель - всегда прислушивать",meta:[{property:"og:url",content:"/ru/miscellaneous/social_media.html"},{property:"og:title",content:"Ссылки в социальных сетях"},{property:"og:description",content:"Ссылки в социальных сетях SubQuery - это активный проект, который поддерживает и общается с нашими последователями через множество социальных сетей. Наша цель - всегда прислушивать"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/miscellaneous/social_media.html",relativePath:"ru/miscellaneous/social_media.md",key:"v-d647e6e6",path:"/ru/miscellaneous/social_media/",headers:[{level:2,title:"Официальные комьюнити SubQuery",slug:"официальные-комьюнити-subquery",normalizedTitle:"официальные комьюнити subquery",charIndex:336},{level:2,title:"Неофициальные комьюнити SubQuery",slug:"неофициальные-комьюнити-subquery",normalizedTitle:"неофициальные комьюнити subquery",charIndex:584}],readingTime:{minutes:.16,words:47},headersStr:"Официальные комьюнити SubQuery Неофициальные комьюнити SubQuery",content:"# Ссылки в социальных сетях\n\nSubQuery - это активный проект, который поддерживает и общается с нашими последователями через множество социальных сетей.\n\nНаша цель - всегда прислушиваться к нашему лояльному сообществу и взаимодействовать с ним, поэтому, пожалуйста, присоединяйтесь к беседам и отправляйте нам свои идеи или вопросы!\n\n\n# Официальные комьюнити SubQuery\n\n * Discord (основное сообщество с выделенными каналами технической поддержки)\n * Medium (основной канал объявлений)\n * Твиттер\n * WeChat\n * Telegram (только канал объявлений)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Неофициальные комьюнити SubQuery\n\nЭти сообщества не модерируются командой SubQuery, но наши представители могут быть там для оказания поддержки. Пожалуйста, будьте осторожны с мошенниками, поскольку SubQuery ** не ** несет ответственности за ваше взаимодействии с ними.",normalizedContent:"# ссылки в социальных сетях\n\nsubquery - это активныи проект, которыи поддерживает и общается с нашими последователями через множество социальных сетеи.\n\nнаша цель - всегда прислушиваться к нашему лояльному сообществу и взаимодеиствовать с ним, поэтому, пожалуиста, присоединяитесь к беседам и отправляите нам свои идеи или вопросы!\n\n\n# официальные комьюнити subquery\n\n * discord (основное сообщество с выделенными каналами техническои поддержки)\n * medium (основнои канал объявлении)\n * твиттер\n * wechat\n * telegram (только канал объявлении)\n * github\n * matrix/riot\n * linkedin\n\n\n# неофициальные комьюнити subquery\n\nэти сообщества не модерируются командои subquery, но наши представители могут быть там для оказания поддержки. пожалуиста, будьте осторожны с мошенниками, поскольку subquery ** не ** несет ответственности за ваше взаимодеиствии с ними.",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Подключитесь к вашему новому проекту",frontmatter:{summary:"Подключитесь к вашему новому проекту После того, как ваше развертывание будет успешно завершено и наши узлы проиндексируют ваши данные из цепочки, вы сможете подключиться к своему ",meta:[{property:"og:url",content:"/ru/publish/connect.html"},{property:"og:title",content:"Подключитесь к вашему новому проекту"},{property:"og:description",content:"Подключитесь к вашему новому проекту После того, как ваше развертывание будет успешно завершено и наши узлы проиндексируют ваши данные из цепочки, вы сможете подключиться к своему "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/publish/connect.html",relativePath:"ru/publish/connect.md",key:"v-720d45dd",path:"/ru/publish/connect/",readingTime:{minutes:.19,words:56},headersStr:null,content:"# Подключитесь к вашему новому проекту\n\nПосле того, как ваше развертывание будет успешно завершено и наши узлы проиндексируют ваши данные из цепочки, вы сможете подключиться к своему проекту через отображаемую конечную точку запроса.\n\n\n\nКроме того, вы можете щелкнуть по трем точкам рядом с названием вашего проекта и просмотреть его в SubQuery Explorer. Там вы можете использовать в браузере игровую площадку для начала.\n\n\n\n\n# Подробнее о GraphQL\n\nВы можете следовать официальному руководству по GraphQL здесь , чтобы узнать больше о GraphQL, как он работает и как его использовать:\n\n * Есть библиотеки, которые помогут вам реализовать GraphQL на разных языках\n * Информацию об углубленном обучении с практическими уроками см. в How to GraphQL.\n * Ознакомьтесь с бесплатным онлайн-курсом, Исследование GraphQL: язык запроса API.",normalizedContent:"# подключитесь к вашему новому проекту\n\nпосле того, как ваше развертывание будет успешно завершено и наши узлы проиндексируют ваши данные из цепочки, вы сможете подключиться к своему проекту через отображаемую конечную точку запроса.\n\n\n\nкроме того, вы можете щелкнуть по трем точкам рядом с названием вашего проекта и просмотреть его в subquery explorer. там вы можете использовать в браузере игровую площадку для начала.\n\n\n\n\n# подробнее о graphql\n\nвы можете следовать официальному руководству по graphql здесь , чтобы узнать больше о graphql, как он работает и как его использовать:\n\n * есть библиотеки, которые помогут вам реализовать graphql на разных языках\n * информацию об углубленном обучении с практическими уроками см. в how to graphql.\n * ознакомьтесь с бесплатным онлаин-курсом, исследование graphql: язык запроса api.",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Руководство Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate du",meta:[{property:"og:url",content:"/ru/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Руководство Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate du"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/publish/upgrade.html",relativePath:"ru/publish/upgrade.md",key:"v-1f0ac379",path:"/ru/publish/upgrade/",headers:[{level:2,title:"Руководство",slug:"руководство",normalizedTitle:"руководство",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:605},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1471}],readingTime:{minutes:1.14,words:342},headersStr:"Руководство Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Руководство\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nПосле успешного завершения установки и успешного индексирования нашими узлами ваших данных из цепочки, вы сможете подключиться к вашему проекту через отображенную конечную точку запроса GraphQL Query.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# руководство\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nпосле успешного завершения установки и успешного индексирования нашими узлами ваших данных из цепочки, вы сможете подключиться к вашему проекту через отображенную конечную точку запроса graphql query.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Опубликовать ваш проект SubQuery",frontmatter:{summary:"Опубликовать ваш проект SubQuery Преимущества хостинга вашего проекта с SubQuery Мы будем запускать ваши проекты SubQuery для вас в высокопроизводительной, масштабируемой и управля",meta:[{property:"og:url",content:"/ru/publish/publish.html"},{property:"og:title",content:"Опубликовать ваш проект SubQuery"},{property:"og:description",content:"Опубликовать ваш проект SubQuery Преимущества хостинга вашего проекта с SubQuery Мы будем запускать ваши проекты SubQuery для вас в высокопроизводительной, масштабируемой и управля"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/publish/publish.html",relativePath:"ru/publish/publish.md",key:"v-605e5d93",path:"/ru/publish/publish/",headers:[{level:2,title:"Преимущества хостинга вашего проекта с SubQuery",slug:"преимущества-хостинга-вашего-проекта-с-subquery",normalizedTitle:"преимущества хостинга вашего проекта с subquery",charIndex:39},{level:2,title:"Создайте свой первый проект",slug:"создаите-свои-первыи-проект",normalizedTitle:"создаите свои первыи проект",charIndex:527},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3956},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4411}],readingTime:{minutes:3,words:899},headersStr:"Преимущества хостинга вашего проекта с SubQuery Создайте свой первый проект Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Опубликовать ваш проект SubQuery\n\n\n# Преимущества хостинга вашего проекта с SubQuery\n\n * Мы будем запускать ваши проекты SubQuery для вас в высокопроизводительной, масштабируемой и управляемой общедоступной службе\n * Эта услуга предоставляется сообществу бесплатно!\n * Вы можете сделать свои проекты общедоступными, чтобы они были перечислены в SubQuery Explorer , и любой желающий мог их просматривать\n * Мы интегрированы с GitHub, поэтому любой в вашей организации GitHub сможет просматривать общие проекты организации\n\n\n# Создайте свой первый проект\n\n# Login to SubQuery Projects\n\nПеред началом убедитесь, что ваш проект SubQuery находится в общедоступном репозитории GitHub. Файл schema.graphql должен быть в корне вашей директории.\n\nЧтобы создать свой первый проект, перейдите на project.subquery.network. Вам нужно авторизоваться с помощью вашей учетной записи GitHub, чтобы войти.\n\nПри первом входе вам будет предложено авторизовать SubQuery. Нам нужен только ваш адрес электронной почты, чтобы идентифицировать вашу учётную запись, и по другим причинам мы не используем никаких других данных из вашей учетной записи GitHub. На этом этапе вы также можете запросить или предоставить доступ к своей учетной записи GitHub Organization, чтобы вы могли публиковать проекты SubQuery в своей организации GitHub вместо своей личной учетной записи.\n\n\n\nSubQuery Projects - это место, где вы управляете всеми размещенными проектами, загруженными на платформу SubQuery. Вы можете создавать, удалять и даже обновлять проекты всех из этого приложения.\n\n\n\nЕсли у вас есть учетные записи организации GitHub, можно использовать переключатель в заголовке для изменения между вашим персональным аккаунтом и вашей учетной записью организации GitHub. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. _We're almost there! We just need to deploy a new version of it. _\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# опубликовать ваш проект subquery\n\n\n# преимущества хостинга вашего проекта с subquery\n\n * мы будем запускать ваши проекты subquery для вас в высокопроизводительнои, масштабируемои и управляемои общедоступнои службе\n * эта услуга предоставляется сообществу бесплатно!\n * вы можете сделать свои проекты общедоступными, чтобы они были перечислены в subquery explorer , и любои желающии мог их просматривать\n * мы интегрированы с github, поэтому любои в вашеи организации github сможет просматривать общие проекты организации\n\n\n# создаите свои первыи проект\n\n# login to subquery projects\n\nперед началом убедитесь, что ваш проект subquery находится в общедоступном репозитории github. фаил schema.graphql должен быть в корне вашеи директории.\n\nчтобы создать свои первыи проект, переидите на project.subquery.network. вам нужно авторизоваться с помощью вашеи учетнои записи github, чтобы воити.\n\nпри первом входе вам будет предложено авторизовать subquery. нам нужен только ваш адрес электроннои почты, чтобы идентифицировать вашу учетную запись, и по другим причинам мы не используем никаких других данных из вашеи учетнои записи github. на этом этапе вы также можете запросить или предоставить доступ к своеи учетнои записи github organization, чтобы вы могли публиковать проекты subquery в своеи организации github вместо своеи личнои учетнои записи.\n\n\n\nsubquery projects - это место, где вы управляете всеми размещенными проектами, загруженными на платформу subquery. вы можете создавать, удалять и даже обновлять проекты всех из этого приложения.\n\n\n\nесли у вас есть учетные записи организации github, можно использовать переключатель в заголовке для изменения между вашим персональным аккаунтом и вашеи учетнои записью организации github. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. _we're almost there! we just need to deploy a new version of it. _\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/ru/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/query/graphql.html",relativePath:"ru/query/graphql.md",key:"v-50fd6d6d",path:"/ru/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/ru/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/query/query.html",relativePath:"ru/query/query.md",key:"v-0ffdfaaf",path:"/ru/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/ru/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/quickstart/helloworld-hosted.html",relativePath:"ru/quickstart/helloworld-hosted.md",key:"v-38af4ead",path:"/ru/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (локальный хост + докер)",frontmatter:{summary:"Hello World (локальный хост + докер) Добро пожаловать в краткое руководство по SubQuery Hello World. Краткое руководство призвано показать вам, как запустить стартовый проект по ум",meta:[{property:"og:url",content:"/ru/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (локальный хост + докер)"},{property:"og:description",content:"Hello World (локальный хост + докер) Добро пожаловать в краткое руководство по SubQuery Hello World. Краткое руководство призвано показать вам, как запустить стартовый проект по ум"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/quickstart/helloworld-localhost.html",relativePath:"ru/quickstart/helloworld-localhost.md",key:"v-953a799e",path:"/ru/quickstart/helloworld-localhost/",headers:[{level:2,title:"Цели обучения",slug:"цели-обучения",normalizedTitle:"цели обучения",charIndex:232},{level:2,title:"Целевая аудитория",slug:"целевая-аудитория",normalizedTitle:"целевая аудитория",charIndex:548},{level:2,title:"Видео инструкция",slug:"видео-инструкция",normalizedTitle:"видео инструкция",charIndex:727},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:748},{level:2,title:"1. Step 1: Initialise project",slug:"_1-step-1-initialise-project",normalizedTitle:"1. step 1: initialise project",charIndex:1540},{level:2,title:"2. Step 2: Install dependencies",slug:"_2-step-2-install-dependencies",normalizedTitle:"2. step 2: install dependencies",charIndex:2123},{level:2,title:"3. Step 3: Generate code",slug:"_3-step-3-generate-code",normalizedTitle:"3. step 3: generate code",charIndex:2526},{level:2,title:"4. Step 4: Build code",slug:"_4-step-4-build-code",normalizedTitle:"4. step 4: build code",charIndex:3097},{level:2,title:"5. Run Docker",slug:"_5-run-docker",normalizedTitle:"5. run docker",charIndex:3292},{level:2,title:"6. Browse playground",slug:"_6-browse-playground",normalizedTitle:"6. browse playground",charIndex:4554},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:4990}],readingTime:{minutes:2.5,words:749},headersStr:"Цели обучения Целевая аудитория Видео инструкция Pre-requisites 1. Step 1: Initialise project 2. Step 2: Install dependencies 3. Step 3: Generate code 4. Step 4: Build code 5. Run Docker 6. Browse playground Summary",content:'# Hello World (локальный хост + докер)\n\nДобро пожаловать в краткое руководство по SubQuery Hello World. Краткое руководство призвано показать вам, как запустить стартовый проект по умолчанию в Docker за несколько простых шагов.\n\n\n# Цели обучения\n\nВ конце этого краткого руководства вам следует:\n\n * понимать необходимые предварительные условия\n * понимать основные стандартные команды\n * иметь возможность перейти на localhost: 3000 и просмотреть игровую площадку\n * запустить простой запрос, чтобы получить высоту блока основной сети Polkadot\n\n\n# Целевая аудитория\n\nЭто руководство предназначено для новых разработчиков, имеющих некоторый опыт разработки и заинтересованных в получении дополнительных сведений о SubQuery.\n\n\n# Видео инструкция\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# 1. Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# 2. Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn yarn install # NPM npm install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 3. Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn yarn codegen # NPM npm run-script codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# 4. Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn yarn build # NPM npm run-script build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# 5. Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 6. Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (локальныи хост + докер)\n\nдобро пожаловать в краткое руководство по subquery hello world. краткое руководство призвано показать вам, как запустить стартовыи проект по умолчанию в docker за несколько простых шагов.\n\n\n# цели обучения\n\nв конце этого краткого руководства вам следует:\n\n * понимать необходимые предварительные условия\n * понимать основные стандартные команды\n * иметь возможность переити на localhost: 3000 и просмотреть игровую площадку\n * запустить простои запрос, чтобы получить высоту блока основнои сети polkadot\n\n\n# целевая аудитория\n\nэто руководство предназначено для новых разработчиков, имеющих некоторыи опыт разработки и заинтересованных в получении дополнительных сведении о subquery.\n\n\n# видео инструкция\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# 1. step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# 2. step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn yarn install # npm npm install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 3. step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn yarn codegen # npm npm run-script codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# 4. step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn yarn build # npm npm run-script build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# 5. run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 6. browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cyrillic:!0,cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Краткое руководство пользователя",frontmatter:{summary:"Краткое руководство пользователя В этом кратком руководстве мы собираемся создать простой стартовый проект, который вы можете использовать в качестве основы для разработки собствен",meta:[{property:"og:url",content:"/ru/quickstart/quickstart.html"},{property:"og:title",content:"Краткое руководство пользователя"},{property:"og:description",content:"Краткое руководство пользователя В этом кратком руководстве мы собираемся создать простой стартовый проект, который вы можете использовать в качестве основы для разработки собствен"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/quickstart/quickstart.html",relativePath:"ru/quickstart/quickstart.md",key:"v-0133a45a",path:"/ru/quickstart/quickstart/",headers:[{level:2,title:"Подготовка",slug:"подготовка",normalizedTitle:"подготовка",charIndex:475},{level:3,title:"Местная среда развития",slug:"местная-среда-развития",normalizedTitle:"местная среда развития",charIndex:490},{level:3,title:"Установите SubQuery CLI",slug:"установите-subquery-cli",normalizedTitle:"установите subquery cli",charIndex:717},{level:2,title:"Инициализировать начальный проект подзапроса",slug:"инициализировать-начальныи-проект-подзапроса",normalizedTitle:"инициализировать начальныи проект подзапроса",charIndex:1133},{level:3,title:"Создание модели GraphQL",slug:"создание-модели-graphql",normalizedTitle:"создание модели graphql",charIndex:3151},{level:2,title:"Построить проект",slug:"построить-проект",normalizedTitle:"построить проект",charIndex:3450},{level:3,title:"Запросите свой проект",slug:"запросите-свои-проект",normalizedTitle:"запросите свои проект",charIndex:4185},{level:2,title:"Следующие шаги",slug:"следующие-шаги",normalizedTitle:"следующие шаги",charIndex:4907}],readingTime:{minutes:.71,words:212},headersStr:"Подготовка Местная среда развития Установите SubQuery CLI Инициализировать начальный проект подзапроса Создание модели GraphQL Построить проект Запросите свой проект Следующие шаги",content:"# Краткое руководство пользователя\n\nВ этом кратком руководстве мы собираемся создать простой стартовый проект, который вы можете использовать в качестве основы для разработки собственного проекта SubQuery.\n\nВ конце этого руководства у вас будет рабочий проект SubQuery, запущенный на узле SubQuery с конечной точкой GraphQL, из которой вы можете запрашивать данные.\n\nЕсли вы еще этого не сделали, мы предлагаем вам ознакомиться с терминологией , используемой в SubQuery.\n\n\n# Подготовка\n\n\n# Местная среда развития\n\n * Typescript необходим для компиляции проекта и определения типов.\n * И SubQuery CLI, и сгенерированный Project имеют зависимости и требуют современной версии Node .\n * SubQuery нода требует Docker\n\n\n# Установите SubQuery CLI\n\nУстановите SubQuery CLI глобально на свой терминалe с помощью NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nОбратите внимание, что мы ** НЕ ** поощряем использование yarn global из-за его плохого управления зависимостями, что может привести к ошибкам в дальнейшем.\n\nЗатем вы можете запустить справку, чтобы увидеть доступные команды и использование, предоставляемые CLI\n\nsubql help\n\n\n1\n\n\n\n# Инициализировать начальный проект подзапроса\n\nВнутри каталога, в котором вы хотите создать проект SubQuery, просто замените PROJECT_NAME своим собственным и выполните команду:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nПри инициализации проекта SubQuery вам будут заданы определенные вопросы:\n\n * Репозиторий Git (необязательно): укажите URL-адрес Git для репо, в котором будет размещен этот проект SubQuery (при размещении в SubQuery Explorer)\n * Конечная точка RPC (обязательно): укажите URL-адрес wss для работающей конечной точки RPC, которая будет использоваться по умолчанию для этого проекта. Вы можете быстро получить доступ к общедоступным конечным точкам для различных сетей Polkadot или даже создать свой собственный выделенный частный узел с помощью OnFinality или просто использовать конечную точку Polkadot по умолчанию.\n * Авторы (обязательно): введите здесь владельца этого проекта SubQuery\n * Описание (необязательно): вы можете предоставить короткий абзац о своем проекте, описывающий, какие данные он содержит и что пользователи могут с ними делать\n * Версия (обязательно): введите собственный номер версии или используйте значение по умолчанию (1.0.0)\n * Лицензия (обязательно): предоставьте лицензию на программное обеспечение для этого проекта или примите лицензию по умолчанию (Apache-2.0)\n\nПосле завершения процесса инициализации вы должны увидеть, что внутри каталога была создана папка с именем вашего проекта. Содержимое этого каталога должно быть идентично тому, что указано в структуре каталога .\n\nНаконец, в каталоге проекта выполните следующую команду, чтобы установить зависимости нового проекта.\n\ncd PROJECT_NAME # Yarn yarn install # NPM npm install В основном вы будете работать со следующими файлами:\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * В основном вы будете работать со следующими файлами:\n\nДля получения дополнительной информации о том, как написать свой собственный подзапрос, ознакомьтесь с нашей документацией в разделе Создание проекта\n\n\n# Создание модели GraphQL\n\nЧтобы проиндексировать ваш проект SubQuery, вы должны сначала сгенерировать необходимые модели GraphQL, которые вы определили в своем файле схемы GraphQL (schema.graphql). Выполните эту команду в корне каталога проекта.\n\n# Yarn yarn codegen # NPM npm run-script codegen\n\n\n# Построить проект\n\nЧтобы запустить проект SubQuery на локально размещенной ноде SubQuery, вам необходимо построить свою работу.\n\nЗапустите команду сборки из корневого каталога проекта.\n\nAll configuration that controls how a SubQuery node is run is defined in this `docker-compose.yml` file. Для нового проекта, который был только что инициализирован, вам не нужно здесь ничего менять, но вы можете узнать больше о файле и настройках в разделе [ Запуск проекта ](../run/run.md)\n\nВ каталоге проекта выполните следующую команду:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nПервая загрузка необходимых пакетов (@ subql / node, @ subql / query и Postgres) может занять некоторое время, но вскоре вы увидите запущенную ноду SubQuery.\n\n\n# Запросите свой проект\n\nОткройте браузер и перейдите по адресу http: // localhost: 3000 .\n\nВы должны увидеть игровую площадку GraphQL, отображаемую в проводнике, и схемы, готовые к запросу. В правом верхнем углу игровой площадки вы найдете кнопку _ Документы _, которая откроет розыгрыш документации. Эта документация создается автоматически и помогает вам найти, какие сущности и методы вы можете запрашивать.\n\nДля нового начального проекта SubQuery вы можете попробовать следующий запрос, чтобы понять, как он работает, или узнать больше о языке запросов GraphQL .\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Следующие шаги\n\nПоздравляем, теперь у вас есть локально работающий проект SubQuery, который принимает запросы GraphQL API для демонстрационных данных. В следующем руководстве мы покажем вам, как опубликовать ваш новый проект в SubQuery Projects и запросить его с помощью нашего Explorer\n\nОпубликуйте свой новый проект в SubQuery Projects",normalizedContent:"# краткое руководство пользователя\n\nв этом кратком руководстве мы собираемся создать простои стартовыи проект, которыи вы можете использовать в качестве основы для разработки собственного проекта subquery.\n\nв конце этого руководства у вас будет рабочии проект subquery, запущенныи на узле subquery с конечнои точкои graphql, из которои вы можете запрашивать данные.\n\nесли вы еще этого не сделали, мы предлагаем вам ознакомиться с терминологиеи , используемои в subquery.\n\n\n# подготовка\n\n\n# местная среда развития\n\n * typescript необходим для компиляции проекта и определения типов.\n * и subquery cli, и сгенерированныи project имеют зависимости и требуют современнои версии node .\n * subquery нода требует docker\n\n\n# установите subquery cli\n\nустановите subquery cli глобально на свои терминалe с помощью npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nобратите внимание, что мы ** не ** поощряем использование yarn global из-за его плохого управления зависимостями, что может привести к ошибкам в дальнеишем.\n\nзатем вы можете запустить справку, чтобы увидеть доступные команды и использование, предоставляемые cli\n\nsubql help\n\n\n1\n\n\n\n# инициализировать начальныи проект подзапроса\n\nвнутри каталога, в котором вы хотите создать проект subquery, просто замените project_name своим собственным и выполните команду:\n\nsubql init --starter project_name\n\n\n1\n\n\nпри инициализации проекта subquery вам будут заданы определенные вопросы:\n\n * репозитории git (необязательно): укажите url-адрес git для репо, в котором будет размещен этот проект subquery (при размещении в subquery explorer)\n * конечная точка rpc (обязательно): укажите url-адрес wss для работающеи конечнои точки rpc, которая будет использоваться по умолчанию для этого проекта. вы можете быстро получить доступ к общедоступным конечным точкам для различных сетеи polkadot или даже создать свои собственныи выделенныи частныи узел с помощью onfinality или просто использовать конечную точку polkadot по умолчанию.\n * авторы (обязательно): введите здесь владельца этого проекта subquery\n * описание (необязательно): вы можете предоставить короткии абзац о своем проекте, описывающии, какие данные он содержит и что пользователи могут с ними делать\n * версия (обязательно): введите собственныи номер версии или используите значение по умолчанию (1.0.0)\n * лицензия (обязательно): предоставьте лицензию на программное обеспечение для этого проекта или примите лицензию по умолчанию (apache-2.0)\n\nпосле завершения процесса инициализации вы должны увидеть, что внутри каталога была создана папка с именем вашего проекта. содержимое этого каталога должно быть идентично тому, что указано в структуре каталога .\n\nнаконец, в каталоге проекта выполните следующую команду, чтобы установить зависимости нового проекта.\n\ncd project_name # yarn yarn install # npm npm install в основном вы будете работать со следующими фаилами:\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * в основном вы будете работать со следующими фаилами:\n\nдля получения дополнительнои информации о том, как написать свои собственныи подзапрос, ознакомьтесь с нашеи документациеи в разделе создание проекта\n\n\n# создание модели graphql\n\nчтобы проиндексировать ваш проект subquery, вы должны сначала сгенерировать необходимые модели graphql, которые вы определили в своем фаиле схемы graphql (schema.graphql). выполните эту команду в корне каталога проекта.\n\n# yarn yarn codegen # npm npm run-script codegen\n\n\n# построить проект\n\nчтобы запустить проект subquery на локально размещеннои ноде subquery, вам необходимо построить свою работу.\n\nзапустите команду сборки из корневого каталога проекта.\n\nall configuration that controls how a subquery node is run is defined in this `docker-compose.yml` file. для нового проекта, которыи был только что инициализирован, вам не нужно здесь ничего менять, но вы можете узнать больше о фаиле и настроиках в разделе [ запуск проекта ](../run/run.md)\n\nв каталоге проекта выполните следующую команду:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nпервая загрузка необходимых пакетов (@ subql / node, @ subql / query и postgres) может занять некоторое время, но вскоре вы увидите запущенную ноду subquery.\n\n\n# запросите свои проект\n\nоткроите браузер и переидите по адресу http: // localhost: 3000 .\n\nвы должны увидеть игровую площадку graphql, отображаемую в проводнике, и схемы, готовые к запросу. в правом верхнем углу игровои площадки вы наидете кнопку _ документы _, которая откроет розыгрыш документации. эта документация создается автоматически и помогает вам наити, какие сущности и методы вы можете запрашивать.\n\nдля нового начального проекта subquery вы можете попробовать следующии запрос, чтобы понять, как он работает, или узнать больше о языке запросов graphql .\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# следующие шаги\n\nпоздравляем, теперь у вас есть локально работающии проект subquery, которыи принимает запросы graphql api для демонстрационных данных. в следующем руководстве мы покажем вам, как опубликовать ваш новыи проект в subquery projects и запросить его с помощью нашего explorer\n\nопубликуите свои новыи проект в subquery projects",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/ru/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/quickstart/understanding-helloworld.html",relativePath:"ru/quickstart/understanding-helloworld.md",key:"v-05c24d2b",path:"/ru/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Запуск SubQuery локально",frontmatter:{summary:"Запуск SubQuery локально В этом руководстве рассказывается как локально запустить ноду SubQuery на вашем устройстве, который включает как индексатор, так и службу запросов. Не хоти",meta:[{property:"og:url",content:"/ru/run/run.html"},{property:"og:title",content:"Запуск SubQuery локально"},{property:"og:description",content:"Запуск SubQuery локально В этом руководстве рассказывается как локально запустить ноду SubQuery на вашем устройстве, который включает как индексатор, так и службу запросов. Не хоти"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/run/run.html",relativePath:"ru/run/run.md",key:"v-0df44aba",path:"/ru/run/run/",headers:[{level:2,title:"Использование Docker",slug:"использование-docker",normalizedTitle:"использование docker",charIndex:423},{level:2,title:"Запуск индексатора (subql/node)",slug:"запуск-индексатора-subql-node",normalizedTitle:"запуск индексатора (subql/node)",charIndex:898},{level:3,title:"Установка",slug:"установка",normalizedTitle:"установка",charIndex:1251},{level:3,title:"Ключевые команды",slug:"ключевые-команды",normalizedTitle:"ключевые команды",charIndex:1566},{level:2,title:"Запуск службы запросов (subql / query)",slug:"запуск-службы-запросов-subql-query",normalizedTitle:"запуск службы запросов (subql / query)",charIndex:6182},{level:3,title:"Установка",slug:"установка-2",normalizedTitle:"установка",charIndex:1251},{level:3,title:"Запуск службы запросов",slug:"запуск-службы-запросов",normalizedTitle:"запуск службы запросов",charIndex:6182}],readingTime:{minutes:1.18,words:355},headersStr:"Использование Docker Запуск индексатора (subql/node) Установка Ключевые команды Запуск службы запросов (subql / query) Установка Запуск службы запросов",content:'# Запуск SubQuery локально\n\nВ этом руководстве рассказывается как локально запустить ноду SubQuery на вашем устройстве, который включает как индексатор, так и службу запросов. Не хотите беспокоиться о запуске SubQuery на собственном устройстве? SubQuery обеспечивает выделенный сервер для комьюнити бесплатно. Следуйте нашему опубликованному гайду что бы увидеть как вы можете загрузить ваш проект в SubQuery Projects.\n\n\n# Использование Docker\n\nКак альтернативное решение это запустить Docker Container, определенный docker-compose.yml файлом. Для нового проекта которой уже был установлен вам не понадобится ничего менять здесь.\n\nВ командной строке проекта выполните следующую команду:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nВ начале может потребоваться некоторое время для загрузки требующихся пакетов (@subql/node, @subql/query, Postgres) далее вы увидите запущенную SubQuery ноду.\n\n\n# Запуск индексатора (subql/node)\n\nТребования:\n\n * Postgres база данных ( версия 12 или выше). Пока SubQuery node индексируется в блокчейн, извлеченные данные хранятся во внешнем экземпляре базы данных.\n\nНода SubQuery - это реализация, которая извлекает данные блокчейна на основе субстрата для проекта SubQuery и сохраняет их в базе данных Postgres.\n\n\n# Установка\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nОбратите внимание, что мы ** НЕ ** поддерживаем использование yarn global из-за его плохого управления зависимостями, что может привести к ошибкам в дальнейшем.\n\nПосле установки вы можете запустить ноду с помощью следующей команды:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Ключевые команды\n\nСледующие команды помогут вам завершить настройку ноды SubQuery и начать индексацию. Чтобы узнать больше, вы всегда можете запустить --help.\n\n# Укажите путь к локальному проекту\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Используй словарь\n\nИспользование словаря полной цепочки может значительно ускорить обработку проекта SubQuery во время тестирования или во время вашего первого индекса. В некоторых случаях мы наблюдали увеличение производительности индексации до 10 раз.\n\nПолный словарь цепочки предварительно индексирует расположение всех событий и внешних элементов в определенной цепочке и позволяет службе вашей ноды переходить к соответствующим местоположениям при индексировании, а не при проверке каждого блока.\n\nВы можете добавить конечную точку словаря в свой project.yaml файл (see Manifest File), или указать ее во время выполнения, используя следующую команду:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\nПодробнее о том, как работает словарь подзапросов .\n\n# Подключиться к базе данных\n\nв зависимости от конфигурации вашей базы данных Postgres (например, другой пароль базы данных) убедитесь, что и индексатор (`subql / node`), и служба запросов (` subql / query`) могут установить к ней соединение.\n\n#### Укажите файл конфигурации\n\n\n\n1\n2\n3\n4\n\n\nsubql-node -c your-project-config.yml\n\n\nЭто укажет узлу запроса на файл конфигурации, который может быть в формате YAML или JSON. Посмотрите на пример ниже.\n\n```yaml\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n# Изменить размер пакета выборки блока\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nКогда индексатор впервые индексирует цепочку, выборка отдельных блоков значительно снизит производительность. Увеличение размера пакета для корректировки количества извлекаемых блоков уменьшит общее время обработки. Текущий размер пакета по умолчанию - 100.\n\n# Запуск в локальном режиме\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nВ целях отладки пользователи могут запускать узел в локальном режиме. При переключении на локальную модель таблицы Postgres будут созданы в схеме по умолчанию public.\n\nЕсли локальный режим не используется, будет создана новая схема Postgres с начальным subquery_ и соответствующими таблицами проекта.\n\n# Проверьте состояние вашего узла\n\nЕсть 2 конечные точки, которые можно использовать для проверки и мониторинга работоспособности работающей ноды SubQuery.\n\n * Конечная точка проверки работоспособности, которая возвращает простой ответ 200\n * Конечная точка метаданных, которая включает дополнительную аналитику вашей работающей ноды SubQuery\n\nДобавьте это к базовому URL-адресу вашей ноды SubQuery. Например, http: // localhost: 3000 / meta вернет:\n\n{\n    "currentProcessingHeight": 1000699,\n    "currentProcessingTimestamp": 1631517883547,\n    "targetHeight": 6807295,\n    "bestHeight": 6807298,\n    "indexerNodeVersion": "0.19.1",\n    "lastProcessedHeight": 1000699,\n    "lastProcessedTimestamp": 1631517883555,\n    "uptime": 41.151789063,\n    "polkadotSdkVersion": "5.4.1",\n    "apiConnected": true,\n    "injectedApiConnected": true,\n    "usingDictionary": false,\n    "chain": "Polkadot",\n    "specName": "polkadot",\n    "genesisHash": "0x91b171bb158e2d3848fa23a9f1c25182fb8e20313b2c1eb49219da7a70ce90c3",\n    "blockTime": 6000\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nhttp: // localhost: 3000 / health вернет HTTP 200 в случае успеха.\n\nЕсли индексатор неисправен, будет возвращена ошибка 500. Это часто можно увидеть, когда узел загружается.\n\n{\n    "status": 500,\n    "error": "Indexer is not healthy"\n}\n\n\n1\n2\n3\n4\n\n\nЕсли используется неправильный URL-адрес, будет возвращена ошибка 404: не найден.\n\n{\n"statusCode": 404,\n"message": "Cannot GET /healthy",\n"error": "Not Found"\n}\n\n\n1\n2\n3\n4\n5\n\n\n# Отладить свой проект\n\nИспользуйте инспектор нод для выполнения следующей команды.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nНапример:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\nЗатем откройте инструменты разработчика Chrome, перейдите в Source & # 062; Filesystem, добавьте свой проект в рабочую область и начните отладку. Для получения дополнительной информации ознакомьтесь с Как отлаживать проект SubQuery\n\n\n# Запуск службы запросов (subql / query)\n\n\n# Установка\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nОбратите внимание, что мы ** НЕ ** поощряем использование yarn global из-за его плохого управления зависимостями, что может привести к ошибкам в дальнейшем.\n\n\n# Запуск службы запросов\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nУбедитесь, что имя проекта совпадает с именем проекта при инициализации проекта . Также проверьте правильность переменных среды.\n\nПосле успешного запуска службы subql-query откройте браузер и перейдите по адресу http: // localhost: 3000. Вы должны увидеть игровую площадку GraphQL, отображаемую в проводнике, и схему, готовую к запросу.',normalizedContent:'# запуск subquery локально\n\nв этом руководстве рассказывается как локально запустить ноду subquery на вашем устроистве, которыи включает как индексатор, так и службу запросов. не хотите беспокоиться о запуске subquery на собственном устроистве? subquery обеспечивает выделенныи сервер для комьюнити бесплатно. следуите нашему опубликованному гаиду что бы увидеть как вы можете загрузить ваш проект в subquery projects.\n\n\n# использование docker\n\nкак альтернативное решение это запустить docker container, определенныи docker-compose.yml фаилом. для нового проекта которои уже был установлен вам не понадобится ничего менять здесь.\n\nв команднои строке проекта выполните следующую команду:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nв начале может потребоваться некоторое время для загрузки требующихся пакетов (@subql/node, @subql/query, postgres) далее вы увидите запущенную subquery ноду.\n\n\n# запуск индексатора (subql/node)\n\nтребования:\n\n * postgres база данных ( версия 12 или выше). пока subquery node индексируется в блокчеин, извлеченные данные хранятся во внешнем экземпляре базы данных.\n\nнода subquery - это реализация, которая извлекает данные блокчеина на основе субстрата для проекта subquery и сохраняет их в базе данных postgres.\n\n\n# установка\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nобратите внимание, что мы ** не ** поддерживаем использование yarn global из-за его плохого управления зависимостями, что может привести к ошибкам в дальнеишем.\n\nпосле установки вы можете запустить ноду с помощью следующеи команды:\n\nsubql-node <command>\n\n\n1\n\n\n\n# ключевые команды\n\nследующие команды помогут вам завершить настроику ноды subquery и начать индексацию. чтобы узнать больше, вы всегда можете запустить --help.\n\n# укажите путь к локальному проекту\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# используи словарь\n\nиспользование словаря полнои цепочки может значительно ускорить обработку проекта subquery во время тестирования или во время вашего первого индекса. в некоторых случаях мы наблюдали увеличение производительности индексации до 10 раз.\n\nполныи словарь цепочки предварительно индексирует расположение всех событии и внешних элементов в определеннои цепочке и позволяет службе вашеи ноды переходить к соответствующим местоположениям при индексировании, а не при проверке каждого блока.\n\nвы можете добавить конечную точку словаря в свои project.yaml фаил (see manifest file), или указать ее во время выполнения, используя следующую команду:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\nподробнее о том, как работает словарь подзапросов .\n\n# подключиться к базе данных\n\nв зависимости от конфигурации вашеи базы данных postgres (например, другои пароль базы данных) убедитесь, что и индексатор (`subql / node`), и служба запросов (` subql / query`) могут установить к неи соединение.\n\n#### укажите фаил конфигурации\n\n\n\n1\n2\n3\n4\n\n\nsubql-node -c your-project-config.yml\n\n\nэто укажет узлу запроса на фаил конфигурации, которыи может быть в формате yaml или json. посмотрите на пример ниже.\n\n```yaml\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n# изменить размер пакета выборки блока\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nкогда индексатор впервые индексирует цепочку, выборка отдельных блоков значительно снизит производительность. увеличение размера пакета для корректировки количества извлекаемых блоков уменьшит общее время обработки. текущии размер пакета по умолчанию - 100.\n\n# запуск в локальном режиме\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nв целях отладки пользователи могут запускать узел в локальном режиме. при переключении на локальную модель таблицы postgres будут созданы в схеме по умолчанию public.\n\nесли локальныи режим не используется, будет создана новая схема postgres с начальным subquery_ и соответствующими таблицами проекта.\n\n# проверьте состояние вашего узла\n\nесть 2 конечные точки, которые можно использовать для проверки и мониторинга работоспособности работающеи ноды subquery.\n\n * конечная точка проверки работоспособности, которая возвращает простои ответ 200\n * конечная точка метаданных, которая включает дополнительную аналитику вашеи работающеи ноды subquery\n\nдобавьте это к базовому url-адресу вашеи ноды subquery. например, http: // localhost: 3000 / meta вернет:\n\n{\n    "currentprocessingheight": 1000699,\n    "currentprocessingtimestamp": 1631517883547,\n    "targetheight": 6807295,\n    "bestheight": 6807298,\n    "indexernodeversion": "0.19.1",\n    "lastprocessedheight": 1000699,\n    "lastprocessedtimestamp": 1631517883555,\n    "uptime": 41.151789063,\n    "polkadotsdkversion": "5.4.1",\n    "apiconnected": true,\n    "injectedapiconnected": true,\n    "usingdictionary": false,\n    "chain": "polkadot",\n    "specname": "polkadot",\n    "genesishash": "0x91b171bb158e2d3848fa23a9f1c25182fb8e20313b2c1eb49219da7a70ce90c3",\n    "blocktime": 6000\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nhttp: // localhost: 3000 / health вернет http 200 в случае успеха.\n\nесли индексатор неисправен, будет возвращена ошибка 500. это часто можно увидеть, когда узел загружается.\n\n{\n    "status": 500,\n    "error": "indexer is not healthy"\n}\n\n\n1\n2\n3\n4\n\n\nесли используется неправильныи url-адрес, будет возвращена ошибка 404: не наиден.\n\n{\n"statuscode": 404,\n"message": "cannot get /healthy",\n"error": "not found"\n}\n\n\n1\n2\n3\n4\n5\n\n\n# отладить свои проект\n\nиспользуите инспектор нод для выполнения следующеи команды.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nнапример:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\nзатем откроите инструменты разработчика chrome, переидите в source & # 062; filesystem, добавьте свои проект в рабочую область и начните отладку. для получения дополнительнои информации ознакомьтесь с как отлаживать проект subquery\n\n\n# запуск службы запросов (subql / query)\n\n\n# установка\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nобратите внимание, что мы ** не ** поощряем использование yarn global из-за его плохого управления зависимостями, что может привести к ошибкам в дальнеишем.\n\n\n# запуск службы запросов\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nубедитесь, что имя проекта совпадает с именем проекта при инициализации проекта . также проверьте правильность переменных среды.\n\nпосле успешного запуска службы subql-query откроите браузер и переидите по адресу http: // localhost: 3000. вы должны увидеть игровую площадку graphql, отображаемую в проводнике, и схему, готовую к запросу.',charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox В нашем предполагаемом сценарии использования узел SubQuery обычно запускается доверенным хостом, и код проекта SubQuery, отправленный пользователем узлу, не является п",meta:[{property:"og:url",content:"/ru/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox В нашем предполагаемом сценарии использования узел SubQuery обычно запускается доверенным хостом, и код проекта SubQuery, отправленный пользователем узлу, не является п"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/run/sandbox.html",relativePath:"ru/run/sandbox.md",key:"v-3ba014ab",path:"/ru/run/sandbox/",headers:[{level:2,title:"Ограничения",slug:"ограничения",normalizedTitle:"ограничения",charIndex:813}],readingTime:{minutes:.08,words:25},headersStr:"Ограничения",content:"# The Sandbox\n\nВ нашем предполагаемом сценарии использования узел SubQuery обычно запускается доверенным хостом, и код проекта SubQuery, отправленный пользователем узлу, не является полностью надежным.\n\nНекоторый вредоносный код может атаковать хост или даже скомпрометировать его, а также нанести ущерб данным других проектов на том же хосте. Поэтому мы используем защищенный механизм Sandbox VM2 для снижения рисков. Это позволяет:\n\n * Безопасно запускать ненадежный код в изолированной среде, и вредоносный код не получит доступа к сети и файловой системе хоста, кроме как через открытый интерфейс, который мы внедрили в изолированную среду.\n\n * Безопасно вызывать методы и обмениваться данными и обратными вызовами между изолированными средами.\n\n * Обладать иммунитетом ко многим известным методам атаки.\n\n\n# Ограничения\n\n * Ограниченный доступ к определенным встроенным модулям, только assert, буфер, крипто,util и путь занесены в белый список.\n\n * Поддерживаются сторонние модули, написанные в CommonJS и гибридных библиотеках, таких как @polkadot/*, которые используют ESM по умолчанию.\n\n * Любые модули, использующие HTTP и WebSocket, запрещены.",normalizedContent:"# the sandbox\n\nв нашем предполагаемом сценарии использования узел subquery обычно запускается доверенным хостом, и код проекта subquery, отправленныи пользователем узлу, не является полностью надежным.\n\nнекоторыи вредоносныи код может атаковать хост или даже скомпрометировать его, а также нанести ущерб данным других проектов на том же хосте. поэтому мы используем защищенныи механизм sandbox vm2 для снижения рисков. это позволяет:\n\n * безопасно запускать ненадежныи код в изолированнои среде, и вредоносныи код не получит доступа к сети и фаиловои системе хоста, кроме как через открытыи интерфеис, которыи мы внедрили в изолированную среду.\n\n * безопасно вызывать методы и обмениваться данными и обратными вызовами между изолированными средами.\n\n * обладать иммунитетом ко многим известным методам атаки.\n\n\n# ограничения\n\n * ограниченныи доступ к определенным встроенным модулям, только assert, буфер, крипто,util и путь занесены в белыи список.\n\n * поддерживаются сторонние модули, написанные в commonjs и гибридных библиотеках, таких как @polkadot/*, которые используют esm по умолчанию.\n\n * любые модули, использующие http и websocket, запрещены.",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Как изменить размер пакетной выборки блокчейна?",frontmatter:{summary:"Как изменить размер пакетной выборки блокчейна? Видеоинструкция Вступление Размер пакета по умолчанию равен 100, но это может быть изменено с помощью дополнительной команды --batch",meta:[{property:"og:url",content:"/ru/tutorials_examples/batch-size.html"},{property:"og:title",content:"Как изменить размер пакетной выборки блокчейна?"},{property:"og:description",content:"Как изменить размер пакетной выборки блокчейна? Видеоинструкция Вступление Размер пакета по умолчанию равен 100, но это может быть изменено с помощью дополнительной команды --batch"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/tutorials_examples/batch-size.html",relativePath:"ru/tutorials_examples/batch-size.md",key:"v-911794de",path:"/ru/tutorials_examples/batch-size/",headers:[{level:2,title:"Видеоинструкция",slug:"видеоинструкция",normalizedTitle:"видеоинструкция",charIndex:54},{level:2,title:"Вступление",slug:"вступление",normalizedTitle:"вступление",charIndex:74},{level:2,title:"Зачем изменять размер пакета?",slug:"зачем-изменять-размер-пакета",normalizedTitle:"зачем изменять размер пакета?",charIndex:781}],readingTime:{minutes:.19,words:58},headersStr:"Видеоинструкция Вступление Зачем изменять размер пакета?",content:'# Как изменить размер пакетной выборки блокчейна?\n\n\n# Видеоинструкция\n\n\n# Вступление\n\nРазмер пакета по умолчанию равен 100, но это может быть изменено с помощью дополнительной команды --batch-size=xx.\n\nВам нужно сделать это в командной строке как дополнительный признак или, если вы используете Docker, изменить docker-compose.yml на:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nВ данном примере задается размер пакета - 50.\n\n\n# Зачем изменять размер пакета?\n\nИспользование меньшего размера пакета может уменьшить использование памяти и не оставлять пользователей в подвешенном состоянии при выполнении больших запросов. Другими словами, ваше приложение может быть более быстро реагировать.',normalizedContent:'# как изменить размер пакетнои выборки блокчеина?\n\n\n# видеоинструкция\n\n\n# вступление\n\nразмер пакета по умолчанию равен 100, но это может быть изменено с помощью дополнительнои команды --batch-size=xx.\n\nвам нужно сделать это в команднои строке как дополнительныи признак или, если вы используете docker, изменить docker-compose.yml на:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nв данном примере задается размер пакета - 50.\n\n\n# зачем изменять размер пакета?\n\nиспользование меньшего размера пакета может уменьшить использование памяти и не оставлять пользователеи в подвешенном состоянии при выполнении больших запросов. другими словами, ваше приложение может быть более быстро реагировать.',charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Как начать с другой высоты блока?",frontmatter:{summary:"Как начать с другой высоты блока? Видеоинструкция Вступление По умолчанию все запускаемые проекты начинают синхронизироваться с блокчейном с генезис блока. Другими словами - с перв",meta:[{property:"og:url",content:"/ru/tutorials_examples/block-height.html"},{property:"og:title",content:"Как начать с другой высоты блока?"},{property:"og:description",content:"Как начать с другой высоты блока? Видеоинструкция Вступление По умолчанию все запускаемые проекты начинают синхронизироваться с блокчейном с генезис блока. Другими словами - с перв"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/tutorials_examples/block-height.html",relativePath:"ru/tutorials_examples/block-height.md",key:"v-bb2c6aaa",path:"/ru/tutorials_examples/block-height/",headers:[{level:2,title:"Видеоинструкция",slug:"видеоинструкция",normalizedTitle:"видеоинструкция",charIndex:40},{level:2,title:"Вступление",slug:"вступление",normalizedTitle:"вступление",charIndex:60},{level:2,title:"Почему бы не начать с нуля?",slug:"почему-бы-не-начать-с-нуля",normalizedTitle:"почему бы не начать с нуля?",charIndex:986},{level:2,title:"В чем недостаток старта с ненулевого блока?",slug:"в-чем-недостаток-старта-с-ненулевого-блока",normalizedTitle:"в чем недостаток старта с ненулевого блока?",charIndex:1314},{level:2,title:"Как узнать текущую высоту блокчейна?",slug:"как-узнать-текущую-высоту-блокчеина",normalizedTitle:"как узнать текущую высоту блокчеина?",charIndex:1485},{level:2,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1663}],readingTime:{minutes:.3,words:91},headersStr:"Видеоинструкция Вступление Почему бы не начать с нуля? В чем недостаток старта с ненулевого блока? Как узнать текущую высоту блокчейна? Do I have to do a rebuild or a codegen?",content:'# Как начать с другой высоты блока?\n\n\n# Видеоинструкция\n\n\n# Вступление\n\nПо умолчанию все запускаемые проекты начинают синхронизироваться с блокчейном с генезис блока. Другими словами - с первого блока. Для больших блокчейнов это, как правило, может занять несколько дней или даже недель для полной синхронизации.\n\nЧтобы запустить синхронизацию ноды SubQuery с ненулевой высоты, все, что вам нужно сделать, это изменить файл project.yaml и изменить ключ startBlock.\n\nНиже представлен файл project.yaml, в котором начальный блок установлен на 1000000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Почему бы не начать с нуля?\n\nОсновная причина в том, что это может сократить время синхронизации блокчейна. Это означает, что если вас интересуют транзакции только за последние 3 месяца, вы можете синхронизировать только последние 3 месяца, что означает меньшее время ожидания, а значит вы можете быстрее начать разработку.\n\n\n# В чем недостаток старта с ненулевого блока?\n\nНаиболее очевидным недостатком будет то, что вы не сможете запрашивать данные из блокчейна для блоков, которых у вас нет.\n\n\n# Как узнать текущую высоту блокчейна?\n\nЕсли вы используете сеть Polkadot, вы можете посетить https://polkascan.io/, выбрать сеть, а затем просмотреть номер "Finalised Block".\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Поскольку вы изменяете файл project.yaml, который по сути является файлом конфигурации, вам не нужно будет перестраивать или регенерировать код машинописного текста.',normalizedContent:'# как начать с другои высоты блока?\n\n\n# видеоинструкция\n\n\n# вступление\n\nпо умолчанию все запускаемые проекты начинают синхронизироваться с блокчеином с генезис блока. другими словами - с первого блока. для больших блокчеинов это, как правило, может занять несколько днеи или даже недель для полнои синхронизации.\n\nчтобы запустить синхронизацию ноды subquery с ненулевои высоты, все, что вам нужно сделать, это изменить фаил project.yaml и изменить ключ startblock.\n\nниже представлен фаил project.yaml, в котором начальныи блок установлен на 1000000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# почему бы не начать с нуля?\n\nосновная причина в том, что это может сократить время синхронизации блокчеина. это означает, что если вас интересуют транзакции только за последние 3 месяца, вы можете синхронизировать только последние 3 месяца, что означает меньшее время ожидания, а значит вы можете быстрее начать разработку.\n\n\n# в чем недостаток старта с ненулевого блока?\n\nнаиболее очевидным недостатком будет то, что вы не сможете запрашивать данные из блокчеина для блоков, которых у вас нет.\n\n\n# как узнать текущую высоту блокчеина?\n\nесли вы используете сеть polkadot, вы можете посетить https://polkascan.io/, выбрать сеть, а затем просмотреть номер "finalised block".\n\n\n# do i have to do a rebuild or a codegen?\n\nno. поскольку вы изменяете фаил project.yaml, которыи по сути является фаилом конфигурации, вам не нужно будет перестраивать или регенерировать код машинописного текста.',charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Как отлаживать проект SubQuery?",frontmatter:{summary:"Как отлаживать проект SubQuery? Видео гайд Вступление Для отладки проектов SubQuery, таких как пошаговое выполнение кода, установка брейкпоинтов и проверка переменных, вам придется",meta:[{property:"og:url",content:"/ru/tutorials_examples/debug-projects.html"},{property:"og:title",content:"Как отлаживать проект SubQuery?"},{property:"og:description",content:"Как отлаживать проект SubQuery? Видео гайд Вступление Для отладки проектов SubQuery, таких как пошаговое выполнение кода, установка брейкпоинтов и проверка переменных, вам придется"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/tutorials_examples/debug-projects.html",relativePath:"ru/tutorials_examples/debug-projects.md",key:"v-542b4a91",path:"/ru/tutorials_examples/debug-projects/",headers:[{level:2,title:"Видео гайд",slug:"видео-гаид",normalizedTitle:"видео гаид",charIndex:38},{level:2,title:"Вступление",slug:"вступление",normalizedTitle:"вступление",charIndex:53},{level:2,title:"Node inspector",slug:"node-inspector",normalizedTitle:"node inspector",charIndex:276},{level:2,title:"Инструменты разработчика Chrome",slug:"инструменты-разработчика-chrome",normalizedTitle:"инструменты разработчика chrome",charIndex:695}],readingTime:{minutes:.3,words:91},headersStr:"Видео гайд Вступление Node inspector Инструменты разработчика Chrome",content:"# Как отлаживать проект SubQuery?\n\n\n# Видео гайд\n\n\n# Вступление\n\nДля отладки проектов SubQuery, таких как пошаговое выполнение кода, установка брейкпоинтов и проверка переменных, вам придется использовать Node.js inspector в сочетании с инструментами разработчика Chrome.\n\n\n# Node inspector\n\nВыполните следующую команду на экране терминала.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nНапример:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nДля помощи смотрите: https://nodejs.org/en/docs/inspector \nПрилагается отладчик.\n\n\n1\n2\n3\n4\n\n\n\n# Инструменты разработчика Chrome\n\nОткройте Chrome DevTools и перейдите на вкладку «Источники». Обратите внимание, что при нажатии на зеленый значок откроется новое окно.\n\n\n\nПерейдите в Файловую систему и добавьте папку проекта в рабочую область. Затем откройте dist > mappings и выберите код, который хотите отлаживать. Затем выполните код, как и в любом стандартном инструменте отладки.\n\n",normalizedContent:"# как отлаживать проект subquery?\n\n\n# видео гаид\n\n\n# вступление\n\nдля отладки проектов subquery, таких как пошаговое выполнение кода, установка бреикпоинтов и проверка переменных, вам придется использовать node.js inspector в сочетании с инструментами разработчика chrome.\n\n\n# node inspector\n\nвыполните следующую команду на экране терминала.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nнапример:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nдля помощи смотрите: https://nodejs.org/en/docs/inspector \nприлагается отладчик.\n\n\n1\n2\n3\n4\n\n\n\n# инструменты разработчика chrome\n\nоткроите chrome devtools и переидите на вкладку «источники». обратите внимание, что при нажатии на зеленыи значок откроется новое окно.\n\n\n\nпереидите в фаиловую систему и добавьте папку проекта в рабочую область. затем откроите dist > mappings и выберите код, которыи хотите отлаживать. затем выполните код, как и в любом стандартном инструменте отладки.\n\n",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Как работает словарь SubQuery?",frontmatter:{summary:"Как работает словарь SubQuery? Вся идея проекта универсального словаря состоит в том, чтобы индексировать все данные из цепочки блоков и записывать события, внешние данные и их тип",meta:[{property:"og:url",content:"/ru/tutorials_examples/dictionary.html"},{property:"og:title",content:"Как работает словарь SubQuery?"},{property:"og:description",content:"Как работает словарь SubQuery? Вся идея проекта универсального словаря состоит в том, чтобы индексировать все данные из цепочки блоков и записывать события, внешние данные и их тип"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/tutorials_examples/dictionary.html",relativePath:"ru/tutorials_examples/dictionary.md",key:"v-da271566",path:"/ru/tutorials_examples/dictionary/",headers:[{level:2,title:"Как включить словарь в свой проект?",slug:"как-включить-словарь-в-свои-проект",normalizedTitle:"как включить словарь в свои проект?",charIndex:1088},{level:2,title:"Что происходит, если словарь НЕ используется?",slug:"что-происходит-если-словарь-не-используется",normalizedTitle:"что происходит, если словарь не используется?",charIndex:1398},{level:2,title:"Что происходит, когда словарь используется?",slug:"что-происходит-когда-словарь-используется",normalizedTitle:"что происходит, когда словарь используется?",charIndex:1825},{level:2,title:"Когда словарь НЕ полезен?",slug:"когда-словарь-не-полезен",normalizedTitle:"когда словарь не полезен?",charIndex:2963}],readingTime:{minutes:.38,words:114},headersStr:"Как включить словарь в свой проект? Что происходит, если словарь НЕ используется? Что происходит, когда словарь используется? Когда словарь НЕ полезен?",content:"# Как работает словарь SubQuery?\n\nВся идея проекта универсального словаря состоит в том, чтобы индексировать все данные из цепочки блоков и записывать события, внешние данные и их типы (модуль и метод) в базу данных в порядке высоты блока. Затем другой проект может запросить эту конечную точку network.dictionary вместо значения по умолчанию network.endpoint, определенного в файле манифеста.\n\nКонечная точка network.dictionary - это необязательный параметр, который, если он присутствует, SDK автоматически обнаружит и использует. network.endpoint является обязательным и не будет компилироваться, если он отсутствует.\n\nВзяв в качестве примера проект SubQuery dictionary , файл schema определяет 3 объекта; внешние, события, specVersion. Эти 3 объекта содержат 6, 4 и 2 поля соответственно. При запуске этого проекта эти поля отражаются в таблицах базы данных.\n\n\n\nЗатем данные из цепочки блоков сохраняются в этих таблицах и индексируются для повышения производительности. Затем проект размещается в проектах SubQuery, и конечная точка API доступна для добавления в файл манифеста.\n\n\n# Как включить словарь в свой проект?\n\nДобавьте dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot в сетевой раздел манифеста. Например:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# Что происходит, если словарь НЕ используется?\n\nКогда словарь НЕ используется, индексатор будет извлекать данные каждого блока через api polkadot в соответствии с флагом batch-size, который по умолчанию равен 100, и помещает их в буфер для обработки. Позже индексатор берет все эти блоки из буфера и при обработке данных блока проверяет, соответствуют ли событие и внешний вид в этих блоках заданному пользователем фильтру.\n\n\n# Что происходит, когда словарь используется?\n\nКогда используется словарь, индексатор сначала принимает фильтры вызовов и событий в качестве параметров и объединяет их в запрос GraphQL. Затем он использует API словаря для получения списка только соответствующих высот блоков, который содержит конкретные события и внешние элементы. Часто это существенно меньше 100, если используется значение по умолчанию.\n\nНапример, представьте себе ситуацию, когда вы индексируете события передачи. Не все блоки имеют это событие (на изображении ниже нет событий передачи в блоках 3 и 4).\n\n\n\nСловарь позволяет вашему проекту пропустить это, поэтому вместо того, чтобы искать в каждом блоке событие передачи, он пропускает только блоки 1, 2 и 5. Это потому, что словарь является предварительно вычисленной ссылкой на все вызовы и события в каждом блоке.\n\nЭто означает, что использование словаря может уменьшить объем данных, которые индексатор получает из цепочки, и уменьшить количество «нежелательных» блоков, хранящихся в локальном буфере. Но по сравнению с традиционным методом он добавляет дополнительный шаг для получения данных из API словаря.\n\n\n# Когда словарь НЕ полезен?\n\nКогда обработчики блоков используются для захвата данных из цепочки, каждый блок должен быть обработан. Следовательно, использование словаря в этом случае не дает никаких преимуществ, и индексатор автоматически переключится на не словарный подход по умолчанию.\n\nКроме того, при работе с событиями или внешними событиями, которые происходят или существуют в каждом блоке, таком как timestamp.set, использование словаря не даст никаких дополнительных преимуществ.",normalizedContent:"# как работает словарь subquery?\n\nвся идея проекта универсального словаря состоит в том, чтобы индексировать все данные из цепочки блоков и записывать события, внешние данные и их типы (модуль и метод) в базу данных в порядке высоты блока. затем другои проект может запросить эту конечную точку network.dictionary вместо значения по умолчанию network.endpoint, определенного в фаиле манифеста.\n\nконечная точка network.dictionary - это необязательныи параметр, которыи, если он присутствует, sdk автоматически обнаружит и использует. network.endpoint является обязательным и не будет компилироваться, если он отсутствует.\n\nвзяв в качестве примера проект subquery dictionary , фаил schema определяет 3 объекта; внешние, события, specversion. эти 3 объекта содержат 6, 4 и 2 поля соответственно. при запуске этого проекта эти поля отражаются в таблицах базы данных.\n\n\n\nзатем данные из цепочки блоков сохраняются в этих таблицах и индексируются для повышения производительности. затем проект размещается в проектах subquery, и конечная точка api доступна для добавления в фаил манифеста.\n\n\n# как включить словарь в свои проект?\n\nдобавьте dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot в сетевои раздел манифеста. например:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# что происходит, если словарь не используется?\n\nкогда словарь не используется, индексатор будет извлекать данные каждого блока через api polkadot в соответствии с флагом batch-size, которыи по умолчанию равен 100, и помещает их в буфер для обработки. позже индексатор берет все эти блоки из буфера и при обработке данных блока проверяет, соответствуют ли событие и внешнии вид в этих блоках заданному пользователем фильтру.\n\n\n# что происходит, когда словарь используется?\n\nкогда используется словарь, индексатор сначала принимает фильтры вызовов и событии в качестве параметров и объединяет их в запрос graphql. затем он использует api словаря для получения списка только соответствующих высот блоков, которыи содержит конкретные события и внешние элементы. часто это существенно меньше 100, если используется значение по умолчанию.\n\nнапример, представьте себе ситуацию, когда вы индексируете события передачи. не все блоки имеют это событие (на изображении ниже нет событии передачи в блоках 3 и 4).\n\n\n\nсловарь позволяет вашему проекту пропустить это, поэтому вместо того, чтобы искать в каждом блоке событие передачи, он пропускает только блоки 1, 2 и 5. это потому, что словарь является предварительно вычисленнои ссылкои на все вызовы и события в каждом блоке.\n\nэто означает, что использование словаря может уменьшить объем данных, которые индексатор получает из цепочки, и уменьшить количество «нежелательных» блоков, хранящихся в локальном буфере. но по сравнению с традиционным методом он добавляет дополнительныи шаг для получения данных из api словаря.\n\n\n# когда словарь не полезен?\n\nкогда обработчики блоков используются для захвата данных из цепочки, каждыи блок должен быть обработан. следовательно, использование словаря в этом случае не дает никаких преимуществ, и индексатор автоматически переключится на не словарныи подход по умолчанию.\n\nкроме того, при работе с событиями или внешними событиями, которые происходят или существуют в каждом блоке, таком как timestamp.set, использование словаря не даст никаких дополнительных преимуществ.",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/ru/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/tutorials_examples/howto.html",relativePath:"ru/tutorials_examples/howto.md",key:"v-11f6eb4d",path:"/ru/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Обучение & Примеры",frontmatter:{summary:"Обучение & Примеры Здесь мы перечислим наши учебные пособия и рассмотрим различные примеры, которые помогут вам приступить к работе самым простым и быстрым способом. SubQuery приме",meta:[{property:"og:url",content:"/ru/tutorials_examples/introduction.html"},{property:"og:title",content:"Обучение & Примеры"},{property:"og:description",content:"Обучение & Примеры Здесь мы перечислим наши учебные пособия и рассмотрим различные примеры, которые помогут вам приступить к работе самым простым и быстрым способом. SubQuery приме"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/tutorials_examples/introduction.html",relativePath:"ru/tutorials_examples/introduction.md",key:"v-b42dc576",path:"/ru/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery примеры",slug:"subquery-примеры",normalizedTitle:"subquery примеры",charIndex:173},{level:2,title:"Примеры проектов SubQuery",slug:"примеры-проектов-subquery",normalizedTitle:"примеры проектов subquery",charIndex:194}],readingTime:{minutes:.23,words:68},headersStr:"SubQuery примеры Примеры проектов SubQuery",content:'# Обучение & Примеры\n\nЗдесь мы перечислим наши учебные пособия и рассмотрим различные примеры, которые помогут вам приступить к работе самым простым и быстрым способом.\n\n\n# SubQuery примеры\n\n\n# Примеры проектов SubQuery\n\nПРИМЕРЫ                    ОПИСАНИЕ                                                      ТЕМЫ\nвнешний-завершенный-блок   Индексирует внешние элементы, чтобы их можно было             Простейший пример с функцией __обработка блоков __\n                           запрашивать по их хешу\nотметка времени блока      Индексирует временную метку каждого завершенного блока        Еще одна простая функция __ обработчика вызовов __\nпредел валидаторов         Индексирует наименьшую сумму ставок, необходимую для выбора   Более сложная функция __ обработчика блоков __, которая\n                           валидатора.                                                   выполняет __ внешние вызовы __ к @ polkadot / api для\n                                                                                         получения дополнительных данных в цепочке\nсумма-вознаграждение       Индексы ставок, вознаграждений и косых черт от событий        Более сложные __ обработчики событий __ с отношением __\n                           завершенного блока                                            один-ко-многим __\nentity-отношение           Индексирует переводы баланса между счетами, а также           __ отношения "один ко многим __" и __ многие ко многим __ и\n                           индексирует пакет служебных программ, чтобы узнать            сложная __ внешняя обработка __\n                           содержание внешних вызовов\nkitty                      Индексирует информацию о рождении kitties.                    Сложные обработчики вызовов и обработчики событий с данными,\n                                                                                         индексируемыми из настраиваемой цепочки',normalizedContent:'# обучение & примеры\n\nздесь мы перечислим наши учебные пособия и рассмотрим различные примеры, которые помогут вам приступить к работе самым простым и быстрым способом.\n\n\n# subquery примеры\n\n\n# примеры проектов subquery\n\nпримеры                    описание                                                      темы\nвнешнии-завершенныи-блок   индексирует внешние элементы, чтобы их можно было             простеишии пример с функциеи __обработка блоков __\n                           запрашивать по их хешу\nотметка времени блока      индексирует временную метку каждого завершенного блока        еще одна простая функция __ обработчика вызовов __\nпредел валидаторов         индексирует наименьшую сумму ставок, необходимую для выбора   более сложная функция __ обработчика блоков __, которая\n                           валидатора.                                                   выполняет __ внешние вызовы __ к @ polkadot / api для\n                                                                                         получения дополнительных данных в цепочке\nсумма-вознаграждение       индексы ставок, вознаграждении и косых черт от событии        более сложные __ обработчики событии __ с отношением __\n                           завершенного блока                                            один-ко-многим __\nentity-отношение           индексирует переводы баланса между счетами, а также           __ отношения "один ко многим __" и __ многие ко многим __ и\n                           индексирует пакет служебных программ, чтобы узнать            сложная __ внешняя обработка __\n                           содержание внешних вызовов\nkitty                      индексирует информацию о рождении kitties.                    сложные обработчики вызовов и обработчики событии с данными,\n                                                                                         индексируемыми из настраиваемои цепочки',charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Как запустить узел индексатора?",frontmatter:{summary:"Как запустить узел индексатора? Видео гайд Введение Запуск узла индексатора - еще один вариант помимо использования Docker или размещения проекта в SubQuery Projects . Это требует ",meta:[{property:"og:url",content:"/ru/tutorials_examples/run-indexer.html"},{property:"og:title",content:"Как запустить узел индексатора?"},{property:"og:description",content:"Как запустить узел индексатора? Видео гайд Введение Запуск узла индексатора - еще один вариант помимо использования Docker или размещения проекта в SubQuery Projects . Это требует "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/tutorials_examples/run-indexer.html",relativePath:"ru/tutorials_examples/run-indexer.md",key:"v-7076ed4d",path:"/ru/tutorials_examples/run-indexer/",headers:[{level:2,title:"Видео гайд",slug:"видео-гаид",normalizedTitle:"видео гаид",charIndex:38},{level:2,title:"Введение",slug:"введение",normalizedTitle:"введение",charIndex:53},{level:2,title:"Postgres",slug:"postgres",normalizedTitle:"postgres",charIndex:285},{level:2,title:"Установка subql/node",slug:"установка-subql-node",normalizedTitle:"установка subql/node",charIndex:474},{level:2,title:"Настройка конфигов DB",slug:"настроика-конфигов-db",normalizedTitle:"настроика конфигов db",charIndex:805},{level:2,title:"Индексирование проекта",slug:"индексирование-проекта",normalizedTitle:"индексирование проекта",charIndex:1392},{level:2,title:"Проверка Postgres",slug:"проверка-postgres",normalizedTitle:"проверка postgres",charIndex:1715}],readingTime:{minutes:.38,words:115},headersStr:"Видео гайд Введение Postgres Установка subql/node Настройка конфигов DB Индексирование проекта Проверка Postgres",content:"# Как запустить узел индексатора?\n\n\n# Видео гайд\n\n\n# Введение\n\nЗапуск узла индексатора - еще один вариант помимо использования Docker или размещения проекта в SubQuery Projects . Это требует больше времени и усилий, но улучшит ваше понимание того, каким образом работает SubQuery.\n\n\n# Postgres\n\nДля запуска узла индексатора в вашей инфраструктуре потребуется установка базы данных Postgres. Вы можете установить Postgres здесь а также убедиться, что версия 12 или выше.\n\n\n# Установка subql/node\n\nЗатем, чтобы запустить узел SubQuery, выполните следующую команду:\n\nnpm install -g @subql/node\n\n\n1\n\n\nThe -g flag means to install it globally which means on OSX, the location will be /usr/local/lib/node_modules.\n\nПосле установки вы можете проверить версию, запустив:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# Настройка конфигов DB\n\nЗатем вам нужно установить следующие переменные среды:\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\n\n\n1\n2\n3\n4\n5\n\n\nКонечно, если у вас разные значения для вышеуказанных ключей, отрегулируйте их соответствующим образом. Обратите внимание, что команда env отобразит текущие переменные среды и что этот процесс устанавливает эти значения только временно. То есть они действительны только на время работы с терминалом. Чтобы установить их навсегда, сохраните их в своем ~ / bash_profile.\n\n\n# Индексирование проекта\n\nЧтобы начать индексирование проекта, перейдите в папку своего проекта и выполните следующую команду:\n\nsubql-node -f .\n\n\n1\n\n\nЕсли у вас нет под рукой проекта, git clone https://github.com/subquery/subql-helloworld. Вы должны увидеть, как узел индексатора заработает и начнет индексировать блоки.\n\n\n# Проверка Postgres\n\nЕсли вы перейдете в Postgres, вы должны увидеть две созданные таблицы. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries содержит только 1 строку, которую индексатор проверяет при запуске, чтобы «понять текущее состояние», чтобы понимать, продолжение. Таблица starter_entities содержит индексы. Чтобы просмотреть данные, запустите select (*) из subquery_1.starter_entities.",normalizedContent:"# как запустить узел индексатора?\n\n\n# видео гаид\n\n\n# введение\n\nзапуск узла индексатора - еще один вариант помимо использования docker или размещения проекта в subquery projects . это требует больше времени и усилии, но улучшит ваше понимание того, каким образом работает subquery.\n\n\n# postgres\n\nдля запуска узла индексатора в вашеи инфраструктуре потребуется установка базы данных postgres. вы можете установить postgres здесь а также убедиться, что версия 12 или выше.\n\n\n# установка subql/node\n\nзатем, чтобы запустить узел subquery, выполните следующую команду:\n\nnpm install -g @subql/node\n\n\n1\n\n\nthe -g flag means to install it globally which means on osx, the location will be /usr/local/lib/node_modules.\n\nпосле установки вы можете проверить версию, запустив:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# настроика конфигов db\n\nзатем вам нужно установить следующие переменные среды:\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\n\n\n1\n2\n3\n4\n5\n\n\nконечно, если у вас разные значения для вышеуказанных ключеи, отрегулируите их соответствующим образом. обратите внимание, что команда env отобразит текущие переменные среды и что этот процесс устанавливает эти значения только временно. то есть они деиствительны только на время работы с терминалом. чтобы установить их навсегда, сохраните их в своем ~ / bash_profile.\n\n\n# индексирование проекта\n\nчтобы начать индексирование проекта, переидите в папку своего проекта и выполните следующую команду:\n\nsubql-node -f .\n\n\n1\n\n\nесли у вас нет под рукои проекта, git clone https://github.com/subquery/subql-helloworld. вы должны увидеть, как узел индексатора заработает и начнет индексировать блоки.\n\n\n# проверка postgres\n\nесли вы переидете в postgres, вы должны увидеть две созданные таблицы. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries содержит только 1 строку, которую индексатор проверяет при запуске, чтобы «понять текущее состояние», чтобы понимать, продолжение. таблица starter_entities содержит индексы. чтобы просмотреть данные, запустите select (*) из subquery_1.starter_entities.",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Терминология",frontmatter:{summary:"Терминология SubQuery Project ( где происходит волшебство ): определение ( @ subql / cli ) того, как SubQuery Node должен проходить и агрегировать сеть проектов и как данные должны",meta:[{property:"og:url",content:"/ru/tutorials_examples/terminology.html"},{property:"og:title",content:"Терминология"},{property:"og:description",content:"Терминология SubQuery Project ( где происходит волшебство ): определение ( @ subql / cli ) того, как SubQuery Node должен проходить и агрегировать сеть проектов и как данные должны"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/ru/tutorials_examples/terminology.html",relativePath:"ru/tutorials_examples/terminology.md",key:"v-48f9c38d",path:"/ru/tutorials_examples/terminology/",readingTime:{minutes:.16,words:48},headersStr:null,content:"# Терминология\n\n * SubQuery Project (* где происходит волшебство *): определение (@ subql / cli) того, как SubQuery Node должен проходить и агрегировать сеть проектов и как данные должны преобразовываться и храниться, для включения полезных запросов GraphQL\n * SubQuery Node (* где выполняется работа *): пакет (@ subql / node), который примет определение SubQuery project и запустит ноду, которая постоянно индексирует подключенную сеть к базе данных\n * Служба запросов SubQuery (* откуда мы получаем данные *): пакет (@ subql / query), который взаимодействует с GraphQL API запущенной ноды SubQuery для запроса и просмотра индексированных данных\n * GraphQL (* как мы запрашиваем данные *): язык запросов для API, который специально подходит для гибких данных на основе графиков - смотрите graphql.org",normalizedContent:"# терминология\n\n * subquery project (* где происходит волшебство *): определение (@ subql / cli) того, как subquery node должен проходить и агрегировать сеть проектов и как данные должны преобразовываться и храниться, для включения полезных запросов graphql\n * subquery node (* где выполняется работа *): пакет (@ subql / node), которыи примет определение subquery project и запустит ноду, которая постоянно индексирует подключенную сеть к базе данных\n * служба запросов subquery (* откуда мы получаем данные *): пакет (@ subql / query), которыи взаимодеиствует с graphql api запущеннои ноды subquery для запроса и просмотра индексированных данных\n * graphql (* как мы запрашиваем данные *): язык запросов для api, которыи специально подходит для гибких данных на основе графиков - смотрите graphql.org",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/run/run.html",relativePath:"run/run.md",key:"v-09dfd14d",path:"/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:6013},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:6256}],readingTime:{minutes:3.54,words:1063},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:'# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don\'t want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won\'t need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you\'ll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Use a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we\'ve seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\nRead more about how a SubQuery Dictionary works.\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Run in local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n# Check your node health\n\nThere are 2 endpoints that you can use to check and monitor the health of a running SubQuery node.\n\n * Health check endpoint that returns a simple 200 response\n * Metadata endpoint that includes additional analytics of your running SubQuery node\n\nAppend this to the base URL of your SubQuery node. Eg http://localhost:3000/meta will return:\n\n{\n    "currentProcessingHeight": 1000699,\n    "currentProcessingTimestamp": 1631517883547,\n    "targetHeight": 6807295,\n    "bestHeight": 6807298,\n    "indexerNodeVersion": "0.19.1",\n    "lastProcessedHeight": 1000699,\n    "lastProcessedTimestamp": 1631517883555,\n    "uptime": 41.151789063,\n    "polkadotSdkVersion": "5.4.1",\n    "apiConnected": true,\n    "injectedApiConnected": true,\n    "usingDictionary": false,\n    "chain": "Polkadot",\n    "specName": "polkadot",\n    "genesisHash": "0x91b171bb158e2d3848fa23a9f1c25182fb8e20313b2c1eb49219da7a70ce90c3",\n    "blockTime": 6000\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nhttp://localhost:3000/health will return HTTP 200 if successful.\n\nA 500 error will be returned if the indexer is not healthy. This can often be seen when the node is booting up.\n\n{\n    "status": 500,\n    "error": "Indexer is not healthy"\n}\n\n\n1\n2\n3\n4\n\n\nIf an incorrect URL is used, a 404 not found error will be returned.\n\n{\n"statusCode": 404,\n"message": "Cannot GET /healthy",\n"error": "Not Found"\n}\n\n\n1\n2\n3\n4\n5\n\n\n# Debug your project\n\nUse the node inspector to run the following command.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nFor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\nThen open up the Chrome dev tools, go to Source > Filesystem and add your project to the workspace and start debugging. For more information, check out How to debug a SubQuery project\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\nexport DB_HOST=localhost\nsubql-query --name <project_name> --playground\n\n\n1\n2\n\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.',normalizedContent:'# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don\'t want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won\'t need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you\'ll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# use a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we\'ve seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\nread more about how a subquery dictionary works.\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# run in local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n# check your node health\n\nthere are 2 endpoints that you can use to check and monitor the health of a running subquery node.\n\n * health check endpoint that returns a simple 200 response\n * metadata endpoint that includes additional analytics of your running subquery node\n\nappend this to the base url of your subquery node. eg http://localhost:3000/meta will return:\n\n{\n    "currentprocessingheight": 1000699,\n    "currentprocessingtimestamp": 1631517883547,\n    "targetheight": 6807295,\n    "bestheight": 6807298,\n    "indexernodeversion": "0.19.1",\n    "lastprocessedheight": 1000699,\n    "lastprocessedtimestamp": 1631517883555,\n    "uptime": 41.151789063,\n    "polkadotsdkversion": "5.4.1",\n    "apiconnected": true,\n    "injectedapiconnected": true,\n    "usingdictionary": false,\n    "chain": "polkadot",\n    "specname": "polkadot",\n    "genesishash": "0x91b171bb158e2d3848fa23a9f1c25182fb8e20313b2c1eb49219da7a70ce90c3",\n    "blocktime": 6000\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nhttp://localhost:3000/health will return http 200 if successful.\n\na 500 error will be returned if the indexer is not healthy. this can often be seen when the node is booting up.\n\n{\n    "status": 500,\n    "error": "indexer is not healthy"\n}\n\n\n1\n2\n3\n4\n\n\nif an incorrect url is used, a 404 not found error will be returned.\n\n{\n"statuscode": 404,\n"message": "cannot get /healthy",\n"error": "not found"\n}\n\n\n1\n2\n3\n4\n5\n\n\n# debug your project\n\nuse the node inspector to run the following command.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nfor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\nthen open up the chrome dev tools, go to source > filesystem and add your project to the workspace and start debugging. for more information, check out how to debug a subquery project\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\nexport db_host=localhost\nsubql-query --name <project_name> --playground\n\n\n1\n2\n\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/run/sandbox.html",relativePath:"run/sandbox.md",key:"v-07cf064d",path:"/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{frontmatter:{summary:"ยินดีต้อนรับสู่ Docs ของ SubQuery สำรวจและแปลงข้อมูลเชนของคุณเพื่อสร้าง dApps ที่ใช้งานง่ายเร็วขึ้น! คู่มือสำหรับการเริ่มต้นอย่างรวดเร็ว ทำความเข้าใจ SubQuery โดยลองใช้ตัวอย่าง Hel",meta:[{property:"og:url",content:"/th/"},{property:"og:description",content:"ยินดีต้อนรับสู่ Docs ของ SubQuery สำรวจและแปลงข้อมูลเชนของคุณเพื่อสร้าง dApps ที่ใช้งานง่ายเร็วขึ้น! คู่มือสำหรับการเริ่มต้นอย่างรวดเร็ว ทำความเข้าใจ SubQuery โดยลองใช้ตัวอย่าง Hel"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/",relativePath:"th/README.md",key:"v-6eb67c5e",path:"/th/",readingTime:{minutes:1.74,words:521},headersStr:null,content:"ยินดีต้อนรับสู่ Docs ของ SubQuery\n\nสำรวจและแปลงข้อมูลเชนของคุณเพื่อสร้าง dApps ที่ใช้งานง่ายเร็วขึ้น!\n\n\nคู่มือสำหรับการเริ่มต้นอย่างรวดเร็ว\n\nทำความเข้าใจ SubQuery โดยลองใช้ตัวอย่าง Hello World แบบทั่วไป การใช้โปรเจ็กต์เทมเพลตภายในสภาพแวดล้อมของ Docker ทำให้คุณสร้างโหนดและทำงานได้อย่างรวดเร็ว และเริ่มการสืบค้นบล็อกเชนในเวลาเพียงไม่กี่นาทีด้วยคำสั่งง่ายๆ\n\nเริ่มต้น\n * บทแนะนำและตัวอย่าง\n   \n   เรียนรู้จากการลงมือทำ บทช่วยสอนและตัวอย่างเกี่ยวกับวิธีสร้างโปรเจ็กต์ SubQuery\n\n * เอกสารอ้างอิงทางเทคนิค\n   \n   เขียนขึ้นโดยนักพัฒนาสำหรับนักพัฒนา ค้นหาสิ่งที่คุณต้องการเพื่อสร้าง dApps ที่ยอดเยี่ยมได้อย่างรวดเร็ว\n\n * SubQuery Network\n   \n   อนาคตเกี่ยวกับการกระจายอำนาจของ SubQuery อ่านเพิ่มเติมเกี่ยวกับวิธีการให้รางวัลแก่ indexers และผู้ใช้งาน\n\n\nคำถามที่พบบ่อย\n\n * SubQuery คืออะไร?\n   \n   SubQuery เป็นโครงการโอเพ่นซอร์สที่ช่วยให้นักพัฒนาสามารถทำการ index เปลี่ยนแปลง และสืบค้นข้อมูลเชนของ Substrate เพื่อขับเคลื่อนแอปพลิเคชันของตนได้\n   \n   อ่านเพิ่มเติม\n * วิธีที่ดีที่สุดในการเริ่มต้นใช้งาน SubQuery คืออะไร?\n   \n   วิธีที่ดีที่สุดในการเริ่มต้นใช้งาน SubQuery คือทดลองทำตาม บทแนะนำ Hello World ของเรา นี่คือขั้นตอนง่ายๆ ในการดาวน์โหลดเทมเพลตเริ่มต้น สร้างโครงการ จากนั้นใช้ Docker เพื่อเรียกใช้โหนดบน localhost ของคุณและรัน query อย่างง่าย\n\n * ฉันจะมีส่วนร่วมหรือให้คำติชมกับ SubQuery ได้อย่างไร?\n   \n   เรารักการมีส่วนร่วมและข้อเสนอแนะจากชุมชน ในการสนับสนุนโค้ด ให้ fork repository ที่สนใจ และทำการเปลี่ยนแปลง จากนั้นส่ง PR หรือ Pull Request อ้อ อย่าลืมทดสอบด้วยล่ะ! รวมถึงตรวจสอบหลักเกณฑ์การสนับสนุน (TBA) ของเราด้วย\n   \n   อ่านเพิ่มเติม\n * การโฮสต์โปรเจ็กต์ของฉันใน SubQuery Projects มีค่าใช้จ่ายเท่าไหร่?\n   \n   การโฮสต์โปรเจ็กต์ของคุณใน SubQuery Projects นั้นฟรี - นั่นเป็นวิธีการตอบแทนชุมชนของเรา หากต้องการเรียนรู้วิธีโฮสต์โปรเจ็กต์ของคุณกับเรา โปรดดูบทแนะนำ Hello World (SubQuery hosted)\n   \n   การโฮสต์โปรเจ็กต์ของคุณ\n\n\nสำหรับคำถามที่พบบ่อยเพิ่มเติม โปรดดูที่ หน้า FAQ ของเรา\n\nการผสานรวมกับ Custom Chain ของคุณ?\n\nไม่ว่าคุณกำลังสร้าง Parachain ใหม่หรือ blockchain ใหม่ทั้งหมดบน Substrate - SubQuery สามารถช่วยคุณ index และแก้ไขปัญหาข้อมูลของ chain ของคุณ SubQuery ได้รับการออกแบบให้สามารถรวมกับ Substrate แบบกำหนดเองได้อย่างง่ายดาย\n\nเรียนรู้วิธีการรวมกับ chain ของคุณ\n\nการสนับสนุนและการมีส่วนร่วม\n\nมีคำถาม หรือต้องการที่จะทราบข้อมูลเพิ่มเติม หรือคุณจะมีส่วนร่วมได้อย่างไร? เรายินดีที่จะรับฟังคุณ โปรดติดต่อเราทางอีเมลหรือโซเชียลมีเดียจากลิงก์ด้านล่าง ต้องการความเชี่ยวชาญด้านเทคนิคหรือไม่? เข้าร่วมชุมชน Discord ของเราและรับการสนับสนุนจากสมาชิกที่กระตือรือร้นของเราในชุมชน\n\nเข้าร่วมการสนทนาบน DISCORD\nติดต่อเรา สวัสดี@subquery.network\nติดตามเราบนโซเชียล\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"ยินดีต้อนรับสู่ docs ของ subquery\n\nสำรวจและแปลงข้อมูลเชนของคุณเพื่อสร้าง dapps ที่ใช้งานง่ายเร็วขึ้น!\n\n\nคู่มือสำหรับการเริ่มต้นอย่างรวดเร็ว\n\nทำความเข้าใจ subquery โดยลองใช้ตัวอย่าง hello world แบบทั่วไป การใช้โปรเจ็กต์เทมเพลตภายในสภาพแวดล้อมของ docker ทำให้คุณสร้างโหนดและทำงานได้อย่างรวดเร็ว และเริ่มการสืบค้นบล็อกเชนในเวลาเพียงไม่กี่นาทีด้วยคำสั่งง่ายๆ\n\nเริ่มต้น\n * บทแนะนำและตัวอย่าง\n   \n   เรียนรู้จากการลงมือทำ บทช่วยสอนและตัวอย่างเกี่ยวกับวิธีสร้างโปรเจ็กต์ subquery\n\n * เอกสารอ้างอิงทางเทคนิค\n   \n   เขียนขึ้นโดยนักพัฒนาสำหรับนักพัฒนา ค้นหาสิ่งที่คุณต้องการเพื่อสร้าง dapps ที่ยอดเยี่ยมได้อย่างรวดเร็ว\n\n * subquery network\n   \n   อนาคตเกี่ยวกับการกระจายอำนาจของ subquery อ่านเพิ่มเติมเกี่ยวกับวิธีการให้รางวัลแก่ indexers และผู้ใช้งาน\n\n\nคำถามที่พบบ่อย\n\n * subquery คืออะไร?\n   \n   subquery เป็นโครงการโอเพ่นซอร์สที่ช่วยให้นักพัฒนาสามารถทำการ index เปลี่ยนแปลง และสืบค้นข้อมูลเชนของ substrate เพื่อขับเคลื่อนแอปพลิเคชันของตนได้\n   \n   อ่านเพิ่มเติม\n * วิธีที่ดีที่สุดในการเริ่มต้นใช้งาน subquery คืออะไร?\n   \n   วิธีที่ดีที่สุดในการเริ่มต้นใช้งาน subquery คือทดลองทำตาม บทแนะนำ hello world ของเรา นี่คือขั้นตอนง่ายๆ ในการดาวน์โหลดเทมเพลตเริ่มต้น สร้างโครงการ จากนั้นใช้ docker เพื่อเรียกใช้โหนดบน localhost ของคุณและรัน query อย่างง่าย\n\n * ฉันจะมีส่วนร่วมหรือให้คำติชมกับ subquery ได้อย่างไร?\n   \n   เรารักการมีส่วนร่วมและข้อเสนอแนะจากชุมชน ในการสนับสนุนโค้ด ให้ fork repository ที่สนใจ และทำการเปลี่ยนแปลง จากนั้นส่ง pr หรือ pull request อ้อ อย่าลืมทดสอบด้วยล่ะ! รวมถึงตรวจสอบหลักเกณฑ์การสนับสนุน (tba) ของเราด้วย\n   \n   อ่านเพิ่มเติม\n * การโฮสต์โปรเจ็กต์ของฉันใน subquery projects มีค่าใช้จ่ายเท่าไหร่?\n   \n   การโฮสต์โปรเจ็กต์ของคุณใน subquery projects นั้นฟรี - นั่นเป็นวิธีการตอบแทนชุมชนของเรา หากต้องการเรียนรู้วิธีโฮสต์โปรเจ็กต์ของคุณกับเรา โปรดดูบทแนะนำ hello world (subquery hosted)\n   \n   การโฮสต์โปรเจ็กต์ของคุณ\n\n\nสำหรับคำถามที่พบบ่อยเพิ่มเติม โปรดดูที่ หน้า faq ของเรา\n\nการผสานรวมกับ custom chain ของคุณ?\n\nไม่ว่าคุณกำลังสร้าง parachain ใหม่หรือ blockchain ใหม่ทั้งหมดบน substrate - subquery สามารถช่วยคุณ index และแก้ไขปัญหาข้อมูลของ chain ของคุณ subquery ได้รับการออกแบบให้สามารถรวมกับ substrate แบบกำหนดเองได้อย่างง่ายดาย\n\nเรียนรู้วิธีการรวมกับ chain ของคุณ\n\nการสนับสนุนและการมีส่วนร่วม\n\nมีคำถาม หรือต้องการที่จะทราบข้อมูลเพิ่มเติม หรือคุณจะมีส่วนร่วมได้อย่างไร? เรายินดีที่จะรับฟังคุณ โปรดติดต่อเราทางอีเมลหรือโซเชียลมีเดียจากลิงก์ด้านล่าง ต้องการความเชี่ยวชาญด้านเทคนิคหรือไม่? เข้าร่วมชุมชน discord ของเราและรับการสนับสนุนจากสมาชิกที่กระตือรือร้นของเราในชุมชน\n\nเข้าร่วมการสนทนาบน discord\nติดต่อเรา สวัสดี@subquery.network\nติดตามเราบนโซเชียล\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"GraphQL Schema",frontmatter:{summary:"GraphQL Schema การกำหนด Entities ไฟล์ schema.graphql กำหนด GraphQL schemas ต่างๆ เนื่องจากวิธีการทำงานของภาษา GraphQL query, ไฟล์สคีมาจึงกำหนดรูปร่างของข้อมูลของคุณจาก SubQuery หาก",meta:[{property:"og:url",content:"/th/create/graphql.html"},{property:"og:title",content:"GraphQL Schema"},{property:"og:description",content:"GraphQL Schema การกำหนด Entities ไฟล์ schema.graphql กำหนด GraphQL schemas ต่างๆ เนื่องจากวิธีการทำงานของภาษา GraphQL query, ไฟล์สคีมาจึงกำหนดรูปร่างของข้อมูลของคุณจาก SubQuery หาก"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/create/graphql.html",relativePath:"th/create/graphql.md",key:"v-73ea2666",path:"/th/create/graphql/",headers:[{level:2,title:"การกำหนด Entities",slug:"การกําหนด-entities",normalizedTitle:"การกำหนด entities",charIndex:21},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:30},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:849},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1200},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1104},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3208},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3677},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:3981},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5015},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1186},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6364},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7064}],readingTime:{minutes:3.61,words:1082},headersStr:"การกำหนด Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL Schema\n\n\n# การกำหนด Entities\n\nไฟล์ schema.graphql กำหนด GraphQL schemas ต่างๆ เนื่องจากวิธีการทำงานของภาษา GraphQL query, ไฟล์สคีมาจึงกำหนดรูปร่างของข้อมูลของคุณจาก SubQuery หากต้องการเรียนรู้เพิ่มเติมเกี่ยวกับวิธีการเขียนในภาษาสคีมา GraphQL เราขอแนะนำให้ตรวจสอบ สคีมาและประเภท\n\nสำคัญ: เมื่อคุณทำการเปลี่ยนแปลงใดๆ กับไฟล์สคีมา โปรดตรวจสอบให้แน่ใจว่าคุณได้สร้างไดเร็กทอรี types ของคุณใหม่ด้วยคำสั่ง yarn codegen\n\n\n# Entities\n\nแต่ละเอนทิตีต้องกำหนดฟิลด์ id ที่จำเป็นด้วยประเภทของ ID! มันถูกใช้เป็น primary key และไม่ซ้ำกันในเอนทิตีทั้งหมดที่เป็นประเภทเดียวกัน\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field \n}\n\ntype Title @entity {\n  id: ID!  \n  name: String! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nWhen code generation is run, this will automatically create a getByName under the User model, and the foreign key field title will create a getByTitleId method, which both can directly be accessed in the mapping function.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from \"../types/models/User\"\nimport {Title} from \"../types/models/Title\"\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account] \n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID! \n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactCard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# graphql schema\n\n\n# การกำหนด entities\n\nไฟล์ schema.graphql กำหนด graphql schemas ต่างๆ เนื่องจากวิธีการทำงานของภาษา graphql query, ไฟล์สคีมาจึงกำหนดรูปร่างของข้อมูลของคุณจาก subquery หากต้องการเรียนรู้เพิ่มเติมเกี่ยวกับวิธีการเขียนในภาษาสคีมา graphql เราขอแนะนำให้ตรวจสอบ สคีมาและประเภท\n\nสำคัญ: เมื่อคุณทำการเปลี่ยนแปลงใดๆ กับไฟล์สคีมา โปรดตรวจสอบให้แน่ใจว่าคุณได้สร้างไดเร็กทอรี types ของคุณใหม่ด้วยคำสั่ง yarn codegen\n\n\n# entities\n\nแต่ละเอนทิตีต้องกำหนดฟิลด์ id ที่จำเป็นด้วยประเภทของ id! มันถูกใช้เป็น primary key และไม่ซ้ำกันในเอนทิตีทั้งหมดที่เป็นประเภทเดียวกัน\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field \n}\n\ntype title @entity {\n  id: id!  \n  name: string! @index(unique:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nwhen code generation is run, this will automatically create a getbyname under the user model, and the foreign key field title will create a getbytitleid method, which both can directly be accessed in the mapping function.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from \"../types/models/user\"\nimport {title} from \"../types/models/title\"\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account] \n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id! \n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactcard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/th/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/create/introduction.html",relativePath:"th/create/introduction.md",key:"v-11c575b5",path:"/th/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2325}],readingTime:{minutes:1.79,words:537},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n```shell yarn build ``` ```bash npm run-script build ```\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n```shell yarn build ``` ```bash npm run-script build ```\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/it/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/miscellaneous/social_media.html",relativePath:"it/miscellaneous/social_media.md",key:"v-662cece6",path:"/it/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"คำถามที่พบบ่อย",frontmatter:{summary:"คำถามที่พบบ่อย SubQuery คืออะไร? SubQuery เป็นโปรเจ็กต์โอเพ่นซอร์สที่ช่วยให้นักพัฒนาสามารถทำการ index เปลี่ยนแปลง และสืบค้นข้อมูลเชนของ Substrate เพื่อขับเคลื่อนแอปพลิเคชันของตนได้",meta:[{property:"og:url",content:"/th/faqs/faqs.html"},{property:"og:title",content:"คำถามที่พบบ่อย"},{property:"og:description",content:"คำถามที่พบบ่อย SubQuery คืออะไร? SubQuery เป็นโปรเจ็กต์โอเพ่นซอร์สที่ช่วยให้นักพัฒนาสามารถทำการ index เปลี่ยนแปลง และสืบค้นข้อมูลเชนของ Substrate เพื่อขับเคลื่อนแอปพลิเคชันของตนได้"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/faqs/faqs.html",relativePath:"th/faqs/faqs.md",key:"v-62c494b1",path:"/th/faqs/faqs/",headers:[{level:2,title:"SubQuery คืออะไร?",slug:"subquery-คืออะไร",normalizedTitle:"subquery คืออะไร?",charIndex:21},{level:2,title:"วิธีที่ดีที่สุดในการเริ่มต้นใช้งาน SubQuery คืออะไร?",slug:"วิธีที่ดีที่สุดในการเริ่มต้นใช้งาน-subquery-คืออะไร",normalizedTitle:"วิธีที่ดีที่สุดในการเริ่มต้นใช้งาน subquery คืออะไร?",charIndex:386},{level:2,title:"ฉันจะมีส่วนร่วมหรือให้คำติชมกับ SubQuery ได้อย่างไร?",slug:"ฉันจะมีส่วนร่วมหรือให้คําติชมกับ-subquery-ได้อย่างไร",normalizedTitle:"ฉันจะมีส่วนร่วมหรือให้คำติชมกับ subquery ได้อย่างไร?",charIndex:669},{level:2,title:"การโฮสต์โปรเจ็กต์ของฉันใน SubQuery Projects มีค่าใช้จ่ายเท่าไหร่?",slug:"การโฮสต์โปรเจ็กต์ของฉันใน-subquery-projects-มีค่าใช้จ่ายเท่าไหร่",normalizedTitle:"การโฮสต์โปรเจ็กต์ของฉันใน subquery projects มีค่าใช้จ่ายเท่าไหร่?",charIndex:1032},{level:2,title:"Deployment slots คืออะไร?",slug:"deployment-slots-คืออะไร",normalizedTitle:"deployment slots คืออะไร?",charIndex:1281},{level:2,title:"ข้อดีของ staging slot คืออะไร?",slug:"ข้อดีของ-staging-slot-คืออะไร",normalizedTitle:"ข้อดีของ staging slot คืออะไร?",charIndex:1932},{level:2,title:"Extrinsics คืออะไร?",slug:"extrinsics-คืออะไร",normalizedTitle:"extrinsics คืออะไร?",charIndex:2377},{level:2,title:"Endpoint  สำหรับเครือข่าย Kusama คืออะไร?",slug:"endpoint-สําหรับเครือข่าย-kusama-คืออะไร",normalizedTitle:"endpoint  สำหรับเครือข่าย kusama คืออะไร?",charIndex:null},{level:2,title:"Endpoint  สำหรับเครือข่าย Polkadot mainnet คืออะไร?",slug:"endpoint-สําหรับเครือข่าย-polkadot-mainnet-คืออะไร",normalizedTitle:"endpoint  สำหรับเครือข่าย polkadot mainnet คืออะไร?",charIndex:null}],readingTime:{minutes:.47,words:141},headersStr:"SubQuery คืออะไร? วิธีที่ดีที่สุดในการเริ่มต้นใช้งาน SubQuery คืออะไร? ฉันจะมีส่วนร่วมหรือให้คำติชมกับ SubQuery ได้อย่างไร? การโฮสต์โปรเจ็กต์ของฉันใน SubQuery Projects มีค่าใช้จ่ายเท่าไหร่? Deployment slots คืออะไร? ข้อดีของ staging slot คืออะไร? Extrinsics คืออะไร? Endpoint  สำหรับเครือข่าย Kusama คืออะไร? Endpoint  สำหรับเครือข่าย Polkadot mainnet คืออะไร?",content:'# คำถามที่พบบ่อย\n\n\n# SubQuery คืออะไร?\n\nSubQuery เป็นโปรเจ็กต์โอเพ่นซอร์สที่ช่วยให้นักพัฒนาสามารถทำการ index เปลี่ยนแปลง และสืบค้นข้อมูลเชนของ Substrate เพื่อขับเคลื่อนแอปพลิเคชันของตนได้\n\nSubQuery ยังให้บริการโฮสติ้งโปรเจ็กต์ระดับโปรดักชันฟรีสำหรับนักพัฒนา เพื่อลดความรับผิดชอบในการจัดการโครงสร้างพื้นฐาน และปล่อยให้นักพัฒนาได้ทำในสิ่งที่พวกเขาทำได้ดีที่สุด - นั่นคือ การพัฒนาระบบ\n\n\n# วิธีที่ดีที่สุดในการเริ่มต้นใช้งาน SubQuery คืออะไร?\n\nวิธีที่ดีที่สุดในการเริ่มต้นใช้งาน SubQuery คือทดลองทำตาม บทแนะนำ Hello World ของเรา นี่คือขั้นตอนง่ายๆในการดาวน์โหลดเทมเพลตเริ่มต้น สร้างโปรเจ็กต์ จากนั้นใช้ Docker เพื่อเรียกใช้โหนดบน localhost ของคุณและรัน query อย่างง่าย\n\n\n# ฉันจะมีส่วนร่วมหรือให้คำติชมกับ SubQuery ได้อย่างไร?\n\nเรารักการมีส่วนร่วมและข้อเสนอแนะจากชุมชน ในการสนับสนุนโค้ด ให้ fork repository ที่สนใจ และทำการเปลี่ยนแปลง จากนั้นส่ง PR หรือ Pull Request อ้อ อย่าลืมทดสอบด้วยล่ะ! รวมถึงตรวจสอบหลักเกณฑ์การสนับสนุน (TBA) ของเราด้วย\n\nหากต้องการแสดงความคิดเห็น โปรดติดต่อเราที่ hello@subquery.network หรือไปที่ ช่อง discord\n\n\n# การโฮสต์โปรเจ็กต์ของฉันใน SubQuery Projects มีค่าใช้จ่ายเท่าไหร่?\n\nการโฮสต์โปรเจ็กต์ของคุณใน SubQuery Projects นั้นฟรี - นั่นเป็นวิธีการตอบแทนชุมชนของเรา หากต้องการเรียนรู้วิธีโฮสต์โครงการของคุณกับเรา โปรดดูบทแนะนำ Hello World (SubQuery hosted)\n\n\n# Deployment slots คืออะไร?\n\nDeployment slots เป็นฟีเจอร์ใน SubQuery Projects ซึ่งเทียบเท่ากับสภาพแวดล้อมสำหรับการพัฒนา ตัวอย่างเช่น ในองค์กรซอฟต์แวร์ใดๆ โดยปกติจะมีสภาพแวดล้อมสำหรับการพัฒนาและสภาพแวดล้อมสำหรับการผลิตเป็นขั้นต่ำ (ไม่นับรวม localhost) โดยทั่วไปแล้วอาจจะมีสภาพแวดล้อมอื่นๆเพิ่มเติม เช่น การจัดเตรียมและก่อนการผลิต หรือแม้กระทั่ง QA จะรวมอยู่ด้วย ขึ้นอยู่กับความต้องการขององค์กรและการตั้งค่ากระบวนการการพัฒนา\n\nSubQuery ปัจจุบันมีสอง slot ที่พร้อมใช้งาน คือ slot สำหรับ staging และ production ซึ่งช่วยให้นักพัฒนา deploy SubQuery ของตนกับ staging environment และเมื่อทุกอย่างเป็นไปด้วยดี ก็สามารถ"โปรโมตเป็น production" ได้เพียงคลิกปุ่ม\n\n\n# ข้อดีของ staging slot คืออะไร?\n\nประโยชน์หลักของการใช้ staging slot คือช่วยให้คุณสามารถเตรียม new release ของโปรเจ็กต์ SubQuery โดยยังไม่ต้องเปิดเผยต่อสาธารณะ คุณสามารถรอให้ staging slot ทำการ index ข้อมูลทั้งหมดใหม่โดยไม่กระทบต่อแอปพลิเคชันที่ใช้งานจริงของคุณ\n\nStaging slot จะไม่แสดงต่อสาธารณะใน Explorer และมี URL เฉพาะที่มองเห็นได้เฉพาะคุณเท่านั้น และแน่นอน สภาพแวดล้อมที่แยกจากกันทำให้คุณสามารถทดสอบโค้ดใหม่ได้โดยไม่กระทบต่อการใช้งานจริง\n\n\n# Extrinsics คืออะไร?\n\nหากคุณคุ้นเคยกับบล็อคเชนอยู่แล้ว คุณสามารถเปรียบ extrinsics ได้กับธุรกรรม หรืออธิบายให้เป็นทางการมากขึ้น extrinsic เป็นส่วนของข้อมูลที่มาจากนอก chain และถูกรวมอยู่ในบล็อก extrinsics มีสามประเภท เป็น inherent extrinsics, signed transactions และ unsigned transactions\n\nInherent extrinsics คือชิ้นส่วนของข้อมูลที่ไม่ได้ลงนามและแทรกเข้าไปในบล็อกโดยผู้เขียนบล็อกเท่านั้น\n\nSigned transaction extrinsics คือธุรกรรมที่มีลายเซ็นของบัญชีที่ออกธุรกรรม พวกเขาพร้อมที่จะจ่ายค่าธรรมเนียมเพื่อให้ธุรกรรมรวมอยู่ใน chain\n\nUnsigned transactions extrinsics คือธุรกรรมที่ไม่มีลายเซ็นของบัญชีที่ออกธุรกรรม Unsigned transactions extrinsics ควรใช้ด้วยความระมัดระวังเพราะไม่มีใครจ่ายค่าธรรมเนียมเนื่องจากมีการลงนาม ด้วยเหตุนี้ คิวธุรกรรมจึงขาดตรรกะทางเศรษฐกิจในการป้องกันการสแปม\n\nสำหรับข้อมูลเพิ่มเติม คลิก ที่นี่\n\n\n# Endpoint สำหรับเครือข่าย Kusama คืออะไร?\n\nnetwork.endpoint สำหรับเครือข่าย Kusama คือ wss://kusama.api.onfinality.io/public-ws\n\n\n# Endpoint สำหรับเครือข่าย Polkadot mainnet คืออะไร?\n\nnetwork.endpoint สำหรับเครือข่าย Polkadot คือ wss://polkadot.api.onfinality.io/public-ws',normalizedContent:'# คำถามที่พบบ่อย\n\n\n# subquery คืออะไร?\n\nsubquery เป็นโปรเจ็กต์โอเพ่นซอร์สที่ช่วยให้นักพัฒนาสามารถทำการ index เปลี่ยนแปลง และสืบค้นข้อมูลเชนของ substrate เพื่อขับเคลื่อนแอปพลิเคชันของตนได้\n\nsubquery ยังให้บริการโฮสติ้งโปรเจ็กต์ระดับโปรดักชันฟรีสำหรับนักพัฒนา เพื่อลดความรับผิดชอบในการจัดการโครงสร้างพื้นฐาน และปล่อยให้นักพัฒนาได้ทำในสิ่งที่พวกเขาทำได้ดีที่สุด - นั่นคือ การพัฒนาระบบ\n\n\n# วิธีที่ดีที่สุดในการเริ่มต้นใช้งาน subquery คืออะไร?\n\nวิธีที่ดีที่สุดในการเริ่มต้นใช้งาน subquery คือทดลองทำตาม บทแนะนำ hello world ของเรา นี่คือขั้นตอนง่ายๆในการดาวน์โหลดเทมเพลตเริ่มต้น สร้างโปรเจ็กต์ จากนั้นใช้ docker เพื่อเรียกใช้โหนดบน localhost ของคุณและรัน query อย่างง่าย\n\n\n# ฉันจะมีส่วนร่วมหรือให้คำติชมกับ subquery ได้อย่างไร?\n\nเรารักการมีส่วนร่วมและข้อเสนอแนะจากชุมชน ในการสนับสนุนโค้ด ให้ fork repository ที่สนใจ และทำการเปลี่ยนแปลง จากนั้นส่ง pr หรือ pull request อ้อ อย่าลืมทดสอบด้วยล่ะ! รวมถึงตรวจสอบหลักเกณฑ์การสนับสนุน (tba) ของเราด้วย\n\nหากต้องการแสดงความคิดเห็น โปรดติดต่อเราที่ hello@subquery.network หรือไปที่ ช่อง discord\n\n\n# การโฮสต์โปรเจ็กต์ของฉันใน subquery projects มีค่าใช้จ่ายเท่าไหร่?\n\nการโฮสต์โปรเจ็กต์ของคุณใน subquery projects นั้นฟรี - นั่นเป็นวิธีการตอบแทนชุมชนของเรา หากต้องการเรียนรู้วิธีโฮสต์โครงการของคุณกับเรา โปรดดูบทแนะนำ hello world (subquery hosted)\n\n\n# deployment slots คืออะไร?\n\ndeployment slots เป็นฟีเจอร์ใน subquery projects ซึ่งเทียบเท่ากับสภาพแวดล้อมสำหรับการพัฒนา ตัวอย่างเช่น ในองค์กรซอฟต์แวร์ใดๆ โดยปกติจะมีสภาพแวดล้อมสำหรับการพัฒนาและสภาพแวดล้อมสำหรับการผลิตเป็นขั้นต่ำ (ไม่นับรวม localhost) โดยทั่วไปแล้วอาจจะมีสภาพแวดล้อมอื่นๆเพิ่มเติม เช่น การจัดเตรียมและก่อนการผลิต หรือแม้กระทั่ง qa จะรวมอยู่ด้วย ขึ้นอยู่กับความต้องการขององค์กรและการตั้งค่ากระบวนการการพัฒนา\n\nsubquery ปัจจุบันมีสอง slot ที่พร้อมใช้งาน คือ slot สำหรับ staging และ production ซึ่งช่วยให้นักพัฒนา deploy subquery ของตนกับ staging environment และเมื่อทุกอย่างเป็นไปด้วยดี ก็สามารถ"โปรโมตเป็น production" ได้เพียงคลิกปุ่ม\n\n\n# ข้อดีของ staging slot คืออะไร?\n\nประโยชน์หลักของการใช้ staging slot คือช่วยให้คุณสามารถเตรียม new release ของโปรเจ็กต์ subquery โดยยังไม่ต้องเปิดเผยต่อสาธารณะ คุณสามารถรอให้ staging slot ทำการ index ข้อมูลทั้งหมดใหม่โดยไม่กระทบต่อแอปพลิเคชันที่ใช้งานจริงของคุณ\n\nstaging slot จะไม่แสดงต่อสาธารณะใน explorer และมี url เฉพาะที่มองเห็นได้เฉพาะคุณเท่านั้น และแน่นอน สภาพแวดล้อมที่แยกจากกันทำให้คุณสามารถทดสอบโค้ดใหม่ได้โดยไม่กระทบต่อการใช้งานจริง\n\n\n# extrinsics คืออะไร?\n\nหากคุณคุ้นเคยกับบล็อคเชนอยู่แล้ว คุณสามารถเปรียบ extrinsics ได้กับธุรกรรม หรืออธิบายให้เป็นทางการมากขึ้น extrinsic เป็นส่วนของข้อมูลที่มาจากนอก chain และถูกรวมอยู่ในบล็อก extrinsics มีสามประเภท เป็น inherent extrinsics, signed transactions และ unsigned transactions\n\ninherent extrinsics คือชิ้นส่วนของข้อมูลที่ไม่ได้ลงนามและแทรกเข้าไปในบล็อกโดยผู้เขียนบล็อกเท่านั้น\n\nsigned transaction extrinsics คือธุรกรรมที่มีลายเซ็นของบัญชีที่ออกธุรกรรม พวกเขาพร้อมที่จะจ่ายค่าธรรมเนียมเพื่อให้ธุรกรรมรวมอยู่ใน chain\n\nunsigned transactions extrinsics คือธุรกรรมที่ไม่มีลายเซ็นของบัญชีที่ออกธุรกรรม unsigned transactions extrinsics ควรใช้ด้วยความระมัดระวังเพราะไม่มีใครจ่ายค่าธรรมเนียมเนื่องจากมีการลงนาม ด้วยเหตุนี้ คิวธุรกรรมจึงขาดตรรกะทางเศรษฐกิจในการป้องกันการสแปม\n\nสำหรับข้อมูลเพิ่มเติม คลิก ที่นี่\n\n\n# endpoint สำหรับเครือข่าย kusama คืออะไร?\n\nnetwork.endpoint สำหรับเครือข่าย kusama คือ wss://kusama.api.onfinality.io/public-ws\n\n\n# endpoint สำหรับเครือข่าย polkadot mainnet คืออะไร?\n\nnetwork.endpoint สำหรับเครือข่าย polkadot คือ wss://polkadot.api.onfinality.io/public-ws',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"การติดตั้ง SubQuery",frontmatter:{summary:"การติดตั้ง SubQuery มีส่วนประกอบต่างๆ ที่จำเป็นในการสร้างโปรเจ็กต์ SubQuery เครื่องมือ @subql/cli ใช้เพื่อสร้างโครงการ SubQuery จำเป็นต้องมีคอมโพเนนต์ @subql/node เพื่อรัน indexer ",meta:[{property:"og:url",content:"/th/install/install.html"},{property:"og:title",content:"การติดตั้ง SubQuery"},{property:"og:description",content:"การติดตั้ง SubQuery มีส่วนประกอบต่างๆ ที่จำเป็นในการสร้างโปรเจ็กต์ SubQuery เครื่องมือ @subql/cli ใช้เพื่อสร้างโครงการ SubQuery จำเป็นต้องมีคอมโพเนนต์ @subql/node เพื่อรัน indexer "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/install/install.html",relativePath:"th/install/install.md",key:"v-6f84b701",path:"/th/install/install/",headers:[{level:2,title:"ติดตั้ง @subql/cli",slug:"ติดตั้ง-subql-cli",normalizedTitle:"ติดตั้ง @subql/cli",charIndex:243},{level:2,title:"ติดตั้ง @subql/node",slug:"ติดตั้ง-subql-node",normalizedTitle:"ติดตั้ง @subql/node",charIndex:616},{level:2,title:"ติดตั้ง @subql/query",slug:"ติดตั้ง-subql-query",normalizedTitle:"ติดตั้ง @subql/query",charIndex:1237}],readingTime:{minutes:.62,words:187},headersStr:"ติดตั้ง @subql/cli ติดตั้ง @subql/node ติดตั้ง @subql/query",content:'# การติดตั้ง SubQuery\n\nมีส่วนประกอบต่างๆ ที่จำเป็นในการสร้างโปรเจ็กต์ SubQuery เครื่องมือ @subql/cli ใช้เพื่อสร้างโครงการ SubQuery จำเป็นต้องมีคอมโพเนนต์ @subql/node เพื่อรัน indexer จำเป็นต้องมีไลบรารี @subql/query เพื่อสร้างข้อความค้นหา\n\n\n# ติดตั้ง @subql/cli\n\nเครื่องมือ @subql/cli ช่วยสร้างเฟรมเวิร์คโครงร่างให้กับโครงการ ซึ่งหมายความว่าคุณไม่จำเป็นต้องเริ่มต้นใหม่ทั้งหมด\n\nติดตั้ง SubQuery CLI แบบ global บนเทอร์มินัลของคุณโดยใช้ Yarn หรือ NPM:\n\n```shell yarn global add @subql/cli ``` ```bash npm install -g @subql/cli ```\n\nจากนั้นคุณสามารถรัน help เพื่อดูคำสั่งและการใช้งานที่ CLI ให้มา:\n\nsubql help\n\n\n1\n\n\n\n# ติดตั้ง @subql/node\n\nโหนด SubQuery เป็นการ implement ที่ดึงข้อมูลบล็อกเชนที่ใช้ substrate จากโปรเจ็กต์ SubQuery และบันทึกลงในฐานข้อมูล Postgres\n\nติดตั้งโหนด SubQuery แบบ global บนเทอร์มินัลของคุณโดยใช้ Yarn หรือ NPM:\n\n```shell yarn global add @subql/node ``` ```bash npm install -g @subql/node ```\n\nเมื่อติดตั้งแล้ว คุณจะสามารถ start โหนดด้วย:\n\nsubql-node <command>\n\n\n1\n\n\nText XPath: /p[4]/CodeGroup/p[3]/CodeGroup/text\n\n> หมายเหตุ: หากคุณใช้ Docker หรือคุณโฮสต์โปรเจ็กต์ของคุณใน SubQuery Projects คุณสามารถข้ามขั้นตอนนี้ได้ เนื่องจากมีโหนด SubQuery ให้ใน Docker container รวมถึงมีโครงสร้างพื้นฐานของโฮสต์ให้อยู่แล้ว\n\n\n# ติดตั้ง @subql/query\n\nไลบรารี SubQuery query ให้บริการที่จะช่วยให้คุณสามารถ query โปรเจ็กต์ของคุณใน "playground" environment ผ่านเบราว์เซอร์ของคุณ\n\nติดตั้ง SubQuery query แบบ global บนเทอร์มินัลของคุณโดยใช้ Yarn หรือ NPM:\n\n```shell yarn global add @subql/query ``` ```bash npm install -g @subql/query ```\n\n> หมายเหตุ: หากคุณใช้ Docker หรือโฮสต์โปรเจ็กต์ของคุณใน SubQuery Projects คุณสามารถข้ามขั้นตอนนี้ได้เช่นกัน เนื่องจากมี SubQuery node ให้ใน Docker container และโครงสร้างพื้นฐานของโฮสต์อยู่แล้ว',normalizedContent:'# การติดตั้ง subquery\n\nมีส่วนประกอบต่างๆ ที่จำเป็นในการสร้างโปรเจ็กต์ subquery เครื่องมือ @subql/cli ใช้เพื่อสร้างโครงการ subquery จำเป็นต้องมีคอมโพเนนต์ @subql/node เพื่อรัน indexer จำเป็นต้องมีไลบรารี @subql/query เพื่อสร้างข้อความค้นหา\n\n\n# ติดตั้ง @subql/cli\n\nเครื่องมือ @subql/cli ช่วยสร้างเฟรมเวิร์คโครงร่างให้กับโครงการ ซึ่งหมายความว่าคุณไม่จำเป็นต้องเริ่มต้นใหม่ทั้งหมด\n\nติดตั้ง subquery cli แบบ global บนเทอร์มินัลของคุณโดยใช้ yarn หรือ npm:\n\n```shell yarn global add @subql/cli ``` ```bash npm install -g @subql/cli ```\n\nจากนั้นคุณสามารถรัน help เพื่อดูคำสั่งและการใช้งานที่ cli ให้มา:\n\nsubql help\n\n\n1\n\n\n\n# ติดตั้ง @subql/node\n\nโหนด subquery เป็นการ implement ที่ดึงข้อมูลบล็อกเชนที่ใช้ substrate จากโปรเจ็กต์ subquery และบันทึกลงในฐานข้อมูล postgres\n\nติดตั้งโหนด subquery แบบ global บนเทอร์มินัลของคุณโดยใช้ yarn หรือ npm:\n\n```shell yarn global add @subql/node ``` ```bash npm install -g @subql/node ```\n\nเมื่อติดตั้งแล้ว คุณจะสามารถ start โหนดด้วย:\n\nsubql-node <command>\n\n\n1\n\n\ntext xpath: /p[4]/codegroup/p[3]/codegroup/text\n\n> หมายเหตุ: หากคุณใช้ docker หรือคุณโฮสต์โปรเจ็กต์ของคุณใน subquery projects คุณสามารถข้ามขั้นตอนนี้ได้ เนื่องจากมีโหนด subquery ให้ใน docker container รวมถึงมีโครงสร้างพื้นฐานของโฮสต์ให้อยู่แล้ว\n\n\n# ติดตั้ง @subql/query\n\nไลบรารี subquery query ให้บริการที่จะช่วยให้คุณสามารถ query โปรเจ็กต์ของคุณใน "playground" environment ผ่านเบราว์เซอร์ของคุณ\n\nติดตั้ง subquery query แบบ global บนเทอร์มินัลของคุณโดยใช้ yarn หรือ npm:\n\n```shell yarn global add @subql/query ``` ```bash npm install -g @subql/query ```\n\n> หมายเหตุ: หากคุณใช้ docker หรือโฮสต์โปรเจ็กต์ของคุณใน subquery projects คุณสามารถข้ามขั้นตอนนี้ได้เช่นกัน เนื่องจากมี subquery node ให้ใน docker container และโครงสร้างพื้นฐานของโฮสต์อยู่แล้ว',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"โปรแกรมแอมบาสเดอร์",frontmatter:{summary:"โปรแกรมแอมบาสเดอร์ เราเข้าใจดีว่าจุดแข็งที่ใหญ่ที่สุดจุดหนึ่งของเราคือชุมชน และด้วยความช่วยเหลือของคุณ เราต้องการที่จะเติบโตและจัดตั้งแอมบาสเดอร์ท้องถิ่นเพื่อชุมชนต่างๆ ทั่วโลก สมั",meta:[{property:"og:url",content:"/th/miscellaneous/ambassadors.html"},{property:"og:title",content:"โปรแกรมแอมบาสเดอร์"},{property:"og:description",content:"โปรแกรมแอมบาสเดอร์ เราเข้าใจดีว่าจุดแข็งที่ใหญ่ที่สุดจุดหนึ่งของเราคือชุมชน และด้วยความช่วยเหลือของคุณ เราต้องการที่จะเติบโตและจัดตั้งแอมบาสเดอร์ท้องถิ่นเพื่อชุมชนต่างๆ ทั่วโลก สมั"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/miscellaneous/ambassadors.html",relativePath:"th/miscellaneous/ambassadors.md",key:"v-1c946e8d",path:"/th/miscellaneous/ambassadors/",headers:[{level:2,title:"ความเชื่อของเรา",slug:"ความเชื่อของเรา",normalizedTitle:"ความเชื่อของเรา",charIndex:197},{level:2,title:"โปรแกรมแอมบาสเดอร์ของเรา",slug:"โปรแกรมแอมบาสเดอร์ของเรา",normalizedTitle:"โปรแกรมแอมบาสเดอร์ของเรา",charIndex:1244},{level:3,title:"สิทธิประโยชน์ของแอมบาสเดอร์",slug:"สิทธิประโยชน์ของแอมบาสเดอร์",normalizedTitle:"สิทธิประโยชน์ของแอมบาสเดอร์",charIndex:1554},{level:2,title:"ระบบของโปรแกรมแอมบาสเดอร์",slug:"ระบบของโปรแกรมแอมบาสเดอร์",normalizedTitle:"ระบบของโปรแกรมแอมบาสเดอร์",charIndex:2703},{level:2,title:"กิจกรรมของแอมบาสเดอร์",slug:"กิจกรรมของแอมบาสเดอร์",normalizedTitle:"กิจกรรมของแอมบาสเดอร์",charIndex:3537}],readingTime:{minutes:.19,words:56},headersStr:"ความเชื่อของเรา โปรแกรมแอมบาสเดอร์ของเรา สิทธิประโยชน์ของแอมบาสเดอร์ ระบบของโปรแกรมแอมบาสเดอร์ กิจกรรมของแอมบาสเดอร์",content:"# โปรแกรมแอมบาสเดอร์\n\n\n\nเราเข้าใจดีว่าจุดแข็งที่ใหญ่ที่สุดจุดหนึ่งของเราคือชุมชน และด้วยความช่วยเหลือของคุณ เราต้องการที่จะเติบโตและจัดตั้งแอมบาสเดอร์ท้องถิ่นเพื่อชุมชนต่างๆ ทั่วโลก\n\nสมัครเลย!\n\n\n# ความเชื่อของเรา\n\nทีมงานของเรามาพร้อมกับวิสัยทัศน์เดียวกันที่จะสร้างรากฐานของบริการข้อมูลที่ยืดหยุ่นและครอบคลุมสำหรับระบบนิเวศ Polkadot\n\nสร้างโดยนักพัฒนาเพื่อนักพัฒนา: SubQuery เป็นชุมชนที่กำลังเติบโตซึ่งมุ่งเน้นการจัดหาผลิตภัณฑ์และบริการที่ดีที่สุดสำหรับนักพัฒนาและผู้สร้างในระบบนิเวศของเรา SubQuery จะประสบความสำเร็จก็ต่อเมื่อระบบนิเวศของ Polkadot ประสบความสำเร็จ ดังนั้นทุกสิ่งที่ทำเราจะคำนึงถึงลูกค้าของเราเสมอ\n\nความซื่อสัตย์และความรับผิดชอบ: เรามีสมาชิกทีมในโอ๊คแลนด์ เซี่ยงไฮ้ และซิดนีย์ ดังนั้นการทำงานทางไกลจึงสำคัญสำหรับเรา เราคาดหวังว่าสมาชิกในทีมจะได้รับพลังและทำงานร่วมกันอย่างอิสระเพื่อให้บรรลุเป้าหมายของเรา ซึ่งเงื่อนไขที่สำคัญต่อสิ่งนี้คือทีมของเราต้องรับผิดชอบต่อการกระทำของพวกเขาและรักษาความซื่อสัตย์\n\nคำแนะนำและการสนับสนุนที่ครอบคลุม: บล็อกเชนนั้นเป็นเรื่องยาก และทุกคนก็ต้องการความช่วยเหลือในบางครั้ง จะไม่มีคำว่าคำถามโง่ๆ ในชุมชนของเรา และทุกคนในทีมจะคอยให้การช่วยเหลือสนับสนุนผู้ใช้ของเรา เราได้เรียนรู้ข้อมูลเชิงลึกที่มีค่าที่สุดบางอย่างเกี่ยวกับบริการของเรา (และวิธีที่เราจะปรับปรุงบริการให้ดีขึ้น) โดยตรงจากชุมชนของเรา\n\n\n# โปรแกรมแอมบาสเดอร์ของเรา\n\nโปรแกรมแอมบาสเดอร์ SubQuery มีเป้าหมายเพื่อค้นหาผู้นำชุมชนที่หลงใหลใน Polkadot และ SubQuery โดยเรากำลังมองหาผู้ริเริ่มที่จะสามารถกระจายข่าวและข้อมูลเกี่ยวกับ SubQuery ในพื้นที่ของตนและให้การสนับสนุนนักพัฒนารายใหม่ที่ต้องการใช้ SubQuery เพื่อสร้างแอปและบริการที่น่าทึ่งบน Polkadot\n\n\n# สิทธิประโยชน์ของแอมบาสเดอร์\n\nที่ SubQuery เราทำงานอย่างหนักเพื่อบรรลุสิ่งที่เราทำ และแอมบาสเดอร์ก็จะต้องใช้เวลาพอสมควรเช่นกันเมื่อเข้าร่วมโปรแกรมกับเรา แต่จะได้รับรางวัลเป็นสิทธิประโยชน์ต่างๆ มากมาย\n\nเงินทุนและการสนับสนุน: คุณอาจได้รับรางวัลสำหรับการทำงานที่ดีเป็นโอกาสในการเข้าร่วม private sales และ bounties ก่อนคนอื่น นอกจากนี้ เรายังมีทุนสนับสนุนเพื่อให้คุณจัดการพบปะสังสรรค์สำหรับชุมชนอีกด้วย\n\nการเข้าถึงทีม SubQuery: คุณจะสามารถเข้าถึงทีมหลัก SubQuery ได้โดยตรงพร้อมโอกาสในการฝึกอบรมภาคปฏิบัติ, AMA สุดพิเศษกับผู้นำและนักพัฒนาของเรา, รวมถึงรับรู้ข้อมูลเชิงลึกเกี่ยวกับแผนงานของเรา\n\nการพัฒนาเครือข่าย: คุณจะสามารถขยายเครือข่ายมืออาชีพของคุณด้วยการเป็นแอมบาสเดอร์ให้หนึ่งในโปรเจกต์ชั้นนำของ Polkadot รวมถึงพบกับแอมบาสเดอร์คนอื่นๆ ทั่วโลกและรับการแนะนำสู่โปรเจกต์ Polkadot ในท้องถิ่นที่เราจำเป็นต้องสนับสนุน โดยคุณอาจได้รับสิทธิ์เข้าร่วมเพื่อเป็นตัวแทนของ SubQuery สำหรับกิจกรรมในพื้นที่ของคุณฟรีอีกด้วย\n\nขอที่ระลึกและของฟรีอื่นๆ: ใครๆ ก็ชอบของฟรี! คุณสามารถรับของที่ระลึกประจำปีจาก SubQuery ที่จะทำให้คุณโดดเด่นท่ามกลางฝูงชน รวมถึงส่วนแบ่งจากการจัดสรรเพิ่มเติมในกิจกรรมต่างๆ ของชุมชน และคุณยังจะได้รับ NFT พิเศษเฉพาะสำหรับแอมบาสเดอร์อีกด้วย\n\n\n# ระบบของโปรแกรมแอมบาสเดอร์\n\nโปรแกรมแอมบาสเดอร์ของเรามีหลายระดับ โดยแต่ละระดับก็มีสิทธิประโยชน์และขีดความสามารถที่แตกต่างกัน คุณสามารถเลื่อนระดับได้โดยการเข้าร่วมกิจกรรมแอมบาสเดอร์และทำงานหนักเพื่อเรา\n\nเมื่อคุณส่งใบสมัครแล้ว เราจะคัดเลือกผู้สมัครที่สอดคล้องกับค่านิยมของเรา และหากได้รับเลือก คุณจะอยู่ในโปรแกรมฝึกหัดของเราและจะได้รับแพ็คเกจข้อมูล ซึ่งจะช่วยให้คุณมีความเข้าใจเกี่ยวกับ SubQuery มากขึ้น หลังจากนี้ คุณสามารถเริ่มทำงานผ่านโปรแกรมฝึกหัดโดยการทำงานปฐมนิเทศบางอย่างให้เสร็จสิ้น (เช่น การสร้างโปรเจกต์ SubQuery) โดยเราจะจัดเวิร์กช็อปตลอดกระบวนการนี้เพื่อให้ความช่วยเหลือกับคุณ\n\nเมื่อคุณผ่านโปรแกรมฝึกหัดแล้ว คุณจะสามารถเรียกตัวเองว่าแอมบาสเดอร์ SubQuery และจะได้เข้าร่วมโปรแกรมอย่างเต็มรูปแบบของเรา โดยคุณสามารถทำงานต่อไปในโปรแกรมและเลื่อนระดับขึ้น เพื่อรับรางวัลและสิทธิประโยชน์ที่มากขึ้นสำหรับระดับที่สูงขึ้น\n\nสมัครเลย!\n\n\n# กิจกรรมของแอมบาสเดอร์\n\nแอมบาสเดอร์ SubQuery สามารถมีส่วนร่วมได้ผ่านสี่หมวดหลัก ได้แก่ การจัดกิจกรรม, การสร้างคอนเทนต์, การแปล, และการดูแลชุมชน ซึ่งคุณสามารถเข้าร่วมกิจกรรมต่างๆ ได้มากเท่าที่ต้องการ โดยไม่ผูกมัดกับกิจกรรมใดกิจกรรมหนึ่งเท่านั้น\n\nการจัดกิจกรรม: สร้างชุมชนท้องถิ่นโดยการจัดงาน, ดูแลและจัดการกิจกรรมต่างๆ การสร้างชุมชนท้องถิ่นนั้นจะเป็นส่วนสำคัญในการเติบโตของชุมชน SubQuery SubQuery จะสนับสนุนคุณโดยการจัดหาเงินทุนสำหรับกิจกรรม, การจัดส่งของที่ระลึก/สินค้าเพื่อแจกจ่าย, รวมถึงการเข้าร่วม Q&As หรือกิจกรรมออนไลน์ในฐานะวิทยากรหรือใน AMA\n\nการสร้างคอนเทนต์: เรามีรายการคอนเทนต์และเอกสารสนับสนุนจำนวนมากที่เราต้องการความช่วยเหลือในการสร้าง เพราะความสำเร็จของเราขึ้นอยู่กับความสามารถของลูกค้าในการสร้างสรรค์สิ่งที่น่าทึ่งบนบริการของเรา ดังนั้นเราจึงต้องการความช่วยเหลือจากคุณเพื่อทำให้สิ่งนั้นง่ายยิ่งขึ้น โดยคอนเทนต์ต่างๆ นั้นรวมถึงวิดีโอ, อินโฟกราฟิก, คลิปหรือบทความ tutorials, แอนิเมชั่น, หรือเนื้อหาที่เกี่ยวข้องอื่นๆ เพื่อให้ความรู้หรือสร้างแรงบันดาลใจให้สมาชิกชุมชนภายในระบบนิเวศ SubQuery เราจะสนับสนุนผู้สร้างคอนเทนต์โดยการจัดหาวัตถุดิบแบรนด์ดิ้งและข้อมูลต่างๆ ของโปรเจกต์ และเรายังจะใช้ช่องทางการตลาดของ SubQuery เพื่อให้คอนเทนต์ของคุณเข้าถึงผู้คนได้มากขึ้นอีกด้วย (รวมทั้งตัวคุณเอง)\n\nการแปล: ลูกค้าของเราไม่ได้พูดแค่ภาษาอังกฤษเท่านั้น! เราต้องการความช่วยเหลือจากคุณในการทำให้ SubQuery สามารถเข้าถึงได้มากขึ้นโดยการแปลเนื้อหาของเราเป็นภาษาของคุณเอง รวมถึงการช่วยประชาสัมพันธ์ข่าวสารต่างๆ กับชุมชนนานาชาติของเรา\n\nการดูแลชุมชน: โมเดอเรเตอร์จะช่วยให้ชุมชน SubQuery เติบโตได้โดยการดูแลให้ช่องทางหลักของชุมชนมีชีวิตชีวาและให้ทุกคนได้มีส่วนร่วม SubQuery จะสนับสนุนโมเดอเรเตอร์โดยส่งเสริมช่องที่พวกเขาดูแลตลอดจนให้แนวทางเกี่ยวกับความคาดหวังของเรา\n\nสมัครเลย!",normalizedContent:"# โปรแกรมแอมบาสเดอร์\n\n\n\nเราเข้าใจดีว่าจุดแข็งที่ใหญ่ที่สุดจุดหนึ่งของเราคือชุมชน และด้วยความช่วยเหลือของคุณ เราต้องการที่จะเติบโตและจัดตั้งแอมบาสเดอร์ท้องถิ่นเพื่อชุมชนต่างๆ ทั่วโลก\n\nสมัครเลย!\n\n\n# ความเชื่อของเรา\n\nทีมงานของเรามาพร้อมกับวิสัยทัศน์เดียวกันที่จะสร้างรากฐานของบริการข้อมูลที่ยืดหยุ่นและครอบคลุมสำหรับระบบนิเวศ polkadot\n\nสร้างโดยนักพัฒนาเพื่อนักพัฒนา: subquery เป็นชุมชนที่กำลังเติบโตซึ่งมุ่งเน้นการจัดหาผลิตภัณฑ์และบริการที่ดีที่สุดสำหรับนักพัฒนาและผู้สร้างในระบบนิเวศของเรา subquery จะประสบความสำเร็จก็ต่อเมื่อระบบนิเวศของ polkadot ประสบความสำเร็จ ดังนั้นทุกสิ่งที่ทำเราจะคำนึงถึงลูกค้าของเราเสมอ\n\nความซื่อสัตย์และความรับผิดชอบ: เรามีสมาชิกทีมในโอ๊คแลนด์ เซี่ยงไฮ้ และซิดนีย์ ดังนั้นการทำงานทางไกลจึงสำคัญสำหรับเรา เราคาดหวังว่าสมาชิกในทีมจะได้รับพลังและทำงานร่วมกันอย่างอิสระเพื่อให้บรรลุเป้าหมายของเรา ซึ่งเงื่อนไขที่สำคัญต่อสิ่งนี้คือทีมของเราต้องรับผิดชอบต่อการกระทำของพวกเขาและรักษาความซื่อสัตย์\n\nคำแนะนำและการสนับสนุนที่ครอบคลุม: บล็อกเชนนั้นเป็นเรื่องยาก และทุกคนก็ต้องการความช่วยเหลือในบางครั้ง จะไม่มีคำว่าคำถามโง่ๆ ในชุมชนของเรา และทุกคนในทีมจะคอยให้การช่วยเหลือสนับสนุนผู้ใช้ของเรา เราได้เรียนรู้ข้อมูลเชิงลึกที่มีค่าที่สุดบางอย่างเกี่ยวกับบริการของเรา (และวิธีที่เราจะปรับปรุงบริการให้ดีขึ้น) โดยตรงจากชุมชนของเรา\n\n\n# โปรแกรมแอมบาสเดอร์ของเรา\n\nโปรแกรมแอมบาสเดอร์ subquery มีเป้าหมายเพื่อค้นหาผู้นำชุมชนที่หลงใหลใน polkadot และ subquery โดยเรากำลังมองหาผู้ริเริ่มที่จะสามารถกระจายข่าวและข้อมูลเกี่ยวกับ subquery ในพื้นที่ของตนและให้การสนับสนุนนักพัฒนารายใหม่ที่ต้องการใช้ subquery เพื่อสร้างแอปและบริการที่น่าทึ่งบน polkadot\n\n\n# สิทธิประโยชน์ของแอมบาสเดอร์\n\nที่ subquery เราทำงานอย่างหนักเพื่อบรรลุสิ่งที่เราทำ และแอมบาสเดอร์ก็จะต้องใช้เวลาพอสมควรเช่นกันเมื่อเข้าร่วมโปรแกรมกับเรา แต่จะได้รับรางวัลเป็นสิทธิประโยชน์ต่างๆ มากมาย\n\nเงินทุนและการสนับสนุน: คุณอาจได้รับรางวัลสำหรับการทำงานที่ดีเป็นโอกาสในการเข้าร่วม private sales และ bounties ก่อนคนอื่น นอกจากนี้ เรายังมีทุนสนับสนุนเพื่อให้คุณจัดการพบปะสังสรรค์สำหรับชุมชนอีกด้วย\n\nการเข้าถึงทีม subquery: คุณจะสามารถเข้าถึงทีมหลัก subquery ได้โดยตรงพร้อมโอกาสในการฝึกอบรมภาคปฏิบัติ, ama สุดพิเศษกับผู้นำและนักพัฒนาของเรา, รวมถึงรับรู้ข้อมูลเชิงลึกเกี่ยวกับแผนงานของเรา\n\nการพัฒนาเครือข่าย: คุณจะสามารถขยายเครือข่ายมืออาชีพของคุณด้วยการเป็นแอมบาสเดอร์ให้หนึ่งในโปรเจกต์ชั้นนำของ polkadot รวมถึงพบกับแอมบาสเดอร์คนอื่นๆ ทั่วโลกและรับการแนะนำสู่โปรเจกต์ polkadot ในท้องถิ่นที่เราจำเป็นต้องสนับสนุน โดยคุณอาจได้รับสิทธิ์เข้าร่วมเพื่อเป็นตัวแทนของ subquery สำหรับกิจกรรมในพื้นที่ของคุณฟรีอีกด้วย\n\nขอที่ระลึกและของฟรีอื่นๆ: ใครๆ ก็ชอบของฟรี! คุณสามารถรับของที่ระลึกประจำปีจาก subquery ที่จะทำให้คุณโดดเด่นท่ามกลางฝูงชน รวมถึงส่วนแบ่งจากการจัดสรรเพิ่มเติมในกิจกรรมต่างๆ ของชุมชน และคุณยังจะได้รับ nft พิเศษเฉพาะสำหรับแอมบาสเดอร์อีกด้วย\n\n\n# ระบบของโปรแกรมแอมบาสเดอร์\n\nโปรแกรมแอมบาสเดอร์ของเรามีหลายระดับ โดยแต่ละระดับก็มีสิทธิประโยชน์และขีดความสามารถที่แตกต่างกัน คุณสามารถเลื่อนระดับได้โดยการเข้าร่วมกิจกรรมแอมบาสเดอร์และทำงานหนักเพื่อเรา\n\nเมื่อคุณส่งใบสมัครแล้ว เราจะคัดเลือกผู้สมัครที่สอดคล้องกับค่านิยมของเรา และหากได้รับเลือก คุณจะอยู่ในโปรแกรมฝึกหัดของเราและจะได้รับแพ็คเกจข้อมูล ซึ่งจะช่วยให้คุณมีความเข้าใจเกี่ยวกับ subquery มากขึ้น หลังจากนี้ คุณสามารถเริ่มทำงานผ่านโปรแกรมฝึกหัดโดยการทำงานปฐมนิเทศบางอย่างให้เสร็จสิ้น (เช่น การสร้างโปรเจกต์ subquery) โดยเราจะจัดเวิร์กช็อปตลอดกระบวนการนี้เพื่อให้ความช่วยเหลือกับคุณ\n\nเมื่อคุณผ่านโปรแกรมฝึกหัดแล้ว คุณจะสามารถเรียกตัวเองว่าแอมบาสเดอร์ subquery และจะได้เข้าร่วมโปรแกรมอย่างเต็มรูปแบบของเรา โดยคุณสามารถทำงานต่อไปในโปรแกรมและเลื่อนระดับขึ้น เพื่อรับรางวัลและสิทธิประโยชน์ที่มากขึ้นสำหรับระดับที่สูงขึ้น\n\nสมัครเลย!\n\n\n# กิจกรรมของแอมบาสเดอร์\n\nแอมบาสเดอร์ subquery สามารถมีส่วนร่วมได้ผ่านสี่หมวดหลัก ได้แก่ การจัดกิจกรรม, การสร้างคอนเทนต์, การแปล, และการดูแลชุมชน ซึ่งคุณสามารถเข้าร่วมกิจกรรมต่างๆ ได้มากเท่าที่ต้องการ โดยไม่ผูกมัดกับกิจกรรมใดกิจกรรมหนึ่งเท่านั้น\n\nการจัดกิจกรรม: สร้างชุมชนท้องถิ่นโดยการจัดงาน, ดูแลและจัดการกิจกรรมต่างๆ การสร้างชุมชนท้องถิ่นนั้นจะเป็นส่วนสำคัญในการเติบโตของชุมชน subquery subquery จะสนับสนุนคุณโดยการจัดหาเงินทุนสำหรับกิจกรรม, การจัดส่งของที่ระลึก/สินค้าเพื่อแจกจ่าย, รวมถึงการเข้าร่วม q&as หรือกิจกรรมออนไลน์ในฐานะวิทยากรหรือใน ama\n\nการสร้างคอนเทนต์: เรามีรายการคอนเทนต์และเอกสารสนับสนุนจำนวนมากที่เราต้องการความช่วยเหลือในการสร้าง เพราะความสำเร็จของเราขึ้นอยู่กับความสามารถของลูกค้าในการสร้างสรรค์สิ่งที่น่าทึ่งบนบริการของเรา ดังนั้นเราจึงต้องการความช่วยเหลือจากคุณเพื่อทำให้สิ่งนั้นง่ายยิ่งขึ้น โดยคอนเทนต์ต่างๆ นั้นรวมถึงวิดีโอ, อินโฟกราฟิก, คลิปหรือบทความ tutorials, แอนิเมชั่น, หรือเนื้อหาที่เกี่ยวข้องอื่นๆ เพื่อให้ความรู้หรือสร้างแรงบันดาลใจให้สมาชิกชุมชนภายในระบบนิเวศ subquery เราจะสนับสนุนผู้สร้างคอนเทนต์โดยการจัดหาวัตถุดิบแบรนด์ดิ้งและข้อมูลต่างๆ ของโปรเจกต์ และเรายังจะใช้ช่องทางการตลาดของ subquery เพื่อให้คอนเทนต์ของคุณเข้าถึงผู้คนได้มากขึ้นอีกด้วย (รวมทั้งตัวคุณเอง)\n\nการแปล: ลูกค้าของเราไม่ได้พูดแค่ภาษาอังกฤษเท่านั้น! เราต้องการความช่วยเหลือจากคุณในการทำให้ subquery สามารถเข้าถึงได้มากขึ้นโดยการแปลเนื้อหาของเราเป็นภาษาของคุณเอง รวมถึงการช่วยประชาสัมพันธ์ข่าวสารต่างๆ กับชุมชนนานาชาติของเรา\n\nการดูแลชุมชน: โมเดอเรเตอร์จะช่วยให้ชุมชน subquery เติบโตได้โดยการดูแลให้ช่องทางหลักของชุมชนมีชีวิตชีวาและให้ทุกคนได้มีส่วนร่วม subquery จะสนับสนุนโมเดอเรเตอร์โดยส่งเสริมช่องที่พวกเขาดูแลตลอดจนให้แนวทางเกี่ยวกับความคาดหวังของเรา\n\nสมัครเลย!",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/it/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/it/publish/connect.html",relativePath:"it/publish/connect.md",key:"v-1d35e80d",path:"/it/publish/connect/",readingTime:{minutes:.61,words:182},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"วัตถุดิบแบรนด์ดิ้ง",frontmatter:{summary:"วัตถุดิบแบรนด์ดิ้ง โลโก้หรือเครื่องหมายต่างๆ ของ SubQuery ทั้งหมดเป็นกรรมสิทธิ์ของเรา และเราให้ความสำคัญกับแบรนด์ของเราเป็นอย่างมาก หากคุณเลือกใช้เครื่องหมายการค้า, โลโก้, งานดีไซน",meta:[{property:"og:url",content:"/th/miscellaneous/branding.html"},{property:"og:title",content:"วัตถุดิบแบรนด์ดิ้ง"},{property:"og:description",content:"วัตถุดิบแบรนด์ดิ้ง โลโก้หรือเครื่องหมายต่างๆ ของ SubQuery ทั้งหมดเป็นกรรมสิทธิ์ของเรา และเราให้ความสำคัญกับแบรนด์ของเราเป็นอย่างมาก หากคุณเลือกใช้เครื่องหมายการค้า, โลโก้, งานดีไซน"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/miscellaneous/branding.html",relativePath:"th/miscellaneous/branding.md",key:"v-5e938c0d",path:"/th/miscellaneous/branding/",headers:[{level:2,title:"ไฟล์ Figma ที่สามารถ export ได้",slug:"ไฟล์-figma-ที่สามารถ-export-ได้",normalizedTitle:"ไฟล์ figma ที่สามารถ export ได้",charIndex:365},{level:2,title:"แพ็คเกจทรัพยากรแบรนด์",slug:"แพ็คเกจทรัพยากรแบรนด์",normalizedTitle:"แพ็คเกจทรัพยากรแบรนด์",charIndex:549}],readingTime:{minutes:.1,words:31},headersStr:"ไฟล์ Figma ที่สามารถ export ได้ แพ็คเกจทรัพยากรแบรนด์",content:"# วัตถุดิบแบรนด์ดิ้ง\n\nโลโก้หรือเครื่องหมายต่างๆ ของ SubQuery ทั้งหมดเป็นกรรมสิทธิ์ของเรา และเราให้ความสำคัญกับแบรนด์ของเราเป็นอย่างมาก\n\nหากคุณเลือกใช้เครื่องหมายการค้า, โลโก้, งานดีไซน์, หรือคุณลักษณะอื่นๆ ของแบรนด์ โปรดปฏิบัติตามหลักเกณฑ์นี้อย่างละเอียด หรือติดต่อเราผ่านโซเชียลมีเดียเพื่อสอบถามเพิ่มเติม\n\nหากมีข้อสงสัย โปรดอย่าลังเลที่จะติดต่อเราเพื่อสอบถาม!\n\n\n# ไฟล์ Figma ที่สามารถ export ได้\n\nไฟล์ Figma ของเรามีคอลเลกชั่นเต็มรูปแบบของทรัพยากรของแบรนด์ทั้งหมด (โลโก้, ฟอนต์, สี, ภาพ, ฯลฯ) สำหรับการ export\n\nFigma - SubQuery Brand Resources\n\n\n# แพ็คเกจทรัพยากรแบรนด์\n\nแพ็คเกจไฟล์ ZIP ขนาดเล็กของทรัพยากรแบรนด์\n\npublic_branding.zip",normalizedContent:"# วัตถุดิบแบรนด์ดิ้ง\n\nโลโก้หรือเครื่องหมายต่างๆ ของ subquery ทั้งหมดเป็นกรรมสิทธิ์ของเรา และเราให้ความสำคัญกับแบรนด์ของเราเป็นอย่างมาก\n\nหากคุณเลือกใช้เครื่องหมายการค้า, โลโก้, งานดีไซน์, หรือคุณลักษณะอื่นๆ ของแบรนด์ โปรดปฏิบัติตามหลักเกณฑ์นี้อย่างละเอียด หรือติดต่อเราผ่านโซเชียลมีเดียเพื่อสอบถามเพิ่มเติม\n\nหากมีข้อสงสัย โปรดอย่าลังเลที่จะติดต่อเราเพื่อสอบถาม!\n\n\n# ไฟล์ figma ที่สามารถ export ได้\n\nไฟล์ figma ของเรามีคอลเลกชั่นเต็มรูปแบบของทรัพยากรของแบรนด์ทั้งหมด (โลโก้, ฟอนต์, สี, ภาพ, ฯลฯ) สำหรับการ export\n\nfigma - subquery brand resources\n\n\n# แพ็คเกจทรัพยากรแบรนด์\n\nแพ็คเกจไฟล์ zip ขนาดเล็กของทรัพยากรแบรนด์\n\npublic_branding.zip",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/th/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/miscellaneous/contributing.html",relativePath:"th/miscellaneous/contributing.md",key:"v-6837abad",path:"/th/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/th/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/miscellaneous/social_media.html",relativePath:"th/miscellaneous/social_media.md",key:"v-037fd2a6",path:"/th/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529},{level:3,title:"Telegram",slug:"telegram",normalizedTitle:"telegram",charIndex:450}],readingTime:{minutes:.55,words:166},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities Telegram",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.\n\n\n# Telegram\n\nSubQuery Russia SubQuery Russia SubQuery Vietnam SubQuery Vietnam Announcement",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.\n\n\n# telegram\n\nsubquery russia subquery russia subquery vietnam subquery vietnam announcement",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"เชื่อมต่อกับโปรเจ็กต์ใหม่ของคุณ",frontmatter:{summary:"เชื่อมต่อกับโปรเจ็กต์ใหม่ของคุณ เมื่อการ deploy ของคุณเสร็จสิ้นเรียบน้อยแล้ว และโหนดของเราได้จัดทำดัชนีข้อมูลของคุณจาก chain คุณจะสามารถเชื่อมต่อกับโปรเจ็กต์ของคุณผ่านทาง Query end",meta:[{property:"og:url",content:"/th/publish/connect.html"},{property:"og:title",content:"เชื่อมต่อกับโปรเจ็กต์ใหม่ของคุณ"},{property:"og:description",content:"เชื่อมต่อกับโปรเจ็กต์ใหม่ของคุณ เมื่อการ deploy ของคุณเสร็จสิ้นเรียบน้อยแล้ว และโหนดของเราได้จัดทำดัชนีข้อมูลของคุณจาก chain คุณจะสามารถเชื่อมต่อกับโปรเจ็กต์ของคุณผ่านทาง Query end"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/publish/connect.html",relativePath:"th/publish/connect.md",key:"v-fe33ad0a",path:"/th/publish/connect/",readingTime:{minutes:.18,words:53},headersStr:null,content:"# เชื่อมต่อกับโปรเจ็กต์ใหม่ของคุณ\n\nเมื่อการ deploy ของคุณเสร็จสิ้นเรียบน้อยแล้ว และโหนดของเราได้จัดทำดัชนีข้อมูลของคุณจาก chain คุณจะสามารถเชื่อมต่อกับโปรเจ็กต์ของคุณผ่านทาง Query endpoint ที่แสดงอยู่\n\n\n\nหรือคุณสามารถคลิกที่จุดสามจุดถัดจากชื่อโปรเจ็กต์ของคุณ แล้วดูใน SubQuery Explorer คุณสามารถใช้ playground ในเบราว์เซอร์เพื่อเริ่มต้นได้\n\n\n\n\n# เรียนรู้เพิ่มเติมเกี่ยวกับ GraphQL\n\nคุณสามารถทำตาม คู่มือ GraphQL อย่างเป็นทางการที่นี่ เพื่อเรียนรู้เพิ่มเติมเกี่ยวกับ GraphQL วิธีการทำงาน และวิธีใช้งาน:\n\n * มีไลบรารี่ที่จะช่วยคุณใช้งาน GraphQL ใน ภาษาต่างๆ มากมาย\n * สำหรับประสบการณ์การเรียนรู้เชิงลึกพร้อมบทช่วยสอนเชิงปฏิบัติ โปรดดูที่ วิธีสร้าง GraphQL\n * ดูหลักสูตรออนไลน์ฟรี การสำรวจ GraphQL: ภาษาการสืบค้นสำหรับ API",normalizedContent:"# เชื่อมต่อกับโปรเจ็กต์ใหม่ของคุณ\n\nเมื่อการ deploy ของคุณเสร็จสิ้นเรียบน้อยแล้ว และโหนดของเราได้จัดทำดัชนีข้อมูลของคุณจาก chain คุณจะสามารถเชื่อมต่อกับโปรเจ็กต์ของคุณผ่านทาง query endpoint ที่แสดงอยู่\n\n\n\nหรือคุณสามารถคลิกที่จุดสามจุดถัดจากชื่อโปรเจ็กต์ของคุณ แล้วดูใน subquery explorer คุณสามารถใช้ playground ในเบราว์เซอร์เพื่อเริ่มต้นได้\n\n\n\n\n# เรียนรู้เพิ่มเติมเกี่ยวกับ graphql\n\nคุณสามารถทำตาม คู่มือ graphql อย่างเป็นทางการที่นี่ เพื่อเรียนรู้เพิ่มเติมเกี่ยวกับ graphql วิธีการทำงาน และวิธีใช้งาน:\n\n * มีไลบรารี่ที่จะช่วยคุณใช้งาน graphql ใน ภาษาต่างๆ มากมาย\n * สำหรับประสบการณ์การเรียนรู้เชิงลึกพร้อมบทช่วยสอนเชิงปฏิบัติ โปรดดูที่ วิธีสร้าง graphql\n * ดูหลักสูตรออนไลน์ฟรี การสำรวจ graphql: ภาษาการสืบค้นสำหรับ api",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"เผยแพร่โครงการ SubQuery ของคุณ",frontmatter:{summary:"เผยแพร่โครงการ SubQuery ของคุณ ประโยชน์ในการโฮสต์โปรเจ็กต์ของคุณกับ SubQuery เราจะรันโปรเจ็กต์ SubQuery ให้กับคุณด้วยบริการที่มีประสิทธิภาพสูง สามารถปรับขนาดได้ และมีการจัดการแบบบร",meta:[{property:"og:url",content:"/th/publish/publish.html"},{property:"og:title",content:"เผยแพร่โครงการ SubQuery ของคุณ"},{property:"og:description",content:"เผยแพร่โครงการ SubQuery ของคุณ ประโยชน์ในการโฮสต์โปรเจ็กต์ของคุณกับ SubQuery เราจะรันโปรเจ็กต์ SubQuery ให้กับคุณด้วยบริการที่มีประสิทธิภาพสูง สามารถปรับขนาดได้ และมีการจัดการแบบบร"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/publish/publish.html",relativePath:"th/publish/publish.md",key:"v-6f374131",path:"/th/publish/publish/",headers:[{level:2,title:"ประโยชน์ในการโฮสต์โปรเจ็กต์ของคุณกับ SubQuery",slug:"ประโยชน์ในการโฮสต์โปรเจ็กต์ของคุณกับ-subquery",normalizedTitle:"ประโยชน์ในการโฮสต์โปรเจ็กต์ของคุณกับ subquery",charIndex:37},{level:2,title:"สร้างโปรเจ็กต์แรกของคุณ",slug:"สร้างโปรเจ็กต์แรกของคุณ",normalizedTitle:"สร้างโปรเจ็กต์แรกของคุณ",charIndex:462},{level:2,title:"ขั้นตอนต่อไป - เชื่อมต่อกับโปรเจ็กต์ของคุณ",slug:"ขั้นตอนต่อไป-เชื่อมต่อกับโปรเจ็กต์ของคุณ",normalizedTitle:"ขั้นตอนต่อไป - เชื่อมต่อกับโปรเจ็กต์ของคุณ",charIndex:3480},{level:2,title:"เพิ่มบัญชี GitHub Organization ในโปรเจ็กต์ SubQuery",slug:"เพิ่มบัญชี-github-organization-ในโปรเจ็กต์-subquery",normalizedTitle:"เพิ่มบัญชี github organization ในโปรเจ็กต์ subquery",charIndex:3893}],readingTime:{minutes:.99,words:297},headersStr:"ประโยชน์ในการโฮสต์โปรเจ็กต์ของคุณกับ SubQuery สร้างโปรเจ็กต์แรกของคุณ ขั้นตอนต่อไป - เชื่อมต่อกับโปรเจ็กต์ของคุณ เพิ่มบัญชี GitHub Organization ในโปรเจ็กต์ SubQuery",content:'# เผยแพร่โครงการ SubQuery ของคุณ\n\n\n# ประโยชน์ในการโฮสต์โปรเจ็กต์ของคุณกับ SubQuery\n\n * เราจะรันโปรเจ็กต์ SubQuery ให้กับคุณด้วยบริการที่มีประสิทธิภาพสูง สามารถปรับขนาดได้ และมีการจัดการแบบบริการสาธารณะ\n * บริการนี้มอบให้กับชุมชนฟรี!\n * คุณสามารถกำหนดให้โปรเจ็กต์ของคุณเป็นแบบสาธารณะเพื่อให้ลิสต์อยู่ใน SubQuery Explorer และทุกคนทั่วโลกสามารถดูได้\n * เราผสานรวมกับ GitHub ดังนั้นทุกคนใน GitHub organisations ของคุณจะสามารถดูโปรเจ็กต์ขององค์กรที่ใช้ร่วมกันได้\n\n\n# สร้างโปรเจ็กต์แรกของคุณ\n\n# เข้าสู่ระบบโปรเจ็กต์ SubQuery\n\nก่อนเริ่มต้น โปรดตรวจสอบให้แน่ใจว่าโปรเจ็กต์ SubQuery ของคุณออนไลน์อยู่ใน GitHub repository แบบสาธารณะ ไฟล์ schema.graphql ต้องอยู่ในรูทไดเร็กทอรีของคุณ\n\nในการสร้างโปรเจ็กต์แรกของคุณ ให้ไปที่ project.subquery.network คุณจะต้องตรวจสอบสิทธิ์ด้วยบัญชี GitHub ของคุณเพื่อเข้าสู่ระบบ\n\nในการเข้าสู่ระบบครั้งแรก คุณจะถูกขอให้ทำการ authorize แก่ SubQuery เราต้องการเพียงที่อยู่อีเมลของคุณเพื่อระบุบัญชีของคุณ และเราไม่ใช้ข้อมูลอื่นใดจากบัญชี GitHub ของคุณด้วยเหตุผลอื่นๆ ในขั้นตอนนี้ คุณยังสามารถขอหรือให้สิทธิ์การเข้าถึงบัญชี GitHub Organization ของคุณเพื่อโพสต์โปรเจ็กต์ SubQuery ภายใต้ GitHub Organization แทนบัญชีส่วนตัวของคุณ\n\n\n\nSubQuery Projects คือที่ที่คุณจัดการโปรเจ็กต์ที่โฮสต์อยู่ทั้งหมดของคุณ ที่อัปโหลดไปยังแพลตฟอร์ม SubQuery คุณสามารถสร้าง ลบ หรือแม้กระทั่งอัปเกรดโปรเจ็กต์ทั้งหมดจากแอปพลิเคชันนี้\n\n\n\nหากคุณมีบัญชี GitHub Organization ที่เชื่อมต่ออยู่ คุณสามารถใช้ switcher ที่ header เพื่อเปลี่ยนระหว่างบัญชีส่วนตัวและบัญชี GitHub Organization ได้ โปรเจ็กต์ที่สร้างในบัญชี GitHub Organization จะแชร์ระหว่างสมาชิกใน GitHub Organization นั้นๆ ในการเชื่อมต่อบัญชี GitHub Organization ของคุณ คุณสามารถทำตามขั้นตอนที่นี่\n\n\n\n# สร้างโปรเจ็กต์แรกของคุณ\n\nเริ่มต้นด้วยการคลิกที่ "Create Project" คุณจะถูกนำไปที่แบบฟอร์ม New Project โปรดป้อนข้อมูลต่อไปนี้ (คุณสามารถเปลี่ยนแปลงได้ในอนาคต):\n\n * บัญชี GitHub: หากคุณมีบัญชี GitHub มากกว่าหนึ่งบัญชี ให้เลือกบัญชีที่จะใช้สร้างโปรเจ็กต์นี้ โปรเจ็กต์ที่สร้างขึ้นในบัญชี GitHub organisation จะถูกแชร์ระหว่างสมาชิกใน organisation นั้นๆ\n * ชื่อ\n * ชื่อรอง (Subtitle)\n * คำอธิบาย\n * GitHub Repository URL: ต้องเป็น GitHub URL ที่ใช้งานได้ซึ่งชี้ไปยัง repositoryสาธารณะที่มีโปรเจ็กต์ SubQuery ของคุณ ไฟล์ schema.graphql ต้องอยู่ในรูทของไดเร็กทอรีของคุณ (เรียนรู้เพิ่มเติมเกี่ยวกับโครงสร้างไดเร็กทอรี)\n * Hide project: หากเลือก จะเป็นการซ่อนโปรเจ็กต์จาก SubQuery explorer สาธารณะ อย่าเลือกตัวเลือกนี้หากคุณต้องการแชร์ SubQuery ของคุณกับชุมชน!\n\nสร้างโปรเจ็กต์ของคุณ แล้วคุณจะเห็นในลิสต์รายการโปรเจ็กต์ SubQuery ของคุณ ใกล้แล้ว! เราแค่ต้องทำการ deploy เป็นเวอร์ชันใหม่\n\n\n\n# Deploy เวอร์ชันแรกของคุณ\n\nขณะสร้างโปรเจ็กต์จะมีการตั้งค่าลักษณะการแสดงผลของโปรเจ็กต์ คุณต้อง deploy เวอร์ชันของโปรเจ็กต์ก่อนที่จะดำเนินการได้ การ deploy เวอร์ชันจะเปิดการดำเนินการสร้าง SubQuery index ใหม่เพื่อเริ่มต้น และตั้งค่าบริการการสืบค้นที่จำเป็นเพื่อเริ่มยอมรับ GraphQL requests คุณยังสามารถ deploy เวอร์ชันใหม่กับโปรเจ็กต์ที่มีอยู่ได้ที่นี่\n\nที่โปรเจ็กต์ใหม่ของคุณนี้ คุณจะเห็นปุ่ม Deploy New Version ให้คลิกปุ่ม และกรอกข้อมูลที่จำเป็นเกี่ยวกับการ deploy:\n\n * Commit Hash of new Version: ให้คัดลอก commit hash แบบเต็มจากโค้ดโปรเจ็กต์ SubQuery ที่คุณต้องการ deploy จาก GitHub\n * Indexer Version: คือเวอร์ชันของ node service ของ SubQuery ที่คุณต้องการรัน SubQuery อ่าน @subql/node\n * Query Version: คือเวอร์ชันของ query service ของ SubQuery ที่คุณต้องการรัน SubQuery อ่าน @subql/query\n\n\n\nหาก deploy ได้สำเร็จ คุณจะเห็น indexer เริ่มทำงานและมีรายงานความคืบหน้าในการทำ indexing ของ chain ในปัจจุบัน ขั้นตอนนี้อาจใช้เวลาระยะหนึ่งจนกว่าจะถึง 100%\n\n\n# ขั้นตอนต่อไป - เชื่อมต่อกับโปรเจ็กต์ของคุณ\n\nเมื่อการ deploy ของคุณเสร็จสมบูรณ์ และ node ของเราได้ทำการ index ข้อมูลของคุณจาก chain แล้ว คุณจะสามารถเชื่อมต่อกับโปรเจ็กต์ผ่าน GraphQL Query endpoint ที่ปรากฎขึ้นมา\n\n\n\nหรือคุณสามารถคลิกที่จุดสามจุดถัดจากชื่อโปรเจ็กต์ของคุณ และดูใน SubQuery Explorer ซึ่งคุณสามารถใช้ Playground ในเบราว์เซอร์เพื่อเริ่มต้นได้ - อ่านเพิ่มเติมเกี่ยวกับวิธีใช้ Explorer ของเราที่นี่\n\n\n\n\n# เพิ่มบัญชี GitHub Organization ในโปรเจ็กต์ SubQuery\n\nเป็นเรื่องปกติที่จะเผยแพร่โปรเจ็กต์ SubQuery ภายใต้ชื่อบัญชี GitHub Organization ของคุณ แทนที่จะเป็นบัญชี GitHub ส่วนตัว คุณสามารถเปลี่ยนบัญชีที่เลือกในปัจจุบันของคุณใน SubQuery Projects ได้ทุกเมื่อโดยการใช้ account switcher\n\n\n\nหากคุณไม่เห็นบัญชี GitHub Organization ของคุณที่ switcher คุณอาจต้องให้สิทธิ์การเข้าถึง SubQuery สำหรับ GitHub Organization ของคุณ (หรือขอจากผู้ดูแลระบบ) ในการดำเนินการนี้ คุณจะต้องเพิกถอนการอนุญาตบัญชี GitHub ของคุณกับแอปพลิเคชัน SubQuery ก่อน ในการดำเนินการนี้ ให้เข้าสู่ระบบการตั้งค่าบัญชีของคุณใน GitHub ไปที่ Applications และภายใต้แท็บ Authorized OAuth Apps ให้เพิกถอน SubQuery - คุณสามารถทำตามขั้นตอนแบบละเอียดได้ที่นี่ อย่ากังวล การดำเนินการนี้จะไม่ลบโปรเจ็กต์ SubQuery ของคุณและคุณจะไม่สูญเสียข้อมูลใดๆ\n\n\n\nเมื่อคุณเพิกถอนการเข้าถึงแล้ว ให้ออกจากระบบ SubQuery Projects และกลับเข้าสู่ระบบใหม่อีกครั้ง คุณจะเข้าไปยังหน้าที่ชื่อว่า Authorize SubQuery ซึ่งคุณสามารถขอหรือให้สิทธิ์การเข้าถึง SubQuery กับบัญชี GitHub Organization ของคุณ หากคุณไม่มีสิทธิ์ของผู้ดูแลระบบ คุณต้องขอผู้ดูแลระบบเพื่อเปิดใช้งานสิ่งนี้ให้กับคุณ\n\n\n\nเมื่อคำขอนี้ได้รับการอนุมัติจากผู้ดูแลระบบของคุณ (หรือหากสามารถให้สิทธิ์เองได้) คุณจะเห็นบัญชี GitHub Organization ที่ถูกต้องใน account switcher',normalizedContent:'# เผยแพร่โครงการ subquery ของคุณ\n\n\n# ประโยชน์ในการโฮสต์โปรเจ็กต์ของคุณกับ subquery\n\n * เราจะรันโปรเจ็กต์ subquery ให้กับคุณด้วยบริการที่มีประสิทธิภาพสูง สามารถปรับขนาดได้ และมีการจัดการแบบบริการสาธารณะ\n * บริการนี้มอบให้กับชุมชนฟรี!\n * คุณสามารถกำหนดให้โปรเจ็กต์ของคุณเป็นแบบสาธารณะเพื่อให้ลิสต์อยู่ใน subquery explorer และทุกคนทั่วโลกสามารถดูได้\n * เราผสานรวมกับ github ดังนั้นทุกคนใน github organisations ของคุณจะสามารถดูโปรเจ็กต์ขององค์กรที่ใช้ร่วมกันได้\n\n\n# สร้างโปรเจ็กต์แรกของคุณ\n\n# เข้าสู่ระบบโปรเจ็กต์ subquery\n\nก่อนเริ่มต้น โปรดตรวจสอบให้แน่ใจว่าโปรเจ็กต์ subquery ของคุณออนไลน์อยู่ใน github repository แบบสาธารณะ ไฟล์ schema.graphql ต้องอยู่ในรูทไดเร็กทอรีของคุณ\n\nในการสร้างโปรเจ็กต์แรกของคุณ ให้ไปที่ project.subquery.network คุณจะต้องตรวจสอบสิทธิ์ด้วยบัญชี github ของคุณเพื่อเข้าสู่ระบบ\n\nในการเข้าสู่ระบบครั้งแรก คุณจะถูกขอให้ทำการ authorize แก่ subquery เราต้องการเพียงที่อยู่อีเมลของคุณเพื่อระบุบัญชีของคุณ และเราไม่ใช้ข้อมูลอื่นใดจากบัญชี github ของคุณด้วยเหตุผลอื่นๆ ในขั้นตอนนี้ คุณยังสามารถขอหรือให้สิทธิ์การเข้าถึงบัญชี github organization ของคุณเพื่อโพสต์โปรเจ็กต์ subquery ภายใต้ github organization แทนบัญชีส่วนตัวของคุณ\n\n\n\nsubquery projects คือที่ที่คุณจัดการโปรเจ็กต์ที่โฮสต์อยู่ทั้งหมดของคุณ ที่อัปโหลดไปยังแพลตฟอร์ม subquery คุณสามารถสร้าง ลบ หรือแม้กระทั่งอัปเกรดโปรเจ็กต์ทั้งหมดจากแอปพลิเคชันนี้\n\n\n\nหากคุณมีบัญชี github organization ที่เชื่อมต่ออยู่ คุณสามารถใช้ switcher ที่ header เพื่อเปลี่ยนระหว่างบัญชีส่วนตัวและบัญชี github organization ได้ โปรเจ็กต์ที่สร้างในบัญชี github organization จะแชร์ระหว่างสมาชิกใน github organization นั้นๆ ในการเชื่อมต่อบัญชี github organization ของคุณ คุณสามารถทำตามขั้นตอนที่นี่\n\n\n\n# สร้างโปรเจ็กต์แรกของคุณ\n\nเริ่มต้นด้วยการคลิกที่ "create project" คุณจะถูกนำไปที่แบบฟอร์ม new project โปรดป้อนข้อมูลต่อไปนี้ (คุณสามารถเปลี่ยนแปลงได้ในอนาคต):\n\n * บัญชี github: หากคุณมีบัญชี github มากกว่าหนึ่งบัญชี ให้เลือกบัญชีที่จะใช้สร้างโปรเจ็กต์นี้ โปรเจ็กต์ที่สร้างขึ้นในบัญชี github organisation จะถูกแชร์ระหว่างสมาชิกใน organisation นั้นๆ\n * ชื่อ\n * ชื่อรอง (subtitle)\n * คำอธิบาย\n * github repository url: ต้องเป็น github url ที่ใช้งานได้ซึ่งชี้ไปยัง repositoryสาธารณะที่มีโปรเจ็กต์ subquery ของคุณ ไฟล์ schema.graphql ต้องอยู่ในรูทของไดเร็กทอรีของคุณ (เรียนรู้เพิ่มเติมเกี่ยวกับโครงสร้างไดเร็กทอรี)\n * hide project: หากเลือก จะเป็นการซ่อนโปรเจ็กต์จาก subquery explorer สาธารณะ อย่าเลือกตัวเลือกนี้หากคุณต้องการแชร์ subquery ของคุณกับชุมชน!\n\nสร้างโปรเจ็กต์ของคุณ แล้วคุณจะเห็นในลิสต์รายการโปรเจ็กต์ subquery ของคุณ ใกล้แล้ว! เราแค่ต้องทำการ deploy เป็นเวอร์ชันใหม่\n\n\n\n# deploy เวอร์ชันแรกของคุณ\n\nขณะสร้างโปรเจ็กต์จะมีการตั้งค่าลักษณะการแสดงผลของโปรเจ็กต์ คุณต้อง deploy เวอร์ชันของโปรเจ็กต์ก่อนที่จะดำเนินการได้ การ deploy เวอร์ชันจะเปิดการดำเนินการสร้าง subquery index ใหม่เพื่อเริ่มต้น และตั้งค่าบริการการสืบค้นที่จำเป็นเพื่อเริ่มยอมรับ graphql requests คุณยังสามารถ deploy เวอร์ชันใหม่กับโปรเจ็กต์ที่มีอยู่ได้ที่นี่\n\nที่โปรเจ็กต์ใหม่ของคุณนี้ คุณจะเห็นปุ่ม deploy new version ให้คลิกปุ่ม และกรอกข้อมูลที่จำเป็นเกี่ยวกับการ deploy:\n\n * commit hash of new version: ให้คัดลอก commit hash แบบเต็มจากโค้ดโปรเจ็กต์ subquery ที่คุณต้องการ deploy จาก github\n * indexer version: คือเวอร์ชันของ node service ของ subquery ที่คุณต้องการรัน subquery อ่าน @subql/node\n * query version: คือเวอร์ชันของ query service ของ subquery ที่คุณต้องการรัน subquery อ่าน @subql/query\n\n\n\nหาก deploy ได้สำเร็จ คุณจะเห็น indexer เริ่มทำงานและมีรายงานความคืบหน้าในการทำ indexing ของ chain ในปัจจุบัน ขั้นตอนนี้อาจใช้เวลาระยะหนึ่งจนกว่าจะถึง 100%\n\n\n# ขั้นตอนต่อไป - เชื่อมต่อกับโปรเจ็กต์ของคุณ\n\nเมื่อการ deploy ของคุณเสร็จสมบูรณ์ และ node ของเราได้ทำการ index ข้อมูลของคุณจาก chain แล้ว คุณจะสามารถเชื่อมต่อกับโปรเจ็กต์ผ่าน graphql query endpoint ที่ปรากฎขึ้นมา\n\n\n\nหรือคุณสามารถคลิกที่จุดสามจุดถัดจากชื่อโปรเจ็กต์ของคุณ และดูใน subquery explorer ซึ่งคุณสามารถใช้ playground ในเบราว์เซอร์เพื่อเริ่มต้นได้ - อ่านเพิ่มเติมเกี่ยวกับวิธีใช้ explorer ของเราที่นี่\n\n\n\n\n# เพิ่มบัญชี github organization ในโปรเจ็กต์ subquery\n\nเป็นเรื่องปกติที่จะเผยแพร่โปรเจ็กต์ subquery ภายใต้ชื่อบัญชี github organization ของคุณ แทนที่จะเป็นบัญชี github ส่วนตัว คุณสามารถเปลี่ยนบัญชีที่เลือกในปัจจุบันของคุณใน subquery projects ได้ทุกเมื่อโดยการใช้ account switcher\n\n\n\nหากคุณไม่เห็นบัญชี github organization ของคุณที่ switcher คุณอาจต้องให้สิทธิ์การเข้าถึง subquery สำหรับ github organization ของคุณ (หรือขอจากผู้ดูแลระบบ) ในการดำเนินการนี้ คุณจะต้องเพิกถอนการอนุญาตบัญชี github ของคุณกับแอปพลิเคชัน subquery ก่อน ในการดำเนินการนี้ ให้เข้าสู่ระบบการตั้งค่าบัญชีของคุณใน github ไปที่ applications และภายใต้แท็บ authorized oauth apps ให้เพิกถอน subquery - คุณสามารถทำตามขั้นตอนแบบละเอียดได้ที่นี่ อย่ากังวล การดำเนินการนี้จะไม่ลบโปรเจ็กต์ subquery ของคุณและคุณจะไม่สูญเสียข้อมูลใดๆ\n\n\n\nเมื่อคุณเพิกถอนการเข้าถึงแล้ว ให้ออกจากระบบ subquery projects และกลับเข้าสู่ระบบใหม่อีกครั้ง คุณจะเข้าไปยังหน้าที่ชื่อว่า authorize subquery ซึ่งคุณสามารถขอหรือให้สิทธิ์การเข้าถึง subquery กับบัญชี github organization ของคุณ หากคุณไม่มีสิทธิ์ของผู้ดูแลระบบ คุณต้องขอผู้ดูแลระบบเพื่อเปิดใช้งานสิ่งนี้ให้กับคุณ\n\n\n\nเมื่อคำขอนี้ได้รับการอนุมัติจากผู้ดูแลระบบของคุณ (หรือหากสามารถให้สิทธิ์เองได้) คุณจะเห็นบัญชี github organization ที่ถูกต้องใน account switcher',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Deploy โปรเจ็กต์ SubQuery เวอร์ชั่นใหม่ของคุณ",frontmatter:{summary:"Deploy โปรเจ็กต์ SubQuery เวอร์ชั่นใหม่ของคุณ Guidelines แม้ว่าคุณจะมีอิสระในการอัปเกรดและ deploy เวอร์ชันใหม่โปรเจ็กต์ SubQuery ของคุณได้ตลอดเวลา แต่โปรดเอาใจใส่กระบวนการนี้หากโปร",meta:[{property:"og:url",content:"/th/publish/upgrade.html"},{property:"og:title",content:"Deploy โปรเจ็กต์ SubQuery เวอร์ชั่นใหม่ของคุณ"},{property:"og:description",content:"Deploy โปรเจ็กต์ SubQuery เวอร์ชั่นใหม่ของคุณ Guidelines แม้ว่าคุณจะมีอิสระในการอัปเกรดและ deploy เวอร์ชันใหม่โปรเจ็กต์ SubQuery ของคุณได้ตลอดเวลา แต่โปรดเอาใจใส่กระบวนการนี้หากโปร"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/publish/upgrade.html",relativePath:"th/publish/upgrade.md",key:"v-2de3a717",path:"/th/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy การเปลี่ยนแปลง",slug:"deploy-การเปลี่ยนแปลง",normalizedTitle:"deploy การเปลี่ยนแปลง",charIndex:602},{level:2,title:"ขั้นตอนต่อไป - เชื่อมต่อกับโปรเจ็กต์ของคุณ",slug:"ขั้นตอนต่อไป-เชื่อมต่อกับโปรเจ็กต์ของคุณ",normalizedTitle:"ขั้นตอนต่อไป - เชื่อมต่อกับโปรเจ็กต์ของคุณ",charIndex:2248}],readingTime:{minutes:.45,words:134},headersStr:"Guidelines Deploy การเปลี่ยนแปลง ขั้นตอนต่อไป - เชื่อมต่อกับโปรเจ็กต์ของคุณ",content:"# Deploy โปรเจ็กต์ SubQuery เวอร์ชั่นใหม่ของคุณ\n\n\n# Guidelines\n\nแม้ว่าคุณจะมีอิสระในการอัปเกรดและ deploy เวอร์ชันใหม่โปรเจ็กต์ SubQuery ของคุณได้ตลอดเวลา แต่โปรดเอาใจใส่กระบวนการนี้หากโปรเจ็กต์ SubQuery ของคุณเป็นแบบสาธารณะที่ทุกคนสามารถเข้าถึงได้ ประเด็นสำคัญที่ควรทราบ:\n\n * หากการอัปเกรดของคุณเป็นการเปลี่ยนแปลงครั้งใหญ่ ให้สร้างโปรเจ็กต์ใหม่ (เช่น My SubQuery Project V2) หรือให้ชุมชนของคุณรับทราบถึงการเปลี่ยนแปลงมากมายผ่านช่องทางโซเชียลมีเดีย\n * การ deploy โปรเจ็กต์ SubQuery เวอร์ชั่นใหม่ ส่งผลให้เกิดการ down time เนื่องจากเวอร์ชันใหม่ต้อง index ข้อมูล chain ทั้งหมดทั้งหมดจาก genesis block\n\n\n# Deploy การเปลี่ยนแปลง\n\nเข้าสู่ระบบ SubQuery Project และเลือกโปรเจ็กต์ที่คุณต้องการ deploy เวอร์ชันใหม่ คุณสามารถเลือกที่จะ deploy ไปยัง production slot หรือ staging slot โดย slot ทั้งสองนี้เป็นสภาพแวดล้อมที่แยกออกจากกัน และแต่ละ slot มีฐานข้อมูลของตนเองและมีการ synchronise อย่างอิสระ\n\nเราแนะนำให้ deploy ไปยัง staging slot ของคุณสำหรับการทดสอบขั้นสุดท้ายเท่านั้น หรือเมื่อคุณต้องการซิงค์ข้อมูลโปรเจ็กต์ของคุณอีกครั้ง จากนั้นคุณสามารถปรับเป็นเวอร์ชัน production โดยไม่มี downtime คุณจะพบว่าการทดสอบเร็วขึ้นเมื่อ รันโปรเจ็กต์ในเครื่อง เนื่องจากคุณสามารถ debug ปัญหาต่างๆได้ง่ายขึ้น\n\nStaging slot เหมาะสำหรับ:\n\n * การตรวจสอบครั้งสุดท้ายของการเปลี่ยนแปลงในโปรเจ็กต์ SubQuery ในสภาพแวดล้อมที่แยกจากกัน staging slot มี URL ที่แตกต่างไปจากการ production ที่คุณสามารถใช้ได้ใน dApps ของคุณ\n * การวอร์มอัพและทำ index ข้อมูลสำหรับโปรเจ็กต์ SubQuery ที่อัปเดต โดยไม่ต้องหยุดการทำงานของ dApp ของคุณ\n * การเตรียม new release สำหรับโครงการ SubQuery ของคุณโดยไม่เปิดเผยต่อสาธารณะ staging slot จะไม่ปรากฏต่อสาธารณะใน Explorer และมี URL เฉพาะที่มองเห็นได้เฉพาะคุณเท่านั้น\n\n\n\n# อัปเกรด Indexer และ Query Service ล่าสุด\n\nหากคุณต้องการอัปเกรด indexer (@subql/node) หรือ query service (@subql/query) เป็นตัวล่าสุด เพื่อใช้ประโยชน์จากการปรับปรุงประสิทธิภาพและความเสถียร เพียงเลือกแพ็คเกจเวอร์ชันใหม่กว่าของเราแล้วบันทึก ซึ่งจะทำให้เกิดการ downtime เพียงไม่กี่นาที\n\n# Deploy SubQuery Project เวอร์ชันใหม่ของคุณ\n\nกรอก Commit Hash จาก GitHub (คัดลอก commit hash แบบเต็ม) ของโค้ดโปรเจ็กต์ SubQuery เวอร์ชั่นที่คุณต้องการ deploy ซึ่งจะทำให้มี downtime นานขึ้น ซึ่งขึ้นอยู่กับเวลาที่ใช้ในการจัดทำ index ข้อมูลของเชนปัจจุบัน You can always report back here for progress.\n\n\n# ขั้นตอนต่อไป - เชื่อมต่อกับโปรเจ็กต์ของคุณ\n\nเมื่อการ deploy ของคุณเสร็จสมบูรณ์ และ node ของเราได้ทำการ index ข้อมูลของคุณจาก chain แล้ว คุณจะสามารถเชื่อมต่อกับโปรเจ็กต์ผ่าน GraphQL Query endpoint ที่ปรากฎขึ้นมา\n\n\n\nหรือคุณสามารถคลิกที่จุดสามจุดถัดจากชื่อโปรเจ็กต์ของคุณ และดูใน SubQuery Explorer คุณสามารถใช้ Playground ในเบราว์เซอร์เพื่อเริ่มต้นได้ - อ่านเพิ่มเติมเกี่ยวกับวิธีใช้ Explorer ของเราที่นี่",normalizedContent:"# deploy โปรเจ็กต์ subquery เวอร์ชั่นใหม่ของคุณ\n\n\n# guidelines\n\nแม้ว่าคุณจะมีอิสระในการอัปเกรดและ deploy เวอร์ชันใหม่โปรเจ็กต์ subquery ของคุณได้ตลอดเวลา แต่โปรดเอาใจใส่กระบวนการนี้หากโปรเจ็กต์ subquery ของคุณเป็นแบบสาธารณะที่ทุกคนสามารถเข้าถึงได้ ประเด็นสำคัญที่ควรทราบ:\n\n * หากการอัปเกรดของคุณเป็นการเปลี่ยนแปลงครั้งใหญ่ ให้สร้างโปรเจ็กต์ใหม่ (เช่น my subquery project v2) หรือให้ชุมชนของคุณรับทราบถึงการเปลี่ยนแปลงมากมายผ่านช่องทางโซเชียลมีเดีย\n * การ deploy โปรเจ็กต์ subquery เวอร์ชั่นใหม่ ส่งผลให้เกิดการ down time เนื่องจากเวอร์ชันใหม่ต้อง index ข้อมูล chain ทั้งหมดทั้งหมดจาก genesis block\n\n\n# deploy การเปลี่ยนแปลง\n\nเข้าสู่ระบบ subquery project และเลือกโปรเจ็กต์ที่คุณต้องการ deploy เวอร์ชันใหม่ คุณสามารถเลือกที่จะ deploy ไปยัง production slot หรือ staging slot โดย slot ทั้งสองนี้เป็นสภาพแวดล้อมที่แยกออกจากกัน และแต่ละ slot มีฐานข้อมูลของตนเองและมีการ synchronise อย่างอิสระ\n\nเราแนะนำให้ deploy ไปยัง staging slot ของคุณสำหรับการทดสอบขั้นสุดท้ายเท่านั้น หรือเมื่อคุณต้องการซิงค์ข้อมูลโปรเจ็กต์ของคุณอีกครั้ง จากนั้นคุณสามารถปรับเป็นเวอร์ชัน production โดยไม่มี downtime คุณจะพบว่าการทดสอบเร็วขึ้นเมื่อ รันโปรเจ็กต์ในเครื่อง เนื่องจากคุณสามารถ debug ปัญหาต่างๆได้ง่ายขึ้น\n\nstaging slot เหมาะสำหรับ:\n\n * การตรวจสอบครั้งสุดท้ายของการเปลี่ยนแปลงในโปรเจ็กต์ subquery ในสภาพแวดล้อมที่แยกจากกัน staging slot มี url ที่แตกต่างไปจากการ production ที่คุณสามารถใช้ได้ใน dapps ของคุณ\n * การวอร์มอัพและทำ index ข้อมูลสำหรับโปรเจ็กต์ subquery ที่อัปเดต โดยไม่ต้องหยุดการทำงานของ dapp ของคุณ\n * การเตรียม new release สำหรับโครงการ subquery ของคุณโดยไม่เปิดเผยต่อสาธารณะ staging slot จะไม่ปรากฏต่อสาธารณะใน explorer และมี url เฉพาะที่มองเห็นได้เฉพาะคุณเท่านั้น\n\n\n\n# อัปเกรด indexer และ query service ล่าสุด\n\nหากคุณต้องการอัปเกรด indexer (@subql/node) หรือ query service (@subql/query) เป็นตัวล่าสุด เพื่อใช้ประโยชน์จากการปรับปรุงประสิทธิภาพและความเสถียร เพียงเลือกแพ็คเกจเวอร์ชันใหม่กว่าของเราแล้วบันทึก ซึ่งจะทำให้เกิดการ downtime เพียงไม่กี่นาที\n\n# deploy subquery project เวอร์ชันใหม่ของคุณ\n\nกรอก commit hash จาก github (คัดลอก commit hash แบบเต็ม) ของโค้ดโปรเจ็กต์ subquery เวอร์ชั่นที่คุณต้องการ deploy ซึ่งจะทำให้มี downtime นานขึ้น ซึ่งขึ้นอยู่กับเวลาที่ใช้ในการจัดทำ index ข้อมูลของเชนปัจจุบัน you can always report back here for progress.\n\n\n# ขั้นตอนต่อไป - เชื่อมต่อกับโปรเจ็กต์ของคุณ\n\nเมื่อการ deploy ของคุณเสร็จสมบูรณ์ และ node ของเราได้ทำการ index ข้อมูลของคุณจาก chain แล้ว คุณจะสามารถเชื่อมต่อกับโปรเจ็กต์ผ่าน graphql query endpoint ที่ปรากฎขึ้นมา\n\n\n\nหรือคุณสามารถคลิกที่จุดสามจุดถัดจากชื่อโปรเจ็กต์ของคุณ และดูใน subquery explorer คุณสามารถใช้ playground ในเบราว์เซอร์เพื่อเริ่มต้นได้ - อ่านเพิ่มเติมเกี่ยวกับวิธีใช้ explorer ของเราที่นี่",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"เรียนรู้เพิ่มเติมเกี่ยวกับ GraphQL",frontmatter:{summary:"เรียนรู้เพิ่มเติมเกี่ยวกับ GraphQL คุณสามารถทำตาม คู่มือ GraphQL อย่างเป็นทางการที่นี่ เพื่อเรียนรู้เพิ่มเติมเกี่ยวกับ GraphQL วิธีการทำงาน และวิธีใช้งาน: มีไลบรารี่ที่จะช่วยคุณใช้",meta:[{property:"og:url",content:"/th/query/graphql.html"},{property:"og:title",content:"เรียนรู้เพิ่มเติมเกี่ยวกับ GraphQL"},{property:"og:description",content:"เรียนรู้เพิ่มเติมเกี่ยวกับ GraphQL คุณสามารถทำตาม คู่มือ GraphQL อย่างเป็นทางการที่นี่ เพื่อเรียนรู้เพิ่มเติมเกี่ยวกับ GraphQL วิธีการทำงาน และวิธีใช้งาน: มีไลบรารี่ที่จะช่วยคุณใช้"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/query/graphql.html",relativePath:"th/query/graphql.md",key:"v-53b2904b",path:"/th/query/graphql/",readingTime:{minutes:.1,words:31},headersStr:null,content:"# เรียนรู้เพิ่มเติมเกี่ยวกับ GraphQL\n\nคุณสามารถทำตาม คู่มือ GraphQL อย่างเป็นทางการที่นี่ เพื่อเรียนรู้เพิ่มเติมเกี่ยวกับ GraphQL วิธีการทำงาน และวิธีใช้งาน:\n\n * มีไลบรารี่ที่จะช่วยคุณใช้งาน GraphQL ใน ภาษาต่างๆ มากมาย\n * สำหรับประสบการณ์การเรียนรู้เชิงลึกพร้อมบทช่วยสอนเชิงปฏิบัติ โปรดดูที่ วิธีสร้าง GraphQL\n * ดูหลักสูตรออนไลน์ฟรี การสำรวจ GraphQL: ภาษาการสืบค้นสำหรับ API",normalizedContent:"# เรียนรู้เพิ่มเติมเกี่ยวกับ graphql\n\nคุณสามารถทำตาม คู่มือ graphql อย่างเป็นทางการที่นี่ เพื่อเรียนรู้เพิ่มเติมเกี่ยวกับ graphql วิธีการทำงาน และวิธีใช้งาน:\n\n * มีไลบรารี่ที่จะช่วยคุณใช้งาน graphql ใน ภาษาต่างๆ มากมาย\n * สำหรับประสบการณ์การเรียนรู้เชิงลึกพร้อมบทช่วยสอนเชิงปฏิบัติ โปรดดูที่ วิธีสร้าง graphql\n * ดูหลักสูตรออนไลน์ฟรี การสำรวจ graphql: ภาษาการสืบค้นสำหรับ api",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"สืบค้นโปรเจ็กต์ของคุณใน SubQuery Explorer",frontmatter:{summary:"สืบค้นโปรเจ็กต์ของคุณใน SubQuery Explorer SubQuery Explorer เป็นบริการออนไลน์ (explorer.subquery.network) ให้บริการการเข้าถึงโครงการ SubQuery ซึ่งเผยแพร่โดยผู้ร่วมให้ข้อมูลในชุมชนข",meta:[{property:"og:url",content:"/th/query/query.html"},{property:"og:title",content:"สืบค้นโปรเจ็กต์ของคุณใน SubQuery Explorer"},{property:"og:description",content:"สืบค้นโปรเจ็กต์ของคุณใน SubQuery Explorer SubQuery Explorer เป็นบริการออนไลน์ (explorer.subquery.network) ให้บริการการเข้าถึงโครงการ SubQuery ซึ่งเผยแพร่โดยผู้ร่วมให้ข้อมูลในชุมชนข"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/query/query.html",relativePath:"th/query/query.md",key:"v-1ff7e666",path:"/th/query/query/",readingTime:{minutes:.29,words:88},headersStr:null,content:"# สืบค้นโปรเจ็กต์ของคุณใน SubQuery Explorer\n\nSubQuery Explorer เป็นบริการออนไลน์ (explorer.subquery.network) ให้บริการการเข้าถึงโครงการ SubQuery ซึ่งเผยแพร่โดยผู้ร่วมให้ข้อมูลในชุมชนของเราและถูกจัดการโดยทีม SubQuery คุณสามารถเผยแพร่โครงการ SubQuery ของคุณเองให้กับ explorer ของเราโดยทำตามคำแนะนำของเราในการ เผยแพร่โครงการ SubQuery ของคุณ\n\n\n\nSubQuery explorer ทำให้การเริ่มต้นใช้งานเป็นเรื่องง่าย เรากำลังโฮสต์โปรเจ็กต์ SubQuery เหล่านี้แบบออนไลน์ และอนุญาตให้ทุกคน query แต่ละโปรเจ็กต์ได้ฟรี โหนดที่มีการจัดการเหล่านี้จะได้รับการตรวจสอบและรันโดยทีม SubQuery ในระดับประสิทธิภาพที่จะอนุญาตให้แอปที่ใช้งานจริงใช้และสามารถพึ่งพาได้\n\n\n\nนอกจากนี้ คุณควรทราบด้วยว่า SubQuery Explorer มี playground สำหรับการค้นหาข้อมูลที่มีอยู่ พร้อมด้วยตัวอย่างการสืบค้น - คุณสามารถทดสอบการสืบค้นโดยตรงในเบราว์เซอร์ของคุณโดยไม่ต้องเขียนโค้ด นอกจากนี้ เราได้ทำการปรับปรุงเล็กน้อยในเอกสารของเรา เพื่อสนับสนุนนักพัฒนาในเส้นทางการค้นหาที่ดีขึ้นและวิเคราะห์ข้อมูล Polkadot ของโลกได้ดียิ่งขึ้น\n\nที่ด้านบนขวาของ Playground คุณจะพบปุ่ม เอกสาร ที่จะเปิดการสร้างเอกสาร เอกสารนี้สร้างขึ้นโดยอัตโนมัติและช่วยให้คุณค้นหา entities และ methods ที่คุณสามารถค้นหาได้ ในตัวอย่างด้านล่าง เราใช้ Sum Rewards SubQuery เพื่อให้ได้บัญชีที่มีรางวัลมากที่สุด 5 อันดับแรก (ในแง่ของรายได้จากการ stake) บน Polkadot ที่ไม่เคยถูก slash มาก่อน\n\n\n\nเรียนรู้เพิ่มเติมเกี่ยวกับภาษา GraphQL Query",normalizedContent:"# สืบค้นโปรเจ็กต์ของคุณใน subquery explorer\n\nsubquery explorer เป็นบริการออนไลน์ (explorer.subquery.network) ให้บริการการเข้าถึงโครงการ subquery ซึ่งเผยแพร่โดยผู้ร่วมให้ข้อมูลในชุมชนของเราและถูกจัดการโดยทีม subquery คุณสามารถเผยแพร่โครงการ subquery ของคุณเองให้กับ explorer ของเราโดยทำตามคำแนะนำของเราในการ เผยแพร่โครงการ subquery ของคุณ\n\n\n\nsubquery explorer ทำให้การเริ่มต้นใช้งานเป็นเรื่องง่าย เรากำลังโฮสต์โปรเจ็กต์ subquery เหล่านี้แบบออนไลน์ และอนุญาตให้ทุกคน query แต่ละโปรเจ็กต์ได้ฟรี โหนดที่มีการจัดการเหล่านี้จะได้รับการตรวจสอบและรันโดยทีม subquery ในระดับประสิทธิภาพที่จะอนุญาตให้แอปที่ใช้งานจริงใช้และสามารถพึ่งพาได้\n\n\n\nนอกจากนี้ คุณควรทราบด้วยว่า subquery explorer มี playground สำหรับการค้นหาข้อมูลที่มีอยู่ พร้อมด้วยตัวอย่างการสืบค้น - คุณสามารถทดสอบการสืบค้นโดยตรงในเบราว์เซอร์ของคุณโดยไม่ต้องเขียนโค้ด นอกจากนี้ เราได้ทำการปรับปรุงเล็กน้อยในเอกสารของเรา เพื่อสนับสนุนนักพัฒนาในเส้นทางการค้นหาที่ดีขึ้นและวิเคราะห์ข้อมูล polkadot ของโลกได้ดียิ่งขึ้น\n\nที่ด้านบนขวาของ playground คุณจะพบปุ่ม เอกสาร ที่จะเปิดการสร้างเอกสาร เอกสารนี้สร้างขึ้นโดยอัตโนมัติและช่วยให้คุณค้นหา entities และ methods ที่คุณสามารถค้นหาได้ ในตัวอย่างด้านล่าง เราใช้ sum rewards subquery เพื่อให้ได้บัญชีที่มีรางวัลมากที่สุด 5 อันดับแรก (ในแง่ของรายได้จากการ stake) บน polkadot ที่ไม่เคยถูก slash มาก่อน\n\n\n\nเรียนรู้เพิ่มเติมเกี่ยวกับภาษา graphql query",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (โฮสต์บน SubQuery)",frontmatter:{summary:"Hello World (โฮสต์บน SubQuery) จุดมุ่งหมายของ quick start นี้คือการแสดงวิธีการเริ่มใช้งานโปรเจ็กต์เริ่มต้นสำหรับทำงานใน SubQuery Projects (บริการของเรา) ด้วยไม่กี่ขั้นตอนง่ายๆ เราจ",meta:[{property:"og:url",content:"/th/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (โฮสต์บน SubQuery)"},{property:"og:description",content:"Hello World (โฮสต์บน SubQuery) จุดมุ่งหมายของ quick start นี้คือการแสดงวิธีการเริ่มใช้งานโปรเจ็กต์เริ่มต้นสำหรับทำงานใน SubQuery Projects (บริการของเรา) ด้วยไม่กี่ขั้นตอนง่ายๆ เราจ"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/quickstart/helloworld-hosted.html",relativePath:"th/quickstart/helloworld-hosted.md",key:"v-69c2fde6",path:"/th/quickstart/helloworld-hosted/",headers:[{level:2,title:"วัตถุประสงค์การเรียนรู้",slug:"วัตถุประสงค์การเรียนรู้",normalizedTitle:"วัตถุประสงค์การเรียนรู้",charIndex:476},{level:2,title:"กลุ่มเป้าหมาย",slug:"กลุ่มเป้าหมาย",normalizedTitle:"กลุ่มเป้าหมาย",charIndex:819},{level:2,title:"คู่มือวิดีโอ",slug:"คู่มือวิดีโอ",normalizedTitle:"คู่มือวิดีโอ",charIndex:963},{level:2,title:"ข้อกำหนดเบื้องต้น",slug:"ข้อกําหนดเบื้องต้น",normalizedTitle:"ข้อกำหนดเบื้องต้น",charIndex:551},{level:2,title:"1. สร้างโปรเจ็กต์ของคุณ",slug:"_1-สร้างโปรเจ็กต์ของคุณ",normalizedTitle:"1. สร้างโปรเจ็กต์ของคุณ",charIndex:1033},{level:2,title:"2. สร้าง GitHub repo",slug:"_2-สร้าง-github-repo",normalizedTitle:"2. สร้าง github repo",charIndex:1294},{level:2,title:"3. Push to GitHub",slug:"_3-push-to-github",normalizedTitle:"3. push to github",charIndex:1544},{level:2,title:"4. Create your project",slug:"_4-create-your-project",normalizedTitle:"4. create your project",charIndex:3288},{level:2,title:"5. Deploy your project",slug:"_5-deploy-your-project",normalizedTitle:"5. deploy your project",charIndex:4501},{level:2,title:"6. Testing your project",slug:"_6-testing-your-project",normalizedTitle:"6. testing your project",charIndex:6010},{level:2,title:"7. Bonus step",slug:"_7-bonus-step",normalizedTitle:"7. bonus step",charIndex:6253},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7705}],readingTime:{minutes:4.11,words:1234},headersStr:"วัตถุประสงค์การเรียนรู้ กลุ่มเป้าหมาย คู่มือวิดีโอ ข้อกำหนดเบื้องต้น 1. สร้างโปรเจ็กต์ของคุณ 2. สร้าง GitHub repo 3. Push to GitHub 4. Create your project 5. Deploy your project 6. Testing your project 7. Bonus step Summary",content:'# Hello World (โฮสต์บน SubQuery)\n\nจุดมุ่งหมายของ quick start นี้คือการแสดงวิธีการเริ่มใช้งานโปรเจ็กต์เริ่มต้นสำหรับทำงานใน SubQuery Projects (บริการของเรา) ด้วยไม่กี่ขั้นตอนง่ายๆ\n\nเราจะใช้ starter project ที่เรียบง่ายนี้ (รวมถึงทุกอย่างที่เราได้เรียนรู้มาจนถึงตอนนี้) แต่แทนที่จะเรียกใช้ Docker เราจะใช้ประโยชน์จากโครงสร้างพื้นฐานของโฮสติ้งที่มีการจัดการโดย SubQuery กล่าวอีกนัยหนึ่ง เราให้ SubQuery จัดการโครงสร้างพื้นฐานของงาน production การรัน และจัดการงานหนักๆทั้งหมด\n\n\n# วัตถุประสงค์การเรียนรู้\n\nเมื่อจบจาก quick start นี้ คุณจะ:\n\n * ทำความเข้าใจข้อกำหนดเบื้องต้นที่จำเป็น\n * สามารถโฮสต์โปรเจ็กต์ใน SubQuery Projects ได้\n * รัน query อย่างง่ายเพื่อ get ค่า block height ของเครือข่าย Polkadot mainnet โดยใช้ Playground\n * รัน GET query อย่างง่ายเพื่อขอค่า block height ของเครือข่าย Polkadot mainnet โดยใช้ cURL\n\n\n# กลุ่มเป้าหมาย\n\nคู่มือนี้จัดทำขึ้นสำหรับนักพัฒนาหน้าใหม่ที่มีประสบการณ์ด้านการพัฒนามาบ้างแล้วและสนใจที่จะเรียนรู้เพิ่มเติมเกี่ยวกับ SubQuery\n\n\n# คู่มือวิดีโอ\n\n\n# ข้อกำหนดเบื้องต้น\n\nคุณจะต้องมี:\n\n * บัญชี GitHub\n\n\n# 1. สร้างโปรเจ็กต์ของคุณ\n\nเริ่มสร้างโปรเจ็กต์ชื่อ subql_hellowworld และรันการติดตั้ง codegen และทำการ build ด้วยตัวจัดการแพ็คเกจที่คุณชื่นชอบ\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nอย่ารันโดยใช้คำสั่ง docker\n\n\n# 2. สร้าง GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# 3. Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# 4. Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# 5. Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# 6. Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# 7. Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (โฮสต์บน subquery)\n\nจุดมุ่งหมายของ quick start นี้คือการแสดงวิธีการเริ่มใช้งานโปรเจ็กต์เริ่มต้นสำหรับทำงานใน subquery projects (บริการของเรา) ด้วยไม่กี่ขั้นตอนง่ายๆ\n\nเราจะใช้ starter project ที่เรียบง่ายนี้ (รวมถึงทุกอย่างที่เราได้เรียนรู้มาจนถึงตอนนี้) แต่แทนที่จะเรียกใช้ docker เราจะใช้ประโยชน์จากโครงสร้างพื้นฐานของโฮสติ้งที่มีการจัดการโดย subquery กล่าวอีกนัยหนึ่ง เราให้ subquery จัดการโครงสร้างพื้นฐานของงาน production การรัน และจัดการงานหนักๆทั้งหมด\n\n\n# วัตถุประสงค์การเรียนรู้\n\nเมื่อจบจาก quick start นี้ คุณจะ:\n\n * ทำความเข้าใจข้อกำหนดเบื้องต้นที่จำเป็น\n * สามารถโฮสต์โปรเจ็กต์ใน subquery projects ได้\n * รัน query อย่างง่ายเพื่อ get ค่า block height ของเครือข่าย polkadot mainnet โดยใช้ playground\n * รัน get query อย่างง่ายเพื่อขอค่า block height ของเครือข่าย polkadot mainnet โดยใช้ curl\n\n\n# กลุ่มเป้าหมาย\n\nคู่มือนี้จัดทำขึ้นสำหรับนักพัฒนาหน้าใหม่ที่มีประสบการณ์ด้านการพัฒนามาบ้างแล้วและสนใจที่จะเรียนรู้เพิ่มเติมเกี่ยวกับ subquery\n\n\n# คู่มือวิดีโอ\n\n\n# ข้อกำหนดเบื้องต้น\n\nคุณจะต้องมี:\n\n * บัญชี github\n\n\n# 1. สร้างโปรเจ็กต์ของคุณ\n\nเริ่มสร้างโปรเจ็กต์ชื่อ subql_hellowworld และรันการติดตั้ง codegen และทำการ build ด้วยตัวจัดการแพ็คเกจที่คุณชื่นชอบ\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nอย่ารันโดยใช้คำสั่ง docker\n\n\n# 2. สร้าง github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# 3. push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# 4. create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# 5. deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# 6. testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# 7. bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/th/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/quickstart/helloworld-localhost.html",relativePath:"th/quickstart/helloworld-localhost.md",key:"v-06bb2662",path:"/th/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"1. Initialise project",slug:"_1-initialise-project",normalizedTitle:"1. initialise project",charIndex:1455},{level:2,title:"2. Install dependencies",slug:"_2-install-dependencies",normalizedTitle:"2. install dependencies",charIndex:2030},{level:2,title:"3. Generate code",slug:"_3-generate-code",normalizedTitle:"3. generate code",charIndex:2465},{level:2,title:"4. Build code",slug:"_4-build-code",normalizedTitle:"4. build code",charIndex:3068},{level:2,title:"5. Run Docker",slug:"_5-run-docker",normalizedTitle:"5. run docker",charIndex:3293},{level:2,title:"6. Browse playground",slug:"_6-browse-playground",normalizedTitle:"6. browse playground",charIndex:4555},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:4991}],readingTime:{minutes:2.93,words:879},headersStr:"Learning objectives Intended audience Video guide Pre-requisites 1. Initialise project 2. Install dependencies 3. Generate code 4. Build code 5. Run Docker 6. Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# 1. Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# 2. Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n```shell yarn install ``` ```bash npm install ```\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 3. Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n```shell yarn codegen ``` ```bash npm run-script codegen ```\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# 4. Build code\n\nThe next step is to build the code with yarn build.\n\n```shell yarn build ``` ```bash npm run-script build ```\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# 5. Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 6. Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# 1. initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# 2. install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n```shell yarn install ``` ```bash npm install ```\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 3. generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n```shell yarn codegen ``` ```bash npm run-script codegen ```\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# 4. build code\n\nthe next step is to build the code with yarn build.\n\n```shell yarn build ``` ```bash npm run-script build ```\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# 5. run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 6. browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/th/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/quickstart/quickstart.html",relativePath:"th/quickstart/quickstart.md",key:"v-52ce73b1",path:"/th/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2575},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3018},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3395},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3633},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3986},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4553},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5240}],readingTime:{minutes:3.33,words:999},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\n```shell cd PROJECT_NAME yarn install ``` ```bash cd PROJECT_NAME npm install ```\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n```shell yarn codegen ``` ```bash npm run-script codegen ```\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n```shell yarn build ``` ```bash npm run-script build ```\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\n```shell cd project_name yarn install ``` ```bash cd project_name npm install ```\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n```shell yarn codegen ``` ```bash npm run-script codegen ```\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n```shell yarn build ``` ```bash npm run-script build ```\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/th/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/quickstart/understanding-helloworld.html",relativePath:"th/quickstart/understanding-helloworld.md",key:"v-38028849",path:"/th/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/th/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/run/run.html",relativePath:"th/run/run.md",key:"v-4c7bdb41",path:"/th/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:6013},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:6256}],readingTime:{minutes:3.54,words:1063},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:'# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don\'t want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won\'t need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you\'ll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Use a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we\'ve seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\nRead more about how a SubQuery Dictionary works.\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Run in local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n# Check your node health\n\nThere are 2 endpoints that you can use to check and monitor the health of a running SubQuery node.\n\n * Health check endpoint that returns a simple 200 response\n * Metadata endpoint that includes additional analytics of your running SubQuery node\n\nAppend this to the base URL of your SubQuery node. Eg http://localhost:3000/meta will return:\n\n{\n    "currentProcessingHeight": 1000699,\n    "currentProcessingTimestamp": 1631517883547,\n    "targetHeight": 6807295,\n    "bestHeight": 6807298,\n    "indexerNodeVersion": "0.19.1",\n    "lastProcessedHeight": 1000699,\n    "lastProcessedTimestamp": 1631517883555,\n    "uptime": 41.151789063,\n    "polkadotSdkVersion": "5.4.1",\n    "apiConnected": true,\n    "injectedApiConnected": true,\n    "usingDictionary": false,\n    "chain": "Polkadot",\n    "specName": "polkadot",\n    "genesisHash": "0x91b171bb158e2d3848fa23a9f1c25182fb8e20313b2c1eb49219da7a70ce90c3",\n    "blockTime": 6000\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nhttp://localhost:3000/health will return HTTP 200 if successful.\n\nA 500 error will be returned if the indexer is not healthy. This can often be seen when the node is booting up.\n\n{\n    "status": 500,\n    "error": "Indexer is not healthy"\n}\n\n\n1\n2\n3\n4\n\n\nIf an incorrect URL is used, a 404 not found error will be returned.\n\n{\n"statusCode": 404,\n"message": "Cannot GET /healthy",\n"error": "Not Found"\n}\n\n\n1\n2\n3\n4\n5\n\n\n# Debug your project\n\nUse the node inspector to run the following command.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nFor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\nThen open up the Chrome dev tools, go to Source > Filesystem and add your project to the workspace and start debugging. For more information, check out How to debug a SubQuery project\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.',normalizedContent:'# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don\'t want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won\'t need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you\'ll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# use a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we\'ve seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\nread more about how a subquery dictionary works.\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path \n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# run in local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n# check your node health\n\nthere are 2 endpoints that you can use to check and monitor the health of a running subquery node.\n\n * health check endpoint that returns a simple 200 response\n * metadata endpoint that includes additional analytics of your running subquery node\n\nappend this to the base url of your subquery node. eg http://localhost:3000/meta will return:\n\n{\n    "currentprocessingheight": 1000699,\n    "currentprocessingtimestamp": 1631517883547,\n    "targetheight": 6807295,\n    "bestheight": 6807298,\n    "indexernodeversion": "0.19.1",\n    "lastprocessedheight": 1000699,\n    "lastprocessedtimestamp": 1631517883555,\n    "uptime": 41.151789063,\n    "polkadotsdkversion": "5.4.1",\n    "apiconnected": true,\n    "injectedapiconnected": true,\n    "usingdictionary": false,\n    "chain": "polkadot",\n    "specname": "polkadot",\n    "genesishash": "0x91b171bb158e2d3848fa23a9f1c25182fb8e20313b2c1eb49219da7a70ce90c3",\n    "blocktime": 6000\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nhttp://localhost:3000/health will return http 200 if successful.\n\na 500 error will be returned if the indexer is not healthy. this can often be seen when the node is booting up.\n\n{\n    "status": 500,\n    "error": "indexer is not healthy"\n}\n\n\n1\n2\n3\n4\n\n\nif an incorrect url is used, a 404 not found error will be returned.\n\n{\n"statuscode": 404,\n"message": "cannot get /healthy",\n"error": "not found"\n}\n\n\n1\n2\n3\n4\n5\n\n\n# debug your project\n\nuse the node inspector to run the following command.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nfor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\nthen open up the chrome dev tools, go to source > filesystem and add your project to the workspace and start debugging. for more information, check out how to debug a subquery project\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/th/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/run/sandbox.html",relativePath:"th/run/sandbox.md",key:"v-1ba626c9",path:"/th/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"จะเปลี่ยน batch size การ fetch บล็อคเชนได้อย่างไร?",frontmatter:{summary:"จะเปลี่ยน batch size การ fetch บล็อคเชนได้อย่างไร? คู่มือวิดีโอ บทนำ batch size เริ่มต้นคือ 100 แต่สามารถเปลี่ยนแปลงได้โดยใช้คำสั่งเพิ่มเติม --batch-size=xx คุณต้องใช้สิ่งนี้กับ co",meta:[{property:"og:url",content:"/th/tutorials_examples/batch-size.html"},{property:"og:title",content:"จะเปลี่ยน batch size การ fetch บล็อคเชนได้อย่างไร?"},{property:"og:description",content:"จะเปลี่ยน batch size การ fetch บล็อคเชนได้อย่างไร? คู่มือวิดีโอ บทนำ batch size เริ่มต้นคือ 100 แต่สามารถเปลี่ยนแปลงได้โดยใช้คำสั่งเพิ่มเติม --batch-size=xx คุณต้องใช้สิ่งนี้กับ co"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/tutorials_examples/batch-size.html",relativePath:"th/tutorials_examples/batch-size.md",key:"v-304ac322",path:"/th/tutorials_examples/batch-size/",headers:[{level:2,title:"คู่มือวิดีโอ",slug:"คู่มือวิดีโอ",normalizedTitle:"คู่มือวิดีโอ",charIndex:57},{level:2,title:"บทนำ",slug:"บทนํา",normalizedTitle:"บทนำ",charIndex:74},{level:2,title:"ทำไมต้องเปลี่ยน batch size?",slug:"ทําไมต้องเปลี่ยน-batch-size",normalizedTitle:"ทำไมต้องเปลี่ยน batch size?",charIndex:722}],readingTime:{minutes:.24,words:72},headersStr:"คู่มือวิดีโอ บทนำ ทำไมต้องเปลี่ยน batch size?",content:'# จะเปลี่ยน batch size การ fetch บล็อคเชนได้อย่างไร?\n\n\n# คู่มือวิดีโอ\n\n\n# บทนำ\n\nbatch size เริ่มต้นคือ 100 แต่สามารถเปลี่ยนแปลงได้โดยใช้คำสั่งเพิ่มเติม --batch-size=xx\n\nคุณต้องใช้สิ่งนี้กับ command line ซึ่งเป็น flag เพิ่มเติม หรือหากคุณใช้ Docker ให้แก้ไขไฟล์ docker-compose.yml ด้วย:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nตัวอย่างนี้กำหนด batch size เป็น 50\n\n\n# ทำไมต้องเปลี่ยน batch size?\n\nการใช้ batch size ที่เล็กลงสามารถลดการใช้หน่วยความจำได้ และไม่ปล่อยให้ผู้ใช้ต้องค้างกับการสืบค้นข้อมูลจำนวนมาก กล่าวอีกนัยหนึ่งคือ แอปพลิเคชันของคุณสามารถตอบสนองได้มากขึ้น',normalizedContent:'# จะเปลี่ยน batch size การ fetch บล็อคเชนได้อย่างไร?\n\n\n# คู่มือวิดีโอ\n\n\n# บทนำ\n\nbatch size เริ่มต้นคือ 100 แต่สามารถเปลี่ยนแปลงได้โดยใช้คำสั่งเพิ่มเติม --batch-size=xx\n\nคุณต้องใช้สิ่งนี้กับ command line ซึ่งเป็น flag เพิ่มเติม หรือหากคุณใช้ docker ให้แก้ไขไฟล์ docker-compose.yml ด้วย:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nตัวอย่างนี้กำหนด batch size เป็น 50\n\n\n# ทำไมต้องเปลี่ยน batch size?\n\nการใช้ batch size ที่เล็กลงสามารถลดการใช้หน่วยความจำได้ และไม่ปล่อยให้ผู้ใช้ต้องค้างกับการสืบค้นข้อมูลจำนวนมาก กล่าวอีกนัยหนึ่งคือ แอปพลิเคชันของคุณสามารถตอบสนองได้มากขึ้น',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"จะเริ่มต้นที่ block height ที่ต่างกันได้อย่างไร?",frontmatter:{summary:"จะเริ่มต้นที่ block height ที่ต่างกันได้อย่างไร? คู่มือวิดีโอ บทนำ โดยค่าเริ่มต้น โปรเจ็กต์เริ่มต้นทั้งหมดจะเริ่มซิงโครไนซ์บล็อกเชนจาก genesis block กล่าวอีกนัยหนึ่งจากบล็อก 1 สำหร",meta:[{property:"og:url",content:"/th/tutorials_examples/block-height.html"},{property:"og:title",content:"จะเริ่มต้นที่ block height ที่ต่างกันได้อย่างไร?"},{property:"og:description",content:"จะเริ่มต้นที่ block height ที่ต่างกันได้อย่างไร? คู่มือวิดีโอ บทนำ โดยค่าเริ่มต้น โปรเจ็กต์เริ่มต้นทั้งหมดจะเริ่มซิงโครไนซ์บล็อกเชนจาก genesis block กล่าวอีกนัยหนึ่งจากบล็อก 1 สำหร"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/tutorials_examples/block-height.html",relativePath:"th/tutorials_examples/block-height.md",key:"v-2cad176e",path:"/th/tutorials_examples/block-height/",headers:[{level:2,title:"คู่มือวิดีโอ",slug:"คู่มือวิดีโอ",normalizedTitle:"คู่มือวิดีโอ",charIndex:55},{level:2,title:"บทนำ",slug:"บทนํา",normalizedTitle:"บทนำ",charIndex:72},{level:2,title:"ทำไมไม่เริ่มจากศูนย์?",slug:"ทําไมไม่เริ่มจากศูนย์",normalizedTitle:"ทำไมไม่เริ่มจากศูนย์?",charIndex:959},{level:2,title:"ข้อเสียของการไม่เริ่มจากศูนย์คืออะไร?",slug:"ข้อเสียของการไม่เริ่มจากศูนย์คืออะไร",normalizedTitle:"ข้อเสียของการไม่เริ่มจากศูนย์คืออะไร?",charIndex:1208},{level:2,title:"จะทราบความ blockchain height ปัจจุบันได้อย่างไร?",slug:"จะทราบความ-blockchain-height-ปัจจุบันได้อย่างไร",normalizedTitle:"จะทราบความ blockchain height ปัจจุบันได้อย่างไร?",charIndex:1344},{level:2,title:"ฉันต้องทำการ rebuild หรือ codegen หรือไม่?",slug:"ฉันต้องทําการ-rebuild-หรือ-codegen-หรือไม่",normalizedTitle:"ฉันต้องทำการ rebuild หรือ codegen หรือไม่?",charIndex:1510}],readingTime:{minutes:.34,words:103},headersStr:"คู่มือวิดีโอ บทนำ ทำไมไม่เริ่มจากศูนย์? ข้อเสียของการไม่เริ่มจากศูนย์คืออะไร? จะทราบความ blockchain height ปัจจุบันได้อย่างไร? ฉันต้องทำการ rebuild หรือ codegen หรือไม่?",content:'# จะเริ่มต้นที่ block height ที่ต่างกันได้อย่างไร?\n\n\n# คู่มือวิดีโอ\n\n\n# บทนำ\n\nโดยค่าเริ่มต้น โปรเจ็กต์เริ่มต้นทั้งหมดจะเริ่มซิงโครไนซ์บล็อกเชนจาก genesis block กล่าวอีกนัยหนึ่งจากบล็อก 1 สำหรับบล็อคเชนขนาดใหญ่ โดยปกติจะใช้เวลาหลายวันหรือหลายสัปดาห์ในการซิงโครไนซ์อย่างสมบูรณ์\n\nในการเริ่มโหนด SubQuery ที่ซิงโครไนซ์จาก block height ที่ไม่ใช่ศูนย์ สิ่งที่คุณต้องทำคือแก้ไขไฟล์ project.yaml ของคุณและเปลี่ยน key startBlock\n\nด้านล่างเป็นไฟล์ project.yaml ที่ตั้งค่าบล็อกเริ่มต้นเป็น 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n \nText\nXPath: /pre/code\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# ทำไมไม่เริ่มจากศูนย์?\n\nสาเหตุหลักคือสามารถลดเวลาในการซิงโครไนซ์บล็อกเชนได้ ซึ่งหมายความว่าหากคุณสนใจเฉพาะธุรกรรมในช่วง 3 เดือนที่ผ่านมา คุณสามารถซิงโครไนซ์เฉพาะช่วง 3 เดือนที่ผ่านมาเท่านั้น ทำให้เวลารอน้อยลง และคุณสามารถเริ่มการพัฒนาได้เร็วขึ้น\n\n\n# ข้อเสียของการไม่เริ่มจากศูนย์คืออะไร?\n\nข้อเสียเปรียบที่ชัดเจนที่สุดคือคุณจะไม่สามารถสืบค้นข้อมูลบนบล็อคเชนสำหรับบล็อกที่คุณไม่มีได้\n\n\n# จะทราบความ blockchain height ปัจจุบันได้อย่างไร?\n\nหากคุณกำลังใช้เครือข่าย Polkadot คุณสามารถไปที่ https://polkascan.io/ เลือกเครือข่ายแล้วดูค่า "Finalized Block"\n\n\n# ฉันต้องทำการ rebuild หรือ codegen หรือไม่?\n\nไม่ เนื่องจากคุณกำลังแก้ไขไฟล์ project.yaml ซึ่งโดยพื้นฐานแล้วเป็น configuration file คุณจะไม่ต้องทำการ rebuild หรือ regenerate โค้ด typescript ใหม่',normalizedContent:'# จะเริ่มต้นที่ block height ที่ต่างกันได้อย่างไร?\n\n\n# คู่มือวิดีโอ\n\n\n# บทนำ\n\nโดยค่าเริ่มต้น โปรเจ็กต์เริ่มต้นทั้งหมดจะเริ่มซิงโครไนซ์บล็อกเชนจาก genesis block กล่าวอีกนัยหนึ่งจากบล็อก 1 สำหรับบล็อคเชนขนาดใหญ่ โดยปกติจะใช้เวลาหลายวันหรือหลายสัปดาห์ในการซิงโครไนซ์อย่างสมบูรณ์\n\nในการเริ่มโหนด subquery ที่ซิงโครไนซ์จาก block height ที่ไม่ใช่ศูนย์ สิ่งที่คุณต้องทำคือแก้ไขไฟล์ project.yaml ของคุณและเปลี่ยน key startblock\n\nด้านล่างเป็นไฟล์ project.yaml ที่ตั้งค่าบล็อกเริ่มต้นเป็น 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n \ntext\nxpath: /pre/code\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# ทำไมไม่เริ่มจากศูนย์?\n\nสาเหตุหลักคือสามารถลดเวลาในการซิงโครไนซ์บล็อกเชนได้ ซึ่งหมายความว่าหากคุณสนใจเฉพาะธุรกรรมในช่วง 3 เดือนที่ผ่านมา คุณสามารถซิงโครไนซ์เฉพาะช่วง 3 เดือนที่ผ่านมาเท่านั้น ทำให้เวลารอน้อยลง และคุณสามารถเริ่มการพัฒนาได้เร็วขึ้น\n\n\n# ข้อเสียของการไม่เริ่มจากศูนย์คืออะไร?\n\nข้อเสียเปรียบที่ชัดเจนที่สุดคือคุณจะไม่สามารถสืบค้นข้อมูลบนบล็อคเชนสำหรับบล็อกที่คุณไม่มีได้\n\n\n# จะทราบความ blockchain height ปัจจุบันได้อย่างไร?\n\nหากคุณกำลังใช้เครือข่าย polkadot คุณสามารถไปที่ https://polkascan.io/ เลือกเครือข่ายแล้วดูค่า "finalized block"\n\n\n# ฉันต้องทำการ rebuild หรือ codegen หรือไม่?\n\nไม่ เนื่องจากคุณกำลังแก้ไขไฟล์ project.yaml ซึ่งโดยพื้นฐานแล้วเป็น configuration file คุณจะไม่ต้องทำการ rebuild หรือ regenerate โค้ด typescript ใหม่',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"จะ debug โปรเจ็กต์ SubQuery ได้อย่างไร?",frontmatter:{summary:"จะ debug โปรเจ็กต์ SubQuery ได้อย่างไร? คู่มือวิดีโอ บทนำ ในการ debug โปรเจ็กต์ SubQuery เช่น การข้ามไปยังบรรทัดโค้ดที่ต้องการ การตั้งค่า breakpoints และการตรวจสอบตัวแปร คุณจะต้องใ",meta:[{property:"og:url",content:"/th/tutorials_examples/debug-projects.html"},{property:"og:title",content:"จะ debug โปรเจ็กต์ SubQuery ได้อย่างไร?"},{property:"og:description",content:"จะ debug โปรเจ็กต์ SubQuery ได้อย่างไร? คู่มือวิดีโอ บทนำ ในการ debug โปรเจ็กต์ SubQuery เช่น การข้ามไปยังบรรทัดโค้ดที่ต้องการ การตั้งค่า breakpoints และการตรวจสอบตัวแปร คุณจะต้องใ"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/tutorials_examples/debug-projects.html",relativePath:"th/tutorials_examples/debug-projects.md",key:"v-7c7ce4ef",path:"/th/tutorials_examples/debug-projects/",headers:[{level:2,title:"คู่มือวิดีโอ",slug:"คู่มือวิดีโอ",normalizedTitle:"คู่มือวิดีโอ",charIndex:46},{level:2,title:"บทนำ",slug:"บทนํา",normalizedTitle:"บทนำ",charIndex:63},{level:2,title:"Node inspector",slug:"node-inspector",normalizedTitle:"node inspector",charIndex:251},{level:2,title:"Chrome devtools",slug:"chrome-devtools",normalizedTitle:"chrome devtools",charIndex:652}],readingTime:{minutes:.36,words:107},headersStr:"คู่มือวิดีโอ บทนำ Node inspector Chrome devtools",content:"# จะ debug โปรเจ็กต์ SubQuery ได้อย่างไร?\n\n\n# คู่มือวิดีโอ\n\n\n# บทนำ\n\nในการ debug โปรเจ็กต์ SubQuery เช่น การข้ามไปยังบรรทัดโค้ดที่ต้องการ การตั้งค่า breakpoints และการตรวจสอบตัวแปร คุณจะต้องใช้ inspector ของ Node.js ร่วมกับ Chrome developer tools\n\n\n# Node inspector\n\nเรียกใช้คำสั่งต่อไปนี้ในหน้าจอเทอร์มินัล\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nตัวอย่าง:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# Chrome devtools\n\nเปิด Chrome DevTools และไปที่แท็บ Sources โปรดทราบว่าการคลิกที่ไอคอนสีเขียวจะเป็นการเปิดหน้าต่างใหม่\n\n\n\nไปที่ Filesystem และเพิ่มโฟลเดอร์โปรเจ็กต์ของคุณไป workspace จากนั้นเปิด dist > โฟลเดอร์ mappings และเลือกโค้ดคุณต้องการ debug จากนั้นตรวจสอบโค้ดเช่นเดียวกับเครื่องมือสำหรับ debug มาตรฐานทั่วไป\n\n",normalizedContent:"# จะ debug โปรเจ็กต์ subquery ได้อย่างไร?\n\n\n# คู่มือวิดีโอ\n\n\n# บทนำ\n\nในการ debug โปรเจ็กต์ subquery เช่น การข้ามไปยังบรรทัดโค้ดที่ต้องการ การตั้งค่า breakpoints และการตรวจสอบตัวแปร คุณจะต้องใช้ inspector ของ node.js ร่วมกับ chrome developer tools\n\n\n# node inspector\n\nเรียกใช้คำสั่งต่อไปนี้ในหน้าจอเทอร์มินัล\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nตัวอย่าง:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# chrome devtools\n\nเปิด chrome devtools และไปที่แท็บ sources โปรดทราบว่าการคลิกที่ไอคอนสีเขียวจะเป็นการเปิดหน้าต่างใหม่\n\n\n\nไปที่ filesystem และเพิ่มโฟลเดอร์โปรเจ็กต์ของคุณไป workspace จากนั้นเปิด dist > โฟลเดอร์ mappings และเลือกโค้ดคุณต้องการ debug จากนั้นตรวจสอบโค้ดเช่นเดียวกับเครื่องมือสำหรับ debug มาตรฐานทั่วไป\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How does a SubQuery dictionary work?",frontmatter:{summary:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod",meta:[{property:"og:url",content:"/th/tutorials_examples/dictionary.html"},{property:"og:title",content:"How does a SubQuery dictionary work?"},{property:"og:description",content:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/tutorials_examples/dictionary.html",relativePath:"th/tutorials_examples/dictionary.md",key:"v-795a43aa",path:"/th/tutorials_examples/dictionary/",headers:[{level:2,title:"How to incorporate a dictionary into your project?",slug:"how-to-incorporate-a-dictionary-into-your-project",normalizedTitle:"how to incorporate a dictionary into your project?",charIndex:1024},{level:2,title:"What happens when a dictionary IS NOT used?",slug:"what-happens-when-a-dictionary-is-not-used",normalizedTitle:"what happens when a dictionary is not used?",charIndex:1350},{level:2,title:"What happens when a dictionary IS used?",slug:"what-happens-when-a-dictionary-is-used",normalizedTitle:"what happens when a dictionary is used?",charIndex:1772},{level:2,title:"When is a dictionary NOT useful?",slug:"when-is-a-dictionary-not-useful",normalizedTitle:"when is a dictionary not useful?",charIndex:2849}],readingTime:{minutes:2,words:601},headersStr:"How to incorporate a dictionary into your project? What happens when a dictionary IS NOT used? What happens when a dictionary IS used? When is a dictionary NOT useful?",content:"# How does a SubQuery dictionary work?\n\nThe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. Another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nThe network.dictionary endpoint is an optional parameter that if present, the SDK will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\nTaking the SubQuery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specVersion. These 3 entities contain 6, 4, and 2 fields respectively. When this project is run, these fields are reflected in the database tables.\n\n\n\nData from the blockchain is then stored in these tables and indexed for performance. The project is then hosted in SubQuery Projects and the API endpoint is available to be added to the manifest file.\n\n\n# How to incorporate a dictionary into your project?\n\nAdd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. Eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# What happens when a dictionary IS NOT used?\n\nWhen a dictionary is NOT used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. Later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# What happens when a dictionary IS used?\n\nWhen a dictionary IS used, the indexer will first take the call and event filters as parameters and merge this into a GraphQL query. It then uses the dictionary's API to obtain a list of relevant block heights only that contains the specific events and extrinsics. Often this is substantially less than 100 if the default is used.\n\nFor example, imagine a situation where you're indexing transfer events. Not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nThe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. This is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nThis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. But compared to the traditional method, it adds an additional step to get data from the dictionary’s API.\n\n\n# When is a dictionary NOT useful?\n\nWhen block handlers are used to grab data from a chain, every block needs to be processed. Therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nAlso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",normalizedContent:"# how does a subquery dictionary work?\n\nthe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nthe network.dictionary endpoint is an optional parameter that if present, the sdk will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\ntaking the subquery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specversion. these 3 entities contain 6, 4, and 2 fields respectively. when this project is run, these fields are reflected in the database tables.\n\n\n\ndata from the blockchain is then stored in these tables and indexed for performance. the project is then hosted in subquery projects and the api endpoint is available to be added to the manifest file.\n\n\n# how to incorporate a dictionary into your project?\n\nadd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# what happens when a dictionary is not used?\n\nwhen a dictionary is not used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# what happens when a dictionary is used?\n\nwhen a dictionary is used, the indexer will first take the call and event filters as parameters and merge this into a graphql query. it then uses the dictionary's api to obtain a list of relevant block heights only that contains the specific events and extrinsics. often this is substantially less than 100 if the default is used.\n\nfor example, imagine a situation where you're indexing transfer events. not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nthe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. this is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nthis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. but compared to the traditional method, it adds an additional step to get data from the dictionary’s api.\n\n\n# when is a dictionary not useful?\n\nwhen block handlers are used to grab data from a chain, every block needs to be processed. therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nalso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. Tutorials SubQuery Example Proje",meta:[{property:"og:url",content:"/th/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. Tutorials SubQuery Example Proje"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/tutorials_examples/introduction.html",relativePath:"th/tutorials_examples/introduction.md",key:"v-25ae723a",path:"/th/tutorials_examples/introduction/",headers:[{level:2,title:"Tutorials",slug:"tutorials",normalizedTitle:"tutorials",charIndex:2},{level:2,title:"SubQuery Example Projects",slug:"subquery-example-projects",normalizedTitle:"subquery example projects",charIndex:169}],readingTime:{minutes:.72,words:216},headersStr:"Tutorials SubQuery Example Projects",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# Tutorials\n\n\n# SubQuery Example Projects\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# tutorials\n\n\n# subquery example projects\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"วิธีการรัน indexer node",frontmatter:{summary:"วิธีการรัน indexer node คู่มือวิดีโอ บทนำ การรัน indexer node เป็นอีกตัวเลือกหนึ่งนอกเหนือจากการใช้ Docker หรือการโฮสต์โปรเจ็กต์ของคุณที่ SubQuery Projects ซึ่งต้องใช้เวลาและความพย",meta:[{property:"og:url",content:"/th/tutorials_examples/run-indexer.html"},{property:"og:title",content:"วิธีการรัน indexer node"},{property:"og:description",content:"วิธีการรัน indexer node คู่มือวิดีโอ บทนำ การรัน indexer node เป็นอีกตัวเลือกหนึ่งนอกเหนือจากการใช้ Docker หรือการโฮสต์โปรเจ็กต์ของคุณที่ SubQuery Projects ซึ่งต้องใช้เวลาและความพย"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/tutorials_examples/run-indexer.html",relativePath:"th/tutorials_examples/run-indexer.md",key:"v-433617ed",path:"/th/tutorials_examples/run-indexer/",headers:[{level:2,title:"คู่มือวิดีโอ",slug:"คู่มือวิดีโอ",normalizedTitle:"คู่มือวิดีโอ",charIndex:30},{level:2,title:"บทนำ",slug:"บทนํา",normalizedTitle:"บทนำ",charIndex:47},{level:2,title:"Postgres",slug:"postgres",normalizedTitle:"postgres",charIndex:296},{level:2,title:"ติดตั้ง subql/node",slug:"ติดตั้ง-subql-node",normalizedTitle:"ติดตั้ง subql/node",charIndex:470},{level:2,title:"การตั้งค่า DB",slug:"การตั้งค่า-db",normalizedTitle:"การตั้งค่า db",charIndex:768},{level:2,title:"การ Index โปรเจ็กต์",slug:"การ-index-โปรเจ็กต์",normalizedTitle:"การ index โปรเจ็กต์",charIndex:1279},{level:2,title:"การตรวจสอบ Postgres",slug:"การตรวจสอบ-postgres",normalizedTitle:"การตรวจสอบ postgres",charIndex:1552}],readingTime:{minutes:.4,words:120},headersStr:"คู่มือวิดีโอ บทนำ Postgres ติดตั้ง subql/node การตั้งค่า DB การ Index โปรเจ็กต์ การตรวจสอบ Postgres",content:'# วิธีการรัน indexer node\n\n\n# คู่มือวิดีโอ\n\n\n# บทนำ\n\nการรัน indexer node เป็นอีกตัวเลือกหนึ่งนอกเหนือจากการใช้ Docker หรือการโฮสต์โปรเจ็กต์ของคุณที่ SubQuery Projects ซึ่งต้องใช้เวลาและความพยายามมากขึ้น แต่จะช่วยเพิ่มความเข้าใจเกี่ยวกับวิธีการทำงานของ SubQuery เบื้องหลังให้กับคุณมากยิ่งขึ้น\n\n\n# Postgres\n\nการรัน indexer node บนโครงสร้างพื้นฐานของคุณจะต้องมีการตั้งค่าฐานข้อมูล Postgres คุณสามารถติดตั้ง Postgres ได้ที่นี่ และตรวจดูให้แน่ใจว่าเป็นเวอร์ชัน 12 ขึ้นไป\n\n\n# ติดตั้ง subql/node\n\nจากนั้นให้ใช้คำสั่งต่อไปนี้เพื่อรันโหนด SubQuery:\n\nnpm install -g @subql/node\n\n\n1\n\n\nflag -g หมายถึงการติดตั้งแบบ global ซึ่งหมายถึงตำแหน่งจะเป็น /usr/local/lib/node_modules บน OSX\n\nเมื่อติดตั้งแล้ว คุณสามารถตรวจสอบเวอร์ชันได้โดยการรัน:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# การตั้งค่า DB\n\nจากนั้น คุณต้องตั้งค่า environmental variables ต่อไปนี้:\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\n\n\n1\n2\n3\n4\n5\n\n\nแน่นอนว่าหากคุณมีค่าที่ต่างออกไปสำหรับตัวแปรด้านบน โปรดปรับตามนั้น โปรดทราบว่าคำสั่ง env จะแสดง environment variables ปัจจุบัน และกระบวนการนี้จะทำตั้งค่าเหล่านี้เพียงชั่วคราวเท่านั้น นั่นคือใช้ได้เฉพาะในช่วงเวลาที่ใช้งานเทอร์มินัล หากต้องการตั้งค่าอย่างถาวร ให้เก็บค่าไว้ใน ~/bash_profile ของคุณแทน\n\n\n# การ Index โปรเจ็กต์\n\nในการเริ่มทำการ index โปรเจ็กต์ ให้ไปที่โฟลเดอร์โปรเจ็กต์ของคุณและรันคำสั่งต่อไปนี้:\n\nsubql-node -f .\n\n\n1\n\n\nหากคุณไม่มีโปรเจ็กต์ในการทำ git clone https://github.com/subquery/subql-helloworld คุณจะเห็น indexer node เริ่มทำงานและเริ่มการ index บล็อก\n\n\n# การตรวจสอบ Postgres\n\nหากคุณไปที่ Postgres คุณจะเห็นตารางที่สร้างขึ้นสองตาราง public.subqueries และ subquery_1.starter_entities\n\npublic.subqueries มี 1 แถวเท่านั้นที่ indexer จะตรวจสอบเมื่อเริ่มต้นใช้งานในการ "เข้าใจสถานะปัจจุบัน" เพื่อให้รู้ว่าจะดำเนินการต่อจากที่ใด ตาราง starter_entities เก็บการ index ต่างๆไว้ หากต้องการดูข้อมูล ให้เรียกใช้ select (*) from subquery_1.starter_entities',normalizedContent:'# วิธีการรัน indexer node\n\n\n# คู่มือวิดีโอ\n\n\n# บทนำ\n\nการรัน indexer node เป็นอีกตัวเลือกหนึ่งนอกเหนือจากการใช้ docker หรือการโฮสต์โปรเจ็กต์ของคุณที่ subquery projects ซึ่งต้องใช้เวลาและความพยายามมากขึ้น แต่จะช่วยเพิ่มความเข้าใจเกี่ยวกับวิธีการทำงานของ subquery เบื้องหลังให้กับคุณมากยิ่งขึ้น\n\n\n# postgres\n\nการรัน indexer node บนโครงสร้างพื้นฐานของคุณจะต้องมีการตั้งค่าฐานข้อมูล postgres คุณสามารถติดตั้ง postgres ได้ที่นี่ และตรวจดูให้แน่ใจว่าเป็นเวอร์ชัน 12 ขึ้นไป\n\n\n# ติดตั้ง subql/node\n\nจากนั้นให้ใช้คำสั่งต่อไปนี้เพื่อรันโหนด subquery:\n\nnpm install -g @subql/node\n\n\n1\n\n\nflag -g หมายถึงการติดตั้งแบบ global ซึ่งหมายถึงตำแหน่งจะเป็น /usr/local/lib/node_modules บน osx\n\nเมื่อติดตั้งแล้ว คุณสามารถตรวจสอบเวอร์ชันได้โดยการรัน:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# การตั้งค่า db\n\nจากนั้น คุณต้องตั้งค่า environmental variables ต่อไปนี้:\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\n\n\n1\n2\n3\n4\n5\n\n\nแน่นอนว่าหากคุณมีค่าที่ต่างออกไปสำหรับตัวแปรด้านบน โปรดปรับตามนั้น โปรดทราบว่าคำสั่ง env จะแสดง environment variables ปัจจุบัน และกระบวนการนี้จะทำตั้งค่าเหล่านี้เพียงชั่วคราวเท่านั้น นั่นคือใช้ได้เฉพาะในช่วงเวลาที่ใช้งานเทอร์มินัล หากต้องการตั้งค่าอย่างถาวร ให้เก็บค่าไว้ใน ~/bash_profile ของคุณแทน\n\n\n# การ index โปรเจ็กต์\n\nในการเริ่มทำการ index โปรเจ็กต์ ให้ไปที่โฟลเดอร์โปรเจ็กต์ของคุณและรันคำสั่งต่อไปนี้:\n\nsubql-node -f .\n\n\n1\n\n\nหากคุณไม่มีโปรเจ็กต์ในการทำ git clone https://github.com/subquery/subql-helloworld คุณจะเห็น indexer node เริ่มทำงานและเริ่มการ index บล็อก\n\n\n# การตรวจสอบ postgres\n\nหากคุณไปที่ postgres คุณจะเห็นตารางที่สร้างขึ้นสองตาราง public.subqueries และ subquery_1.starter_entities\n\npublic.subqueries มี 1 แถวเท่านั้นที่ indexer จะตรวจสอบเมื่อเริ่มต้นใช้งานในการ "เข้าใจสถานะปัจจุบัน" เพื่อให้รู้ว่าจะดำเนินการต่อจากที่ใด ตาราง starter_entities เก็บการ index ต่างๆไว้ หากต้องการดูข้อมูล ให้เรียกใช้ select (*) from subquery_1.starter_entities',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"คำศัพท์",frontmatter:{summary:"คำศัพท์ SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the tr",meta:[{property:"og:url",content:"/th/tutorials_examples/terminology.html"},{property:"og:title",content:"คำศัพท์"},{property:"og:description",content:"คำศัพท์ SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the tr"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/tutorials_examples/terminology.html",relativePath:"th/tutorials_examples/terminology.md",key:"v-1bb8ee2d",path:"/th/tutorials_examples/terminology/",readingTime:{minutes:.49,words:146},headersStr:null,content:"# คำศัพท์\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# คำศัพท์\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{frontmatter:{summary:"Welcome to SubQuery’s Docs Sezgisel dApp'leri daha hızlı oluşturmak için zincir verilerinizi keşfedin ve dönüştürün! Hızlı Başlangıç Guide Geleneksel bir Hello World örneğiyle el e",meta:[{property:"og:url",content:"/tr/"},{property:"og:description",content:"Welcome to SubQuery’s Docs Sezgisel dApp'leri daha hızlı oluşturmak için zincir verilerinizi keşfedin ve dönüştürün! Hızlı Başlangıç Guide Geleneksel bir Hello World örneğiyle el e"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/",relativePath:"tr/README.md",key:"v-1d6eb7c4",path:"/tr/",readingTime:{minutes:2.82,words:846},headersStr:null,content:"Welcome to SubQuery’s Docs\n\nSezgisel dApp'leri daha hızlı oluşturmak için zincir verilerinizi keşfedin ve dönüştürün!\n\n\nHızlı Başlangıç Guide\n\nGeleneksel bir Hello World örneğiyle el ele tutuşarak SubQuery'i anlayın. Docker ortamındaki bir şablon projesini kullanarak, hızlı bir şekilde bir düğüm çalıştırabilir ve birkaç basit komutla birkaç dakika içinde bir blok zincirini sorgulamaya başlayabilirsiniz.\n\nGet started\n * Öğreticiler ve Örnekler\n   \n   Yaparak öğren. Çeşitli SubQuery projeleri oluşturma hakkında öğreticiler ve örnekler.\n\n * Teknik Başvuru Belgeleri\n   \n   Geliştiriciler için geliştiriciler tarafından yazılmıştır. Harika dApp'leri hızlı bir şekilde oluşturmak için ihtiyacınız olanı bulun.\n\n * The SubQuery Network\n   \n   SubQuery’s decentralised future. Read more about how indexers and consumers are rewarded.\n\n\nFAQ\n\n * SubQuery nedir?\n   \n   SubQuery, geliştiricilerin uygulamalarını güç sağlamak için Substrat zinciri verilerini dizine almalarına, dönüştürmelerine ve sorgulamalarına olanak tanıyan açık kaynaklı bir projedir.\n   \n   READ MORE\n * SubQuery'ye başlamanın en iyi yolu nedir?\n   \n   SubQuery'yi kullanmaya başlamanın en iyi yolu, Hello World tutorial denemektir. Bu, başlangıç şablonunu indirme, projeyi oluşturma ve ardından localhost'unuzda bir düğüm çalıştırmak ve basit bir sorgu çalıştırmak için Docker'ı kullanma konusunda basit bir 5 dakikalık yürüme mesafesindedir.\n\n * SubQuery'ye nasıl katkıda bulunabilir veya geri bildirimde bulunabilirim?\n   \n   Topluluktan gelen katkıları ve geri bildirimleri seviyoruz. Koda katkıda bulunmak için, ilgi alanı deponuzu çatallayın ve değişikliklerinizi yapın. Ardından bir PR veya Çekme İsteği gönderin. Test etmeyi de unutma! Ayrıca katkı yönergelerimize de göz atın (yakında).\n   \n   READ MORE\n * Projemi SubQuery Projelerinde barındırmanın maliyeti nedir?\n   \n   Projenizi SubQuery Projects'te barındırmak tamamen ücretsizdir - bu bizim topluma geri verme yöntemimizdir. Projenizi bizimle nasıl barındıracaklarınızı öğrenmek için lütfen Hello World (SubQuery Hosted) öğreticisine göz atın.\n   \n   HOSTING YOUR PROJECT\n\n\nDaha sık sorulan diğer sorular için lütfen FAQ's sayfamıza bakın.\n\nÖzel Zinciriniz ile entegre misiniz?\n\nİster Substrate'de yeni bir parachain ister tamamen yeni bir blok zinciri oluşturuyor olun - SubQuery zincirinizin verilerini dizine almanıza ve sorun gidermenize yardımcı olabilir. SubQuery, özel bir Substrat tabanlı zincirle kolayca entegre olacak şekilde tasarlanmıştır.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nDestek ve Katkıda Bulun\n\nBir sorunuz mu var veya daha fazlasını veya nasıl katkıda bulunabileceğinizi öğrenmek mi istersiniz? Sizden haber almak isteriz. Lütfen aşağıdaki bağlantılardan e-posta veya sosyal medya aracılığıyla bizimle iletişime geçin. Teknik uzmanlığa mı ihtiyacınız var? Discord topluluğumuza katılın ve tutkulu topluluk üyelerimizden destek alın.\n\nDISCORD'DA SOHBETE KATıLıN\nContact us hello@subquery.network\nBizi socialbn'de takip edin\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"welcome to subquery’s docs\n\nsezgisel dapp'leri daha hızlı olusturmak icin zincir verilerinizi kesfedin ve donusturun!\n\n\nhızlı baslangıc guide\n\ngeleneksel bir hello world ornegiyle el ele tutusarak subquery'i anlayın. docker ortamındaki bir sablon projesini kullanarak, hızlı bir sekilde bir dugum calıstırabilir ve birkac basit komutla birkac dakika icinde bir blok zincirini sorgulamaya baslayabilirsiniz.\n\nget started\n * ogreticiler ve ornekler\n   \n   yaparak ogren. cesitli subquery projeleri olusturma hakkında ogreticiler ve ornekler.\n\n * teknik basvuru belgeleri\n   \n   gelistiriciler icin gelistiriciler tarafından yazılmıstır. harika dapp'leri hızlı bir sekilde olusturmak icin ihtiyacınız olanı bulun.\n\n * the subquery network\n   \n   subquery’s decentralised future. read more about how indexers and consumers are rewarded.\n\n\nfaq\n\n * subquery nedir?\n   \n   subquery, gelistiricilerin uygulamalarını guc saglamak icin substrat zinciri verilerini dizine almalarına, donusturmelerine ve sorgulamalarına olanak tanıyan acık kaynaklı bir projedir.\n   \n   read more\n * subquery'ye baslamanın en iyi yolu nedir?\n   \n   subquery'yi kullanmaya baslamanın en iyi yolu, hello world tutorial denemektir. bu, baslangıc sablonunu indirme, projeyi olusturma ve ardından localhost'unuzda bir dugum calıstırmak ve basit bir sorgu calıstırmak icin docker'ı kullanma konusunda basit bir 5 dakikalık yurume mesafesindedir.\n\n * subquery'ye nasıl katkıda bulunabilir veya geri bildirimde bulunabilirim?\n   \n   topluluktan gelen katkıları ve geri bildirimleri seviyoruz. koda katkıda bulunmak icin, ilgi alanı deponuzu catallayın ve degisikliklerinizi yapın. ardından bir pr veya cekme istegi gonderin. test etmeyi de unutma! ayrıca katkı yonergelerimize de goz atın (yakında).\n   \n   read more\n * projemi subquery projelerinde barındırmanın maliyeti nedir?\n   \n   projenizi subquery projects'te barındırmak tamamen ucretsizdir - bu bizim topluma geri verme yontemimizdir. projenizi bizimle nasıl barındıracaklarınızı ogrenmek icin lutfen hello world (subquery hosted) ogreticisine goz atın.\n   \n   hosting your project\n\n\ndaha sık sorulan diger sorular icin lutfen faq's sayfamıza bakın.\n\nozel zinciriniz ile entegre misiniz?\n\nister substrate'de yeni bir parachain ister tamamen yeni bir blok zinciri olusturuyor olun - subquery zincirinizin verilerini dizine almanıza ve sorun gidermenize yardımcı olabilir. subquery, ozel bir substrat tabanlı zincirle kolayca entegre olacak sekilde tasarlanmıstır.\n\nlearn how to integrate with your chain\n\ndestek ve katkıda bulun\n\nbir sorunuz mu var veya daha fazlasını veya nasıl katkıda bulunabileceginizi ogrenmek mi istersiniz? sizden haber almak isteriz. lutfen asagıdaki baglantılardan e-posta veya sosyal medya aracılıgıyla bizimle iletisime gecin. teknik uzmanlıga mı ihtiyacınız var? discord toplulugumuza katılın ve tutkulu topluluk uyelerimizden destek alın.\n\ndiscord'da sohbete katılın\ncontact us hello@subquery.network\nbizi socialbn'de takip edin\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"GraphQ Şema",frontmatter:{summary:"GraphQ Şema Varlıkları Tanımlama schema.graphql dosyası çeşitli GraphQL şemalarını tanımlar. GraphQL sorgu dilinin çalışma biçimi nedeniyle, şema dosyası temel olarak verilerinizin",meta:[{property:"og:url",content:"/tr/create/graphql.html"},{property:"og:title",content:"GraphQ Şema"},{property:"og:description",content:"GraphQ Şema Varlıkları Tanımlama schema.graphql dosyası çeşitli GraphQL şemalarını tanımlar. GraphQL sorgu dilinin çalışma biçimi nedeniyle, şema dosyası temel olarak verilerinizin"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/create/graphql.html",relativePath:"tr/create/graphql.md",key:"v-e40ed1e6",path:"/tr/create/graphql/",headers:[{level:2,title:"Varlıkları Tanımlama",slug:"varlıkları-tanımlama",normalizedTitle:"varlıkları tanımlama",charIndex:18},{level:3,title:"Varlık",slug:"varlık",normalizedTitle:"varlık",charIndex:18},{level:3,title:"Desteklenen skalerler ve türler",slug:"desteklenen-skalerler-ve-turler",normalizedTitle:"desteklenen skalerler ve turler",charIndex:903},{level:2,title:"Birincil anahtar olmayan alana göre dizin oluşturma",slug:"birincil-anahtar-olmayan-alana-gore-dizin-olusturma",normalizedTitle:"birincil anahtar olmayan alana gore dizin olusturma",charIndex:1283},{level:2,title:"Varlık İlişkileri",slug:"varlık-iliskileri",normalizedTitle:"varlık iliskileri",charIndex:3101},{level:3,title:"BireBir İlişkiler",slug:"birebir-iliskiler",normalizedTitle:"birebir iliskiler",charIndex:3424},{level:3,title:"Bire Çok ilişkileri",slug:"bire-cok-iliskileri",normalizedTitle:"bire cok iliskileri",charIndex:3905},{level:3,title:"Çok-Çok ilişkileri",slug:"cok-cok-iliskileri",normalizedTitle:"cok-cok iliskileri",charIndex:4215},{level:3,title:"Geriye Doğru Aramalar",slug:"geriye-dogru-aramalar",normalizedTitle:"geriye dogru aramalar",charIndex:5211},{level:2,title:"JSON türü",slug:"json-turu",normalizedTitle:"json turu",charIndex:1269},{level:3,title:"JSON yönergesi tanımla",slug:"json-yonergesi-tanımla",normalizedTitle:"json yonergesi tanımla",charIndex:6630},{level:3,title:"JSON alanlarını sorgulama",slug:"json-alanlarını-sorgulama",normalizedTitle:"json alanlarını sorgulama",charIndex:7335}],readingTime:{minutes:3.28,words:983},headersStr:"Varlıkları Tanımlama Varlık Desteklenen skalerler ve türler Birincil anahtar olmayan alana göre dizin oluşturma Varlık İlişkileri BireBir İlişkiler Bire Çok ilişkileri Çok-Çok ilişkileri Geriye Doğru Aramalar JSON türü JSON yönergesi tanımla JSON alanlarını sorgulama",content:"# GraphQ Şema\n\n\n# Varlıkları Tanımlama\n\nschema.graphql dosyası çeşitli GraphQL şemalarını tanımlar. GraphQL sorgu dilinin çalışma biçimi nedeniyle, şema dosyası temel olarak verilerinizin şeklini SubQuery'den belirler. GraphQL şema dilinde yazma hakkında daha fazla bilgi edinmek için Schemas and Types.'a göz atmanızı öneririz.\n\nÖnemli: Şema dosyasında herhangi bir değişiklik yaptığınızda, lütfen aşağıdaki komutla türler dizininizi yeniden <>yarn codegen\n\n\n# Varlık\n\nHer varlık gerekli alanlarını < ID! türünde id olarak tanımlamalıdır. Birincil anahtar olarak kullanılır ve aynı türdeki tüm varlıklar arasında benzersizdir.\n\nVarlıktaki null olmayan alanlar ! ile gösterilir. Lütfen aşağıdaki örneğe bakın:\n\nörnek @entity { yazın\n  id: Kimlik! # kimlik alanı her zaman gereklidir ve böyle görünmelidir\n  adı: Dize! # Bu gerekli bir alan\n  adres: Dize # Bu isteğe bağlı bir alandır\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Desteklenen skalerler ve türler\n\nŞu anda akan skalers türlerini destekliyoruz:\n\n * KİMLİĞİ\n * Int\n * Dizgi\n * BigInt\n * Tarih\n * Boolean\n * <EntityName> iç içe geçmiş ilişki varlıkları için, tanımlanan varlığın adını alanlardan biri olarak kullanabilirsiniz. Lütfen Entity Relations bakın.\n * JSON yapılandırılmış verileri alternatif olarak depolayabilir, lütfen bkzJSON türü\n\n\n# Birincil anahtar olmayan alana göre dizin oluşturma\n\nSorgu performansını artırmak için, yalnızca birincil anahtar olmayan bir alana @index ek açıklama uygulayarak bir varlık alanını dizine dizine ekleme.\n\nAncak, kullanıcıların herhangi bir <@index@index<>/1> nesnesine >0>0<> ek açıklama eklemesine izin vermeyiz. Varsayılan olarak, dizinler otomatik olarak yabancı anahtarlara ve veritabanındaki JSON alanlarına eklenir, ancak yalnızca sorgu hizmeti performansını artırmak için.\n\n\n\nİşte bir örnek.\n\nkullanıcı @entity { yazın\n  id: Kimlik!\n  adı: Dize! @index(benzersiz: doğru) # benzersiz doğru veya yanlış olarak ayarlanabilir  başlık: Başlık! # Dizinler otomatik olarak yabancı anahtar alanına eklenir\n }\n\nTitle @entity { yazın\n   yaptım!  \n  adı: Dize! @index(benzersiz:doğru)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nBu kullanıcının adını bildiğimizi varsayarsak, ancak tüm kullanıcıları ayıklamak ve sonra ada göre filtrelemek yerine tam kimlik değerini bilmiyoruz, ad alanının arkasına @index ekleyebiliriz. Bu, sorgulamayı çok daha hızlı hale getirir ve ayrıca benzersizliği sağlamak için unique: true geçirebiliriz.\n\nBir alan benzersiz değilse, en büyük sonuç kümesi boyutu 100'dür\n\nKod oluşturma çalıştırıldığında, bu otomatik olarak >Kullanıcı> modeli altında getByName< oluşturur, ve yabancı anahtar alanı title getByTitleId yöntemi oluşturur, her ikisinde de eşleme işlevinde doğrudan erişilebilen.\n\n/* Başlık varlığı için kayıt hazırlama */\nUNVANLARA EKLE (kimlik, ad) DEĞERLER ('id_1', 'Kaptan')\n\n\n1\n2\n\n\nEşleme işlevinde işleyici\n{User} içinden \".. /types/models/User\"\n{Title} içinden \".. /types/models/Title\"\n\nconst jack = User.getByName('Jack Sparrow');\n\nconst captainTitle = Title.getByName('Kaptan');\n\nconst pirateLords = User.getByTitleId(captainTitle.id) bekliyor; Tüm Kaptanların listesi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Varlık İlişkileri\n\nBir varlığın genellikle diğer varlıklarla iç içe geçmiş ilişkileri vardır. Alan değerini başka bir varlık adına ayarlamak, varsayılan olarak bu iki varlık arasında bire bir ilişki tanımlar.\n\nFarklı varlık ilişkileri (bire bir, bire çok ve çok-çok) aşağıdaki örnekler kullanılarak yapılandırılabilir.\n\n\n# BireBir İlişkiler\n\nYalnızca tek bir varlık başka bir varlıkla eşleştirildiğinde bire bir ilişkiler varsayılandır.\n\nÖrnek: Pasaport yalnızca bir kişiye aittir ve bir kişinin yalnızca bir pasaportu vardır (bu örnekte):\n\nkişi @entity { yazın\n  id: Kimlik!\n}\n\nPassport @entity { yazın\n  id: Kimlik!\n  sahibi: Kişi!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nveya\n\nkişi @entity { yazın\n  id: Kimlik!\n  pasaport: Pasaport!\n}\n\nPassport @entity { yazın\n  id: Kimlik!\n  sahibi: Kişi!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Bire Çok ilişkileri\n\nAlan türünün birden çok varlık içerdiğini belirtmek için köşeli ayraçları kullanabilirsiniz.\n\nÖrnek: Bir kişinin birden fazla hesabı olabilir.\n\nkişi @entity { yazın\n  id: Kimlik!\n  hesaplar: [Hesap] \n}\n\nHesap @entity { yazın\n  id: Kimlik!\n  publicAddress: Dize!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Çok-Çok ilişkileri\n\nDiğer iki varlığı bağlamak için bir eşleme varlığı uygulanarak çok-çok ilişkisi elde edilebilir.\n\nÖrnek: Her kişi birden çok grubun (PersonGroup) bir parçasıdır ve grupların birden çok farklı kişisi (PersonGroup) vardır.\n\nkişi @entity { yazın\n  id: Kimlik!\n  adı: Dize!\n  gruplar: [PersonGroup]\n}\n\nType PersonGroup @entity {\n  id: Kimlik!\n  kişi: Kişi!\n  Grup: Grup!\n}\n\nGrup @entity { yazın\n  id: Kimlik!\n  adı: Dize!\n  kişiler: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAyrıca, orta varlığın birden çok alanında aynı varlığın bağlantısını oluşturmak mümkündür.\n\nÖrneğin, bir hesabın birden çok aktarımı olabilir ve her aktarımda bir kaynak ve hedef hesabı vardır.\n\nBu, Transfer tablosu aracılığıyla iki Hesap (itibaren ve bu) arasında çift yönlü bir ilişki kuracaktır.\n\nhesap @entity { yazın\n  id: Kimlik!\n  publicAddress: Dize!\n}\n\nTransfer @entity { yazın\n  id: Kimlik!\n  miktar: BigInt\n  itibaren: Hesap!\n  için: Hesap!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Geriye Doğru Aramalar\n\nBir objede bir ilişki için geriye doğru aramayı etkinleştirmek için, alana @derivedFrom ekleyin ve başka bir varlığın geriye doğru arama alanının üzerine gelin.\n\nBu, varlık üzerinde sorgulanabilecek bir sanal alan oluşturur.\n\nBir Hesabı \"Kimden\" Aktar'a, sentTransfer veya receivedTransfer değerini ilgili alanlardan veya alanlardan türetilmiş olarak ayarlayarak Hesap varlığından erişilebilir.\n\nhesap @entity { yazın\n  id: Kimlik!\n  publicAddress: Dize!\n  sentTransfers: [Transfer] @derivedFrom(alan: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(alan: \"to\")\n}\n\nTransfer @entity { yazın\n  id: Kimlik!\n  miktar: BigInt\n  itibaren: Hesap!\n  için: Hesap!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON türü\n\nYapılandırılmış verileri depolamanın hızlı bir yolu olan verileri JSON türü olarak kaydetmeyi destekliyoruz. Bu verileri sorgulamak için otomatik olarak karşılık gelen JSON arabirimleri oluşturacağız ve varlıkları tanımlamak ve yönetmek için size zaman kazandıracağız.\n\nKullanıcıların aşağıdaki senaryolarda JSON türünü kullanmalarını öneririz:\n\n * Yapılandırılmış verileri tek bir alanda depolamak, birden çok ayrı varlık oluşturmaktan daha yönetilebilir olduğunda.\n * Rasgele anahtar/değer kullanıcı tercihlerini kaydetme (burada değer boole, metinsel veya sayısal olabilir ve farklı veri türleri için ayrı sütunlara sahip olmak istemezsiniz)\n * Şema geçicidir ve sık sık değişir\n\n\n# JSON yönergesi tanımla\n\nVarlığa jsonField ek açıklaması ekleyerek özelliği JSON türü olarak tanımlayın. Bu, projenizdeki tüm JSON nesneleri için otomatik olarak types/interfaces.ts altında arabirimler oluşturur ve bunlara eşleme işlevinizden erişebilirsiniz.\n\nVarlığın aksine, jsonField yönerge nesnesi herhangi bir id alanı gerektirmez. Bir JSON nesnesi diğer JSON nesneleriyle de iç içe olabilir.\n\naddressDetail @jsonField { yazın\n  sokak: String!\n  bölge: String!\n}\n\nContactCard @jsonField { yazın\n  telefon: String!\n  adres: AddressDetail # İç içe JSON\n}\n\nKullanıcı @entity { yazın\n  id: Kimlik! \n  kişi: [ContactCard] # JSON nesnelerinin listesini depolayın\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# JSON alanlarını sorgulama\n\nJSON türlerini kullanmanın dezavantajı, her metin araması yaptığında tüm varlık üzerinde olduğu gibi, filtreleme yaparken sorgu verimliliği üzerinde küçük bir etkidir.\n\nAncak, etki sorgu hizmetimizde hala kabul edilebilir. '0064' içeren bir telefon numarasına sahip ilk 5 kullanıcıyı bulmak için JSON alanındaki GraphQL sorgusunda contains işlecinin nasıl kullanılacağına ilişkin bir örnek aşağıda verilmiştir.\n\n#To ilk 5 kullanıcının kendi telefon numaralarının '0064' içerdiğini bulun.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactCard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# graphq sema\n\n\n# varlıkları tanımlama\n\nschema.graphql dosyası cesitli graphql semalarını tanımlar. graphql sorgu dilinin calısma bicimi nedeniyle, sema dosyası temel olarak verilerinizin seklini subquery'den belirler. graphql sema dilinde yazma hakkında daha fazla bilgi edinmek icin schemas and types.'a goz atmanızı oneririz.\n\nonemli: sema dosyasında herhangi bir degisiklik yaptıgınızda, lutfen asagıdaki komutla turler dizininizi yeniden <>yarn codegen\n\n\n# varlık\n\nher varlık gerekli alanlarını < id! turunde id olarak tanımlamalıdır. birincil anahtar olarak kullanılır ve aynı turdeki tum varlıklar arasında benzersizdir.\n\nvarlıktaki null olmayan alanlar ! ile gosterilir. lutfen asagıdaki ornege bakın:\n\nornek @entity { yazın\n  id: kimlik! # kimlik alanı her zaman gereklidir ve boyle gorunmelidir\n  adı: dize! # bu gerekli bir alan\n  adres: dize # bu istege baglı bir alandır\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# desteklenen skalerler ve turler\n\nsu anda akan skalers turlerini destekliyoruz:\n\n * kimligi\n * int\n * dizgi\n * bigint\n * tarih\n * boolean\n * <entityname> ic ice gecmis iliski varlıkları icin, tanımlanan varlıgın adını alanlardan biri olarak kullanabilirsiniz. lutfen entity relations bakın.\n * json yapılandırılmıs verileri alternatif olarak depolayabilir, lutfen bkzjson turu\n\n\n# birincil anahtar olmayan alana gore dizin olusturma\n\nsorgu performansını artırmak icin, yalnızca birincil anahtar olmayan bir alana @index ek acıklama uygulayarak bir varlık alanını dizine dizine ekleme.\n\nancak, kullanıcıların herhangi bir <@index@index<>/1> nesnesine >0>0<> ek acıklama eklemesine izin vermeyiz. varsayılan olarak, dizinler otomatik olarak yabancı anahtarlara ve veritabanındaki json alanlarına eklenir, ancak yalnızca sorgu hizmeti performansını artırmak icin.\n\n\n\niste bir ornek.\n\nkullanıcı @entity { yazın\n  id: kimlik!\n  adı: dize! @index(benzersiz: dogru) # benzersiz dogru veya yanlıs olarak ayarlanabilir  baslık: baslık! # dizinler otomatik olarak yabancı anahtar alanına eklenir\n }\n\ntitle @entity { yazın\n   yaptım!  \n  adı: dize! @index(benzersiz:dogru)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nbu kullanıcının adını bildigimizi varsayarsak, ancak tum kullanıcıları ayıklamak ve sonra ada gore filtrelemek yerine tam kimlik degerini bilmiyoruz, ad alanının arkasına @index ekleyebiliriz. bu, sorgulamayı cok daha hızlı hale getirir ve ayrıca benzersizligi saglamak icin unique: true gecirebiliriz.\n\nbir alan benzersiz degilse, en buyuk sonuc kumesi boyutu 100'dur\n\nkod olusturma calıstırıldıgında, bu otomatik olarak >kullanıcı> modeli altında getbyname< olusturur, ve yabancı anahtar alanı title getbytitleid yontemi olusturur, her ikisinde de esleme islevinde dogrudan erisilebilen.\n\n/* baslık varlıgı icin kayıt hazırlama */\nunvanlara ekle (kimlik, ad) degerler ('id_1', 'kaptan')\n\n\n1\n2\n\n\nesleme islevinde isleyici\n{user} icinden \".. /types/models/user\"\n{title} icinden \".. /types/models/title\"\n\nconst jack = user.getbyname('jack sparrow');\n\nconst captaintitle = title.getbyname('kaptan');\n\nconst piratelords = user.getbytitleid(captaintitle.id) bekliyor; tum kaptanların listesi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# varlık iliskileri\n\nbir varlıgın genellikle diger varlıklarla ic ice gecmis iliskileri vardır. alan degerini baska bir varlık adına ayarlamak, varsayılan olarak bu iki varlık arasında bire bir iliski tanımlar.\n\nfarklı varlık iliskileri (bire bir, bire cok ve cok-cok) asagıdaki ornekler kullanılarak yapılandırılabilir.\n\n\n# birebir iliskiler\n\nyalnızca tek bir varlık baska bir varlıkla eslestirildiginde bire bir iliskiler varsayılandır.\n\nornek: pasaport yalnızca bir kisiye aittir ve bir kisinin yalnızca bir pasaportu vardır (bu ornekte):\n\nkisi @entity { yazın\n  id: kimlik!\n}\n\npassport @entity { yazın\n  id: kimlik!\n  sahibi: kisi!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nveya\n\nkisi @entity { yazın\n  id: kimlik!\n  pasaport: pasaport!\n}\n\npassport @entity { yazın\n  id: kimlik!\n  sahibi: kisi!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# bire cok iliskileri\n\nalan turunun birden cok varlık icerdigini belirtmek icin koseli ayracları kullanabilirsiniz.\n\nornek: bir kisinin birden fazla hesabı olabilir.\n\nkisi @entity { yazın\n  id: kimlik!\n  hesaplar: [hesap] \n}\n\nhesap @entity { yazın\n  id: kimlik!\n  publicaddress: dize!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# cok-cok iliskileri\n\ndiger iki varlıgı baglamak icin bir esleme varlıgı uygulanarak cok-cok iliskisi elde edilebilir.\n\nornek: her kisi birden cok grubun (persongroup) bir parcasıdır ve grupların birden cok farklı kisisi (persongroup) vardır.\n\nkisi @entity { yazın\n  id: kimlik!\n  adı: dize!\n  gruplar: [persongroup]\n}\n\ntype persongroup @entity {\n  id: kimlik!\n  kisi: kisi!\n  grup: grup!\n}\n\ngrup @entity { yazın\n  id: kimlik!\n  adı: dize!\n  kisiler: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nayrıca, orta varlıgın birden cok alanında aynı varlıgın baglantısını olusturmak mumkundur.\n\nornegin, bir hesabın birden cok aktarımı olabilir ve her aktarımda bir kaynak ve hedef hesabı vardır.\n\nbu, transfer tablosu aracılıgıyla iki hesap (itibaren ve bu) arasında cift yonlu bir iliski kuracaktır.\n\nhesap @entity { yazın\n  id: kimlik!\n  publicaddress: dize!\n}\n\ntransfer @entity { yazın\n  id: kimlik!\n  miktar: bigint\n  itibaren: hesap!\n  icin: hesap!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# geriye dogru aramalar\n\nbir objede bir iliski icin geriye dogru aramayı etkinlestirmek icin, alana @derivedfrom ekleyin ve baska bir varlıgın geriye dogru arama alanının uzerine gelin.\n\nbu, varlık uzerinde sorgulanabilecek bir sanal alan olusturur.\n\nbir hesabı \"kimden\" aktar'a, senttransfer veya receivedtransfer degerini ilgili alanlardan veya alanlardan turetilmis olarak ayarlayarak hesap varlıgından erisilebilir.\n\nhesap @entity { yazın\n  id: kimlik!\n  publicaddress: dize!\n  senttransfers: [transfer] @derivedfrom(alan: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(alan: \"to\")\n}\n\ntransfer @entity { yazın\n  id: kimlik!\n  miktar: bigint\n  itibaren: hesap!\n  icin: hesap!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json turu\n\nyapılandırılmıs verileri depolamanın hızlı bir yolu olan verileri json turu olarak kaydetmeyi destekliyoruz. bu verileri sorgulamak icin otomatik olarak karsılık gelen json arabirimleri olusturacagız ve varlıkları tanımlamak ve yonetmek icin size zaman kazandıracagız.\n\nkullanıcıların asagıdaki senaryolarda json turunu kullanmalarını oneririz:\n\n * yapılandırılmıs verileri tek bir alanda depolamak, birden cok ayrı varlık olusturmaktan daha yonetilebilir oldugunda.\n * rasgele anahtar/deger kullanıcı tercihlerini kaydetme (burada deger boole, metinsel veya sayısal olabilir ve farklı veri turleri icin ayrı sutunlara sahip olmak istemezsiniz)\n * sema gecicidir ve sık sık degisir\n\n\n# json yonergesi tanımla\n\nvarlıga jsonfield ek acıklaması ekleyerek ozelligi json turu olarak tanımlayın. bu, projenizdeki tum json nesneleri icin otomatik olarak types/interfaces.ts altında arabirimler olusturur ve bunlara esleme islevinizden erisebilirsiniz.\n\nvarlıgın aksine, jsonfield yonerge nesnesi herhangi bir id alanı gerektirmez. bir json nesnesi diger json nesneleriyle de ic ice olabilir.\n\naddressdetail @jsonfield { yazın\n  sokak: string!\n  bolge: string!\n}\n\ncontactcard @jsonfield { yazın\n  telefon: string!\n  adres: addressdetail # ic ice json\n}\n\nkullanıcı @entity { yazın\n  id: kimlik! \n  kisi: [contactcard] # json nesnelerinin listesini depolayın\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# json alanlarını sorgulama\n\njson turlerini kullanmanın dezavantajı, her metin araması yaptıgında tum varlık uzerinde oldugu gibi, filtreleme yaparken sorgu verimliligi uzerinde kucuk bir etkidir.\n\nancak, etki sorgu hizmetimizde hala kabul edilebilir. '0064' iceren bir telefon numarasına sahip ilk 5 kullanıcıyı bulmak icin json alanındaki graphql sorgusunda contains islecinin nasıl kullanılacagına iliskin bir ornek asagıda verilmistir.\n\n#to ilk 5 kullanıcının kendi telefon numaralarının '0064' icerdigini bulun.\n\nquery{\n  user(\n    first: 5,\n    filter: {\n      contactcard: {\n        contains: [{ phone: \"0064\" }]\n    }\n}){\n    nodes{\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Yeni bir SubQuery Projesi Oluşturma",frontmatter:{summary:"Yeni bir SubQuery Projesi Oluşturma quick start kılavuzunda, SubQuery'nin ne olduğunu ve nasıl çalıştığını size tattırmak için çok hızlı bir şekilde bir örnek inceledik. Burada pro",meta:[{property:"og:url",content:"/tr/create/introduction.html"},{property:"og:title",content:"Yeni bir SubQuery Projesi Oluşturma"},{property:"og:description",content:"Yeni bir SubQuery Projesi Oluşturma quick start kılavuzunda, SubQuery'nin ne olduğunu ve nasıl çalıştığını size tattırmak için çok hızlı bir şekilde bir örnek inceledik. Burada pro"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/create/introduction.html",relativePath:"tr/create/introduction.md",key:"v-228e86be",path:"/tr/create/introduction/",headers:[{level:2,title:"Temel İş Akışı",slug:"temel-is-akısı",normalizedTitle:"temel is akısı",charIndex:278},{level:2,title:"Dizin Yapısı",slug:"dizin-yapısı",normalizedTitle:"dizin yapısı",charIndex:1259},{level:2,title:"Kod Oluşturma",slug:"kod-olusturma",normalizedTitle:"kod olusturma",charIndex:1633},{level:2,title:"Yapmak",slug:"yapmak",normalizedTitle:"yapmak",charIndex:2091},{level:2,title:"ünlüğe kaydetme",slug:"unluge-kaydetme",normalizedTitle:"unluge kaydetme",charIndex:2329}],readingTime:{minutes:1.45,words:434},headersStr:"Temel İş Akışı Dizin Yapısı Kod Oluşturma Yapmak ünlüğe kaydetme",content:"# Yeni bir SubQuery Projesi Oluşturma\n\nquick start kılavuzunda, SubQuery'nin ne olduğunu ve nasıl çalıştığını size tattırmak için çok hızlı bir şekilde bir örnek inceledik. Burada projenizi oluştururken iş akışına ve çalışacağınız anahtar dosyalara daha yakından bakacağız.\n\n\n# Temel İş Akışı\n\nAşağıdaki örneklerden bazıları, başlangıç paketini Quick start bölümünde başarıyla başlatmış olduğunuzu varsayar. Bu başlangıç paketinden, SubQuery projenizi özelleştirmek ve uygulamak için standart süreçten geçeceğiz.\n\n 1. PROJECT_NAME</0 subql init kullanarak projenizi başlatın></li> <li>Bildirim dosyasını (<code>project.yaml) blok zinciriniz ve eşleyeceğiniz varlıklar hakkında bilgi içerecek şekilde güncelleştirin - bkzManifest Dosyası\n 2. Şemanızda (schema.graphql) ayıklayacağınız ve sorgulamak için sürdüreceğiniz verilerin şeklini tanımlayan GraphQL varlıkları oluşturun - bkz. GraphQL Şeması\n 3. Zincir verilerini tanımladığınız GraphQL varlıklarına dönüştürmek için çağırmak istediğiniz tüm eşleme işlevlerini (örneğinmappingHandlers.ts) ekleyin - bkzMapping\n 4. Kodunuzu SubQuery Projects oluşturun, oluşturun ve yayımlayın (veya kendi yerel düğümünüzde çalıştırın) - hızlı başlangıç kılavuzumuzda Starter Projenizi Çalıştırma ve Sorgulama bakın.\n\n\n# Dizin Yapısı\n\nAşağıdaki eşleme, init komutu çalıştırıldığında, Bir SubQuery projesinin dizin yapısına genel bir bakış sağlar.\n\n- proje adı\n  L paketi.json\n  L projesi.yaml\n  L README.md\n  L şeması.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L dizini.ts\n    L eşlemeleri\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nMesela:\n\n\n\n\n# Kod Oluşturma\n\nGraphQL varlıklarınızı her değiştirdiğinizde, türler dizininizi aşağıdaki komutla yeniden değiştirmeniz gerekir.\n\niplik kodgeni\n\n\n1\n\n\nBu, daha önce schema.graphql< tanımladığınız her tür için oluşturulan varlık sınıflarını içeren yeni bir dizin (veya varolan) src/types oluşturur. Bu sınıflar varlık alanlarına tür açısından güvenli varlık yükleme, okuma ve yazma erişimi sağlar - GraphQL Şeması bu işlem hakkında daha fazla bilgi edinin.\n\n\n# Yapmak\n\nSubQuery Project yerel olarak barındırılan bir SubQuery Node çalıştırmak için önce çalışmanızı oluşturmanız gerekir.\n\nYapı komutunu projenin kök dizininden çalıştırın.\n\n```shell yarn build ``` ```bash npm run-script build ```\n\n\n# ünlüğe kaydetme\n\nThe console.log yöntemi artık desteklenmiyor. Bunun yerine, türlere logger modülü eklenmiştir, bu da çeşitli günlük düzeylerini kabul edebilecek bir günlükçü destekleyebileceğimiz anlamına gelir.\n\nlogger.info('Bilgi düzeyi mesajı');\nlogger.debug('Hata ayıklayıcı düzeyi iletisi');\nlogger.warn('Uyarı düzeyi iletisi');\n\n\n1\n2\n3\n\n\nlogger.info veya logger.warn kullanmak için, satırı eşleme dosyanıza yerleştirmeniz yeterlidir.\n\n\n\nlogger.debug kullanmak için ek bir adım gerekir. Komut satırınıza --log-level=debug ekleyin.\n\nDocker kapsayıcısı çalıştırıyorsanız, bu satırı docker-compose.yaml dosyanıza ekleyin.\n\n\n\nŞimdi terminal ekranında yeni günlüğe kaydetmeyi görmeniz gerekir.\n\n",normalizedContent:"# yeni bir subquery projesi olusturma\n\nquick start kılavuzunda, subquery'nin ne oldugunu ve nasıl calıstıgını size tattırmak icin cok hızlı bir sekilde bir ornek inceledik. burada projenizi olustururken is akısına ve calısacagınız anahtar dosyalara daha yakından bakacagız.\n\n\n# temel is akısı\n\nasagıdaki orneklerden bazıları, baslangıc paketini quick start bolumunde basarıyla baslatmıs oldugunuzu varsayar. bu baslangıc paketinden, subquery projenizi ozellestirmek ve uygulamak icin standart surecten gececegiz.\n\n 1. project_name</0 subql init kullanarak projenizi baslatın></li> <li>bildirim dosyasını (<code>project.yaml) blok zinciriniz ve esleyeceginiz varlıklar hakkında bilgi icerecek sekilde guncellestirin - bkzmanifest dosyası\n 2. semanızda (schema.graphql) ayıklayacagınız ve sorgulamak icin surdureceginiz verilerin seklini tanımlayan graphql varlıkları olusturun - bkz. graphql seması\n 3. zincir verilerini tanımladıgınız graphql varlıklarına donusturmek icin cagırmak istediginiz tum esleme islevlerini (orneginmappinghandlers.ts) ekleyin - bkzmapping\n 4. kodunuzu subquery projects olusturun, olusturun ve yayımlayın (veya kendi yerel dugumunuzde calıstırın) - hızlı baslangıc kılavuzumuzda starter projenizi calıstırma ve sorgulama bakın.\n\n\n# dizin yapısı\n\nasagıdaki esleme, init komutu calıstırıldıgında, bir subquery projesinin dizin yapısına genel bir bakıs saglar.\n\n- proje adı\n  l paketi.json\n  l projesi.yaml\n  l readme.md\n  l seması.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l dizini.ts\n    l eslemeleri\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nmesela:\n\n\n\n\n# kod olusturma\n\ngraphql varlıklarınızı her degistirdiginizde, turler dizininizi asagıdaki komutla yeniden degistirmeniz gerekir.\n\niplik kodgeni\n\n\n1\n\n\nbu, daha once schema.graphql< tanımladıgınız her tur icin olusturulan varlık sınıflarını iceren yeni bir dizin (veya varolan) src/types olusturur. bu sınıflar varlık alanlarına tur acısından guvenli varlık yukleme, okuma ve yazma erisimi saglar - graphql seması bu islem hakkında daha fazla bilgi edinin.\n\n\n# yapmak\n\nsubquery project yerel olarak barındırılan bir subquery node calıstırmak icin once calısmanızı olusturmanız gerekir.\n\nyapı komutunu projenin kok dizininden calıstırın.\n\n```shell yarn build ``` ```bash npm run-script build ```\n\n\n# unluge kaydetme\n\nthe console.log yontemi artık desteklenmiyor. bunun yerine, turlere logger modulu eklenmistir, bu da cesitli gunluk duzeylerini kabul edebilecek bir gunlukcu destekleyebilecegimiz anlamına gelir.\n\nlogger.info('bilgi duzeyi mesajı');\nlogger.debug('hata ayıklayıcı duzeyi iletisi');\nlogger.warn('uyarı duzeyi iletisi');\n\n\n1\n2\n3\n\n\nlogger.info veya logger.warn kullanmak icin, satırı esleme dosyanıza yerlestirmeniz yeterlidir.\n\n\n\nlogger.debug kullanmak icin ek bir adım gerekir. komut satırınıza --log-level=debug ekleyin.\n\ndocker kapsayıcısı calıstırıyorsanız, bu satırı docker-compose.yaml dosyanıza ekleyin.\n\n\n\nsimdi terminal ekranında yeni gunluge kaydetmeyi gormeniz gerekir.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Bildirim Dosyası",frontmatter:{summary:"Bildirim Dosyası Manifest project.yaml dosyası projenizin giriş noktası olarak görülebilir ve SubQuery'nin zincir verilerini nasıl dizine alacağı ve dönüştüreceğine ilişkin ayrıntı",meta:[{property:"og:url",content:"/tr/create/manifest.html"},{property:"og:title",content:"Bildirim Dosyası"},{property:"og:description",content:"Bildirim Dosyası Manifest project.yaml dosyası projenizin giriş noktası olarak görülebilir ve SubQuery'nin zincir verilerini nasıl dizine alacağı ve dönüştüreceğine ilişkin ayrıntı"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/create/manifest.html",relativePath:"tr/create/manifest.md",key:"v-5779a577",path:"/tr/create/manifest/",headers:[{level:2,title:"Ağ Filtreleri",slug:"ag-filtreleri",normalizedTitle:"ag filtreleri",charIndex:2011},{level:2,title:"Eşleme Filtreleri",slug:"esleme-filtreleri",normalizedTitle:"esleme filtreleri",charIndex:3315},{level:2,title:"Özel Zincirler",slug:"ozel-zincirler",normalizedTitle:"ozel zincirler",charIndex:4710}],readingTime:{minutes:2.26,words:677},headersStr:"Ağ Filtreleri Eşleme Filtreleri Özel Zincirler",content:'# Bildirim Dosyası\n\nManifest project.yaml dosyası projenizin giriş noktası olarak görülebilir ve SubQuery\'nin zincir verilerini nasıl dizine alacağı ve dönüştüreceğine ilişkin ayrıntıların çoğunu tanımlar.\n\nBildirim YAML veya JSON biçiminde olabilir. Bu belgede, tüm örneklerde YAML kullanacağız. Aşağıda temel project.yaml standart bir örneği verilmiştir.\n\nspecVersion: "0.0.1"\naçıklama: ""\ndepo: "https://github.com/subquery/subql-starter"\n\nşema: "./schema.graphql"\n\nağ:\n  uç nokta: "wss://polkadot.api.onfinality.io/public-ws"\n  # İsteğe bağlı olarak, işlemeyi hızlandırmak için tam zincir sözlüğün HTTP uç noktasını sağlayın\n  sözlük: "https://api.subquery.network/sq/subquery/dictionary-polkadot"  veri Kaynakları:\n  - adı: ana\n    tür: substrat/Çalışma Zamanı\n    startBlock: 1\n    eşleme:\n      Işleyici:\n        - işleyici: handleBlock\n          tür: substrat/BlockHandler\n        - işleyici: handleEvent\n          tür: substrat/EventHandler\n          filtre: #Filter isteğe bağlıdır, ancak olay işlemeyi hızlandırması önerilir\n            modül: dengeler\n            yöntem: Depozito\n        - işleyici: handleCall\n          tür: substrat/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n * network.endpoint, dizine eklenecek blok zincirinin wss veya ws uç noktasını tanımlar - Bu tam bir arşiv düğümü olmalıdır.\n * network.dictionary isteğe bağlı olarak işlemeyi hızlandırmak için tam zincir sözlüğün HTTP uç noktasını sağlar - bkz Indexer çalıştırma.\n * dataSources filtre uygulanacak ve ayıklanacak verileri ve uygulanacak veri dönüşümü için eşleme işlevi işleyicisinin konumunu tanımlar.\n   * kind şimdilik yalnızca substrate/Runtime destekler.\n   * startBlock dizine eklenmeye başlanmasının blok yüksekliğini belirtir.\n   * filter, ağ uç noktası belirtimi adına göre yürütülecek veri kaynağına filtre uygular, bkz <>1>network filtreleri\n   * mapping.handlers tüm mapping işlevlerini ve bunlara karşılık gelen işleyici türlerini ek mapping filtreleri ile listeler.\n\n\n# Ağ Filtreleri\n\nGenellikle kullanıcı bir SubQuery oluşturur ve bunu hem testnet hem de mainnet ortamları (örneğin Polkadot ve Kusama) için yeniden kullanmayı bekler. Ağlar arasında, çeşitli seçeneklerin farklı olması muhtemeldir (örneğin, dizin başlangıç bloğu). Bu nedenle, kullanıcıların her veri kaynağı için farklı ayrıntılar tanımlamasına izin veririz, bu da bir SubQuery projesinin birden çok ağda hala kullanılabileceği anlamına gelir.\n\nKullanıcılar, her ağda hangi veri kaynağının çalıştıracağına karar vermek için dataSources filter ekleyebilir.\n\nAşağıda, hem Polkadot hem de Kusama ağları için farklı veri kaynaklarını gösteren bir örnek verilmiştir.\n\n...\nağ:\n  uç nokta: "wss://polkadot.api.onfinality.io/public-ws"\n\nArtıklığı önlemek için şablon #Create\ntanımlar:\n  eşleme: &\n    Işleyici:\n      - işleyici: handleBlock\n        tür: substrat/BlockHandlerveri Kaynakları:\n  - adı: polkadotRuntime\n    tür: substrat/Çalışma Zamanı\n    filtre: #Optional\n        specName: polkadot\n    startBlock: 1000\n    haritalama: *mymapping #use şablonu burada\n  - adı: kusamaRuntime\n    tür: substrat/Çalışma Zamanı\n    filtre: \n        specName: kusama\n    startBlock: 12000 \n    eşleme: *mymapping # yeniden kullanabilir veya değiştirebilir\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n\n# Eşleme Filtreleri\n\nEşleme filtreleri, hangi bloğun, olayın veya dış öğenin bir eşleme işleyicisini tetikleyeceğine karar vermek için son derece kullanışlı bir özelliktir.\n\nYalnızca filtre koşullarını karşılayan gelen veriler eşleme işlevleri tarafından işlenir. Eşleme filtreleri isteğe bağlıdır, ancak SubQuery projeniz tarafından işlenen veri miktarını önemli ölçüde azalttıkları ve dizin oluşturma performansını artıracakları için önerilir.\n\nÇağrı Işleyicisi\'nden #Example filtresi\nfiltre: \n   modül: dengeler\n   yöntem: Depozito\n   başarı: true\n\n\n1\n2\n3\n4\n5\n\n\nAşağıdaki tabloda, farklı işleyiciler tarafından desteklenen filtreler açıklanmaktadır.\n\nIŞLEYICISI         DESTEKLENEN FILTRE\nBlok işleyicisi    spec Sürümü\nOlay İşleyicisi    module,method\nÇağrı Işleyicisi   module,method ,sasası\n\n * Modül ve yöntem filtreleri herhangi bir substrat tabanlı zincirde desteklenir.\n * success filtresi bir boole değeri alır ve dış çizgiyi başarı durumuna göre filtrelemek için kullanılabilir.\n * specVersion filtresi, bir substrat bloğunun belirtim sürüm aralığını belirtir. Aşağıdaki örneklerde sürüm aralıklarının nasıl ayarlandırılacağı açıklanmaktadır.\n\nfiltre:\n  specVersion: [23, 24] #Index blok ile specVersion 23 ile 24 (dahil) arasında.\n  specVersion: [100] #Index bloğu specVersion büyük veya eşit 100.\n  specVersion: [null, 23] #Index bloğu specVersion küçük veya eşit 23.\n\n\n1\n2\n3\n4\n\n\n\n# Özel Zincirler\n\nproject.yaml zincir türlerini de dahil larak özel zincirlerden veri dizine ekleyebilirsiniz. Bu blok zinciri tarafından desteklenen belirli türleri network.types bildirin. Substrat çalışma zamanı modülleri tarafından kullanılan ek türleri destekliyoruz.\n\ntypesAlias, typesBundle, typesChain ve typesSpec da desteklenir.\n\nspecVersion: "0.0.1"\naçıklama: "Bu subquery Kitty\'nin doğum bilgilerini dizine alır"\ndepo: "https://github.com/onfinality-io/subql-examples"\nşema: "./schema.graphql"\nağ:\n  uç nokta: "ws://host.kittychain.io/public-ws"\n  türleri: {\n    "KittyIndex": "u32",\n    "Kedicik": "[u8; 16]"\n  }# typesChain: { zincir: { Type5: \'example\' } }\n# typesSpec: { spec:  { Type6: \'example\' } }\nveri Kaynakları:\n  - adı: çalışma zamanı\n    tür: substrat/Çalışma Zamanı\n    startBlock: 1\n    filtre: #Optional\n      specName: kitty-chain \n    eşleme:\n      Işleyici:\n        - işleyici: handleKittyBred\n          tür: substrat/CallHandler\n          filtre:\n            modül: kedicikler\n            yöntem: cins\n            başarı: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n',normalizedContent:'# bildirim dosyası\n\nmanifest project.yaml dosyası projenizin giris noktası olarak gorulebilir ve subquery\'nin zincir verilerini nasıl dizine alacagı ve donusturecegine iliskin ayrıntıların cogunu tanımlar.\n\nbildirim yaml veya json biciminde olabilir. bu belgede, tum orneklerde yaml kullanacagız. asagıda temel project.yaml standart bir ornegi verilmistir.\n\nspecversion: "0.0.1"\nacıklama: ""\ndepo: "https://github.com/subquery/subql-starter"\n\nsema: "./schema.graphql"\n\nag:\n  uc nokta: "wss://polkadot.api.onfinality.io/public-ws"\n  # istege baglı olarak, islemeyi hızlandırmak icin tam zincir sozlugun http uc noktasını saglayın\n  sozluk: "https://api.subquery.network/sq/subquery/dictionary-polkadot"  veri kaynakları:\n  - adı: ana\n    tur: substrat/calısma zamanı\n    startblock: 1\n    esleme:\n      isleyici:\n        - isleyici: handleblock\n          tur: substrat/blockhandler\n        - isleyici: handleevent\n          tur: substrat/eventhandler\n          filtre: #filter istege baglıdır, ancak olay islemeyi hızlandırması onerilir\n            modul: dengeler\n            yontem: depozito\n        - isleyici: handlecall\n          tur: substrat/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n * network.endpoint, dizine eklenecek blok zincirinin wss veya ws uc noktasını tanımlar - bu tam bir arsiv dugumu olmalıdır.\n * network.dictionary istege baglı olarak islemeyi hızlandırmak icin tam zincir sozlugun http uc noktasını saglar - bkz indexer calıstırma.\n * datasources filtre uygulanacak ve ayıklanacak verileri ve uygulanacak veri donusumu icin esleme islevi isleyicisinin konumunu tanımlar.\n   * kind simdilik yalnızca substrate/runtime destekler.\n   * startblock dizine eklenmeye baslanmasının blok yuksekligini belirtir.\n   * filter, ag uc noktası belirtimi adına gore yurutulecek veri kaynagına filtre uygular, bkz <>1>network filtreleri\n   * mapping.handlers tum mapping islevlerini ve bunlara karsılık gelen isleyici turlerini ek mapping filtreleri ile listeler.\n\n\n# ag filtreleri\n\ngenellikle kullanıcı bir subquery olusturur ve bunu hem testnet hem de mainnet ortamları (ornegin polkadot ve kusama) icin yeniden kullanmayı bekler. aglar arasında, cesitli seceneklerin farklı olması muhtemeldir (ornegin, dizin baslangıc blogu). bu nedenle, kullanıcıların her veri kaynagı icin farklı ayrıntılar tanımlamasına izin veririz, bu da bir subquery projesinin birden cok agda hala kullanılabilecegi anlamına gelir.\n\nkullanıcılar, her agda hangi veri kaynagının calıstıracagına karar vermek icin datasources filter ekleyebilir.\n\nasagıda, hem polkadot hem de kusama agları icin farklı veri kaynaklarını gosteren bir ornek verilmistir.\n\n...\nag:\n  uc nokta: "wss://polkadot.api.onfinality.io/public-ws"\n\nartıklıgı onlemek icin sablon #create\ntanımlar:\n  esleme: &\n    isleyici:\n      - isleyici: handleblock\n        tur: substrat/blockhandlerveri kaynakları:\n  - adı: polkadotruntime\n    tur: substrat/calısma zamanı\n    filtre: #optional\n        specname: polkadot\n    startblock: 1000\n    haritalama: *mymapping #use sablonu burada\n  - adı: kusamaruntime\n    tur: substrat/calısma zamanı\n    filtre: \n        specname: kusama\n    startblock: 12000 \n    esleme: *mymapping # yeniden kullanabilir veya degistirebilir\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n\n# esleme filtreleri\n\nesleme filtreleri, hangi blogun, olayın veya dıs ogenin bir esleme isleyicisini tetikleyecegine karar vermek icin son derece kullanıslı bir ozelliktir.\n\nyalnızca filtre kosullarını karsılayan gelen veriler esleme islevleri tarafından islenir. esleme filtreleri istege baglıdır, ancak subquery projeniz tarafından islenen veri miktarını onemli olcude azalttıkları ve dizin olusturma performansını artıracakları icin onerilir.\n\ncagrı isleyicisi\'nden #example filtresi\nfiltre: \n   modul: dengeler\n   yontem: depozito\n   basarı: true\n\n\n1\n2\n3\n4\n5\n\n\nasagıdaki tabloda, farklı isleyiciler tarafından desteklenen filtreler acıklanmaktadır.\n\nisleyicisi         desteklenen filtre\nblok isleyicisi    spec surumu\nolay isleyicisi    module,method\ncagrı isleyicisi   module,method ,sasası\n\n * modul ve yontem filtreleri herhangi bir substrat tabanlı zincirde desteklenir.\n * success filtresi bir boole degeri alır ve dıs cizgiyi basarı durumuna gore filtrelemek icin kullanılabilir.\n * specversion filtresi, bir substrat blogunun belirtim surum aralıgını belirtir. asagıdaki orneklerde surum aralıklarının nasıl ayarlandırılacagı acıklanmaktadır.\n\nfiltre:\n  specversion: [23, 24] #index blok ile specversion 23 ile 24 (dahil) arasında.\n  specversion: [100] #index blogu specversion buyuk veya esit 100.\n  specversion: [null, 23] #index blogu specversion kucuk veya esit 23.\n\n\n1\n2\n3\n4\n\n\n\n# ozel zincirler\n\nproject.yaml zincir turlerini de dahil larak ozel zincirlerden veri dizine ekleyebilirsiniz. bu blok zinciri tarafından desteklenen belirli turleri network.types bildirin. substrat calısma zamanı modulleri tarafından kullanılan ek turleri destekliyoruz.\n\ntypesalias, typesbundle, typeschain ve typesspec da desteklenir.\n\nspecversion: "0.0.1"\nacıklama: "bu subquery kitty\'nin dogum bilgilerini dizine alır"\ndepo: "https://github.com/onfinality-io/subql-examples"\nsema: "./schema.graphql"\nag:\n  uc nokta: "ws://host.kittychain.io/public-ws"\n  turleri: {\n    "kittyindex": "u32",\n    "kedicik": "[u8; 16]"\n  }# typeschain: { zincir: { type5: \'example\' } }\n# typesspec: { spec:  { type6: \'example\' } }\nveri kaynakları:\n  - adı: calısma zamanı\n    tur: substrat/calısma zamanı\n    startblock: 1\n    filtre: #optional\n      specname: kitty-chain \n    esleme:\n      isleyici:\n        - isleyici: handlekittybred\n          tur: substrat/callhandler\n          filtre:\n            modul: kedicikler\n            yontem: cins\n            basarı: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Eşleme",frontmatter:{summary:"Eşleme Eşleme işlevleri, zincir verilerinin daha önce schema.graphql dosyasında tanımladığımız optimize edilmiş GraphQL varlıklarına nasıl dönüştürüleceğini tanımlar. Eşlemeler, WA",meta:[{property:"og:url",content:"/tr/create/mapping.html"},{property:"og:title",content:"Eşleme"},{property:"og:description",content:"Eşleme Eşleme işlevleri, zincir verilerinin daha önce schema.graphql dosyasında tanımladığımız optimize edilmiş GraphQL varlıklarına nasıl dönüştürüleceğini tanımlar. Eşlemeler, WA"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/create/mapping.html",relativePath:"tr/create/mapping.md",key:"v-43abd9ed",path:"/tr/create/mapping/",headers:[{level:2,title:"Blok işleyicisi",slug:"blok-isleyicisi",normalizedTitle:"blok isleyicisi",charIndex:578},{level:2,title:"Olay İşleyicisi",slug:"olay-isleyicisi",normalizedTitle:"olay isleyicisi",charIndex:1281},{level:2,title:"Çağrı Işleyicisi",slug:"cagrı-isleyicisi",normalizedTitle:"cagrı isleyicisi",charIndex:2492},{level:2,title:"Sorgu Durumları",slug:"sorgu-durumları",normalizedTitle:"sorgu durumları",charIndex:3090},{level:2,title:"RPC çağrıları",slug:"rpc-cagrıları",normalizedTitle:"rpc cagrıları",charIndex:3987},{level:2,title:"Modüller ve Kitaplıklar",slug:"moduller-ve-kitaplıklar",normalizedTitle:"moduller ve kitaplıklar",charIndex:4987},{level:3,title:"Yerleşik modüller",slug:"yerlesik-moduller",normalizedTitle:"yerlesik moduller",charIndex:5457},{level:3,title:"Üçüncü taraf kitaplıkları",slug:"ucuncu-taraf-kitaplıkları",normalizedTitle:"ucuncu taraf kitaplıkları",charIndex:6149},{level:2,title:"Özel Substrat Zincirleri",slug:"ozel-substrat-zincirleri",normalizedTitle:"ozel substrat zincirleri",charIndex:4914},{level:3,title:"Hazırlık",slug:"hazırlık",normalizedTitle:"hazırlık",charIndex:6943},{level:3,title:"Tür oluşturma",slug:"tur-olusturma",normalizedTitle:"tur olusturma",charIndex:10423},{level:3,title:"Kullanım",slug:"kullanım",normalizedTitle:"kullanım",charIndex:11674},{level:3,title:"Özel zincir rpc çağrıları",slug:"ozel-zincir-rpc-cagrıları",normalizedTitle:"ozel zincir rpc cagrıları",charIndex:11937}],readingTime:{minutes:5.91,words:1773},headersStr:"Blok işleyicisi Olay İşleyicisi Çağrı Işleyicisi Sorgu Durumları RPC çağrıları Modüller ve Kitaplıklar Yerleşik modüller Üçüncü taraf kitaplıkları Özel Substrat Zincirleri Hazırlık Tür oluşturma Kullanım Özel zincir rpc çağrıları",content:'# Eşleme\n\nEşleme işlevleri, zincir verilerinin daha önce schema.graphql dosyasında tanımladığımız optimize edilmiş GraphQL varlıklarına nasıl dönüştürüleceğini tanımlar.\n\nEşlemeler, WASM\'ye (WebAssembly) derlenebilen AssemblyScript adlı TypeScript\'in bir alt kümesine yazılır.\n\n * Eşlemeler src/mappings dizininde tanımlanır ve işlev olarak verilir\n * Bu eşlemeler ayrıca src/index.ts</0 olarak da verilir></li> <li>Eşleme dosyaları, eşleme işleyicileri altında <code>project.yaml başvurudur.\n\nEşleme işlevlerinin üç sınıfı vardır; >, Evli İşlercileri ve Call Işleyicileri.\n\n\n# Blok işleyicisi\n\nAlt tabaka zincirine her yeni blok eklendiğinde bilgi yakalamak için blok işleyicilerini kullanabilirsiniz. Bunu başarmak için, tanımlanan bir BlockHandler her blok için bir kez çağrılır.\n\n{SubstrateBlock} öğesini "@subql/türler"den alın;\n\nzaman uyumsuz işlev tanıtıcısını dışa aktarmaBlock(blok: SubstrateBlock): Promise<void> {\n    Kimliği olduğu için blok karmasıyla yeni bir StarterEntity oluşturma\n    const record = yeni starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nSubstrate Block, signedBlock genişletilmiş bir arabirim türüdür, ancak spec Version ve timestamp içerir.\n\n\n# Olay İşleyicisi\n\nBelirli olaylar yeni bir bloğa eklendiğinde bilgi yakalamak için olay işleyicilerini kullanabilirsiniz. Varsayılan Substrat çalışma zamanının ve bir bloğun parçası olan olaylar birden çok olay içerebilir.\n\nİşlem sırasında, olay işleyicisi, olayın yazılan girişleri ve çıktılarıyla bağımsız değişken olarak bir alt tabaka olayı alır. Her türlü olay eşlemeyi tetikleyerek veri kaynağıyla etkinliğin yakalanmasına izin verir. Verileri dizine alma süresini azaltmak ve eşleme performansını artırmak için olayları filtrelemek için bildiriminizde Mapping Filters kullanmalısınız.\n\n{Substrate Event} öğesini "@subql/türler"den alın;\n\nzaman uyumsuz işlevini dışa aktarma handleEvent(olay: SubstratEvent): Promise<void> {\n    const {olay: {data: [account, balance]}} = olay;\n    // Kaydı kimliğine göre alma\n    const record = yeni starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (Bakiye olarak denge).toBigInt();\n    record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nSubstrateEvent Event Record genişletilmiş arabirim türüdür. Olay verilerinin yanı sıra, bir id (bu olayın ait olduğu blok) ve bu bloğun dışsal iç kısmını da içerir.\n\n\n# Çağrı Işleyicisi\n\nÇağrı işleyicileri, belirli substrat dış değerleri hakkında bilgi yakalamak istediğinizde kullanılır.\n\nzaman uyumsuz işlev tanıtıcısını dışa aktarmaCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = yeni starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nSubstrateExtrinsic, GenericExtrinsic\'i genişletir. Bir id (bu dış öğenin ait olduğu blok) atanır ve olayları bu blok arasında genişleten dışsal bir özellik sağlar. Ayrıca, bu dışsal başarı durumunu kaydeder.\n\n\n# Sorgu Durumları\n\nAmacımız, işleyicileri eşlemek için kullanıcılar için tüm veri kaynaklarını kapsamaktır (yukarıdaki üç arabirim olay türünden daha fazlası). Bu nedenle, yetenekleri artırmak için @polkadot /api arabirimlerinden bazılarını kullanıma açtık.\n\nŞu anda desteklediğimiz arayüzler şunlardır:\n\n * api.query. . () current bloğunu sorgular.\n * api.query. . .multi() geçerli blokta same türünde birden çok sorgu yapar.\n * api.queryMulti() geçerli blokta different türlerinin birden çok sorgusunu yapar.\n\nŞu anda desteklediğimiz NOT arabirimler şunlardır:\n\n * ~~api.tx.*~\n * api.derive.*\n * api. sorgu. . .at\n * api.query. . .tries Şunda\n * api.query. . .tries Sayfalı\n * api.query. . . karma\n * ~~api.query. . .keys At ~~\n * api.query. . tuşları Sayfalı\n * api.query. . menzil\n * ~~api.query. . .size ~ ~\n\nBu API\'> validator-threshold örnek kullanım örneğimizde kullanma örneğine bakın.\n\n\n# RPC çağrıları\n\nAyrıca, eşleme işlevinin gerçek düğüm, sorgu ve gönderim ile etkileşime girmesine izin veren uzaktan çağrılar olan bazı API RPC yöntemlerini de destekliyoruz. SubQuery\'nin temel öncülü, deterministik olmasıdır ve bu nedenle sonuçları tutarlı tutmak için yalnızca geçmiş RPC çağrılarına izin veririz.\n\nJSON-RPC belgeler< giriş parametresi olarak BlockHash alan bazı yöntemler sağlar (örneğin, at?: BlockHash). Bu yöntemleri, varsayılan olarak geçerli dizin oluşturma bloğu karmasını alacak şekilde de değiştirdik.\n\n// Diyelim ki şu anda bu karma numaraya sahip bir bloğu dizine ekleniyoruz\nconst blockhash = \'0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a\';\n\n// Özgün yöntemin isteğe bağlı girişi vardır: blok karma\nconst b1 = api.rpc.chain.getBlock(blockhash) bekliyoruz;\n\n// Geçerli bloğun varsayılan olarak böyle olduğunu kullanır\nconst b2 = api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * Özel Substrat Zincirleri RPC çağrıları için kullanım konusuna bakın.\n\n\n# Modüller ve Kitaplıklar\n\nSubQuery\'nin veri işleme yeteneklerini geliştirmek için, NodeJS\'in sandbox eşleme işlevlerini çalıştırmak için yerleşik modüllerinden bazılarına izin verdik ve kullanıcıların üçüncü taraf kitaplıkları aramasına izin verdik.\n\nBunun ** deneysel bir özellik olduğunu unutmayın** ve eşleme işlevlerinizi olumsuz yönde etkileyebilecek hatalar veya sorunlarla karşılaşabilirsiniz. Lütfen GitHub bir sorun oluşturarak bulduğunuz hataları bildirin.\n\n\n# Yerleşik modüller\n\nŞu anda, aşağıdaki NodeJS modüllerine izin <: assert, buffer, crypto, util ve path.\n\nModülün tamamını almak yerine, yalnızca ihtiyacınız olan gerekli yöntemleri almanızı öneririz. Bu modüllerdeki bazı yöntemlerin desteklenmeyen bağımlılıkları olabilir ve alma işlemi başarısız olur.\n\n{hash Message} öğesini "ethers/lib/utils" öğesinden alın; İyi yol\n{utils} öğesini "ethers" //Bad way öğesinden alma\n\nzaman uyumsuz işlev tanıtıcısını dışa aktarmaCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = yeni starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = karmaMessage(\'Merhaba\');\n    record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Üçüncü taraf kitaplıkları\n\nSanal makinenin sanal alanımızdaki sınırlamaları nedeniyle, şu anda yalnızca CommonJS tarafından yazılmış üçüncü taraf kitaplıkları destekliyoruz.\n\nAyrıca, varsayılan olarak ESM kullanan @polkadot/* gibi hybrid bir kitaplığı da destekliyoruz. Ancak, başka kitaplıklar ESM biçimindeki modüllere bağımlıysa, sanal makine ** </0 değİl> derlenir ve bir hata döndürür.\n\n\n\n\n# Özel Substrat Zincirleri\n\nSubQuery, sadece Polkadot veya Kusama\'da değil, substrat tabanlı herhangi bir zincirde kullanılabilir.\n\nÖzel bir Substrat tabanlı zincir kullanabilirsiniz ve @polkadot/typegen kullanarak türleri, arabirimleri ve ek yöntemleri otomatik olarak içe aktarmak için araçlar sağlıyoruz.\n\nAşağıdaki bölümlerde, entegrasyon sürecini açıklamak için kitty example kullanıyoruz.\n\n\n# Hazırlık\n\nGerekli ve oluşturulan tüm dosyaları depolamak için proje >src klasörü altında yeni bir dizin api arabirimleri oluşturun. Ayrıca, api\'ye kitties modülünden dekorasyon eklemek istediğimiz için api-interfaces/kitties dizini oluşturuyoruz.\n\n# Meta veriler\n\nGerçek API uç noktalarını oluşturmak için meta verilere ihtiyacımız var. Kitty örneğinde, yerel bir testnetinden bir uç nokta kullanırız ve ek türler sağlar. Düğümün meta verilerini HTTP uç noktasından almak için PolkadotJS meta veri kurulumu\'daki adımları izleyin.\n\ncurl -H "İçerik Türü: uygulama/json" -d \'{"id":"1", "jsonrpc":"2.0", "yöntem": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nveya websocket uç noktasından websocat yardımıyla:\n\nWebsocat\'i yükleme\ndemleme yükleme websocat\n\nMeta verileri alma\nyankı state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nArdından, çıktıyı kopyalayıp bir JSON dosyasına yapıştırın. kitty örneğimizde, api-interface/kitty.json oluşturduk.\n\n# Tür tanımları\n\nKullanıcının zincirden belirli türleri ve RPC desteğini bildiğini ve Manifest tanımlandığını varsayıyoruz.\n\ntypes setup aşağıdakileri oluştururuz:\n\n * src/api-interfaces/definitions.ts - bu, tüm alt klasör tanımlarını dışa aktarıyor\n\n\'./kitties/definitions\' dizininden { varsayılan olarak kitties } dışa aktarın;{ default as kitties };\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - kitties modülü için tür tanımları\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Paket\n\n * package.json dosyasına, geliştirme bağımlılığı olarak @polkadot/typegen ve normal bir bağımlılık olarak @polkadot/api eklediğinizden emin olun ( ideal olarak aynı sürüm). Ayrıca, komut dosyalarını çalıştırmamıza yardımcı olmak için geliştirme bağımlılığı olarak ts düğümü ihtiyacımız vardır.\n * Her iki türü de çalıştırmak için komut dosyaları ekliyoruz; generate:defs ve meta veri generate:meta üreteçleri (bu sırada, meta veriler türleri kullanabilir).\n\nİşte package.json basitleştirilmiş bir sürümü. scripts bölümünde paket adının doğru olduğundan ve dizinlerin geçerli olduğundan emin olun.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Tür oluşturma\n\nHazırlık tamamlandıktan sonra, türler ve meta veriler oluşturmaya hazırız. Aşağıdaki komutları çalıştırın:\n\n# Yeni bağımlılıklar yüklemek için iplik\nIplik\n\n# Türler oluştur\niplik oluşturma:defs\n\n\n1\n2\n3\n4\n5\n\n\nHer modül klasöründe (örneğin /kitties), bu modüllerin tanımlarından tüm arayüzleri tanımlayan bir types.ts oluşturulmalıdır, ayrıca bir index dosyası hepsini dışa aktaran.ts.\n\n# Meta veriler oluştur\niplik oluşturma:meta\n\n\n1\n2\n\n\nBu komut meta verileri ve API\'ler için yeni bir api-augment oluşturur. Yerleşik API\'yi kullanmak istemediğimiz için, tsconfig.json açık bir geçersiz kılma ekleyerek bunları değiştirmemiz gerekecektir. Güncelleştirmelerden sonra, yapılandırmadaki yollar şöyle görünecektir (açıklamalar olmadan):\n\n{\n  "compilerOptions": {\n      Bu, kullandığımız paket adıdır (arayüz içe aktarmalarında, --jeneratörler için paket) */\n      "kitty-birthinfo/*": ["src/*"],\n      Burada @polkadot/api büyütmeyi zincirden oluşturulan kendi büyütmemizle değiştiriyoruz\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      tanımlardan oluşturulan artırılmış türleri kendi türlerimizle değiştirin\n      "@polkadot/türleri/büyütme": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Kullanım\n\nŞimdi eşleme işlevinde, meta verilerin ve türlerin API\'yi gerçekte nasıl dekore ederek süslediğini gösterebiliriz. RPC uç noktası yukarıda beyan ettiğimiz modülleri ve yöntemleri destekleyecektir. Ve özel rpc çağrısı kullanmak için, lütfen bölüme bakın Özel zincir rpc çağrıları\n\nzaman uyumsuz işlevini dışa aktarma kittyApiHandler(): Promise<void> {\n    KittyIndex türünü döndürme\n    const nextKittyId = api.query.kitties.nextKittyId();\n    Kitty türünü döndürür, giriş parametreleri türleri AccountId ve KittyIndex\'tir\n    const allKitties = api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(\'Sonraki pisi kimliği ${nextKittyId}\')\n    Özel rpc, tanımsız olarak blockhash olarak ayarla\n    const kittyPrice = api.rpc.kitties.getKittyPrice(tanımsız,nextKittyId) bekliyoruz;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nBu projeyi gezginimize yayınlamak istiyorsanız, lütfen oluşturulan dosyaları src/api-interfaces ekleyin.\n\n\n# Özel zincir rpc çağrıları\n\nÖzelleştirilmiş zincir RPC çağrılarını desteklemek için, typesBundle için RPC tanımlarını el ile eklemeli ve her belirti için yapılandırmaya izin vermeliyiz. project.yml< typesBundle tanımlayabilirsiniz. Ve lütfen yalnızca isHistoric tür çağrıların desteklendiğini unutmayın.\n\n...\n  türleri: {\n    "KittyIndex": "u32",\n    "Kedicik": "[u8; 16]",\n  }\n  types Bundle: {\n    spec: {\n      zincir adı: {\n        rpc: {\n          kedicikler: {\n            getKittyPrice:{\n                açıklama: dize,\n                params: [\n                  {\n                    adı: \'at\',\n                    türü: \'BlockHash\',\n                    isHistoric: doğru,\n                    isOptional: false\n                  },\n                  {\n                    adı: \'kittyIndex\',\n                    türü: \'KittyIndex\',\n                    isOptional: false  }\n                ],\n                türü: "Bakiye",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n',normalizedContent:'# esleme\n\nesleme islevleri, zincir verilerinin daha once schema.graphql dosyasında tanımladıgımız optimize edilmis graphql varlıklarına nasıl donusturulecegini tanımlar.\n\neslemeler, wasm\'ye (webassembly) derlenebilen assemblyscript adlı typescript\'in bir alt kumesine yazılır.\n\n * eslemeler src/mappings dizininde tanımlanır ve islev olarak verilir\n * bu eslemeler ayrıca src/index.ts</0 olarak da verilir></li> <li>esleme dosyaları, esleme isleyicileri altında <code>project.yaml basvurudur.\n\nesleme islevlerinin uc sınıfı vardır; >, evli islercileri ve call isleyicileri.\n\n\n# blok isleyicisi\n\nalt tabaka zincirine her yeni blok eklendiginde bilgi yakalamak icin blok isleyicilerini kullanabilirsiniz. bunu basarmak icin, tanımlanan bir blockhandler her blok icin bir kez cagrılır.\n\n{substrateblock} ogesini "@subql/turler"den alın;\n\nzaman uyumsuz islev tanıtıcısını dısa aktarmablock(blok: substrateblock): promise<void> {\n    kimligi oldugu icin blok karmasıyla yeni bir starterentity olusturma\n    const record = yeni starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nsubstrate block, signedblock genisletilmis bir arabirim turudur, ancak spec version ve timestamp icerir.\n\n\n# olay isleyicisi\n\nbelirli olaylar yeni bir bloga eklendiginde bilgi yakalamak icin olay isleyicilerini kullanabilirsiniz. varsayılan substrat calısma zamanının ve bir blogun parcası olan olaylar birden cok olay icerebilir.\n\nislem sırasında, olay isleyicisi, olayın yazılan girisleri ve cıktılarıyla bagımsız degisken olarak bir alt tabaka olayı alır. her turlu olay eslemeyi tetikleyerek veri kaynagıyla etkinligin yakalanmasına izin verir. verileri dizine alma suresini azaltmak ve esleme performansını artırmak icin olayları filtrelemek icin bildiriminizde mapping filters kullanmalısınız.\n\n{substrate event} ogesini "@subql/turler"den alın;\n\nzaman uyumsuz islevini dısa aktarma handleevent(olay: substratevent): promise<void> {\n    const {olay: {data: [account, balance]}} = olay;\n    // kaydı kimligine gore alma\n    const record = yeni starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (bakiye olarak denge).tobigint();\n    record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nsubstrateevent event record genisletilmis arabirim turudur. olay verilerinin yanı sıra, bir id (bu olayın ait oldugu blok) ve bu blogun dıssal ic kısmını da icerir.\n\n\n# cagrı isleyicisi\n\ncagrı isleyicileri, belirli substrat dıs degerleri hakkında bilgi yakalamak istediginizde kullanılır.\n\nzaman uyumsuz islev tanıtıcısını dısa aktarmacall(extrinsic: substrateextrinsic): promise<void> {\n    const record = yeni starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nsubstrateextrinsic, genericextrinsic\'i genisletir. bir id (bu dıs ogenin ait oldugu blok) atanır ve olayları bu blok arasında genisleten dıssal bir ozellik saglar. ayrıca, bu dıssal basarı durumunu kaydeder.\n\n\n# sorgu durumları\n\namacımız, isleyicileri eslemek icin kullanıcılar icin tum veri kaynaklarını kapsamaktır (yukarıdaki uc arabirim olay turunden daha fazlası). bu nedenle, yetenekleri artırmak icin @polkadot /api arabirimlerinden bazılarını kullanıma actık.\n\nsu anda destekledigimiz arayuzler sunlardır:\n\n * api.query. . () current blogunu sorgular.\n * api.query. . .multi() gecerli blokta same turunde birden cok sorgu yapar.\n * api.querymulti() gecerli blokta different turlerinin birden cok sorgusunu yapar.\n\nsu anda destekledigimiz not arabirimler sunlardır:\n\n * ~~api.tx.*~\n * api.derive.*\n * api. sorgu. . .at\n * api.query. . .tries sunda\n * api.query. . .tries sayfalı\n * api.query. . . karma\n * ~~api.query. . .keys at ~~\n * api.query. . tusları sayfalı\n * api.query. . menzil\n * ~~api.query. . .size ~ ~\n\nbu api\'> validator-threshold ornek kullanım ornegimizde kullanma ornegine bakın.\n\n\n# rpc cagrıları\n\nayrıca, esleme islevinin gercek dugum, sorgu ve gonderim ile etkilesime girmesine izin veren uzaktan cagrılar olan bazı api rpc yontemlerini de destekliyoruz. subquery\'nin temel onculu, deterministik olmasıdır ve bu nedenle sonucları tutarlı tutmak icin yalnızca gecmis rpc cagrılarına izin veririz.\n\njson-rpc belgeler< giris parametresi olarak blockhash alan bazı yontemler saglar (ornegin, at?: blockhash). bu yontemleri, varsayılan olarak gecerli dizin olusturma blogu karmasını alacak sekilde de degistirdik.\n\n// diyelim ki su anda bu karma numaraya sahip bir blogu dizine ekleniyoruz\nconst blockhash = \'0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a\';\n\n// ozgun yontemin istege baglı girisi vardır: blok karma\nconst b1 = api.rpc.chain.getblock(blockhash) bekliyoruz;\n\n// gecerli blogun varsayılan olarak boyle oldugunu kullanır\nconst b2 = api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * ozel substrat zincirleri rpc cagrıları icin kullanım konusuna bakın.\n\n\n# moduller ve kitaplıklar\n\nsubquery\'nin veri isleme yeteneklerini gelistirmek icin, nodejs\'in sandbox esleme islevlerini calıstırmak icin yerlesik modullerinden bazılarına izin verdik ve kullanıcıların ucuncu taraf kitaplıkları aramasına izin verdik.\n\nbunun ** deneysel bir ozellik oldugunu unutmayın** ve esleme islevlerinizi olumsuz yonde etkileyebilecek hatalar veya sorunlarla karsılasabilirsiniz. lutfen github bir sorun olusturarak buldugunuz hataları bildirin.\n\n\n# yerlesik moduller\n\nsu anda, asagıdaki nodejs modullerine izin <: assert, buffer, crypto, util ve path.\n\nmodulun tamamını almak yerine, yalnızca ihtiyacınız olan gerekli yontemleri almanızı oneririz. bu modullerdeki bazı yontemlerin desteklenmeyen bagımlılıkları olabilir ve alma islemi basarısız olur.\n\n{hash message} ogesini "ethers/lib/utils" ogesinden alın; iyi yol\n{utils} ogesini "ethers" //bad way ogesinden alma\n\nzaman uyumsuz islev tanıtıcısını dısa aktarmacall(extrinsic: substrateextrinsic): promise<void> {\n    const record = yeni starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = karmamessage(\'merhaba\');\n    record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# ucuncu taraf kitaplıkları\n\nsanal makinenin sanal alanımızdaki sınırlamaları nedeniyle, su anda yalnızca commonjs tarafından yazılmıs ucuncu taraf kitaplıkları destekliyoruz.\n\nayrıca, varsayılan olarak esm kullanan @polkadot/* gibi hybrid bir kitaplıgı da destekliyoruz. ancak, baska kitaplıklar esm bicimindeki modullere bagımlıysa, sanal makine ** </0 degil> derlenir ve bir hata dondurur.\n\n\n\n\n# ozel substrat zincirleri\n\nsubquery, sadece polkadot veya kusama\'da degil, substrat tabanlı herhangi bir zincirde kullanılabilir.\n\nozel bir substrat tabanlı zincir kullanabilirsiniz ve @polkadot/typegen kullanarak turleri, arabirimleri ve ek yontemleri otomatik olarak ice aktarmak icin araclar saglıyoruz.\n\nasagıdaki bolumlerde, entegrasyon surecini acıklamak icin kitty example kullanıyoruz.\n\n\n# hazırlık\n\ngerekli ve olusturulan tum dosyaları depolamak icin proje >src klasoru altında yeni bir dizin api arabirimleri olusturun. ayrıca, api\'ye kitties modulunden dekorasyon eklemek istedigimiz icin api-interfaces/kitties dizini olusturuyoruz.\n\n# meta veriler\n\ngercek api uc noktalarını olusturmak icin meta verilere ihtiyacımız var. kitty orneginde, yerel bir testnetinden bir uc nokta kullanırız ve ek turler saglar. dugumun meta verilerini http uc noktasından almak icin polkadotjs meta veri kurulumu\'daki adımları izleyin.\n\ncurl -h "icerik turu: uygulama/json" -d \'{"id":"1", "jsonrpc":"2.0", "yontem": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nveya websocket uc noktasından websocat yardımıyla:\n\nwebsocat\'i yukleme\ndemleme yukleme websocat\n\nmeta verileri alma\nyankı state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nardından, cıktıyı kopyalayıp bir json dosyasına yapıstırın. kitty ornegimizde, api-interface/kitty.json olusturduk.\n\n# tur tanımları\n\nkullanıcının zincirden belirli turleri ve rpc destegini bildigini ve manifest tanımlandıgını varsayıyoruz.\n\ntypes setup asagıdakileri olustururuz:\n\n * src/api-interfaces/definitions.ts - bu, tum alt klasor tanımlarını dısa aktarıyor\n\n\'./kitties/definitions\' dizininden { varsayılan olarak kitties } dısa aktarın;{ default as kitties };\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - kitties modulu icin tur tanımları\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# paket\n\n * package.json dosyasına, gelistirme bagımlılıgı olarak @polkadot/typegen ve normal bir bagımlılık olarak @polkadot/api eklediginizden emin olun ( ideal olarak aynı surum). ayrıca, komut dosyalarını calıstırmamıza yardımcı olmak icin gelistirme bagımlılıgı olarak ts dugumu ihtiyacımız vardır.\n * her iki turu de calıstırmak icin komut dosyaları ekliyoruz; generate:defs ve meta veri generate:meta uretecleri (bu sırada, meta veriler turleri kullanabilir).\n\niste package.json basitlestirilmis bir surumu. scripts bolumunde paket adının dogru oldugundan ve dizinlerin gecerli oldugundan emin olun.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# tur olusturma\n\nhazırlık tamamlandıktan sonra, turler ve meta veriler olusturmaya hazırız. asagıdaki komutları calıstırın:\n\n# yeni bagımlılıklar yuklemek icin iplik\niplik\n\n# turler olustur\niplik olusturma:defs\n\n\n1\n2\n3\n4\n5\n\n\nher modul klasorunde (ornegin /kitties), bu modullerin tanımlarından tum arayuzleri tanımlayan bir types.ts olusturulmalıdır, ayrıca bir index dosyası hepsini dısa aktaran.ts.\n\n# meta veriler olustur\niplik olusturma:meta\n\n\n1\n2\n\n\nbu komut meta verileri ve api\'ler icin yeni bir api-augment olusturur. yerlesik api\'yi kullanmak istemedigimiz icin, tsconfig.json acık bir gecersiz kılma ekleyerek bunları degistirmemiz gerekecektir. guncellestirmelerden sonra, yapılandırmadaki yollar soyle gorunecektir (acıklamalar olmadan):\n\n{\n  "compileroptions": {\n      bu, kullandıgımız paket adıdır (arayuz ice aktarmalarında, --jeneratorler icin paket) */\n      "kitty-birthinfo/*": ["src/*"],\n      burada @polkadot/api buyutmeyi zincirden olusturulan kendi buyutmemizle degistiriyoruz\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      tanımlardan olusturulan artırılmıs turleri kendi turlerimizle degistirin\n      "@polkadot/turleri/buyutme": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# kullanım\n\nsimdi esleme islevinde, meta verilerin ve turlerin api\'yi gercekte nasıl dekore ederek susledigini gosterebiliriz. rpc uc noktası yukarıda beyan ettigimiz modulleri ve yontemleri destekleyecektir. ve ozel rpc cagrısı kullanmak icin, lutfen bolume bakın ozel zincir rpc cagrıları\n\nzaman uyumsuz islevini dısa aktarma kittyapihandler(): promise<void> {\n    kittyindex turunu dondurme\n    const nextkittyid = api.query.kitties.nextkittyid();\n    kitty turunu dondurur, giris parametreleri turleri accountid ve kittyindex\'tir\n    const allkitties = api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(\'sonraki pisi kimligi ${nextkittyid}\')\n    ozel rpc, tanımsız olarak blockhash olarak ayarla\n    const kittyprice = api.rpc.kitties.getkittyprice(tanımsız,nextkittyid) bekliyoruz;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nbu projeyi gezginimize yayınlamak istiyorsanız, lutfen olusturulan dosyaları src/api-interfaces ekleyin.\n\n\n# ozel zincir rpc cagrıları\n\nozellestirilmis zincir rpc cagrılarını desteklemek icin, typesbundle icin rpc tanımlarını el ile eklemeli ve her belirti icin yapılandırmaya izin vermeliyiz. project.yml< typesbundle tanımlayabilirsiniz. ve lutfen yalnızca ishistoric tur cagrıların desteklendigini unutmayın.\n\n...\n  turleri: {\n    "kittyindex": "u32",\n    "kedicik": "[u8; 16]",\n  }\n  types bundle: {\n    spec: {\n      zincir adı: {\n        rpc: {\n          kedicikler: {\n            getkittyprice:{\n                acıklama: dize,\n                params: [\n                  {\n                    adı: \'at\',\n                    turu: \'blockhash\',\n                    ishistoric: dogru,\n                    isoptional: false\n                  },\n                  {\n                    adı: \'kittyindex\',\n                    turu: \'kittyindex\',\n                    isoptional: false  }\n                ],\n                turu: "bakiye",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Sıkça Sorulan Sorular",frontmatter:{summary:"Sıkça Sorulan Sorular SubQuery nedir? SubQuery, geliştiricilerin uygulamalarını güç sağlamak için Substrat zinciri verilerini dizine almalarına, dönüştürmelerine ve sorgulamalarına",meta:[{property:"og:url",content:"/tr/faqs/faqs.html"},{property:"og:title",content:"Sıkça Sorulan Sorular"},{property:"og:description",content:"Sıkça Sorulan Sorular SubQuery nedir? SubQuery, geliştiricilerin uygulamalarını güç sağlamak için Substrat zinciri verilerini dizine almalarına, dönüştürmelerine ve sorgulamalarına"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/faqs/faqs.html",relativePath:"tr/faqs/faqs.md",key:"v-f74c83c6",path:"/tr/faqs/faqs/",headers:[{level:2,title:"SubQuery nedir?",slug:"subquery-nedir",normalizedTitle:"subquery nedir?",charIndex:28},{level:2,title:"SubQuery'ye başlamanın en iyi yolu nedir?",slug:"subquery-ye-baslamanın-en-iyi-yolu-nedir",normalizedTitle:"subquery'ye baslamanın en iyi yolu nedir?",charIndex:455},{level:2,title:"SubQuery'ye nasıl katkıda bulunabilir veya geri bildirimde bulunabilirim?",slug:"subquery-ye-nasıl-katkıda-bulunabilir-veya-geri-bildirimde-bulunabilirim",normalizedTitle:"subquery'ye nasıl katkıda bulunabilir veya geri bildirimde bulunabilirim?",charIndex:789},{level:2,title:"Projemi SubQuery Projelerinde barındırmanın maliyeti nedir?",slug:"projemi-subquery-projelerinde-barındırmanın-maliyeti-nedir",normalizedTitle:"projemi subquery projelerinde barındırmanın maliyeti nedir?",charIndex:1254},{level:2,title:"Dağıtım yuvaları nelerdir?",slug:"dagıtım-yuvaları-nelerdir",normalizedTitle:"dagıtım yuvaları nelerdir?",charIndex:1546},{level:2,title:"Bir hazırlama yuvasının avantajı nedir?",slug:"bir-hazırlama-yuvasının-avantajı-nedir",normalizedTitle:"bir hazırlama yuvasının avantajı nedir?",charIndex:2237},{level:2,title:"Dışsallar nelerdir?",slug:"dıssallar-nelerdir",normalizedTitle:"dıssallar nelerdir?",charIndex:2738},{level:2,title:"Kusama ağı için son nokta nedir?",slug:"kusama-agı-icin-son-nokta-nedir",normalizedTitle:"kusama agı icin son nokta nedir?",charIndex:3602},{level:2,title:"Polkadot ana ağ ağının bitiş noktası nedir?",slug:"polkadot-ana-ag-agının-bitis-noktası-nedir",normalizedTitle:"polkadot ana ag agının bitis noktası nedir?",charIndex:3719}],readingTime:{minutes:1.71,words:513},headersStr:"SubQuery nedir? SubQuery'ye başlamanın en iyi yolu nedir? SubQuery'ye nasıl katkıda bulunabilir veya geri bildirimde bulunabilirim? Projemi SubQuery Projelerinde barındırmanın maliyeti nedir? Dağıtım yuvaları nelerdir? Bir hazırlama yuvasının avantajı nedir? Dışsallar nelerdir? Kusama ağı için son nokta nedir? Polkadot ana ağ ağının bitiş noktası nedir?",content:"# Sıkça Sorulan Sorular\n\n\n# SubQuery nedir?\n\nSubQuery, geliştiricilerin uygulamalarını güç sağlamak için Substrat zinciri verilerini dizine almalarına, dönüştürmelerine ve sorgulamalarına olanak tanıyan açık kaynaklı bir projedir.\n\nSubQuery ayrıca geliştiriciler için altyapıyı yönetme sorumluluğunu ortadan kaldıran ve geliştiricilerin en iyi yaptıkları şeyi, yani inşa etmelerini sağlayan ücretsiz, üretim düzeyinde proje barındırma hizmeti sağlar.\n\n\n# SubQuery'ye başlamanın en iyi yolu nedir?\n\nSubQuery'yi kullanmaya başlamanın en iyi yolu, Hello World tutorial denemektir. Bu, başlangıç şablonunu indirme, projeyi oluşturma ve ardından localhost'unuzda bir düğüm çalıştırmak ve basit bir sorgu çalıştırmak için Docker'ı kullanma konusunda basit bir 5 dakikalık gözden geçirmedir.\n\n\n# SubQuery'ye nasıl katkıda bulunabilir veya geri bildirimde bulunabilirim?\n\nTopluluktan gelen katkıları ve geri bildirimleri seviyoruz. Koda katkıda bulunmak için, ilgi alanı deponuzu çatallayın ve değişikliklerinizi yapın. Ardından bir PR veya Çekme İsteği gönderin. Test etmeyi de unutma! Ayrıca katkı yönergelerimize de göz atın (yakında).\n\nGeri bildirimde bulunmak için hello@subquery.network adresinden bizimle iletişime geçin veya discord kanalımıza gelin\n\n\n# Projemi SubQuery Projelerinde barındırmanın maliyeti nedir?\n\nProjenizi SubQuery Projects'te barındırmak tamamen ücretsizdir - bu bizim topluma geri verme yöntemimizdir. Projenizi bizimle nasıl barındıracaklarınızı öğrenmek için lütfen Hello World (SubQuery Hosted) öğreticisine göz atın.\n\n\n# Dağıtım yuvaları nelerdir?\n\nDağıtım yuvaları, bir geliştirme ortamına eşdeğer olan SubQuery Projelerindeki bir özelliktir. Örneğin, herhangi bir yazılım organizasyonunda normalde bir geliştirme ortamı ve minimum olarak bir üretim ortamı vardır (yani localhost yok sayılarak). Tipik olarak, organizasyonun ihtiyaçlarına ve geliştirme kurulumlarına bağlı olarak, aşamalandırma ve üretim öncesi ve hatta QA gibi ek ortamlar dahil edilir.\n\nSubQuery şu anda kullanılabilir iki yuvaya sahiptir. Bir hazırlama yuvası ve bir üretim yuvası. Bu, geliştiricilerin SubQuery hazırlama ortamına dağıtmalarına ve her şey yolunda gidiyor, bir düğmeyi tıklatarak \"üretime terfi etmelerine\" olanak tanır.\n\n\n# Bir hazırlama yuvasının avantajı nedir?\n\nHazırlama yuvası kullanmanın ana yararı, SubQuery projenizin yeni bir sürümünü herkese açık hale getirmeden hazırlamanıza olanak sağlamasıdır. Üretim uygulamalarınızı etkilemeden hazırlama yuvasının tüm verileri yeniden indekslemesini bekleyebilirsiniz.\n\nHazırlama yuvası, Explorer'da herkese gösterilmez ve yalnızca sizin görebileceğiniz benzersiz bir URL'ye sahiptir. Ve elbette, ayrı ortam, üretimi etkilemeden yeni kodunuzu test etmenize olanak tanır.\n\n\n# Dışsallar nelerdir?\n\nBlockchain kavramlarına zaten aşina iseniz, dışsalları işlemlerle karşılaştırılabilir olarak düşünebilirsiniz. Daha resmi olarak, dışsal, zincirin dışından gelen ve bir bloğa dahil edilen bir bilgi parçasıdır. Üç dışsal kategori vardır. Bunlar doğal, imzalı işlemler ve imzasız işlemlerdir.\n\nİçsel dışsal bilgiler, imzalanmayan ve yalnızca blok yazarı tarafından bir bloğa eklenen bilgi parçalarıdır.\n\nİmzalı işlem dışsal öğeleri, işlemi yapan hesabın imzasını içeren işlemlerdir. İşlemin zincire dahil edilmesi için bir ücret ödemeye hazırlar.\n\nİmzalı işlem dışsal öğeleri, işlemi yapan hesabın imzasını içeren işlemlerdir. İmzasız işlemler, imzalı olduğu için ücret ödemeyen kimse olmadığı için dikkatli kullanılmalıdır. Bu nedenle, işlem kuyruğu spam'i önlemek için ekonomik mantıktan yoksundur.\n\nDaha fazla bilgi için buraya tıklayın.\n\n\n# Kusama ağı için son nokta nedir?\n\nKusama ağının network.endpoint'i wss://kusama.api.onfinality.io/public-ws'dir.\n\n\n# Polkadot ana ağ ağının bitiş noktası nedir?\n\nPolkadot ağının network.endpoint'i wss://polkadot.api.onfinality.io/public-ws'dir.",normalizedContent:"# sıkca sorulan sorular\n\n\n# subquery nedir?\n\nsubquery, gelistiricilerin uygulamalarını guc saglamak icin substrat zinciri verilerini dizine almalarına, donusturmelerine ve sorgulamalarına olanak tanıyan acık kaynaklı bir projedir.\n\nsubquery ayrıca gelistiriciler icin altyapıyı yonetme sorumlulugunu ortadan kaldıran ve gelistiricilerin en iyi yaptıkları seyi, yani insa etmelerini saglayan ucretsiz, uretim duzeyinde proje barındırma hizmeti saglar.\n\n\n# subquery'ye baslamanın en iyi yolu nedir?\n\nsubquery'yi kullanmaya baslamanın en iyi yolu, hello world tutorial denemektir. bu, baslangıc sablonunu indirme, projeyi olusturma ve ardından localhost'unuzda bir dugum calıstırmak ve basit bir sorgu calıstırmak icin docker'ı kullanma konusunda basit bir 5 dakikalık gozden gecirmedir.\n\n\n# subquery'ye nasıl katkıda bulunabilir veya geri bildirimde bulunabilirim?\n\ntopluluktan gelen katkıları ve geri bildirimleri seviyoruz. koda katkıda bulunmak icin, ilgi alanı deponuzu catallayın ve degisikliklerinizi yapın. ardından bir pr veya cekme istegi gonderin. test etmeyi de unutma! ayrıca katkı yonergelerimize de goz atın (yakında).\n\ngeri bildirimde bulunmak icin hello@subquery.network adresinden bizimle iletisime gecin veya discord kanalımıza gelin\n\n\n# projemi subquery projelerinde barındırmanın maliyeti nedir?\n\nprojenizi subquery projects'te barındırmak tamamen ucretsizdir - bu bizim topluma geri verme yontemimizdir. projenizi bizimle nasıl barındıracaklarınızı ogrenmek icin lutfen hello world (subquery hosted) ogreticisine goz atın.\n\n\n# dagıtım yuvaları nelerdir?\n\ndagıtım yuvaları, bir gelistirme ortamına esdeger olan subquery projelerindeki bir ozelliktir. ornegin, herhangi bir yazılım organizasyonunda normalde bir gelistirme ortamı ve minimum olarak bir uretim ortamı vardır (yani localhost yok sayılarak). tipik olarak, organizasyonun ihtiyaclarına ve gelistirme kurulumlarına baglı olarak, asamalandırma ve uretim oncesi ve hatta qa gibi ek ortamlar dahil edilir.\n\nsubquery su anda kullanılabilir iki yuvaya sahiptir. bir hazırlama yuvası ve bir uretim yuvası. bu, gelistiricilerin subquery hazırlama ortamına dagıtmalarına ve her sey yolunda gidiyor, bir dugmeyi tıklatarak \"uretime terfi etmelerine\" olanak tanır.\n\n\n# bir hazırlama yuvasının avantajı nedir?\n\nhazırlama yuvası kullanmanın ana yararı, subquery projenizin yeni bir surumunu herkese acık hale getirmeden hazırlamanıza olanak saglamasıdır. uretim uygulamalarınızı etkilemeden hazırlama yuvasının tum verileri yeniden indekslemesini bekleyebilirsiniz.\n\nhazırlama yuvası, explorer'da herkese gosterilmez ve yalnızca sizin gorebileceginiz benzersiz bir url'ye sahiptir. ve elbette, ayrı ortam, uretimi etkilemeden yeni kodunuzu test etmenize olanak tanır.\n\n\n# dıssallar nelerdir?\n\nblockchain kavramlarına zaten asina iseniz, dıssalları islemlerle karsılastırılabilir olarak dusunebilirsiniz. daha resmi olarak, dıssal, zincirin dısından gelen ve bir bloga dahil edilen bir bilgi parcasıdır. uc dıssal kategori vardır. bunlar dogal, imzalı islemler ve imzasız islemlerdir.\n\nicsel dıssal bilgiler, imzalanmayan ve yalnızca blok yazarı tarafından bir bloga eklenen bilgi parcalarıdır.\n\nimzalı islem dıssal ogeleri, islemi yapan hesabın imzasını iceren islemlerdir. islemin zincire dahil edilmesi icin bir ucret odemeye hazırlar.\n\nimzalı islem dıssal ogeleri, islemi yapan hesabın imzasını iceren islemlerdir. imzasız islemler, imzalı oldugu icin ucret odemeyen kimse olmadıgı icin dikkatli kullanılmalıdır. bu nedenle, islem kuyrugu spam'i onlemek icin ekonomik mantıktan yoksundur.\n\ndaha fazla bilgi icin buraya tıklayın.\n\n\n# kusama agı icin son nokta nedir?\n\nkusama agının network.endpoint'i wss://kusama.api.onfinality.io/public-ws'dir.\n\n\n# polkadot ana ag agının bitis noktası nedir?\n\npolkadot agının network.endpoint'i wss://polkadot.api.onfinality.io/public-ws'dir.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/cli tool is used to create SubQuery projects. The @subql/node component is re",meta:[{property:"og:url",content:"/tr/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/cli tool is used to create SubQuery projects. The @subql/node component is re"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/install/install.html",relativePath:"tr/install/install.md",key:"v-4dfa1eed",path:"/tr/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:271},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:650},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1265}],readingTime:{minutes:1.22,words:367},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/cli tool is used to create SubQuery projects. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli tool helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n```shell yarn global add @subql/cli ``` ```bash npm install -g @subql/cli ```\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n```shell yarn global add @subql/node ``` ```bash npm install -g @subql/node ```\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n```shell yarn global add @subql/query ``` ```bash npm install -g @subql/query ```\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/cli tool is used to create subquery projects. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli tool helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n```shell yarn global add @subql/cli ``` ```bash npm install -g @subql/cli ```\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n```shell yarn global add @subql/node ``` ```bash npm install -g @subql/node ```\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n```shell yarn global add @subql/query ``` ```bash npm install -g @subql/query ```\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/tr/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/miscellaneous/ambassadors.html",relativePath:"tr/miscellaneous/ambassadors.md",key:"v-5e4113f9",path:"/tr/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/tr/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/miscellaneous/branding.html",relativePath:"tr/miscellaneous/branding.md",key:"v-7cf5604d",path:"/tr/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/tr/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/miscellaneous/contributing.html",relativePath:"tr/miscellaneous/contributing.md",key:"v-788054ed",path:"/tr/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/tr/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/miscellaneous/social_media.html",relativePath:"tr/miscellaneous/social_media.md",key:"v-0e88bfed",path:"/tr/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529},{level:3,title:"Telegram",slug:"telegram",normalizedTitle:"telegram",charIndex:450}],readingTime:{minutes:.55,words:166},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities Telegram",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.\n\n\n# Telegram\n\nSubQuery Russia SubQuery Russia SubQuery Vietnam SubQuery Vietnam Announcement",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.\n\n\n# telegram\n\nsubquery russia subquery russia subquery vietnam subquery vietnam announcement",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Connect to your new project",frontmatter:{summary:"Connect to your new project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/tr/publish/connect.html"},{property:"og:title",content:"Connect to your new project"},{property:"og:description",content:"Connect to your new project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/publish/connect.html",relativePath:"tr/publish/connect.md",key:"v-5f5b9167",path:"/tr/publish/connect/",readingTime:{minutes:.58,words:174},headersStr:null,content:"# Connect to your new project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Publish your SubQuery project",frontmatter:{summary:"Publish your SubQuery project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/tr/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery project"},{property:"og:description",content:"Publish your SubQuery project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/publish/publish.html",relativePath:"tr/publish/publish.md",key:"v-4daca91d",path:"/tr/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3805},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4260}],readingTime:{minutes:3.68,words:1105},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. We're almost there! We just need to deploy a new version of it.\n\n\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. we're almost there! we just need to deploy a new version of it.\n\n\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Deploy a new version of your SubQuery project",frontmatter:{summary:"Deploy a new version of your SubQuery project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/tr/publish/upgrade.html"},{property:"og:title",content:"Deploy a new version of your SubQuery project"},{property:"og:description",content:"Deploy a new version of your SubQuery project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/publish/upgrade.html",relativePath:"tr/publish/upgrade.md",key:"v-0c590f03",path:"/tr/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:2306}],readingTime:{minutes:1.69,words:506},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a new version of your SubQuery project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLog into SubQuery Project and select the project you want to deploy a new version of. You can choose to either deploy to the production or staging slot. These two slots are isolated environments and each has their own databases and synchronise independently.\n\nWe recommend deploying to your staging slot only for final staging testing or when you need to resync your project data. You can then promote it to production with zero downtime. You will find testing is faster when running a project locally as you can more easily debug issues.\n\nThe staging slot is perfect for:\n\n * Final validation of changes to your SubQuery Project in a separate environment. The staging slot has a different URL to production that you can use in your dApps.\n * Warming up and indexing data for an updated SubQuery project to eliminate downtime in your dApp\n * Preparing a new release for your SubQuery Project without exposing it publicly. The staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlog into subquery project and select the project you want to deploy a new version of. you can choose to either deploy to the production or staging slot. these two slots are isolated environments and each has their own databases and synchronise independently.\n\nwe recommend deploying to your staging slot only for final staging testing or when you need to resync your project data. you can then promote it to production with zero downtime. you will find testing is faster when running a project locally as you can more easily debug issues.\n\nthe staging slot is perfect for:\n\n * final validation of changes to your subquery project in a separate environment. the staging slot has a different url to production that you can use in your dapps.\n * warming up and indexing data for an updated subquery project to eliminate downtime in your dapp\n * preparing a new release for your subquery project without exposing it publicly. the staging slot is not shown to the public in the explorer and has a unique url that is visible only to you.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/tr/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/query/graphql.html",relativePath:"tr/query/graphql.md",key:"v-719f4e92",path:"/tr/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/tr/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/query/query.html",relativePath:"tr/query/query.md",key:"v-282f15b9",path:"/tr/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (SubQuery Barındırılan)",frontmatter:{summary:"Hello World (SubQuery Barındırılan) Bu hızlı başlangıcın amacı, Subquery projelerinde (yönetilen hizmetimiz) çalışan varsayılan başlangıç projesini birkaç kolay adımda nasıl alabil",meta:[{property:"og:url",content:"/tr/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery Barındırılan)"},{property:"og:description",content:"Hello World (SubQuery Barındırılan) Bu hızlı başlangıcın amacı, Subquery projelerinde (yönetilen hizmetimiz) çalışan varsayılan başlangıç projesini birkaç kolay adımda nasıl alabil"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/quickstart/helloworld-hosted.html",relativePath:"tr/quickstart/helloworld-hosted.md",key:"v-0859c4cd",path:"/tr/quickstart/helloworld-hosted/",headers:[{level:2,title:"Öğrenme hedefleri",slug:"ogrenme-hedefleri",normalizedTitle:"ogrenme hedefleri",charIndex:518},{level:2,title:"Hedeflenen hedef kitle",slug:"hedeflenen-hedef-kitle",normalizedTitle:"hedeflenen hedef kitle",charIndex:882},{level:2,title:"Video kılavuzu",slug:"video-kılavuzu",normalizedTitle:"video kılavuzu",charIndex:1042},{level:2,title:"Önkoşullar",slug:"onkosullar",normalizedTitle:"onkosullar",charIndex:1061},{level:2,title:"1. Projenizi oluşturma",slug:"_1-projenizi-olusturma",normalizedTitle:"1. projenizi olusturma",charIndex:1115},{level:2,title:"2. GitHub repo'yu oluşturma",slug:"_2-github-repo-yu-olusturma",normalizedTitle:"2. github repo'yu olusturma",charIndex:1408},{level:2,title:"3. GitHub'a itin",slug:"_3-github-a-itin",normalizedTitle:"3. github'a itin",charIndex:1694},{level:2,title:"4. Projenizi oluşturma",slug:"_4-projenizi-olusturma",normalizedTitle:"4. projenizi olusturma",charIndex:3412},{level:2,title:"5. Projenizi dağıtma",slug:"_5-projenizi-dagıtma",normalizedTitle:"5. projenizi dagıtma",charIndex:4521},{level:2,title:"6. Projenizi test etme",slug:"_6-projenizi-test-etme",normalizedTitle:"6. projenizi test etme",charIndex:6014},{level:2,title:"7. Bonus adım",slug:"_7-bonus-adım",normalizedTitle:"7. bonus adım",charIndex:6252},{level:2,title:"Özet",slug:"ozet",normalizedTitle:"ozet",charIndex:7729}],readingTime:{minutes:3.77,words:1131},headersStr:"Öğrenme hedefleri Hedeflenen hedef kitle Video kılavuzu Önkoşullar 1. Projenizi oluşturma 2. GitHub repo'yu oluşturma 3. GitHub'a itin 4. Projenizi oluşturma 5. Projenizi dağıtma 6. Projenizi test etme 7. Bonus adım Özet",content:'# Hello World (SubQuery Barındırılan)\n\nBu hızlı başlangıcın amacı, Subquery projelerinde (yönetilen hizmetimiz) çalışan varsayılan başlangıç projesini birkaç kolay adımda nasıl alabileceğinizi göstermektir.\n\nBasit başlangıç projesini (ve şimdiye kadar öğrendiğimiz her şeyi) alacağız, ancak Docker içinde yerel olarak çalıştırmak yerine, SubQuery\'nin yönetilen barındırma altyapısından yararlanacağız. Başka bir deyişle, subquery\'nin tüm ağır kaldırma, çalıştırma ve üretim altyapısını yönetmesine izin veriyoruz.\n\n\n# Öğrenme hedefleri\n\nBu hızlı başlangıcın sonunda şunları yapmalıyız:\n\n * gerekli önkoşulları anlamak\n * SubQuery Projects bir proje barındırabilir\n * oyun alanını kullanarak Polkadot mainnet\'in blok yüksekliğini elde etmek için basit bir sorgu çalıştırın\n * сURL kullanarak Polkadot mainnet\'in blok yüksekliğini elde etmek için basit bir GET sorgusu çalıştırın\n\n\n# Hedeflenen hedef kitle\n\nBu kılavuz, bazı geliştirme deneyimine sahip ve SubQuery hakkında daha fazla bilgi edinmek isteyen yeni geliştiricilere yöneliktir.\n\n\n# Video kılavuzu\n\n\n# Önkoşullar\n\nİhtiyacınız olacak:\n\n * GitHub Hesabı\n\n\n# 1. Projenizi oluşturma\n\nSubql_hellowworld adlı bir proje oluşturalım ve zorunlu yükleme, codegen ve derlemeyi en sevdiğiniz paket yöneticisiyle çalıştıralım.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nYine de docker komutlarını ÇALıŞTıRMAYIN.\n\n\n# 2. GitHub repo\'yu oluşturma\n\nGitHub\'da yeni bir genel depo oluşturun. Bir ad girin ve görünürlüğünüzü herkese açık olarak ayarlayın. Burada, her şey şimdilik varsayılan olarak tutulur.\n\n\n\nGitHub URL\'nizi not alın, SubQuery\'nin erişebilmesi için bunun herkese açık olması gerekir.\n\n\n\n\n# 3. GitHub\'a itin\n\nProje dizininizde, git dizini olarak başlatın. Aksi takdirde, "önemli: git deposu (veya üst dizinlerden herhangi biri değil): .git" hatasını alabilirsiniz\n\ngit init\n\n\n1\n\n\nArdından şu komutu içeren bir uzak depo ekleyin:\n\ngit uzaktan ekleme kaynak https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nBu temel olarak uzak deponuzu "https://github.com/seandotau/subqlHelloWorld.git" olarak ayarlar ve GitHub\'daki bir uzak deponun standart isimlendirmesi olan "origin" adını verir.\n\nDaha sonra kodu aşağıdaki komutlarla repomuza ekliyoruz:\n\n> git ekleyin.\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nNesneleri sayma: %100 (14/14), bitti.\n12 iş parçacığına kadar kullanarak delta sıkıştırma\nNesneleri sıkıştırma: %100 (13/13), bitti.\nYazma nesneleri: %100 (14/14), 59.35 KiB | 8.48 MiB/s, bitti.\nToplam 14 (delta 0), yeniden kullanılan 0 (delta 0)\nhttps://github.com/seandotau/subqlHelloWorld.git için\n * [yeni dal] usta -> ustası\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nPush komutu "lütfen kodumu ana yerel repo\'mdan kaynak repo\'ya itin" anlamına gelir. GitHub\'ı yenilemek GitHub\'daki tüm kodu göstermelidir.\n\n\n\nKodunuzu GitHub\'a aldığınıza göre, SubQuery Projects\'te nasıl barındırabileceğimize bakalım.\n\n\n# 4. Projenizi oluşturma\n\nhttps://project.subquery.network gidin ve GitHub hesabınızla giriş yapın.\n\n\n\nSonra yeni bir proje oluşturun,\n\n\n\nVe çeşitli alanları uygun ayrıntılarla doldurun.\n\n * GitHub account: Birden fazla GitHub hesabınız varsa, bu projenin hangi hesap altında oluşturulacağını seçin. GitHub kuruluş hesabında oluşturulan projeler bu kuruluştaki üyeler arasında paylaşılır.\n * Project Name: Projenize buradan bir ad verin.\n * Subtitle: Projeniz için bir altyazı sağlayın.\n * Description: SubQuery projenizin ne yaptığını açıklayın.\n * GitHub Repository URL: Bu, SubQuery projenizi içeren genel bir depo için geçerli bir GitHub URL\'si olmalıdır. Schema.graphql dosyası dizininizin kökünde olmalıdır.\n * Hide project: Seçilirse, bu, projeyi genel SubQuery gezgininden gizler. SubQuerynuzu toplulukla paylaşmak istiyorsanız bunu seçimsiz tutun!\n\n\n\nOluştur\'u tıklatıp tıkladığınızda panonuza götürülürsünüz.\n\n\n\nPano, kullandığı ağ, çalıştırdığı kaynak kodun GitHub deposu URL\'si, ne zaman oluşturulduğu ve son güncelleştirilmesi ve özellikle dağıtım ayrıntıları gibi birçok yararlı bilgi içerir.\n\n\n# 5. Projenizi dağıtma\n\nProjenizi SubQuery Projeleri içinde oluşturduğunuza ve görüntüleme davranışını ayarladığınıza göre, bir sonraki adım projenizi çalışır hale getirmektir. Bir sürümü dağıtmak, yeni bir SubQuery dizin oluşturma işlemini başlatır ve GraphQL isteklerini kabul etmeye başlamak için gerekli sorgu hizmetini ayarlar. Yeni sürümleri varolan projelere de buradan dağıtabilirsiniz.\n\nÜretim yuvası veya hazırlama yuvası gibi çeşitli ortamlara dağıtmayı seçebilirsiniz. Burada bir üretim yuvasına konuşlandıracağız. "Deploy" düğmesine tıklanın, aşağıdaki alanlara sahip bir ekran açılır:\n\n\n\n * Commit Hash of new Version: GitHub\'dan, dağıtılmasını istediğiniz SubQuery projesi kod tabanının doğru şekilde tamamlanmış olmasını seçin\n * Indexer Version: Bu, SubQuery\'yi çalıştırmak istediğiniz SubQuery düğüm hizmetinin sürümüdür. Bkz@subql/node\n * Query Version: Bu, Bu SubQuery\'yu çalıştırmak istediğiniz SubQuery\'nin sorgu hizmetinin sürümüdür. Bkz>@subql<0/query\n\nTek bir taahhüdümuz olduğu için, açılır yolda tek bir seçenek var. Ayrıca dizinleyicinin en son sürümü ve sorgu sürümüyle çalışacağız, böylece varsayılanları kabul edeceğiz ve ardından "Deploy Update" ı tıklayacağız.\n\nDaha sonra dağıtımınızı "Processing" durumunda görürsünüz. Burada, kodunuz SubQuery\'nun yönetilen altyapısına dağıtılıyor. Temel olarak bir sunucu talep üzerine döndürülür ve sizin için tedarik edilir. Bu birkaç dakika sürecek, bu yüzden bir kahve almak için zaman!\n\n\n\nDağıtım şimdi çalışıyor.\n\n\n\n\n# 6. Projenizi test etme\n\nProjenizi sınamak için 3 üç noktayı tıklatın ve "View on SubQuery Explorer"yi seçin.\n\n\n\nBu sizi oynat düğmesine tıklayabileceğiniz ve sorgunun sonuçlarını görebileceğiniz tanıdık "Playground"na götürecektir.\n\n\n\n\n# 7. Bonus adım\n\nAramızdaki zekilik için, öğrenme hedeflerinde son noktanın basit bir GET sorgusu çalıştırmak olduğunu hatırlayacaksınız. Bunu yapmak için, dağıtım ayrıntılarında görüntülenen "Query Endpoin" almamız gerekir.\n\n\n\nDaha sonra bu uç noktaya Postman veya Mockoon gibi favori istemcinizi kullanarak veya terminalinizdeki cURL aracılığıyla bir GET isteği gönderebilirsiniz. Basitlik için cURL aşağıda gösterilecektir.\n\nÇalıştıracak kıvrılma komutu:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\nsonuçlarını vererek:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nOkunabilirlik burada bir endişe değildir, çünkü muhtemelen bu JSON yanıtını tüketmek ve ayrıştırmak için bazı ön uç kodunuz olacaktır.\n\n\n# Özet\n\nBu SubQuery ev sahipliği yaptığı hızlı başlangıçta, bir Subql projesini alıp SubQuery Projects dağıtmanın ne kadar hızlı ve kolay olduğunu gösterdik. Çeşitli sorguları çalıştırmak için dahili bir oyun alanının yanı sıra kodunuzun tümleştirilmek için bir API uç noktası vardır.',normalizedContent:'# hello world (subquery barındırılan)\n\nbu hızlı baslangıcın amacı, subquery projelerinde (yonetilen hizmetimiz) calısan varsayılan baslangıc projesini birkac kolay adımda nasıl alabileceginizi gostermektir.\n\nbasit baslangıc projesini (ve simdiye kadar ogrendigimiz her seyi) alacagız, ancak docker icinde yerel olarak calıstırmak yerine, subquery\'nin yonetilen barındırma altyapısından yararlanacagız. baska bir deyisle, subquery\'nin tum agır kaldırma, calıstırma ve uretim altyapısını yonetmesine izin veriyoruz.\n\n\n# ogrenme hedefleri\n\nbu hızlı baslangıcın sonunda sunları yapmalıyız:\n\n * gerekli onkosulları anlamak\n * subquery projects bir proje barındırabilir\n * oyun alanını kullanarak polkadot mainnet\'in blok yuksekligini elde etmek icin basit bir sorgu calıstırın\n * сurl kullanarak polkadot mainnet\'in blok yuksekligini elde etmek icin basit bir get sorgusu calıstırın\n\n\n# hedeflenen hedef kitle\n\nbu kılavuz, bazı gelistirme deneyimine sahip ve subquery hakkında daha fazla bilgi edinmek isteyen yeni gelistiricilere yoneliktir.\n\n\n# video kılavuzu\n\n\n# onkosullar\n\nihtiyacınız olacak:\n\n * github hesabı\n\n\n# 1. projenizi olusturma\n\nsubql_hellowworld adlı bir proje olusturalım ve zorunlu yukleme, codegen ve derlemeyi en sevdiginiz paket yoneticisiyle calıstıralım.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nyine de docker komutlarını calıstırmayin.\n\n\n# 2. github repo\'yu olusturma\n\ngithub\'da yeni bir genel depo olusturun. bir ad girin ve gorunurlugunuzu herkese acık olarak ayarlayın. burada, her sey simdilik varsayılan olarak tutulur.\n\n\n\ngithub url\'nizi not alın, subquery\'nin erisebilmesi icin bunun herkese acık olması gerekir.\n\n\n\n\n# 3. github\'a itin\n\nproje dizininizde, git dizini olarak baslatın. aksi takdirde, "onemli: git deposu (veya ust dizinlerden herhangi biri degil): .git" hatasını alabilirsiniz\n\ngit init\n\n\n1\n\n\nardından su komutu iceren bir uzak depo ekleyin:\n\ngit uzaktan ekleme kaynak https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nbu temel olarak uzak deponuzu "https://github.com/seandotau/subqlhelloworld.git" olarak ayarlar ve github\'daki bir uzak deponun standart isimlendirmesi olan "origin" adını verir.\n\ndaha sonra kodu asagıdaki komutlarla repomuza ekliyoruz:\n\n> git ekleyin.\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\nnesneleri sayma: %100 (14/14), bitti.\n12 is parcacıgına kadar kullanarak delta sıkıstırma\nnesneleri sıkıstırma: %100 (13/13), bitti.\nyazma nesneleri: %100 (14/14), 59.35 kib | 8.48 mib/s, bitti.\ntoplam 14 (delta 0), yeniden kullanılan 0 (delta 0)\nhttps://github.com/seandotau/subqlhelloworld.git icin\n * [yeni dal] usta -> ustası\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\npush komutu "lutfen kodumu ana yerel repo\'mdan kaynak repo\'ya itin" anlamına gelir. github\'ı yenilemek github\'daki tum kodu gostermelidir.\n\n\n\nkodunuzu github\'a aldıgınıza gore, subquery projects\'te nasıl barındırabilecegimize bakalım.\n\n\n# 4. projenizi olusturma\n\nhttps://project.subquery.network gidin ve github hesabınızla giris yapın.\n\n\n\nsonra yeni bir proje olusturun,\n\n\n\nve cesitli alanları uygun ayrıntılarla doldurun.\n\n * github account: birden fazla github hesabınız varsa, bu projenin hangi hesap altında olusturulacagını secin. github kurulus hesabında olusturulan projeler bu kurulustaki uyeler arasında paylasılır.\n * project name: projenize buradan bir ad verin.\n * subtitle: projeniz icin bir altyazı saglayın.\n * description: subquery projenizin ne yaptıgını acıklayın.\n * github repository url: bu, subquery projenizi iceren genel bir depo icin gecerli bir github url\'si olmalıdır. schema.graphql dosyası dizininizin kokunde olmalıdır.\n * hide project: secilirse, bu, projeyi genel subquery gezgininden gizler. subquerynuzu toplulukla paylasmak istiyorsanız bunu secimsiz tutun!\n\n\n\nolustur\'u tıklatıp tıkladıgınızda panonuza goturulursunuz.\n\n\n\npano, kullandıgı ag, calıstırdıgı kaynak kodun github deposu url\'si, ne zaman olusturuldugu ve son guncellestirilmesi ve ozellikle dagıtım ayrıntıları gibi bircok yararlı bilgi icerir.\n\n\n# 5. projenizi dagıtma\n\nprojenizi subquery projeleri icinde olusturdugunuza ve goruntuleme davranısını ayarladıgınıza gore, bir sonraki adım projenizi calısır hale getirmektir. bir surumu dagıtmak, yeni bir subquery dizin olusturma islemini baslatır ve graphql isteklerini kabul etmeye baslamak icin gerekli sorgu hizmetini ayarlar. yeni surumleri varolan projelere de buradan dagıtabilirsiniz.\n\nuretim yuvası veya hazırlama yuvası gibi cesitli ortamlara dagıtmayı secebilirsiniz. burada bir uretim yuvasına konuslandıracagız. "deploy" dugmesine tıklanın, asagıdaki alanlara sahip bir ekran acılır:\n\n\n\n * commit hash of new version: github\'dan, dagıtılmasını istediginiz subquery projesi kod tabanının dogru sekilde tamamlanmıs olmasını secin\n * indexer version: bu, subquery\'yi calıstırmak istediginiz subquery dugum hizmetinin surumudur. bkz@subql/node\n * query version: bu, bu subquery\'yu calıstırmak istediginiz subquery\'nin sorgu hizmetinin surumudur. bkz>@subql<0/query\n\ntek bir taahhudumuz oldugu icin, acılır yolda tek bir secenek var. ayrıca dizinleyicinin en son surumu ve sorgu surumuyle calısacagız, boylece varsayılanları kabul edecegiz ve ardından "deploy update" ı tıklayacagız.\n\ndaha sonra dagıtımınızı "processing" durumunda gorursunuz. burada, kodunuz subquery\'nun yonetilen altyapısına dagıtılıyor. temel olarak bir sunucu talep uzerine dondurulur ve sizin icin tedarik edilir. bu birkac dakika surecek, bu yuzden bir kahve almak icin zaman!\n\n\n\ndagıtım simdi calısıyor.\n\n\n\n\n# 6. projenizi test etme\n\nprojenizi sınamak icin 3 uc noktayı tıklatın ve "view on subquery explorer"yi secin.\n\n\n\nbu sizi oynat dugmesine tıklayabileceginiz ve sorgunun sonuclarını gorebileceginiz tanıdık "playground"na goturecektir.\n\n\n\n\n# 7. bonus adım\n\naramızdaki zekilik icin, ogrenme hedeflerinde son noktanın basit bir get sorgusu calıstırmak oldugunu hatırlayacaksınız. bunu yapmak icin, dagıtım ayrıntılarında goruntulenen "query endpoin" almamız gerekir.\n\n\n\ndaha sonra bu uc noktaya postman veya mockoon gibi favori istemcinizi kullanarak veya terminalinizdeki curl aracılıgıyla bir get istegi gonderebilirsiniz. basitlik icin curl asagıda gosterilecektir.\n\ncalıstıracak kıvrılma komutu:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\nsonuclarını vererek:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nokunabilirlik burada bir endise degildir, cunku muhtemelen bu json yanıtını tuketmek ve ayrıstırmak icin bazı on uc kodunuz olacaktır.\n\n\n# ozet\n\nbu subquery ev sahipligi yaptıgı hızlı baslangıcta, bir subql projesini alıp subquery projects dagıtmanın ne kadar hızlı ve kolay oldugunu gosterdik. cesitli sorguları calıstırmak icin dahili bir oyun alanının yanı sıra kodunuzun tumlestirilmek icin bir api uc noktası vardır.',charsets:{cyrillic:!0,cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Bu SubQuery Hello World hızlı başlangıcına hoş geldiniz. Hızlı başlangıç, docker'da çalışan varsayılan başlangıç projesini birkaç basit adımda nası",meta:[{property:"og:url",content:"/tr/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Bu SubQuery Hello World hızlı başlangıcına hoş geldiniz. Hızlı başlangıç, docker'da çalışan varsayılan başlangıç projesini birkaç basit adımda nası"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/quickstart/helloworld-localhost.html",relativePath:"tr/quickstart/helloworld-localhost.md",key:"v-5ec450bb",path:"/tr/quickstart/helloworld-localhost/",headers:[{level:2,title:"Öğrenme hedefleri",slug:"ogrenme-hedefleri",normalizedTitle:"ogrenme hedefleri",charIndex:231},{level:2,title:"Hedeflenen hedef kitle",slug:"hedeflenen-hedef-kitle",normalizedTitle:"hedeflenen hedef kitle",charIndex:512},{level:2,title:"Video kılavuzu",slug:"video-kılavuzu",normalizedTitle:"video kılavuzu",charIndex:672},{level:2,title:"Önkoşullar",slug:"onkosullar",normalizedTitle:"onkosullar",charIndex:691},{level:2,title:"1. Projeyi başlat",slug:"_1-projeyi-baslat",normalizedTitle:"1. projeyi baslat",charIndex:1549},{level:2,title:"2. Bağımlılıkları yükleme",slug:"_2-bagımlılıkları-yukleme",normalizedTitle:"2. bagımlılıkları yukleme",charIndex:2099},{level:2,title:"3. Kod oluşturma",slug:"_3-kod-olusturma",normalizedTitle:"3. kod olusturma",charIndex:2558},{level:2,title:"4. Kod oluşturma",slug:"_4-kod-olusturma",normalizedTitle:"4. kod olusturma",charIndex:3198},{level:2,title:"5. Docker'ı çalıştırın",slug:"_5-docker-ı-calıstırın",normalizedTitle:"5. docker'ı calıstırın",charIndex:3432},{level:2,title:"6. Oyun alanına göz atın",slug:"_6-oyun-alanına-goz-atın",normalizedTitle:"6. oyun alanına goz atın",charIndex:4682},{level:2,title:"Özet",slug:"ozet",normalizedTitle:"ozet",charIndex:5107}],readingTime:{minutes:2.63,words:788},headersStr:"Öğrenme hedefleri Hedeflenen hedef kitle Video kılavuzu Önkoşullar 1. Projeyi başlat 2. Bağımlılıkları yükleme 3. Kod oluşturma 4. Kod oluşturma 5. Docker'ı çalıştırın 6. Oyun alanına göz atın Özet",content:"# Hello World (localhost + Docker)\n\nBu SubQuery Hello World hızlı başlangıcına hoş geldiniz. Hızlı başlangıç, docker'da çalışan varsayılan başlangıç projesini birkaç basit adımda nasıl elde edersiniz göstermeyi amaçlamaktadır.\n\n\n# Öğrenme hedefleri\n\nBu hızlı başlangıcın sonunda şunları yapmalıyız:\n\n * gerekli önkoşulları anlamak\n * temel ortak komutları anlamak\n * localhost:3000'e gidebilmek ve oyun alanını görüntüleyebilmek\n * Polkadot mainnet'in blok yüksekliğini almak için basit bir sorgu çalıştırın\n\n\n# Hedeflenen hedef kitle\n\nBu kılavuz, bazı geliştirme deneyimine sahip ve SubQuery hakkında daha fazla bilgi edinmek isteyen yeni geliştiricilere yöneliktir.\n\n\n# Video kılavuzu\n\n\n# Önkoşullar\n\nİhtiyacınız olacak:\n\n * yarn veya npm paket yöneticisi\n * SubQuery CLI (@subql/cli)\n * Docker\n\nBu önkoşullardan herhangi birine sahip olup olmadığınızı görmek için terminalde aşağıdaki komutları çalıştırabilirsiniz.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nDaha ileri düzey kullanıcılar için aşağıdakileri kopyalayıp yapıştırın:\n\necho -e \"My yarn version is:\" `yarn -v` \"\\nMy subql version is:\" `subql -v`  \"\\nMy docker version is:\" `docker -v`\n\n\n1\n\n\nBu döndürülmelidir: (npm kullanıcıları için ipliği npm ile değiştirin) vv\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nYukarıdakileri alırsanız, gitmeye hazırsınız demektir. Değilse, yüklemek için şu bağlantıları izleyin:\n\n * yarn veya npm\n * SubQuery CLI\n * Docker\n\n\n# 1. Projeyi başlat\n\nSubQuery ile başlarken ilk adım subql init komutunu çalıştırmaktır. subqlHelloWorld adıyla bir başlangıç projesi başlatalım. Yalnızca yazarın zorunlu olduğunu unutmayın. Aşağıda diğer her şey boş bırakılmıştır.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nBu yeni dizine girmeyi unutmayın.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# 2. Bağımlılıkları yükleme\n\nŞimdi çeşitli bağımlılıkları yüklemek için bir iplik veya düğüm yüklemesi yapın.\n\n```shell yarn install ``` ```bash npm install ```\n\nBir örnek yarn install\n\n> yarn install\nyarn install v1.22.10\nbilgi Kilit dosyası bulunamadı.\n[1/4] 🔍 Paketleri çözme...\n[2/4] 🚚 Paket getiriyor...\n[3/4] 🔗 Bağımlılıkları bağlama...\n[4/4] 🔨 Yeni paketler oluşturma...\nbaşarı Kilit dosyası kaydedildi.\n✨ 31.84'lerde bitti.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 3. Kod oluşturma\n\nŞimdi GraphQL şemasından Typescript oluşturmak için yarn codegen çalıştırın.\n\n```shell yarn codegen ``` ```bash npm run-script codegen ```\n\nBir örnekyarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Modeller endeksi oluşturuldu!\n* Oluşturulan türler dizini !\n✨ 1.02'lerde bitti.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning Şema dosyasında değişiklikler yapıldığında, türler dizininizi yeniden oluşturmanız için lütfen yarn codegen yeniden çalıştırmayı unutmayın.\n\n\n# 4. Kod oluşturma\n\nBir sonraki adım, kodu yarn build ile oluşturmaktır.\n\n```shell yarn build ``` ```bash npm run-script build ```\n\nBir örnek yarn build\n\n> iplik yapısı\nip çalıştırma v1.22.10\n$ tsc -b\n✨ 5.68'lerde bitti.\n\n\n1\n2\n3\n4\n\n\n\n# 5. Docker'ı çalıştırın\n\nDocker'ı kullanmak, gerekli tüm altyapı Docker görüntüsünde sağlanabildiğinden bu örneği çok hızlı bir şekilde çalıştırmanıza olanak tanır. docker-compose pull && liman işçisi-oluşturma.\n\nBu, sonunda blokların getirildiği hayata her şeyi tekmeleyecek.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 6. Oyun alanına göz atın\n\nHttp://localhost:3000/ gidin ve aşağıdaki sorguyu ekranın sol tarafına yapıştırın ve ardından oynat düğmesine basın.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nYerel ev üzerinde SubQuery oyun alanı.\n\n\n\nOyun parkındaki blok sayısı, terminaldeki blok sayısıyla (teknik olarak blok yüksekliği) de eşleşmelidir.\n\n\n# Özet\n\nBu hızlı başlangıçta, bir Docker ortamında bir başlangıç projesini çalışır durumda almak için temel adımları gösterdik ve ardından localhost:3000'e gittik ve ana ağ Polkadot ağının blok numarasını döndürmek için bir sorgu çalıştırdık.",normalizedContent:"# hello world (localhost + docker)\n\nbu subquery hello world hızlı baslangıcına hos geldiniz. hızlı baslangıc, docker'da calısan varsayılan baslangıc projesini birkac basit adımda nasıl elde edersiniz gostermeyi amaclamaktadır.\n\n\n# ogrenme hedefleri\n\nbu hızlı baslangıcın sonunda sunları yapmalıyız:\n\n * gerekli onkosulları anlamak\n * temel ortak komutları anlamak\n * localhost:3000'e gidebilmek ve oyun alanını goruntuleyebilmek\n * polkadot mainnet'in blok yuksekligini almak icin basit bir sorgu calıstırın\n\n\n# hedeflenen hedef kitle\n\nbu kılavuz, bazı gelistirme deneyimine sahip ve subquery hakkında daha fazla bilgi edinmek isteyen yeni gelistiricilere yoneliktir.\n\n\n# video kılavuzu\n\n\n# onkosullar\n\nihtiyacınız olacak:\n\n * yarn veya npm paket yoneticisi\n * subquery cli (@subql/cli)\n * docker\n\nbu onkosullardan herhangi birine sahip olup olmadıgınızı gormek icin terminalde asagıdaki komutları calıstırabilirsiniz.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\ndaha ileri duzey kullanıcılar icin asagıdakileri kopyalayıp yapıstırın:\n\necho -e \"my yarn version is:\" `yarn -v` \"\\nmy subql version is:\" `subql -v`  \"\\nmy docker version is:\" `docker -v`\n\n\n1\n\n\nbu dondurulmelidir: (npm kullanıcıları icin ipligi npm ile degistirin) vv\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nyukarıdakileri alırsanız, gitmeye hazırsınız demektir. degilse, yuklemek icin su baglantıları izleyin:\n\n * yarn veya npm\n * subquery cli\n * docker\n\n\n# 1. projeyi baslat\n\nsubquery ile baslarken ilk adım subql init komutunu calıstırmaktır. subqlhelloworld adıyla bir baslangıc projesi baslatalım. yalnızca yazarın zorunlu oldugunu unutmayın. asagıda diger her sey bos bırakılmıstır.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nbu yeni dizine girmeyi unutmayın.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# 2. bagımlılıkları yukleme\n\nsimdi cesitli bagımlılıkları yuklemek icin bir iplik veya dugum yuklemesi yapın.\n\n```shell yarn install ``` ```bash npm install ```\n\nbir ornek yarn install\n\n> yarn install\nyarn install v1.22.10\nbilgi kilit dosyası bulunamadı.\n[1/4] 🔍 paketleri cozme...\n[2/4] 🚚 paket getiriyor...\n[3/4] 🔗 bagımlılıkları baglama...\n[4/4] 🔨 yeni paketler olusturma...\nbasarı kilit dosyası kaydedildi.\n✨ 31.84'lerde bitti.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 3. kod olusturma\n\nsimdi graphql semasından typescript olusturmak icin yarn codegen calıstırın.\n\n```shell yarn codegen ``` ```bash npm run-script codegen ```\n\nbir ornekyarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* modeller endeksi olusturuldu!\n* olusturulan turler dizini !\n✨ 1.02'lerde bitti.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning sema dosyasında degisiklikler yapıldıgında, turler dizininizi yeniden olusturmanız icin lutfen yarn codegen yeniden calıstırmayı unutmayın.\n\n\n# 4. kod olusturma\n\nbir sonraki adım, kodu yarn build ile olusturmaktır.\n\n```shell yarn build ``` ```bash npm run-script build ```\n\nbir ornek yarn build\n\n> iplik yapısı\nip calıstırma v1.22.10\n$ tsc -b\n✨ 5.68'lerde bitti.\n\n\n1\n2\n3\n4\n\n\n\n# 5. docker'ı calıstırın\n\ndocker'ı kullanmak, gerekli tum altyapı docker goruntusunde saglanabildiginden bu ornegi cok hızlı bir sekilde calıstırmanıza olanak tanır. docker-compose pull && liman iscisi-olusturma.\n\nbu, sonunda blokların getirildigi hayata her seyi tekmeleyecek.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 6. oyun alanına goz atın\n\nhttp://localhost:3000/ gidin ve asagıdaki sorguyu ekranın sol tarafına yapıstırın ve ardından oynat dugmesine basın.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nyerel ev uzerinde subquery oyun alanı.\n\n\n\noyun parkındaki blok sayısı, terminaldeki blok sayısıyla (teknik olarak blok yuksekligi) de eslesmelidir.\n\n\n# ozet\n\nbu hızlı baslangıcta, bir docker ortamında bir baslangıc projesini calısır durumda almak icin temel adımları gosterdik ve ardından localhost:3000'e gittik ve ana ag polkadot agının blok numarasını dondurmek icin bir sorgu calıstırdık.",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hızlı Başlangıç Kılavuzu",frontmatter:{summary:"Hızlı Başlangıç Kılavuzu Bu Hızlı Başlangıç kılavuzunda, kendi SubQuery Projenizi geliştirmek için bir çerçeve olarak kullanılabilecek basit bir başlangıç projesi oluşturacağız. Bu",meta:[{property:"og:url",content:"/tr/quickstart/quickstart.html"},{property:"og:title",content:"Hızlı Başlangıç Kılavuzu"},{property:"og:description",content:"Hızlı Başlangıç Kılavuzu Bu Hızlı Başlangıç kılavuzunda, kendi SubQuery Projenizi geliştirmek için bir çerçeve olarak kullanılabilecek basit bir başlangıç projesi oluşturacağız. Bu"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/quickstart/quickstart.html",relativePath:"tr/quickstart/quickstart.md",key:"v-71d00bc6",path:"/tr/quickstart/quickstart/",headers:[{level:2,title:"Hazırlık",slug:"hazırlık",normalizedTitle:"hazırlık",charIndex:430},{level:3,title:"Yerel Kalkınma Ortamı",slug:"yerel-kalkınma-ortamı",normalizedTitle:"yerel kalkınma ortamı",charIndex:443},{level:3,title:"SubQuery CLI'sını yükleme",slug:"subquery-cli-sını-yukleme",normalizedTitle:"subquery cli'sını yukleme",charIndex:683},{level:2,title:"Başlangıç SubQuery Projesini Başlatma",slug:"baslangıc-subquery-projesini-baslatma",normalizedTitle:"baslangıc subquery projesini baslatma",charIndex:1097},{level:2,title:"Başlangıç Projesini Yapılandırma ve Oluşturma",slug:"baslangıc-projesini-yapılandırma-ve-olusturma",normalizedTitle:"baslangıc projesini yapılandırma ve olusturma",charIndex:2661},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3093},{level:2,title:"Projeyi Oluşturun",slug:"projeyi-olusturun",normalizedTitle:"projeyi olusturun",charIndex:3435},{level:2,title:"Başlangıç Projenizi Çalıştırma ve Sorgulama",slug:"baslangıc-projenizi-calıstırma-ve-sorgulama",normalizedTitle:"baslangıc projenizi calıstırma ve sorgulama",charIndex:3686},{level:3,title:"SubQuery Projenizi Çalıştırma",slug:"subquery-projenizi-calıstırma",normalizedTitle:"subquery projenizi calıstırma",charIndex:4043},{level:3,title:"Projenizi Sorgulama",slug:"projenizi-sorgulama",normalizedTitle:"projenizi sorgulama",charIndex:4586},{level:2,title:"Sonraki Adımlar",slug:"sonraki-adımlar",normalizedTitle:"sonraki adımlar",charIndex:5265}],readingTime:{minutes:2.68,words:803},headersStr:"Hazırlık Yerel Kalkınma Ortamı SubQuery CLI'sını yükleme Başlangıç SubQuery Projesini Başlatma Başlangıç Projesini Yapılandırma ve Oluşturma GraphQL Model Generation Projeyi Oluşturun Başlangıç Projenizi Çalıştırma ve Sorgulama SubQuery Projenizi Çalıştırma Projenizi Sorgulama Sonraki Adımlar",content:"# Hızlı Başlangıç Kılavuzu\n\nBu Hızlı Başlangıç kılavuzunda, kendi SubQuery Projenizi geliştirmek için bir çerçeve olarak kullanılabilecek basit bir başlangıç projesi oluşturacağız.\n\nBu kılavuzun sonunda, verileri sorguyabileceğiniz bir GraphQL uç noktasına sahip bir SubQuery düğümünde çalışan çalışan bir SubQuery projeniz olacaktır.\n\nHenüz yapmadıysanız, SubQuery'de kullanılan terminology hakkında bilgi sahibi > öneririz.\n\n\n# Hazırlık\n\n\n# Yerel Kalkınma Ortamı\n\n * Typescript, projeyi derlemek ve türleri tanımlamak için gereklidir.\n * Hem SubQuery CLI hem de oluşturulan Project bağımlılıkları vardır ve modern bir sürüm Node gerektirir.\n * SubQuery Nodes Docker gerektirir\n\n\n# SubQuery CLI'sını yükleme\n\nNPM kullanarak Terminalinize SubQuery CLI'yi genel olarak yükleyin:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nLütfen DO NOT, zayıf bağımlılık yönetimi nedeniyle yarn global kullanımını teşvik ettiğimizi ve bunun da bir hataya yol açabileceğini unutmayın.\n\nDaha sonra CLI tarafından sunulan kullanılabilir komutları ve kullanımı görmek için yardım çalıştırabilirsiniz\n\nsubql help\n\n\n1\n\n\n\n# Başlangıç SubQuery Projesini Başlatma\n\nBir SubQuery projesi oluşturmak istediğiniz dizinin içinde, PROJECT_NAME kendi projenizle değiştirin ve komutu çalıştırın:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nSubQuery projesi initalised olarak size bazı sorular sorulana olacaktır:\n\n * Git deposu (İsteğe Bağlı): Bu SubQuery projesinin barındırılacağı bir depoya Git URL'si sağlayın (SubQuery Gezgini'nde barındırıldığında)\n * RPC uç noktası (Gerekli): Bu proje için varsayılan olarak kullanılacak çalışan bir RPC uç noktasına wss URL'si sağlayın. Farklı Polkadot ağları için genel uç noktalara hızlı bir şekilde erişebilir veya hatta OnFinality kullanarak kendi özel özel düğümünüzü oluşturabilir veya yalnızca varsayılan Polkadot uç noktasını kullanabilirsiniz.\n * Yazarlar (Gerekli): Bu SubQuery projesinin sahibini buraya girin\n * Açıklama (İsteğe Bağlı): Projeniz hakkında hangi verileri içerdiğini ve kullanıcıların bu verilerle neler yapabileceğini açıklayan kısa bir paragraf sağlayabilirsiniz\n * Sürüm (Gerekli): Özel bir sürüm numarası girin veya varsayılanı kullanın (1.0.0)\n * Lisans (Gerekli): Bu proje için yazılım lisansını sağlayın veya varsayılanı kabul edin (Apache-2.0)\n\nBaşlatma işlemi tamamlandıktan sonra, dizin içinde proje adınızın oluşturulduğu bir klasör görmeniz gerekir. Bu directoy'un içeriği Directory Structure listelenenlerle aynı olmalıdır.\n\nSon olarak, proje dizini altında, yeni projenin bağımlılıklarını yüklemek için aşağıdaki komutu çalıştırın.\n\n```shell cd PROJECT_NAME yarn install ``` ```bash cd PROJECT_NAME npm install ```\n\n\n# Başlangıç Projesini Yapılandırma ve Oluşturma\n\nYeni başlatmış olduğunuz başlangıç paketinde, yeni projeniz için standart bir yapılandırma sağladık. Esas olarak aşağıdaki dosyalar üzerinde çalışacaksınız::\n\n * The Manifest in project.yaml\n * schema.graphql'daki GraphQL Şeması\n * src/mappings/ dizinindeki Eşleme işlevleri\n\nKendi SubQuerynuzu yazma hakkında daha fazla bilgi için Create a Projec altındaki belgelerimize göz atın\n\n\n# GraphQL Model Generation\n\nSubQuery projenizi index için, önce GraphQL Şema dosyanızda tanımladığınız gerekli GraphQL modellerini oluşturmalısınız (schema.graphql). Bu komutu proje dizininin kökünde çalıştırın.\n\n```shell yarn codegen ``` ```bash npm run-script codegen ```\n\nOluşturulan modelleri /src/types/models dizininde bulabilirsiniz\n\n\n# Projeyi Oluşturun\n\nSubQuery Projenizi yerel olarak barındırılan bir SubQuery Düğümünde çalıştırmak için çalışmanızı oluşturmanız gerekir.\n\nYapı komutunu projenin kök dizininden çalıştırın.\n\n```shell yarn build ``` ```bash npm run-script build ```\n\n\n# Başlangıç Projenizi Çalıştırma ve Sorgulama\n\nYeni projenizi hızlı bir şekilde SubQuery Projects 'a yayımlayabilmenize ve Explorer, kullanarak sorgulayabilmenize rağmen, SubQuery düğümlerini yerel olarak çalıştırmanın en kolay yolu bir Docker kapsayıcısındadır, zaten Docker'ınuz yoks docker.com.\n\nBunu atla ve yeni projeni SubQuery Projeleri'ne yayımla\n\n\n# SubQuery Projenizi Çalıştırma\n\nSubQuery düğümünün nasıl çalıştırılacağını denetleyen tüm yapılandırma bu docker-compose.yml file. Yeni initalised yeni bir proje için burada hiçbir şeyi değiştirmenize gerek kalmayacak, ancak dosya ve ayarlar hakkında daha fazla bilgiyi Run a Project section\n\nProje dizini altında aşağıdaki komutu çalıştırın:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nGerekli paketleri (@subql/node, @subql/query ve Postgres) ilk kez indirmek biraz zaman alabilir, ancak yakında çalışan bir SubQuery node görürsünüz.\n\n\n# Projenizi Sorgulama\n\nTarayıcınızı açın ve http://localhost:3000 gidin.\n\nExplorer'da ve sorguya hazır şemalarda bir GraphQL oyun alanının görüntü olduğunu görmeniz gerekir. Oyun alanının sağ üst kısmında, belge çizimini açacak bir Docs düğmesi bulacaksınız. Bu belge otomatik olarak oluşturulur ve hangi varlıkları ve yöntemleri sorgulayabilirsiniz bulmanıza yardımcı olur.\n\nYeni bir SubQuery başlangıç projesi için, nasıl çalıştığını öğrenmek için aşağıdaki sorguyu deneyebilir veya GraphQL Query dili hakkında daha fazla bilgi .\n\nquery {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Sonraki Adımlar\n\nTebrikler, artık örnek veriler için GraphQL API isteklerini kabul eden yerel olarak çalışan bir SubQuery projeniz var. Bir sonraki kılavuzda, yeni projenizi SubQuery Projects nasıl yayımlayacağınızı ve Explorer'imizi kullanarak nasıl sorgulayacağınızı göstereceğiz\n\nYeni projenizi SubQuery Projelerinde yayımlama",normalizedContent:"# hızlı baslangıc kılavuzu\n\nbu hızlı baslangıc kılavuzunda, kendi subquery projenizi gelistirmek icin bir cerceve olarak kullanılabilecek basit bir baslangıc projesi olusturacagız.\n\nbu kılavuzun sonunda, verileri sorguyabileceginiz bir graphql uc noktasına sahip bir subquery dugumunde calısan calısan bir subquery projeniz olacaktır.\n\nhenuz yapmadıysanız, subquery'de kullanılan terminology hakkında bilgi sahibi > oneririz.\n\n\n# hazırlık\n\n\n# yerel kalkınma ortamı\n\n * typescript, projeyi derlemek ve turleri tanımlamak icin gereklidir.\n * hem subquery cli hem de olusturulan project bagımlılıkları vardır ve modern bir surum node gerektirir.\n * subquery nodes docker gerektirir\n\n\n# subquery cli'sını yukleme\n\nnpm kullanarak terminalinize subquery cli'yi genel olarak yukleyin:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nlutfen do not, zayıf bagımlılık yonetimi nedeniyle yarn global kullanımını tesvik ettigimizi ve bunun da bir hataya yol acabilecegini unutmayın.\n\ndaha sonra cli tarafından sunulan kullanılabilir komutları ve kullanımı gormek icin yardım calıstırabilirsiniz\n\nsubql help\n\n\n1\n\n\n\n# baslangıc subquery projesini baslatma\n\nbir subquery projesi olusturmak istediginiz dizinin icinde, project_name kendi projenizle degistirin ve komutu calıstırın:\n\nsubql init --starter project_name\n\n\n1\n\n\nsubquery projesi initalised olarak size bazı sorular sorulana olacaktır:\n\n * git deposu (istege baglı): bu subquery projesinin barındırılacagı bir depoya git url'si saglayın (subquery gezgini'nde barındırıldıgında)\n * rpc uc noktası (gerekli): bu proje icin varsayılan olarak kullanılacak calısan bir rpc uc noktasına wss url'si saglayın. farklı polkadot agları icin genel uc noktalara hızlı bir sekilde erisebilir veya hatta onfinality kullanarak kendi ozel ozel dugumunuzu olusturabilir veya yalnızca varsayılan polkadot uc noktasını kullanabilirsiniz.\n * yazarlar (gerekli): bu subquery projesinin sahibini buraya girin\n * acıklama (istege baglı): projeniz hakkında hangi verileri icerdigini ve kullanıcıların bu verilerle neler yapabilecegini acıklayan kısa bir paragraf saglayabilirsiniz\n * surum (gerekli): ozel bir surum numarası girin veya varsayılanı kullanın (1.0.0)\n * lisans (gerekli): bu proje icin yazılım lisansını saglayın veya varsayılanı kabul edin (apache-2.0)\n\nbaslatma islemi tamamlandıktan sonra, dizin icinde proje adınızın olusturuldugu bir klasor gormeniz gerekir. bu directoy'un icerigi directory structure listelenenlerle aynı olmalıdır.\n\nson olarak, proje dizini altında, yeni projenin bagımlılıklarını yuklemek icin asagıdaki komutu calıstırın.\n\n```shell cd project_name yarn install ``` ```bash cd project_name npm install ```\n\n\n# baslangıc projesini yapılandırma ve olusturma\n\nyeni baslatmıs oldugunuz baslangıc paketinde, yeni projeniz icin standart bir yapılandırma sagladık. esas olarak asagıdaki dosyalar uzerinde calısacaksınız::\n\n * the manifest in project.yaml\n * schema.graphql'daki graphql seması\n * src/mappings/ dizinindeki esleme islevleri\n\nkendi subquerynuzu yazma hakkında daha fazla bilgi icin create a projec altındaki belgelerimize goz atın\n\n\n# graphql model generation\n\nsubquery projenizi index icin, once graphql sema dosyanızda tanımladıgınız gerekli graphql modellerini olusturmalısınız (schema.graphql). bu komutu proje dizininin kokunde calıstırın.\n\n```shell yarn codegen ``` ```bash npm run-script codegen ```\n\nolusturulan modelleri /src/types/models dizininde bulabilirsiniz\n\n\n# projeyi olusturun\n\nsubquery projenizi yerel olarak barındırılan bir subquery dugumunde calıstırmak icin calısmanızı olusturmanız gerekir.\n\nyapı komutunu projenin kok dizininden calıstırın.\n\n```shell yarn build ``` ```bash npm run-script build ```\n\n\n# baslangıc projenizi calıstırma ve sorgulama\n\nyeni projenizi hızlı bir sekilde subquery projects 'a yayımlayabilmenize ve explorer, kullanarak sorgulayabilmenize ragmen, subquery dugumlerini yerel olarak calıstırmanın en kolay yolu bir docker kapsayıcısındadır, zaten docker'ınuz yoks docker.com.\n\nbunu atla ve yeni projeni subquery projeleri'ne yayımla\n\n\n# subquery projenizi calıstırma\n\nsubquery dugumunun nasıl calıstırılacagını denetleyen tum yapılandırma bu docker-compose.yml file. yeni initalised yeni bir proje icin burada hicbir seyi degistirmenize gerek kalmayacak, ancak dosya ve ayarlar hakkında daha fazla bilgiyi run a project section\n\nproje dizini altında asagıdaki komutu calıstırın:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\ngerekli paketleri (@subql/node, @subql/query ve postgres) ilk kez indirmek biraz zaman alabilir, ancak yakında calısan bir subquery node gorursunuz.\n\n\n# projenizi sorgulama\n\ntarayıcınızı acın ve http://localhost:3000 gidin.\n\nexplorer'da ve sorguya hazır semalarda bir graphql oyun alanının goruntu oldugunu gormeniz gerekir. oyun alanının sag ust kısmında, belge cizimini acacak bir docs dugmesi bulacaksınız. bu belge otomatik olarak olusturulur ve hangi varlıkları ve yontemleri sorgulayabilirsiniz bulmanıza yardımcı olur.\n\nyeni bir subquery baslangıc projesi icin, nasıl calıstıgını ogrenmek icin asagıdaki sorguyu deneyebilir veya graphql query dili hakkında daha fazla bilgi .\n\nquery {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# sonraki adımlar\n\ntebrikler, artık ornek veriler icin graphql api isteklerini kabul eden yerel olarak calısan bir subquery projeniz var. bir sonraki kılavuzda, yeni projenizi subquery projects nasıl yayımlayacagınızı ve explorer'imizi kullanarak nasıl sorgulayacagınızı gosterecegiz\n\nyeni projenizi subquery projelerinde yayımlama",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World Açıklandı",frontmatter:{summary:"Hello World Açıklandı Hello World hızlı başlangıç kılavuzunda, bazı basit komutları çalıştırdık ve çok hızlı bir şekilde bir örnek aldık. Bu, tüm önkoşulların yerinde olduğundan ve",meta:[{property:"og:url",content:"/tr/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Açıklandı"},{property:"og:description",content:"Hello World Açıklandı Hello World hızlı başlangıç kılavuzunda, bazı basit komutları çalıştırdık ve çok hızlı bir şekilde bir örnek aldık. Bu, tüm önkoşulların yerinde olduğundan ve"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/quickstart/understanding-helloworld.html",relativePath:"tr/quickstart/understanding-helloworld.md",key:"v-51f04b35",path:"/tr/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:393},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1132},{level:2,title:"iplik kodgeni",slug:"iplik-kodgeni",normalizedTitle:"iplik kodgeni",charIndex:1967},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2351},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2563},{level:2,title:"Özet",slug:"ozet",normalizedTitle:"ozet",charIndex:3198}],readingTime:{minutes:1.75,words:525},headersStr:"subql init yarn install iplik kodgeni yarn build docker-compose Özet",content:"# Hello World Açıklandı\n\nHello World hızlı başlangıç kılavuzunda, bazı basit komutları çalıştırdık ve çok hızlı bir şekilde bir örnek aldık. Bu, tüm önkoşulların yerinde olduğundan ve SubQuery'den ilk verilerinizi almak için basit bir sorgu yapmak için yerel bir oyun alanı kullanabileceğinizden emin olmanızı sağlar. Burada, tüm bu komutların ne anlama geldiğine daha yakından bakıyoruz.\n\n\n# subql init\n\nÇalıştırdığımız ilk komut subql init --starter subqlHelloWorld idi.\n\nBu ağır kaldırma yapar ve sizin için bir sürü dosya oluşturur. official documentation belirtildiği gibi, esas olarak aşağıdaki dosyalar üzerinde çalışacaksınız:\n\n * The Manifest in project.yaml\n * schema.graphql'daki GraphQL Şeması\n * src/mappings/ dizinindeki Eşleme işlevleri\n\n\n\nBu dosyalar yaptığımız her şeyin özü. Bu nedenle, başka bir makalede bu dosyalara daha fazla zaman ayıracağız. Şimdilik, şemanın kullanıcıların SubQuery API'sinden isteyebileceği verilerin bir açıklamasını, \"yapılandırma\" türü parametrelerini içeren proje yaml dosyasını ve elbette verileri dönüştüren işlevleri içeren typescript içeren mappingHandlers'ı içerdiğini bilin.\n\n\n# yarn install\n\nBir sonraki yaptığımız şey yarn install. npm yükleme da kullanılabilir.\n\n> Kısa bir tarih dersi. Node Package Manager veya npm ilk olarak 2010 yılında piyasaya sürüldü ve JavaScript geliştiricileri arasında son derece popüler bir paket yöneticisidir. Node.js sisteminize her yüklediğinizde otomatik olarak yüklenen varsayılan pakettir. İplik ilk olarak 2016 yılında Facebook tarafından npm (o zaman) ile çalışmanın bazı performans ve güvenlik eksikliklerini gidermek amacıyla piyasaya sürüldü.\n\nİpliğin yaptığı şey package.json dosyasına bakmak ve diğer çeşitli bağımlılıkları indirmektir. package.json dosyasına baktığınızda, çok fazla bağımlılık yok gibi görünüyor, ancak komutu çalıştırdığınızda 18,983 dosyanın eklendiğinde fark edeceksiniz. Bunun nedeni, her bağımlılığın kendi bağımlılıklarının da olmasıdır.\n\n\n\n\n# iplik kodgeni\n\nDaha sonra yarn codegen veya npm run-script codegen çalıştırdık. Bunun yaptığı şey GraphQL şemasını (schema.graphql) getirmek ve ilişkili typescript model dosyalarını oluşturmaktır (bu nedenle çıktı dosyalarının bir .ts uzantısı olacaktır). Oluşturulan bu dosyaların hiçbirini asla değiştirmemelisiniz, yalnızca kaynak schema.graphql dosyasını değiştirmelisiniz.\n\n\n\n\n# yarn build\n\nyarn yapı veya npm run-script build yürütüldü. Bu deneyimli programcılar için tanıdık olmalıdır. Dağıtıma hazırlanan kod optimizasyonu gibi şeyleri gerçekleştiren bir dağıtım klasörü oluşturur.\n\n\n\n\n# docker-compose\n\nSon adım, birleşik docker komutu docker-compose pull && docker-compose up (ayrı olarak da çalıştırılabilir). pull komutu Docker Hub'dan gerekli tüm görüntüleri alır ve up komutu kapsayıcıyı başlatır.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nKapsayıcı başlatıldığında, terminalin düğümün ve GraphQL motorunun durumunu gösteren çok sayıda metin tükürdüğünü görürsünüz. İşte o zaman:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nSubQuery düğümünün eşitlemeye başladığını bildiğinizi.\n\n\n# Özet\n\nŞimdi örtünün altında neler olduğuna dair bir fikir edindiğinize göre, soru buradan nereye? Kendinize güveniyorsanız, create a project nasıl oluşturabilirsiniz ve üç anahtar dosya hakkında daha fazla bilgi edinebilirsiniz. Bildirim dosyası, GraphQL şeması ve eşlemeler dosyası.\n\nAksi takdirde, bu Hello World örneğini SubQuery'nin barındırılan altyapısında nasıl çalıştırabileceğimize baktığımız öğreticiler bölümümüze devam edin, başlangıç bloğunu değiştirmeye bakacağız ve hazır ve açık kaynaklı projeler çalıştırarak SubQuery projelerini çalıştırma konusunda daha derin bir dalış yapacağız.",normalizedContent:"# hello world acıklandı\n\nhello world hızlı baslangıc kılavuzunda, bazı basit komutları calıstırdık ve cok hızlı bir sekilde bir ornek aldık. bu, tum onkosulların yerinde oldugundan ve subquery'den ilk verilerinizi almak icin basit bir sorgu yapmak icin yerel bir oyun alanı kullanabileceginizden emin olmanızı saglar. burada, tum bu komutların ne anlama geldigine daha yakından bakıyoruz.\n\n\n# subql init\n\ncalıstırdıgımız ilk komut subql init --starter subqlhelloworld idi.\n\nbu agır kaldırma yapar ve sizin icin bir suru dosya olusturur. official documentation belirtildigi gibi, esas olarak asagıdaki dosyalar uzerinde calısacaksınız:\n\n * the manifest in project.yaml\n * schema.graphql'daki graphql seması\n * src/mappings/ dizinindeki esleme islevleri\n\n\n\nbu dosyalar yaptıgımız her seyin ozu. bu nedenle, baska bir makalede bu dosyalara daha fazla zaman ayıracagız. simdilik, semanın kullanıcıların subquery api'sinden isteyebilecegi verilerin bir acıklamasını, \"yapılandırma\" turu parametrelerini iceren proje yaml dosyasını ve elbette verileri donusturen islevleri iceren typescript iceren mappinghandlers'ı icerdigini bilin.\n\n\n# yarn install\n\nbir sonraki yaptıgımız sey yarn install. npm yukleme da kullanılabilir.\n\n> kısa bir tarih dersi. node package manager veya npm ilk olarak 2010 yılında piyasaya suruldu ve javascript gelistiricileri arasında son derece populer bir paket yoneticisidir. node.js sisteminize her yuklediginizde otomatik olarak yuklenen varsayılan pakettir. iplik ilk olarak 2016 yılında facebook tarafından npm (o zaman) ile calısmanın bazı performans ve guvenlik eksikliklerini gidermek amacıyla piyasaya suruldu.\n\nipligin yaptıgı sey package.json dosyasına bakmak ve diger cesitli bagımlılıkları indirmektir. package.json dosyasına baktıgınızda, cok fazla bagımlılık yok gibi gorunuyor, ancak komutu calıstırdıgınızda 18,983 dosyanın eklendiginde fark edeceksiniz. bunun nedeni, her bagımlılıgın kendi bagımlılıklarının da olmasıdır.\n\n\n\n\n# iplik kodgeni\n\ndaha sonra yarn codegen veya npm run-script codegen calıstırdık. bunun yaptıgı sey graphql semasını (schema.graphql) getirmek ve iliskili typescript model dosyalarını olusturmaktır (bu nedenle cıktı dosyalarının bir .ts uzantısı olacaktır). olusturulan bu dosyaların hicbirini asla degistirmemelisiniz, yalnızca kaynak schema.graphql dosyasını degistirmelisiniz.\n\n\n\n\n# yarn build\n\nyarn yapı veya npm run-script build yurutuldu. bu deneyimli programcılar icin tanıdık olmalıdır. dagıtıma hazırlanan kod optimizasyonu gibi seyleri gerceklestiren bir dagıtım klasoru olusturur.\n\n\n\n\n# docker-compose\n\nson adım, birlesik docker komutu docker-compose pull && docker-compose up (ayrı olarak da calıstırılabilir). pull komutu docker hub'dan gerekli tum goruntuleri alır ve up komutu kapsayıcıyı baslatır.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nkapsayıcı baslatıldıgında, terminalin dugumun ve graphql motorunun durumunu gosteren cok sayıda metin tukurdugunu gorursunuz. iste o zaman:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nsubquery dugumunun esitlemeye basladıgını bildiginizi.\n\n\n# ozet\n\nsimdi ortunun altında neler olduguna dair bir fikir edindiginize gore, soru buradan nereye? kendinize guveniyorsanız, create a project nasıl olusturabilirsiniz ve uc anahtar dosya hakkında daha fazla bilgi edinebilirsiniz. bildirim dosyası, graphql seması ve eslemeler dosyası.\n\naksi takdirde, bu hello world ornegini subquery'nin barındırılan altyapısında nasıl calıstırabilecegimize baktıgımız ogreticiler bolumumuze devam edin, baslangıc blogunu degistirmeye bakacagız ve hazır ve acık kaynaklı projeler calıstırarak subquery projelerini calıstırma konusunda daha derin bir dalıs yapacagız.",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally Bu kılavuz, hem dizinleyiciyi hem de sorgu hizmetini içeren altyapınızda yerel bir SubQuery düğümünün nasıl çalıştırılacağı üzerinde çalışır. Kendi SubQuer",meta:[{property:"og:url",content:"/tr/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally Bu kılavuz, hem dizinleyiciyi hem de sorgu hizmetini içeren altyapınızda yerel bir SubQuery düğümünün nasıl çalıştırılacağı üzerinde çalışır. Kendi SubQuer"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/run/run.html",relativePath:"tr/run/run.md",key:"v-f15ff5a6",path:"/tr/run/run/",headers:[{level:2,title:"Docker'ı kullanma",slug:"docker-ı-kullanma",normalizedTitle:"docker'ı kullanma",charIndex:413},{level:2,title:"Dizinleyici çalıştırma (subql/node)",slug:"dizinleyici-calıstırma-subql-node",normalizedTitle:"dizinleyici calıstırma (subql/node)",charIndex:881},{level:3,title:"Kurma",slug:"kurma",normalizedTitle:"kurma",charIndex:1234},{level:3,title:"Anahtar Komutlar",slug:"anahtar-komutlar",normalizedTitle:"anahtar komutlar",charIndex:1526},{level:2,title:"Sorgu Hizmeti Çalıştırma (altql/query)",slug:"sorgu-hizmeti-calıstırma-altql-query",normalizedTitle:"sorgu hizmeti calıstırma (altql/query)",charIndex:6111},{level:3,title:"Kurma",slug:"kurma-2",normalizedTitle:"kurma",charIndex:1234},{level:3,title:"Sorgu Hizmeti Çalıştırma",slug:"sorgu-hizmeti-calıstırma",normalizedTitle:"sorgu hizmeti calıstırma",charIndex:6111}],readingTime:{minutes:3.08,words:925},headersStr:"Docker'ı kullanma Dizinleyici çalıştırma (subql/node) Kurma Anahtar Komutlar Sorgu Hizmeti Çalıştırma (altql/query) Kurma Sorgu Hizmeti Çalıştırma",content:'# Running SubQuery Locally\n\nBu kılavuz, hem dizinleyiciyi hem de sorgu hizmetini içeren altyapınızda yerel bir SubQuery düğümünün nasıl çalıştırılacağı üzerinde çalışır. Kendi SubQuery altyapınızı çalıştırma konusunda endişelenmek istemiyor musunuz? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Docker\'ı kullanma\n\nAlternatif bir çözüm, >docker-compose.yml dosyası tarafından tanımlanan Docker Container çalıştırmaktır. Yeni başlanmış yeni bir proje için burada hiçbir şeyi değiştirmenize gerek kalmayacak.\n\nProje dizininin altında aşağıdaki komutu çalıştırın:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nGerekli paketleri (@subql/node, @subql/query ve Postgres) ilk kez indirmek biraz zaman alabilir, ancak yakında çalışan bir SubQuery düğümü görürsünüz.\n\n\n# Dizinleyici çalıştırma (subql/node)\n\nGereksinim -leri:\n\n * Postgres database (sürüm 12 veya üstü). SubQuery node blok zincirini dizine alırken, çıkarılan veriler harici bir veritabanı örneğinde depolanır.\n\nSubQuery düğümü, SubQuery projesi başına substrat tabanlı blok zinciri verilerini ayıklayan ve postgres veritabanına kaydeden bir uygulamadır.\n\n\n# Kurma\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nLütfen DO NOT, zayıf bağımlılık yönetimi nedeniyle yarn global kullanımını teşvik ettiğimizi ve bunun da bir hataya yol açabileceğini unutmayın.\n\nYüklendikten sonra, aşağıdaki komutla bir düğüm başlatabilirsiniz:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Anahtar Komutlar\n\nAşağıdaki komutlar, bir SubQuery node yapılandırmasını tamamlamanıza ve dizine eksemeye başlamanıza yardımcı olur. Daha fazla şey öğrenmek için her zaman --help çalıştırabilirsiniz.\n\n# Yerel proje yolunun göster\n\nsubql-node -f proje-yolunuz\n\n\n1\n\n\n# Sözlük Kullanma\n\nTam zincir sözlüğü kullanmak, test sırasında veya ilk dizininiz sırasında bir SubQuery projesinin işlenmesini önemli ölçüde hızlandırabilir. Bazı durumlarda, 10 kata kadar endeksleme performansı artışları gördük.\n\nTam zincir sözlüğü, belirli bir zincir içindeki tüm olayların ve dışsal öğelerin konumunu önceden dizine dizine işaretler ve düğüm hizmetinizin her bloğu incelemek yerine dizine alırken ilgili konumlara atlamasını sağlar.\n\nSözlük uç noktasını project.yaml dosyanıza ekleyebilirsiniz (bkz. Manifest File) veya aşağıdaki komutu kullanarak çalışma zamanında belirtebilirsiniz:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\nRead more about how a SubQuery Dictionary works.\n\n# Veritabanına bağlanma\n\ndB_USER=postgres dışa aktarma\nDB_PASS=postgres dışa aktarma\ndışa aktarma DB_DATABASE=postgres\nDB_HOST=localhost ver\ndışa aktarma DB_PORT=5432\nsubql-node -f proje-yolunuz \n\n\n1\n2\n3\n4\n5\n6\n\n\nPostgres veritabanınızın yapılandırmasına (örneğin, farklı bir veritabanı parolası) bağlı olarak, lütfen hem dizin oluşturucunun (\'subql/node\') hem de sorgu hizmetinin (\'subql/query\') ona bir bağlantı kurabildiğinden emin olun.\n\n# Yapılandırma dosyası belirtme\n\nsubql-node -c projeniz-config.yml\n\n\n1\n\n\nBu, query node YAML veya JSON biçiminde olabilecek bir yapılandırma dosyasına yönlendirecektir. Lütfen aşağıdaki örneğe bakın.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Blok getirme toplu iş boyutunu değiştirme\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nDizinleyici zinciri ilk dizine aldığında, tek blokları getirmek performansı önemli ölçüde düşürecektir. Getirilen blok sayısını ayarlamak için toplu iş boyutunu artırmak genel işlem süresini azaltır. Geçerli varsayılan toplu iş boyutu 100\'dür.\n\n# Yerel mod\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nHata ayıklama amacıyla, kullanıcılar düğümü yerel modda çalıştırabilir. Yerel modele geçiş, varsayılan şemada postgres tabloları public oluşturur.\n\nYerel mod kullanılmazsa, ilk subquery_ ve karşılık gelen proje tablolarına sahip yeni bir Postgres şeması oluşturulur.\n\n# Node sağlığı kontrol ediliyor\n\nÇalışan bir SubQuery node düğümünün durumunu denetlemek ve izlemek için kullanabileceğiniz 2 uç nokta vardır.\n\n * Health check endpoint that returns a simple 200 response\n * Metadata endpoint that includes additional analytics of your running SubQuery node\n\nAppend this to the base URL of your SubQuery node. Eg http://localhost:3000/meta will return:\n\n{\n    "currentProcessingHeight": 1000699,\n    "currentProcessingTimestamp": 1631517883547,\n    "targetHeight": 6807295,\n    "bestHeight": 6807298,\n    "indexerNodeVersion": "0.19.1",\n    "lastProcessedHeight": 1000699,\n    "lastProcessedTimestamp": 1631517883555,\n    "uptime": 41.151789063,\n    "polkadotSdkVersion": "5.4.1",\n    "apiConnected": true,\n    "injectedApiConnected": true,\n    "usingDictionary": false,\n    "chain": "Polkadot",\n    "specName": "polkadot",\n    "genesisHash": "0x91b171bb158e2d3848fa23a9f1c25182fb8e20313b2c1eb49219da7a70ce90c3",\n    "blockTime": 6000\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nhttp://localhost:3000/health will return HTTP 200 if successful.\n\nA 500 error will be returned if the indexer is not healthy. This can often be seen when the node is booting up.\n\n{\n    "status": 500,\n    "error": "Indexer is not healthy"\n}\n\n\n1\n2\n3\n4\n\n\nIf an incorrect URL is used, a 404 not found error will be returned.\n\n{\n"statusCode": 404,\n"message": "Cannot GET /healthy",\n"error": "Not Found"\n}\n\n\n1\n2\n3\n4\n5\n\n\n# Debug your project\n\nUse the node inspector to run the following command.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nFor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\nThen open up the Chrome dev tools, go to Source > Filesystem and add your project to the workspace and start debugging. For more information, check out How to debug a SubQuery project\n\n\n# Sorgu Hizmeti Çalıştırma (altql/query)\n\n\n# Kurma\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nLütfen DO NOT, zayıf bağımlılık yönetimi nedeniyle yarn global kullanımını teşvik ettiğimizi ve bunun da bir hataya yol açabileceğini unutmayın.\n\n\n# Sorgu Hizmeti Çalıştırma\n\nexport DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nProjeyi initialize the project proje adıyla aynı olduğundan emin olun. Ayrıca, ortam değişkenlerinin doğru olup olmadığını denetleyin.\n\nSubQuery hizmetini başarıyla çalıştırdikten sonra tarayıcınızı açın ve http://localhost:3000 gidin. Explorer\'da ve sorguya hazır şemada gösterilen bir GraphQL oyun alanı görmeniz gerekir.',normalizedContent:'# running subquery locally\n\nbu kılavuz, hem dizinleyiciyi hem de sorgu hizmetini iceren altyapınızda yerel bir subquery dugumunun nasıl calıstırılacagı uzerinde calısır. kendi subquery altyapınızı calıstırma konusunda endiselenmek istemiyor musunuz? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# docker\'ı kullanma\n\nalternatif bir cozum, >docker-compose.yml dosyası tarafından tanımlanan docker container calıstırmaktır. yeni baslanmıs yeni bir proje icin burada hicbir seyi degistirmenize gerek kalmayacak.\n\nproje dizininin altında asagıdaki komutu calıstırın:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\ngerekli paketleri (@subql/node, @subql/query ve postgres) ilk kez indirmek biraz zaman alabilir, ancak yakında calısan bir subquery dugumu gorursunuz.\n\n\n# dizinleyici calıstırma (subql/node)\n\ngereksinim -leri:\n\n * postgres database (surum 12 veya ustu). subquery node blok zincirini dizine alırken, cıkarılan veriler harici bir veritabanı orneginde depolanır.\n\nsubquery dugumu, subquery projesi basına substrat tabanlı blok zinciri verilerini ayıklayan ve postgres veritabanına kaydeden bir uygulamadır.\n\n\n# kurma\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nlutfen do not, zayıf bagımlılık yonetimi nedeniyle yarn global kullanımını tesvik ettigimizi ve bunun da bir hataya yol acabilecegini unutmayın.\n\nyuklendikten sonra, asagıdaki komutla bir dugum baslatabilirsiniz:\n\nsubql-node <command>\n\n\n1\n\n\n\n# anahtar komutlar\n\nasagıdaki komutlar, bir subquery node yapılandırmasını tamamlamanıza ve dizine eksemeye baslamanıza yardımcı olur. daha fazla sey ogrenmek icin her zaman --help calıstırabilirsiniz.\n\n# yerel proje yolunun goster\n\nsubql-node -f proje-yolunuz\n\n\n1\n\n\n# sozluk kullanma\n\ntam zincir sozlugu kullanmak, test sırasında veya ilk dizininiz sırasında bir subquery projesinin islenmesini onemli olcude hızlandırabilir. bazı durumlarda, 10 kata kadar endeksleme performansı artısları gorduk.\n\ntam zincir sozlugu, belirli bir zincir icindeki tum olayların ve dıssal ogelerin konumunu onceden dizine dizine isaretler ve dugum hizmetinizin her blogu incelemek yerine dizine alırken ilgili konumlara atlamasını saglar.\n\nsozluk uc noktasını project.yaml dosyanıza ekleyebilirsiniz (bkz. manifest file) veya asagıdaki komutu kullanarak calısma zamanında belirtebilirsiniz:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\nread more about how a subquery dictionary works.\n\n# veritabanına baglanma\n\ndb_user=postgres dısa aktarma\ndb_pass=postgres dısa aktarma\ndısa aktarma db_database=postgres\ndb_host=localhost ver\ndısa aktarma db_port=5432\nsubql-node -f proje-yolunuz \n\n\n1\n2\n3\n4\n5\n6\n\n\npostgres veritabanınızın yapılandırmasına (ornegin, farklı bir veritabanı parolası) baglı olarak, lutfen hem dizin olusturucunun (\'subql/node\') hem de sorgu hizmetinin (\'subql/query\') ona bir baglantı kurabildiginden emin olun.\n\n# yapılandırma dosyası belirtme\n\nsubql-node -c projeniz-config.yml\n\n\n1\n\n\nbu, query node yaml veya json biciminde olabilecek bir yapılandırma dosyasına yonlendirecektir. lutfen asagıdaki ornege bakın.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# blok getirme toplu is boyutunu degistirme\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\ndizinleyici zinciri ilk dizine aldıgında, tek blokları getirmek performansı onemli olcude dusurecektir. getirilen blok sayısını ayarlamak icin toplu is boyutunu artırmak genel islem suresini azaltır. gecerli varsayılan toplu is boyutu 100\'dur.\n\n# yerel mod\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nhata ayıklama amacıyla, kullanıcılar dugumu yerel modda calıstırabilir. yerel modele gecis, varsayılan semada postgres tabloları public olusturur.\n\nyerel mod kullanılmazsa, ilk subquery_ ve karsılık gelen proje tablolarına sahip yeni bir postgres seması olusturulur.\n\n# node saglıgı kontrol ediliyor\n\ncalısan bir subquery node dugumunun durumunu denetlemek ve izlemek icin kullanabileceginiz 2 uc nokta vardır.\n\n * health check endpoint that returns a simple 200 response\n * metadata endpoint that includes additional analytics of your running subquery node\n\nappend this to the base url of your subquery node. eg http://localhost:3000/meta will return:\n\n{\n    "currentprocessingheight": 1000699,\n    "currentprocessingtimestamp": 1631517883547,\n    "targetheight": 6807295,\n    "bestheight": 6807298,\n    "indexernodeversion": "0.19.1",\n    "lastprocessedheight": 1000699,\n    "lastprocessedtimestamp": 1631517883555,\n    "uptime": 41.151789063,\n    "polkadotsdkversion": "5.4.1",\n    "apiconnected": true,\n    "injectedapiconnected": true,\n    "usingdictionary": false,\n    "chain": "polkadot",\n    "specname": "polkadot",\n    "genesishash": "0x91b171bb158e2d3848fa23a9f1c25182fb8e20313b2c1eb49219da7a70ce90c3",\n    "blocktime": 6000\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nhttp://localhost:3000/health will return http 200 if successful.\n\na 500 error will be returned if the indexer is not healthy. this can often be seen when the node is booting up.\n\n{\n    "status": 500,\n    "error": "indexer is not healthy"\n}\n\n\n1\n2\n3\n4\n\n\nif an incorrect url is used, a 404 not found error will be returned.\n\n{\n"statuscode": 404,\n"message": "cannot get /healthy",\n"error": "not found"\n}\n\n\n1\n2\n3\n4\n5\n\n\n# debug your project\n\nuse the node inspector to run the following command.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nfor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\nthen open up the chrome dev tools, go to source > filesystem and add your project to the workspace and start debugging. for more information, check out how to debug a subquery project\n\n\n# sorgu hizmeti calıstırma (altql/query)\n\n\n# kurma\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nlutfen do not, zayıf bagımlılık yonetimi nedeniyle yarn global kullanımını tesvik ettigimizi ve bunun da bir hataya yol acabilecegini unutmayın.\n\n\n# sorgu hizmeti calıstırma\n\nexport db_host=localhost subql-query --name <project_name> --playground ````\n\nprojeyi initialize the project proje adıyla aynı oldugundan emin olun. ayrıca, ortam degiskenlerinin dogru olup olmadıgını denetleyin.\n\nsubquery hizmetini basarıyla calıstırdikten sonra tarayıcınızı acın ve http://localhost:3000 gidin. explorer\'da ve sorguya hazır semada gosterilen bir graphql oyun alanı gormeniz gerekir.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/tr/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/run/sandbox.html",relativePath:"tr/run/sandbox.md",key:"v-53d12fb5",path:"/tr/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Blockchain getirme toplu iş boyutu nasıl değiştirilir?",frontmatter:{summary:"Blockchain getirme toplu iş boyutu nasıl değiştirilir? Video kılavuzu Giriş Varsayılan toplu iş boyutu 100'dür, ancak bu, --batch-size=xx komutu kullanılarak değiştirilebilir. Bunu",meta:[{property:"og:url",content:"/tr/tutorials_examples/batch-size.html"},{property:"og:title",content:"Blockchain getirme toplu iş boyutu nasıl değiştirilir?"},{property:"og:description",content:"Blockchain getirme toplu iş boyutu nasıl değiştirilir? Video kılavuzu Giriş Varsayılan toplu iş boyutu 100'dür, ancak bu, --batch-size=xx komutu kullanılarak değiştirilebilir. Bunu"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/tutorials_examples/batch-size.html",relativePath:"tr/tutorials_examples/batch-size.md",key:"v-ed843a4a",path:"/tr/tutorials_examples/batch-size/",headers:[{level:2,title:"Video kılavuzu",slug:"video-kılavuzu",normalizedTitle:"video kılavuzu",charIndex:61},{level:2,title:"Giriş",slug:"giris",normalizedTitle:"giris",charIndex:80},{level:2,title:"Toplu iş boyutu neden değiştirilir?",slug:"toplu-is-boyutu-neden-degistirilir",normalizedTitle:"toplu is boyutu neden degistirilir?",charIndex:770}],readingTime:{minutes:.42,words:126},headersStr:"Video kılavuzu Giriş Toplu iş boyutu neden değiştirilir?",content:'# Blockchain getirme toplu iş boyutu nasıl değiştirilir?\n\n\n# Video kılavuzu\n\n\n# Giriş\n\nVarsayılan toplu iş boyutu 100\'dür, ancak bu, --batch-size=xx komutu kullanılarak değiştirilebilir.\n\nBunu komut satırına ek bir bayrak olarak yapmanız veya Docker kullanıyorsanız, docker-compose.yml dosyasını aşağıdakilerle değiştirin:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nBu örnek, toplu iş boyutunu 50 olarak ayarlar.\n\n\n# Toplu iş boyutu neden değiştirilir?\n\nDaha küçük bir toplu iş boyutu kullanmak bellek kullanımını azaltabilir ve kullanıcıları büyük sorgular için asılı bırakmaz. Diğer sözcüklerde, uygulamanız daha duyarlı olabilir.',normalizedContent:'# blockchain getirme toplu is boyutu nasıl degistirilir?\n\n\n# video kılavuzu\n\n\n# giris\n\nvarsayılan toplu is boyutu 100\'dur, ancak bu, --batch-size=xx komutu kullanılarak degistirilebilir.\n\nbunu komut satırına ek bir bayrak olarak yapmanız veya docker kullanıyorsanız, docker-compose.yml dosyasını asagıdakilerle degistirin:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nbu ornek, toplu is boyutunu 50 olarak ayarlar.\n\n\n# toplu is boyutu neden degistirilir?\n\ndaha kucuk bir toplu is boyutu kullanmak bellek kullanımını azaltabilir ve kullanıcıları buyuk sorgular icin asılı bırakmaz. diger sozcuklerde, uygulamanız daha duyarlı olabilir.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Farklı bir blok yüksekliğinde nasıl başlarılır?",frontmatter:{summary:"Farklı bir blok yüksekliğinde nasıl başlarılır? Video kılavuzu Giriş Varsayılan olarak, tüm başlangıç projeleri blockchain'i genesis bloğundan senkronize etmeye başlar. Diğer sözcü",meta:[{property:"og:url",content:"/tr/tutorials_examples/block-height.html"},{property:"og:title",content:"Farklı bir blok yüksekliğinde nasıl başlarılır?"},{property:"og:description",content:"Farklı bir blok yüksekliğinde nasıl başlarılır? Video kılavuzu Giriş Varsayılan olarak, tüm başlangıç projeleri blockchain'i genesis bloğundan senkronize etmeye başlar. Diğer sözcü"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/tutorials_examples/block-height.html",relativePath:"tr/tutorials_examples/block-height.md",key:"v-4bcb5835",path:"/tr/tutorials_examples/block-height/",headers:[{level:2,title:"Video kılavuzu",slug:"video-kılavuzu",normalizedTitle:"video kılavuzu",charIndex:54},{level:2,title:"Giriş",slug:"giris",normalizedTitle:"giris",charIndex:73},{level:2,title:"Neden sıfırdan başlamıyorum?",slug:"neden-sıfırdan-baslamıyorum",normalizedTitle:"neden sıfırdan baslamıyorum?",charIndex:1024},{level:2,title:"Sıfırdan başlamamanın dezavantajları nelerdir?",slug:"sıfırdan-baslamamanın-dezavantajları-nelerdir",normalizedTitle:"sıfırdan baslamamanın dezavantajları nelerdir?",charIndex:1303},{level:2,title:"Mevcut blockchain yüksekliği nasıl bulunur?",slug:"mevcut-blockchain-yuksekligi-nasıl-bulunur",normalizedTitle:"mevcut blockchain yuksekligi nasıl bulunur?",charIndex:1461},{level:2,title:"Yeniden oluşturma mı yoksa kodekgen mi yapmam gerekiyor?",slug:"yeniden-olusturma-mı-yoksa-kodekgen-mi-yapmam-gerekiyor",normalizedTitle:"yeniden olusturma mı yoksa kodekgen mi yapmam gerekiyor?",charIndex:1664}],readingTime:{minutes:.78,words:235},headersStr:"Video kılavuzu Giriş Neden sıfırdan başlamıyorum? Sıfırdan başlamamanın dezavantajları nelerdir? Mevcut blockchain yüksekliği nasıl bulunur? Yeniden oluşturma mı yoksa kodekgen mi yapmam gerekiyor?",content:'# Farklı bir blok yüksekliğinde nasıl başlarılır?\n\n\n# Video kılavuzu\n\n\n# Giriş\n\nVarsayılan olarak, tüm başlangıç projeleri blockchain\'i genesis bloğundan senkronize etmeye başlar. Diğer sözcüklerde, blok 1\'den. Büyük blok zincirleri için, bunun tam olarak senkronize olması genellikle günler hatta haftalar alabilir.\n\nSıfır olmayan bir yükseklikten eşitleyici bir SubQuery düğümü başlatmak için tek yapmanız gereken project.yaml dosyanızı değiştirmek ve startBlock anahtarını değiştirmektir.\n\nAşağıda, başlangıç bloğunun 1.000.000 olarak ayarlandığı bir project.yaml dosyası verilmiştir\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Neden sıfırdan başlamıyorum?\n\nAna neden, blockchain\'i senkronize etme süresini azaltabilmesidir. Bu, yalnızca son 3 aydaki işlemlerle ilgileniyorsanız, yalnızca son 3 ayı daha az bekleme süresi anlamına gelen senkronize edebilir ve gelişiminize daha hızlı başlayabilirsiniz.\n\n\n# Sıfırdan başlamamanın dezavantajları nelerdir?\n\nEn belirgin dezavantajı, sahip olmadığınız bloklar için blok zincirindeki verileri sorgulayamayacaksınız.\n\n\n# Mevcut blockchain yüksekliği nasıl bulunur?\n\nPolkadot ağını kullanıyorsanız, https://polkascan.io/ ziyaret edebilir, ağı seçebilir ve ardından "Kesinleştirilmiş Blok" rakamını görüntüleyebilirsiniz.\n\n\n# Yeniden oluşturma mı yoksa kodekgen mi yapmam gerekiyor?\n\nHayır. Temelde bir yapılandırma dosyası olan project.yaml dosyasını değiştirdiğiniz için, typescript kodunu yeniden oluşturmanız veya yeniden oluşturmanız gerekmeyecektir.',normalizedContent:'# farklı bir blok yuksekliginde nasıl baslarılır?\n\n\n# video kılavuzu\n\n\n# giris\n\nvarsayılan olarak, tum baslangıc projeleri blockchain\'i genesis blogundan senkronize etmeye baslar. diger sozcuklerde, blok 1\'den. buyuk blok zincirleri icin, bunun tam olarak senkronize olması genellikle gunler hatta haftalar alabilir.\n\nsıfır olmayan bir yukseklikten esitleyici bir subquery dugumu baslatmak icin tek yapmanız gereken project.yaml dosyanızı degistirmek ve startblock anahtarını degistirmektir.\n\nasagıda, baslangıc blogunun 1.000.000 olarak ayarlandıgı bir project.yaml dosyası verilmistir\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# neden sıfırdan baslamıyorum?\n\nana neden, blockchain\'i senkronize etme suresini azaltabilmesidir. bu, yalnızca son 3 aydaki islemlerle ilgileniyorsanız, yalnızca son 3 ayı daha az bekleme suresi anlamına gelen senkronize edebilir ve gelisiminize daha hızlı baslayabilirsiniz.\n\n\n# sıfırdan baslamamanın dezavantajları nelerdir?\n\nen belirgin dezavantajı, sahip olmadıgınız bloklar icin blok zincirindeki verileri sorgulayamayacaksınız.\n\n\n# mevcut blockchain yuksekligi nasıl bulunur?\n\npolkadot agını kullanıyorsanız, https://polkascan.io/ ziyaret edebilir, agı secebilir ve ardından "kesinlestirilmis blok" rakamını goruntuleyebilirsiniz.\n\n\n# yeniden olusturma mı yoksa kodekgen mi yapmam gerekiyor?\n\nhayır. temelde bir yapılandırma dosyası olan project.yaml dosyasını degistirdiginiz icin, typescript kodunu yeniden olusturmanız veya yeniden olusturmanız gerekmeyecektir.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to debug a SubQuery project?",frontmatter:{summary:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will",meta:[{property:"og:url",content:"/tr/tutorials_examples/debug-projects.html"},{property:"og:title",content:"How to debug a SubQuery project?"},{property:"og:description",content:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/tutorials_examples/debug-projects.html",relativePath:"tr/tutorials_examples/debug-projects.md",key:"v-e1ab6f4a",path:"/tr/tutorials_examples/debug-projects/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:39},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:55},{level:2,title:"Node inspector",slug:"node-inspector",normalizedTitle:"node inspector",charIndex:272},{level:2,title:"Chrome devtools",slug:"chrome-devtools",normalizedTitle:"chrome devtools",charIndex:683}],readingTime:{minutes:.65,words:196},headersStr:"Video guide Introduction Node inspector Chrome devtools",content:"# How to debug a SubQuery project?\n\n\n# Video guide\n\n\n# Introduction\n\nIn order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a Node.js inspector in conjunction with Chrome developer tools.\n\n\n# Node inspector\n\nRun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nFor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# Chrome devtools\n\nOpen up Chrome DevTools and navigate to the Sources tab. Note that clicking on the green icon will open up a new window.\n\n\n\nNavigate to Filesystem and add your project folder to the workspace. Then open the dist > mappings folder and select the code you wish to debug. Then step through the code as with any standard debugging tool.\n\n",normalizedContent:"# how to debug a subquery project?\n\n\n# video guide\n\n\n# introduction\n\nin order to debug subquery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a node.js inspector in conjunction with chrome developer tools.\n\n\n# node inspector\n\nrun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nfor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# chrome devtools\n\nopen up chrome devtools and navigate to the sources tab. note that clicking on the green icon will open up a new window.\n\n\n\nnavigate to filesystem and add your project folder to the workspace. then open the dist > mappings folder and select the code you wish to debug. then step through the code as with any standard debugging tool.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How does a SubQuery dictionary work?",frontmatter:{summary:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod",meta:[{property:"og:url",content:"/tr/tutorials_examples/dictionary.html"},{property:"og:title",content:"How does a SubQuery dictionary work?"},{property:"og:description",content:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/tutorials_examples/dictionary.html",relativePath:"tr/tutorials_examples/dictionary.md",key:"v-64b62297",path:"/tr/tutorials_examples/dictionary/",headers:[{level:2,title:"How to incorporate a dictionary into your project?",slug:"how-to-incorporate-a-dictionary-into-your-project",normalizedTitle:"how to incorporate a dictionary into your project?",charIndex:1024},{level:2,title:"What happens when a dictionary IS NOT used?",slug:"what-happens-when-a-dictionary-is-not-used",normalizedTitle:"what happens when a dictionary is not used?",charIndex:1350},{level:2,title:"What happens when a dictionary IS used?",slug:"what-happens-when-a-dictionary-is-used",normalizedTitle:"what happens when a dictionary is used?",charIndex:1772},{level:2,title:"When is a dictionary NOT useful?",slug:"when-is-a-dictionary-not-useful",normalizedTitle:"when is a dictionary not useful?",charIndex:2849}],readingTime:{minutes:2,words:601},headersStr:"How to incorporate a dictionary into your project? What happens when a dictionary IS NOT used? What happens when a dictionary IS used? When is a dictionary NOT useful?",content:"# How does a SubQuery dictionary work?\n\nThe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. Another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nThe network.dictionary endpoint is an optional parameter that if present, the SDK will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\nTaking the SubQuery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specVersion. These 3 entities contain 6, 4, and 2 fields respectively. When this project is run, these fields are reflected in the database tables.\n\n\n\nData from the blockchain is then stored in these tables and indexed for performance. The project is then hosted in SubQuery Projects and the API endpoint is available to be added to the manifest file.\n\n\n# How to incorporate a dictionary into your project?\n\nAdd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. Eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# What happens when a dictionary IS NOT used?\n\nWhen a dictionary is NOT used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. Later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# What happens when a dictionary IS used?\n\nWhen a dictionary IS used, the indexer will first take the call and event filters as parameters and merge this into a GraphQL query. It then uses the dictionary's API to obtain a list of relevant block heights only that contains the specific events and extrinsics. Often this is substantially less than 100 if the default is used.\n\nFor example, imagine a situation where you're indexing transfer events. Not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nThe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. This is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nThis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. But compared to the traditional method, it adds an additional step to get data from the dictionary’s API.\n\n\n# When is a dictionary NOT useful?\n\nWhen block handlers are used to grab data from a chain, every block needs to be processed. Therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nAlso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",normalizedContent:"# how does a subquery dictionary work?\n\nthe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nthe network.dictionary endpoint is an optional parameter that if present, the sdk will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\ntaking the subquery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specversion. these 3 entities contain 6, 4, and 2 fields respectively. when this project is run, these fields are reflected in the database tables.\n\n\n\ndata from the blockchain is then stored in these tables and indexed for performance. the project is then hosted in subquery projects and the api endpoint is available to be added to the manifest file.\n\n\n# how to incorporate a dictionary into your project?\n\nadd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# what happens when a dictionary is not used?\n\nwhen a dictionary is not used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# what happens when a dictionary is used?\n\nwhen a dictionary is used, the indexer will first take the call and event filters as parameters and merge this into a graphql query. it then uses the dictionary's api to obtain a list of relevant block heights only that contains the specific events and extrinsics. often this is substantially less than 100 if the default is used.\n\nfor example, imagine a situation where you're indexing transfer events. not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nthe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. this is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nthis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. but compared to the traditional method, it adds an additional step to get data from the dictionary’s api.\n\n\n# when is a dictionary not useful?\n\nwhen block handlers are used to grab data from a chain, every block needs to be processed. therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nalso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Öğreticiler & Örnekler",frontmatter:{summary:"Öğreticiler & Örnekler Burada öğreticilerimizi listeleyeceğiz ve en kolay ve en hızlı şekilde çalışmaya devam etmenize yardımcı olacak çeşitli örnekleri keşfedeceğiz. Öğreticiler S",meta:[{property:"og:url",content:"/tr/tutorials_examples/introduction.html"},{property:"og:title",content:"Öğreticiler & Örnekler"},{property:"og:description",content:"Öğreticiler & Örnekler Burada öğreticilerimizi listeleyeceğiz ve en kolay ve en hızlı şekilde çalışmaya devam etmenize yardımcı olacak çeşitli örnekleri keşfedeceğiz. Öğreticiler S"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/tutorials_examples/introduction.html",relativePath:"tr/tutorials_examples/introduction.md",key:"v-4f4aaacf",path:"/tr/tutorials_examples/introduction/",headers:[{level:2,title:"Öğreticiler",slug:"ogreticiler",normalizedTitle:"ogreticiler",charIndex:2},{level:2,title:"SubQuery Örnekleri Projeleri",slug:"subquery-ornekleri-projeleri",normalizedTitle:"subquery ornekleri projeleri",charIndex:190}],readingTime:{minutes:.68,words:203},headersStr:"Öğreticiler SubQuery Örnekleri Projeleri",content:"# Öğreticiler & Örnekler\n\nBurada öğreticilerimizi listeleyeceğiz ve en kolay ve en hızlı şekilde çalışmaya devam etmenize yardımcı olacak çeşitli örnekleri keşfedeceğiz.\n\n\n# Öğreticiler\n\n\n# SubQuery Örnekleri Projeleri\n\nÖRNEK                       AÇIKLAMA                                                      KONU\nextrinsic-finalized-block   Dizinler, karmaları tarafından sorgulanabilmeleri için dış    block handler işleviyle en basit örnek\n                            dizinler\nblock-timestamp             Sonlandırılmış her bloğun zaman damgalarını dizine dizine     Başka bir basit call handler işlevi\n                            ayırır\nvalidator-threshold         Bir doğrulayıcının seçilmesi için gereken en az staking       More complicated block handler function that makes external\n                            tutarını dizineler.                                           calls to the @polkadot/api for additional on-chain data\nsum-reward                  Kesinleşmiş blok olaylarından tahvil, ödül ve eğik çizgiler   one-to-many ilişkisi olan daha karmaşık__event handlers__\n                            dizinler\nentity-relation             Hesaplar arasındaki bakiye transferlerini dizine dizinler,    One-to-many ve many-to-many ilişkiler ve karmaşık\n                            ayrıca yardımcı program toplu işlemini de dizine              relationships and complicated\n                            dizinelerTüm çağrıların içeriğini öğrenmek için\nkitty                       Kediciklerin doğum bilgilerini dizine dizinler.               Complex call handlers and event handlers, with data indexed\n                                                                                          from a custom chain",normalizedContent:"# ogreticiler & ornekler\n\nburada ogreticilerimizi listeleyecegiz ve en kolay ve en hızlı sekilde calısmaya devam etmenize yardımcı olacak cesitli ornekleri kesfedecegiz.\n\n\n# ogreticiler\n\n\n# subquery ornekleri projeleri\n\nornek                       aciklama                                                      konu\nextrinsic-finalized-block   dizinler, karmaları tarafından sorgulanabilmeleri icin dıs    block handler isleviyle en basit ornek\n                            dizinler\nblock-timestamp             sonlandırılmıs her blogun zaman damgalarını dizine dizine     baska bir basit call handler islevi\n                            ayırır\nvalidator-threshold         bir dogrulayıcının secilmesi icin gereken en az staking       more complicated block handler function that makes external\n                            tutarını dizineler.                                           calls to the @polkadot/api for additional on-chain data\nsum-reward                  kesinlesmis blok olaylarından tahvil, odul ve egik cizgiler   one-to-many iliskisi olan daha karmasık__event handlers__\n                            dizinler\nentity-relation             hesaplar arasındaki bakiye transferlerini dizine dizinler,    one-to-many ve many-to-many iliskiler ve karmasık\n                            ayrıca yardımcı program toplu islemini de dizine              relationships and complicated\n                            dizinelertum cagrıların icerigini ogrenmek icin\nkitty                       kediciklerin dogum bilgilerini dizine dizinler.               complex call handlers and event handlers, with data indexed\n                                                                                          from a custom chain",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to run an indexer node?",frontmatter:{summary:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r",meta:[{property:"og:url",content:"/tr/tutorials_examples/run-indexer.html"},{property:"og:title",content:"How to run an indexer node?"},{property:"og:description",content:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/tutorials_examples/run-indexer.html",relativePath:"tr/tutorials_examples/run-indexer.md",key:"v-102e162d",path:"/tr/tutorials_examples/run-indexer/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:34},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:50},{level:2,title:"Postgres",slug:"postgres",normalizedTitle:"postgres",charIndex:300},{level:2,title:"Install subql/node",slug:"install-subql-node",normalizedTitle:"install subql/node",charIndex:484},{level:2,title:"Setting DB configs",slug:"setting-db-configs",normalizedTitle:"setting db configs",charIndex:802},{level:2,title:"Indexing a project",slug:"indexing-a-project",normalizedTitle:"indexing a project",charIndex:1380},{level:2,title:"Inspecting Postgres",slug:"inspecting-postgres",normalizedTitle:"inspecting postgres",charIndex:1687}],readingTime:{minutes:1.18,words:353},headersStr:"Video guide Introduction Postgres Install subql/node Setting DB configs Indexing a project Inspecting Postgres",content:"# How to run an indexer node?\n\n\n# Video guide\n\n\n# Introduction\n\nRunning an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It requires more time and effort but will enhance your understanding of how SubQuery works under the covers.\n\n\n# Postgres\n\nRunning an indexer node on your infrastructure will require the setup of a Postgres database. You can install Postgres from here and ensure the version is 12 or greater.\n\n\n# Install subql/node\n\nThen to run a SubQuery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nThe -g flag means to install it globally which means on OSX, the location will be /usr/local/lib/node_modules.\n\nOnce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# Setting DB configs\n\nNext, you need to set the following environmental variables:\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\n\n\n1\n2\n3\n4\n5\n\n\nOf course, if you have different values for the above keys, please adjust accordingly. Note that the env command will display the current environment variables and that this process only sets these values temporarily. That is, they are only valid for the duration of the terminal session. To set them permanently, store them in your ~/bash_profile instead.\n\n\n# Indexing a project\n\nTo start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nIf you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. You should see the indexer node kick into life and start indexing blocks.\n\n\n# Inspecting Postgres\n\nIf you navigate to Postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. The starter_entities table contains the indexes. To view the data, run select (*) from subquery_1.starter_entities.",normalizedContent:"# how to run an indexer node?\n\n\n# video guide\n\n\n# introduction\n\nrunning an indexer node is another option outside of using docker or having a project hosted for you at subquery projects. it requires more time and effort but will enhance your understanding of how subquery works under the covers.\n\n\n# postgres\n\nrunning an indexer node on your infrastructure will require the setup of a postgres database. you can install postgres from here and ensure the version is 12 or greater.\n\n\n# install subql/node\n\nthen to run a subquery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nthe -g flag means to install it globally which means on osx, the location will be /usr/local/lib/node_modules.\n\nonce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# setting db configs\n\nnext, you need to set the following environmental variables:\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\n\n\n1\n2\n3\n4\n5\n\n\nof course, if you have different values for the above keys, please adjust accordingly. note that the env command will display the current environment variables and that this process only sets these values temporarily. that is, they are only valid for the duration of the terminal session. to set them permanently, store them in your ~/bash_profile instead.\n\n\n# indexing a project\n\nto start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nif you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. you should see the indexer node kick into life and start indexing blocks.\n\n\n# inspecting postgres\n\nif you navigate to postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. the starter_entities table contains the indexes. to view the data, run select (*) from subquery_1.starter_entities.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Terminoloji",frontmatter:{summary:"Terminoloji SubQuery Project ( where the magic happens): Bir SubQuery Düğümünün bir proje ağından nasıl geçmesi ve toplaması gerektiği ve verilerin yararlı GraphQL sorgularını etki",meta:[{property:"og:url",content:"/tr/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminoloji"},{property:"og:description",content:"Terminoloji SubQuery Project ( where the magic happens): Bir SubQuery Düğümünün bir proje ağından nasıl geçmesi ve toplaması gerektiği ve verilerin yararlı GraphQL sorgularını etki"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tr/tutorials_examples/terminology.html",relativePath:"tr/tutorials_examples/terminology.md",key:"v-2e9e2726",path:"/tr/tutorials_examples/terminology/",readingTime:{minutes:.47,words:142},headersStr:null,content:"# Terminoloji\n\n * SubQuery Project (* where the magic happens*): Bir SubQuery Düğümünün bir proje ağından nasıl geçmesi ve toplaması gerektiği ve verilerin yararlı GraphQL sorgularını etkinleştirmek için nasıl dönüştürülmesi ve depolandığı hakkında bir tanım (@subql/cli)\n * SubQuery Node (* where the work is doner*): Bir SubQuery projesi definiton'ını kabul edecek ve bağlı bir ağı veritabanına sürekli olarak dizine alan bir düğümü çalıştıracak bir paket (@subql/node)\n * SubQuery Query Service (where we get the data from): Dizine alınan verileri sorgulamak ve görüntülemek için dağıtılan bir SubQuery node GraphQL API'si ile etkileşime giren bir paket (@subql/query)\n * GraphQL (how we query the data): Esnek grafik tabanlı veriler için özel olarak uygun API'ler için bir query langage - bkzgraphql.org",normalizedContent:"# terminoloji\n\n * subquery project (* where the magic happens*): bir subquery dugumunun bir proje agından nasıl gecmesi ve toplaması gerektigi ve verilerin yararlı graphql sorgularını etkinlestirmek icin nasıl donusturulmesi ve depolandıgı hakkında bir tanım (@subql/cli)\n * subquery node (* where the work is doner*): bir subquery projesi definiton'ını kabul edecek ve baglı bir agı veritabanına surekli olarak dizine alan bir dugumu calıstıracak bir paket (@subql/node)\n * subquery query service (where we get the data from): dizine alınan verileri sorgulamak ve goruntulemek icin dagıtılan bir subquery node graphql api'si ile etkilesime giren bir paket (@subql/query)\n * graphql (how we query the data): esnek grafik tabanlı veriler icin ozel olarak uygun api'ler icin bir query langage - bkzgraphql.org",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to start at a different block height?",frontmatter:{summary:"How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from b",meta:[{property:"og:url",content:"/tutorials_examples/block-height.html"},{property:"og:title",content:"How to start at a different block height?"},{property:"og:description",content:"How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from b"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tutorials_examples/block-height.html",relativePath:"tutorials_examples/block-height.md",key:"v-295c5866",path:"/tutorials_examples/block-height/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:48},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:64},{level:2,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:952},{level:2,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1259},{level:2,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1439},{level:2,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1633}],readingTime:{minutes:1.02,words:307},headersStr:"Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen?",content:'# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.',normalizedContent:'# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to debug a SubQuery project?",frontmatter:{summary:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will",meta:[{property:"og:url",content:"/tutorials_examples/debug-projects.html"},{property:"og:title",content:"How to debug a SubQuery project?"},{property:"og:description",content:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tutorials_examples/debug-projects.html",relativePath:"tutorials_examples/debug-projects.md",key:"v-1bc67126",path:"/tutorials_examples/debug-projects/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:39},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:55},{level:2,title:"Node inspector",slug:"node-inspector",normalizedTitle:"node inspector",charIndex:272},{level:2,title:"Chrome devtools",slug:"chrome-devtools",normalizedTitle:"chrome devtools",charIndex:683}],readingTime:{minutes:.65,words:196},headersStr:"Video guide Introduction Node inspector Chrome devtools",content:"# How to debug a SubQuery project?\n\n\n# Video guide\n\n\n# Introduction\n\nIn order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a Node.js inspector in conjunction with Chrome developer tools.\n\n\n# Node inspector\n\nRun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nFor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# Chrome devtools\n\nOpen up Chrome DevTools and navigate to the Sources tab. Note that clicking on the green icon will open up a new window.\n\n\n\nNavigate to Filesystem and add your project folder to the workspace. Then open the dist > mappings folder and select the code you wish to debug. Then step through the code as with any standard debugging tool.\n\n",normalizedContent:"# how to debug a subquery project?\n\n\n# video guide\n\n\n# introduction\n\nin order to debug subquery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a node.js inspector in conjunction with chrome developer tools.\n\n\n# node inspector\n\nrun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nfor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# chrome devtools\n\nopen up chrome devtools and navigate to the sources tab. note that clicking on the green icon will open up a new window.\n\n\n\nnavigate to filesystem and add your project folder to the workspace. then open the dist > mappings folder and select the code you wish to debug. then step through the code as with any standard debugging tool.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to change the blockchain fetching batch size?",frontmatter:{summary:"How to change the blockchain fetching batch size? Video guide Introduction The default batch size is 100, but this can be changed by using the extra command --batch-size=xx. You ne",meta:[{property:"og:url",content:"/tutorials_examples/batch-size.html"},{property:"og:title",content:"How to change the blockchain fetching batch size?"},{property:"og:description",content:"How to change the blockchain fetching batch size? Video guide Introduction The default batch size is 100, but this can be changed by using the extra command --batch-size=xx. You ne"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tutorials_examples/batch-size.html",relativePath:"tutorials_examples/batch-size.md",key:"v-685a2e6d",path:"/tutorials_examples/batch-size/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:56},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:72},{level:2,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:744}],readingTime:{minutes:.47,words:141},headersStr:"Video guide Introduction Why change the batch size?",content:'# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive.',normalizedContent:'# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How does a SubQuery dictionary work?",frontmatter:{summary:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod",meta:[{property:"og:url",content:"/tutorials_examples/dictionary.html"},{property:"og:title",content:"How does a SubQuery dictionary work?"},{property:"og:description",content:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tutorials_examples/dictionary.html",relativePath:"tutorials_examples/dictionary.md",key:"v-1f91922d",path:"/tutorials_examples/dictionary/",headers:[{level:2,title:"How to incorporate a dictionary into your project?",slug:"how-to-incorporate-a-dictionary-into-your-project",normalizedTitle:"how to incorporate a dictionary into your project?",charIndex:1024},{level:2,title:"What happens when a dictionary IS NOT used?",slug:"what-happens-when-a-dictionary-is-not-used",normalizedTitle:"what happens when a dictionary is not used?",charIndex:1350},{level:2,title:"What happens when a dictionary IS used?",slug:"what-happens-when-a-dictionary-is-used",normalizedTitle:"what happens when a dictionary is used?",charIndex:1772},{level:2,title:"When is a dictionary NOT useful?",slug:"when-is-a-dictionary-not-useful",normalizedTitle:"when is a dictionary not useful?",charIndex:2849}],readingTime:{minutes:2,words:601},headersStr:"How to incorporate a dictionary into your project? What happens when a dictionary IS NOT used? What happens when a dictionary IS used? When is a dictionary NOT useful?",content:"# How does a SubQuery dictionary work?\n\nThe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. Another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nThe network.dictionary endpoint is an optional parameter that if present, the SDK will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\nTaking the SubQuery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specVersion. These 3 entities contain 6, 4, and 2 fields respectively. When this project is run, these fields are reflected in the database tables.\n\n\n\nData from the blockchain is then stored in these tables and indexed for performance. The project is then hosted in SubQuery Projects and the API endpoint is available to be added to the manifest file.\n\n\n# How to incorporate a dictionary into your project?\n\nAdd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. Eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# What happens when a dictionary IS NOT used?\n\nWhen a dictionary is NOT used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. Later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# What happens when a dictionary IS used?\n\nWhen a dictionary IS used, the indexer will first take the call and event filters as parameters and merge this into a GraphQL query. It then uses the dictionary's API to obtain a list of relevant block heights only that contains the specific events and extrinsics. Often this is substantially less than 100 if the default is used.\n\nFor example, imagine a situation where you're indexing transfer events. Not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nThe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. This is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nThis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. But compared to the traditional method, it adds an additional step to get data from the dictionary’s API.\n\n\n# When is a dictionary NOT useful?\n\nWhen block handlers are used to grab data from a chain, every block needs to be processed. Therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nAlso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",normalizedContent:"# how does a subquery dictionary work?\n\nthe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nthe network.dictionary endpoint is an optional parameter that if present, the sdk will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\ntaking the subquery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specversion. these 3 entities contain 6, 4, and 2 fields respectively. when this project is run, these fields are reflected in the database tables.\n\n\n\ndata from the blockchain is then stored in these tables and indexed for performance. the project is then hosted in subquery projects and the api endpoint is available to be added to the manifest file.\n\n\n# how to incorporate a dictionary into your project?\n\nadd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# what happens when a dictionary is not used?\n\nwhen a dictionary is not used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# what happens when a dictionary is used?\n\nwhen a dictionary is used, the indexer will first take the call and event filters as parameters and merge this into a graphql query. it then uses the dictionary's api to obtain a list of relevant block heights only that contains the specific events and extrinsics. often this is substantially less than 100 if the default is used.\n\nfor example, imagine a situation where you're indexing transfer events. not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nthe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. this is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nthis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. but compared to the traditional method, it adds an additional step to get data from the dictionary’s api.\n\n\n# when is a dictionary not useful?\n\nwhen block handlers are used to grab data from a chain, every block needs to be processed. therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nalso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. Tutorials SubQuery Example Proje",meta:[{property:"og:url",content:"/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. Tutorials SubQuery Example Proje"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tutorials_examples/introduction.html",relativePath:"tutorials_examples/introduction.md",key:"v-65affcad",path:"/tutorials_examples/introduction/",headers:[{level:2,title:"Tutorials",slug:"tutorials",normalizedTitle:"tutorials",charIndex:2},{level:2,title:"SubQuery Example Projects",slug:"subquery-example-projects",normalizedTitle:"subquery example projects",charIndex:169}],readingTime:{minutes:.72,words:216},headersStr:"Tutorials SubQuery Example Projects",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# Tutorials\n\n\n# SubQuery Example Projects\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        The simplest example with a block handler function\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# tutorials\n\n\n# subquery example projects\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        the simplest example with a block handler function\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to run an indexer node?",frontmatter:{summary:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r",meta:[{property:"og:url",content:"/tutorials_examples/run-indexer.html"},{property:"og:title",content:"How to run an indexer node?"},{property:"og:description",content:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tutorials_examples/run-indexer.html",relativePath:"tutorials_examples/run-indexer.md",key:"v-4e5b9057",path:"/tutorials_examples/run-indexer/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:34},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:50},{level:2,title:"Postgres",slug:"postgres",normalizedTitle:"postgres",charIndex:300},{level:2,title:"Install subql/node",slug:"install-subql-node",normalizedTitle:"install subql/node",charIndex:484},{level:2,title:"Setting DB configs",slug:"setting-db-configs",normalizedTitle:"setting db configs",charIndex:802},{level:2,title:"Indexing a project",slug:"indexing-a-project",normalizedTitle:"indexing a project",charIndex:1380},{level:2,title:"Inspecting Postgres",slug:"inspecting-postgres",normalizedTitle:"inspecting postgres",charIndex:1687}],readingTime:{minutes:1.18,words:353},headersStr:"Video guide Introduction Postgres Install subql/node Setting DB configs Indexing a project Inspecting Postgres",content:"# How to run an indexer node?\n\n\n# Video guide\n\n\n# Introduction\n\nRunning an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It requires more time and effort but will enhance your understanding of how SubQuery works under the covers.\n\n\n# Postgres\n\nRunning an indexer node on your infrastructure will require the setup of a Postgres database. You can install Postgres from here and ensure the version is 12 or greater.\n\n\n# Install subql/node\n\nThen to run a SubQuery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nThe -g flag means to install it globally which means on OSX, the location will be /usr/local/lib/node_modules.\n\nOnce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# Setting DB configs\n\nNext, you need to set the following environmental variables:\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\n\n\n1\n2\n3\n4\n5\n\n\nOf course, if you have different values for the above keys, please adjust accordingly. Note that the env command will display the current environment variables and that this process only sets these values temporarily. That is, they are only valid for the duration of the terminal session. To set them permanently, store them in your ~/bash_profile instead.\n\n\n# Indexing a project\n\nTo start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nIf you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. You should see the indexer node kick into life and start indexing blocks.\n\n\n# Inspecting Postgres\n\nIf you navigate to Postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. The starter_entities table contains the indexes. To view the data, run select (*) from subquery_1.starter_entities.",normalizedContent:"# how to run an indexer node?\n\n\n# video guide\n\n\n# introduction\n\nrunning an indexer node is another option outside of using docker or having a project hosted for you at subquery projects. it requires more time and effort but will enhance your understanding of how subquery works under the covers.\n\n\n# postgres\n\nrunning an indexer node on your infrastructure will require the setup of a postgres database. you can install postgres from here and ensure the version is 12 or greater.\n\n\n# install subql/node\n\nthen to run a subquery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nthe -g flag means to install it globally which means on osx, the location will be /usr/local/lib/node_modules.\n\nonce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# setting db configs\n\nnext, you need to set the following environmental variables:\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\n\n\n1\n2\n3\n4\n5\n\n\nof course, if you have different values for the above keys, please adjust accordingly. note that the env command will display the current environment variables and that this process only sets these values temporarily. that is, they are only valid for the duration of the terminal session. to set them permanently, store them in your ~/bash_profile instead.\n\n\n# indexing a project\n\nto start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nif you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. you should see the indexer node kick into life and start indexing blocks.\n\n\n# inspecting postgres\n\nif you navigate to postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. the starter_entities table contains the indexes. to view the data, run select (*) from subquery_1.starter_entities.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tutorials_examples/terminology.html",relativePath:"tutorials_examples/terminology.md",key:"v-05bf836b",path:"/tutorials_examples/terminology/",readingTime:{minutes:.49,words:147},headersStr:null,content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * SubQuery Query Service (where we get the data from): A package (@subql/query) that interacts with the GraphQL API of a deployed SubQuery node to query and view the indexed data\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * subquery query service (where we get the data from): a package (@subql/query) that interacts with the graphql api of a deployed subquery node to query and view the indexed data\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"GraphQL Schema",frontmatter:{summary:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict",meta:[{property:"og:url",content:"/uk/create/graphql.html"},{property:"og:title",content:"GraphQL Schema"},{property:"og:description",content:"GraphQL Schema Defining Entities The schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dict"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/create/graphql.html",relativePath:"uk/create/graphql.md",key:"v-6dcc960d",path:"/uk/create/graphql/",headers:[{level:2,title:"Defining Entities",slug:"defining-entities",normalizedTitle:"defining entities",charIndex:21},{level:3,title:"Entities",slug:"entities",normalizedTitle:"entities",charIndex:30},{level:3,title:"Supported scalars and types",slug:"supported-scalars-and-types",normalizedTitle:"supported scalars and types",charIndex:931},{level:2,title:"Indexing by non-primary-key field",slug:"indexing-by-non-primary-key-field",normalizedTitle:"indexing by non-primary-key field",charIndex:1282},{level:2,title:"Entity Relationships",slug:"entity-relationships",normalizedTitle:"entity relationships",charIndex:1186},{level:3,title:"One-to-One Relationships",slug:"one-to-one-relationships",normalizedTitle:"one-to-one relationships",charIndex:3317},{level:3,title:"One-to-Many relationships",slug:"one-to-many-relationships",normalizedTitle:"one-to-many relationships",charIndex:3786},{level:3,title:"Many-to-Many relationships",slug:"many-to-many-relationships",normalizedTitle:"many-to-many relationships",charIndex:4089},{level:3,title:"Reverse Lookups",slug:"reverse-lookups",normalizedTitle:"reverse lookups",charIndex:5123},{level:2,title:"JSON type",slug:"json-type",normalizedTitle:"json type",charIndex:1268},{level:3,title:"Define JSON directive",slug:"define-json-directive",normalizedTitle:"define json directive",charIndex:6472},{level:3,title:"Querying JSON fields",slug:"querying-json-fields",normalizedTitle:"querying json fields",charIndex:7171}],readingTime:{minutes:3.78,words:1134},headersStr:"Defining Entities Entities Supported scalars and types Indexing by non-primary-key field Entity Relationships One-to-One Relationships One-to-Many relationships Many-to-Many relationships Reverse Lookups JSON type Define JSON directive Querying JSON fields",content:"# GraphQL Schema\n\n\n# Defining Entities\n\nThe schema.graphql file defines the various GraphQL schemas. Due to the way that the GraphQL query language works, the schema file essentially dictates the shape of your data from SubQuery. To learn more about how to write in GraphQL schema language, we recommend checking out Schemas and Types.\n\nImportant: When you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# Entities\n\nEach entity must define its required fields id with the type of ID!. It is used as the primary key and unique among all entities of the same type.\n\nNon-nullable fields in the entity are indicated by !. Please see the example below:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Supported scalars and types\n\nWe currently supporting flowing scalars types:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName> for nested relationship entities, you might use the defined entity's name as one of the fields. Please see in Entity Relationships.\n * JSON can alternatively store structured data, please see JSON type\n\n\n# Indexing by non-primary-key field\n\nTo improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nHowever, we don't allow users to add @index annotation on any JSON object. By default, indexes are automatically added to foreign keys and for JSON fields in the database, but only to enhance query service performance.\n\nHere is an example.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field\n}\n\ntype Title @entity {\n  id: ID!\n  name: String! @index(unique: true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nAssuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. This makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nIf a field is not unique, the maximum result set size is 100\n\nКоли запускається генерація коду, це автоматично створуює метод отриманий по імені за моделлю юзера, а заголовок поля зовнішнього ключа створює метод отриманий за назвою, до якого обидва безпосередньо можуть отримати доступ до функції відображення.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from '../types/models/User';\nimport {Title} from '../types/models/Title';\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Entity Relationships\n\nAn entity often has nested relationships with other entities. Setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\nDifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# One-to-One Relationships\n\nOne-to-one relationships are the default when only a single entity is mapped to another.\n\nExample: A passport will only belong to one person and a person only has one passport (in this example):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# One-to-Many relationships\n\nYou can use square brackets to indicate that a field type includes multiple entities.\n\nExample: A person can have multiple accounts.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account]\n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Many-to-Many relationships\n\nA many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nExample: Each person is a part of multiple groups (PersonGroup) and groups have multiple different people (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nAlso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nFor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nThis will establish a bi-directional relationship between two Accounts (from and to) through Transfer table.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Reverse Lookups\n\nTo enable a reverse lookup on an entity to a relation, attach @derivedFrom to the field and point to its reverse lookup field of another entity.\n\nThis creates a virtual field on the entity that can be queried.\n\nThe Transfer \"from\" an Account is accessible from the Account entity by setting the sentTransfer or receivedTransfer as having their value derived from the respective from or to fields.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON type\n\nWe are supporting saving data as a JSON type, which is a fast way to store structured data. We'll automatically generate corresponding JSON interfaces for querying this data and save you time defining and managing entities.\n\nWe recommend users use the JSON type in the following scenarios:\n\n * When storing structured data in a single field is more manageable than creating multiple separate entities.\n * Saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * The schema is volatile and changes frequently\n\n\n# Define JSON directive\n\nDefine the property as a JSON type by adding the jsonField annotation in the entity. This will automatically generate interfaces for all JSON objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nUnlike the entity, the jsonField directive object does not require any id field. A JSON object is also able to nest with other JSON objects.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID!\n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Querying JSON fields\n\nThe drawback of using JSON types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nHowever, the impact is still acceptable in our query service. Here is an example of how to use the contains operator in the GraphQL query on a JSON field to find the first 5 users who own a phone number that contains '0064'.\n\n#To find the the first 5 users own phone numbers contains '0064'.\n\nquery {\n  user(first: 5, filter: {contactCard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",normalizedContent:"# graphql schema\n\n\n# defining entities\n\nthe schema.graphql file defines the various graphql schemas. due to the way that the graphql query language works, the schema file essentially dictates the shape of your data from subquery. to learn more about how to write in graphql schema language, we recommend checking out schemas and types.\n\nimportant: when you make any changes to the schema file, please ensure that you regenerate your types directory with the following command yarn codegen\n\n\n# entities\n\neach entity must define its required fields id with the type of id!. it is used as the primary key and unique among all entities of the same type.\n\nnon-nullable fields in the entity are indicated by !. please see the example below:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# supported scalars and types\n\nwe currently supporting flowing scalars types:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname> for nested relationship entities, you might use the defined entity's name as one of the fields. please see in entity relationships.\n * json can alternatively store structured data, please see json type\n\n\n# indexing by non-primary-key field\n\nto improve query performance, index an entity field simply by implementing the @index annotation on a non-primary-key field.\n\nhowever, we don't allow users to add @index annotation on any json object. by default, indexes are automatically added to foreign keys and for json fields in the database, but only to enhance query service performance.\n\nhere is an example.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field\n}\n\ntype title @entity {\n  id: id!\n  name: string! @index(unique: true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nassuming we knew this user's name, but we don't know the exact id value, rather than extract all users and then filtering by name we can add @index behind the name field. this makes querying much faster and we can additionally pass the unique: true to ensure uniqueness.\n\nif a field is not unique, the maximum result set size is 100\n\nколи запускається генерація коду, це автоматично створуює метод отримании по імені за моделлю юзера, а заголовок поля зовнішнього ключа створює метод отримании за назвою, до якого обидва безпосередньо можуть отримати доступ до функціі відображення.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from '../types/models/user';\nimport {title} from '../types/models/title';\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# entity relationships\n\nan entity often has nested relationships with other entities. setting the field value to another entity name will define a one-to-one relationship between these two entities by default.\n\ndifferent entity relationships (one-to-one, one-to-many, and many-to-many) can be configured using the examples below.\n\n\n# one-to-one relationships\n\none-to-one relationships are the default when only a single entity is mapped to another.\n\nexample: a passport will only belong to one person and a person only has one passport (in this example):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# one-to-many relationships\n\nyou can use square brackets to indicate that a field type includes multiple entities.\n\nexample: a person can have multiple accounts.\n\ntype person @entity {\n  id: id!\n  accounts: [account]\n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# many-to-many relationships\n\na many-to-many relationship can be achieved by implementing a mapping entity to connect the other two entities.\n\nexample: each person is a part of multiple groups (persongroup) and groups have multiple different people (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nalso, it is possible to create a connection of the same entity in multiple fields of the middle entity.\n\nfor example, an account can have multiple transfers, and each transfer has a source and destination account.\n\nthis will establish a bi-directional relationship between two accounts (from and to) through transfer table.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# reverse lookups\n\nto enable a reverse lookup on an entity to a relation, attach @derivedfrom to the field and point to its reverse lookup field of another entity.\n\nthis creates a virtual field on the entity that can be queried.\n\nthe transfer \"from\" an account is accessible from the account entity by setting the senttransfer or receivedtransfer as having their value derived from the respective from or to fields.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json type\n\nwe are supporting saving data as a json type, which is a fast way to store structured data. we'll automatically generate corresponding json interfaces for querying this data and save you time defining and managing entities.\n\nwe recommend users use the json type in the following scenarios:\n\n * when storing structured data in a single field is more manageable than creating multiple separate entities.\n * saving arbitrary key/value user preferences (where the value can be boolean, textual, or numeric, and you don't want to have separate columns for different data types)\n * the schema is volatile and changes frequently\n\n\n# define json directive\n\ndefine the property as a json type by adding the jsonfield annotation in the entity. this will automatically generate interfaces for all json objects in your project under types/interfaces.ts, and you can access them in your mapping function.\n\nunlike the entity, the jsonfield directive object does not require any id field. a json object is also able to nest with other json objects.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id!\n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# querying json fields\n\nthe drawback of using json types is a slight impact on query efficiency when filtering, as each time it performs a text search, it is on the entire entity.\n\nhowever, the impact is still acceptable in our query service. here is an example of how to use the contains operator in the graphql query on a json field to find the first 5 users who own a phone number that contains '0064'.\n\n#to find the the first 5 users own phone numbers contains '0064'.\n\nquery {\n  user(first: 5, filter: {contactcard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Creating a SubQuery Project",frontmatter:{summary:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look",meta:[{property:"og:url",content:"/uk/create/introduction.html"},{property:"og:title",content:"Creating a SubQuery Project"},{property:"og:description",content:"Creating a SubQuery Project In the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/create/introduction.html",relativePath:"uk/create/introduction.md",key:"v-67670071",path:"/uk/create/introduction/",headers:[{level:2,title:"The Basic Workflow",slug:"the-basic-workflow",normalizedTitle:"the basic workflow",charIndex:273},{level:2,title:"Directory Structure",slug:"directory-structure",normalizedTitle:"directory structure",charIndex:1236},{level:2,title:"Code Generation",slug:"code-generation",normalizedTitle:"code generation",charIndex:1629},{level:2,title:"Build",slug:"build",normalizedTitle:"build",charIndex:2090},{level:2,title:"Logging",slug:"logging",normalizedTitle:"logging",charIndex:2327}],readingTime:{minutes:1.76,words:527},headersStr:"The Basic Workflow Directory Structure Code Generation Build Logging",content:"# Creating a SubQuery Project\n\nIn the quick start guide, we very quickly ran through an example to give you a taste of what SubQuery is and how it works. Here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# The Basic Workflow\n\nSome of the following examples will assume you have successfully initialized the starter package in the Quick start section. From that starter package, we'll walk through the standard process to customise and implement your SubQuery project.\n\n 1. Initialise your project using subql init PROJECT_NAME\n 2. Update the Manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see Manifest File\n 3. Create GraphQL entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see GraphQL Schema\n 4. Add all the mapping functions (eg mappingHandlers.ts) you wish to invoke to transform chain data to the GraphQL entities that you have defined - see Mapping\n 5. Generate, build, and publish your code to SubQuery Projects (or run in your own local node) - see Running and Querying your Starter Project in our quick start guide.\n\n\n# Directory Structure\n\nThe following map provides an overview of the directory structure of a SubQuery project when the init command is run.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nFor example:\n\n\n\n\n# Code Generation\n\nWhenever you change your GraphQL entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nThis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. These classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the GraphQL Schema.\n\n\n# Build\n\nIn order to run your SubQuery Project on a locally hosted SubQuery Node, you need to first build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Logging\n\nThe console.log method is no longer supported. Instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nTo use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nTo use logger.debug, an additional step is required. Add --log-level=debug to your command line.\n\nIf you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nYou should now see the new logging in the terminal screen.\n\n",normalizedContent:"# creating a subquery project\n\nin the quick start guide, we very quickly ran through an example to give you a taste of what subquery is and how it works. here we'll take a closer look at the workflow when creating your project and the key files you'll be working with.\n\n\n# the basic workflow\n\nsome of the following examples will assume you have successfully initialized the starter package in the quick start section. from that starter package, we'll walk through the standard process to customise and implement your subquery project.\n\n 1. initialise your project using subql init project_name\n 2. update the manifest file (project.yaml) to include information about your blockchain, and the entities that you will map - see manifest file\n 3. create graphql entities in your schema (schema.graphql) that define the shape of the data that you will extract and persist for querying - see graphql schema\n 4. add all the mapping functions (eg mappinghandlers.ts) you wish to invoke to transform chain data to the graphql entities that you have defined - see mapping\n 5. generate, build, and publish your code to subquery projects (or run in your own local node) - see running and querying your starter project in our quick start guide.\n\n\n# directory structure\n\nthe following map provides an overview of the directory structure of a subquery project when the init command is run.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nfor example:\n\n\n\n\n# code generation\n\nwhenever you change your graphql entities, you must regenerate your types directory with the following command.\n\nyarn codegen\n\n\n1\n\n\nthis will create a new directory (or update the existing) src/types which contain generated entity classes for each type you have defined previously in schema.graphql. these classes provide type-safe entity loading, read and write access to entity fields - see more about this process in the graphql schema.\n\n\n# build\n\nin order to run your subquery project on a locally hosted subquery node, you need to first build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# logging\n\nthe console.log method is no longer supported. instead, a logger module has been injected in the types, which means we can support a logger that can accept various logging levels.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nto use logger.info or logger.warn, just place the line into your mapping file.\n\n\n\nto use logger.debug, an additional step is required. add --log-level=debug to your command line.\n\nif you are running a docker container, add this line to your docker-compose.yaml file.\n\n\n\nyou should now see the new logging in the terminal screen.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{frontmatter:{summary:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello",meta:[{property:"og:url",content:"/uk/"},{property:"og:description",content:"Welcome to SubQuery’s Docs Explore and transform your chain data to build intuitive dApps faster! Quick Start Guide Understand SubQuery by getting hands on with a traditional Hello"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/",relativePath:"uk/README.md",key:"v-5dda9d1e",path:"/uk/",readingTime:{minutes:2.96,words:888},headersStr:null,content:"Welcome to SubQuery’s Docs\n\nExplore and transform your chain data to build intuitive dApps faster!\n\n\nQuick Start Guide\n\nUnderstand SubQuery by getting hands on with a traditional Hello World example. Using a template project within a Docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * The SubQuery Network\n   \n   SubQuery’s decentralised future. Read more about how indexers and consumers are rewarded.\n\n\nЧаПи (Часті Питання)\n\n * What is SubQuery?\n   \n   SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n   \n   READ MORE\n * What is the best way to get started with SubQuery?\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n * How can I contribute or give feedback to SubQuery?\n   \n   We love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guidelines (coming soon).\n   \n   READ MORE\n * How much does it cost to host my project in SubQuery Projects?\n   \n   Hosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nIntegrating with your Custom Chain?\n\nWhether you're building a new parachain or an entirely new blockchain on Substrate - SubQuery can help you index and troubleshoot your chain's data. SubQuery is designed to easily integrate with a custom Substrate based chain.\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\nSupport and Contribute\n\nHave a question or interested to know more or how you can contribute? We’d love to hear from you. Please contact us via email or social media from the links below. Need technical expertise? Join our Discord community and receive support from our passionate community members.\n\nJOIN THE CONVERSATION ON DISCORD\nContact us hello@subquery.network\nFollow us on social\nдіскорд Твіттер Медіум Телеграм Гітхаб Матрікс Лінкедін\nSubQuery © 2021",normalizedContent:"welcome to subquery’s docs\n\nexplore and transform your chain data to build intuitive dapps faster!\n\n\nquick start guide\n\nunderstand subquery by getting hands on with a traditional hello world example. using a template project within a docker environment, you can quickly get a node up and running and start querying a blockchain in just a few minutes with a few simple commands.\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * the subquery network\n   \n   subquery’s decentralised future. read more about how indexers and consumers are rewarded.\n\n\nчапи (часті питання)\n\n * what is subquery?\n   \n   subquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n   \n   read more\n * what is the best way to get started with subquery?\n   \n   the best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n * how can i contribute or give feedback to subquery?\n   \n   we love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guidelines (coming soon).\n   \n   read more\n * how much does it cost to host my project in subquery projects?\n   \n   hosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\nintegrating with your custom chain?\n\nwhether you're building a new parachain or an entirely new blockchain on substrate - subquery can help you index and troubleshoot your chain's data. subquery is designed to easily integrate with a custom substrate based chain.\n\nlearn how to integrate with your chain\n\nsupport and contribute\n\nhave a question or interested to know more or how you can contribute? we’d love to hear from you. please contact us via email or social media from the links below. need technical expertise? join our discord community and receive support from our passionate community members.\n\njoin the conversation on discord\ncontact us hello@subquery.network\nfollow us on social\nдіскорд твіттер медіум телеграм гітхаб матрікс лінкедін\nsubquery © 2021",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/uk/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/create/manifest.html",relativePath:"uk/create/manifest.md",key:"v-3a2d0547",path:"/uk/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:1998},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3223},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4540}],readingTime:{minutes:2.51,words:752},headersStr:"Network Filters Mapping Filters Custom Chains",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - see Running an Indexer\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - see running an indexer\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/uk/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/create/mapping.html",relativePath:"uk/create/mapping.md",key:"v-237fd8ed",path:"/uk/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3128},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4138},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5098},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5528},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6191},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5048},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6916},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10106},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11327},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11549}],readingTime:{minutes:6.81,words:2044},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from \'@subql/types\';\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n  // Create a new StarterEntity with the block hash as it\'s ID\n  const record = new starterEntity(block.block.header.hash.toString());\n  record.field1 = block.block.header.number.toNumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nSubstrateBlock- це розширений тип інтерфейсу Підписаний блок, але також містить спеціальну версію та мітку часу.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n  const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n  record.field4 = extrinsic.block.timestamp;\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from \'ethers/lib/utils\'; //Good way\nimport {utils} from \'ethers\'; //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n  const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n  record.field1 = hashMessage(\'Hello\');\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. Однак, якщо інші бібліотеки залежать від будь -яких модулів у форматі **ESM **, віртуальна машина **НЕ ** скомпілює та покаже помилку.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport {default as kitties} from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n  // custom types\n  types: {\n    Address: \'AccountId\',\n    LookupSource: \'AccountId\',\n    KittyIndex: \'u32\',\n    Kitty: \'[u8; 16]\',\n  },\n  // custom rpc : api.rpc.kitties.getKittyPrice\n  rpc: {\n    getKittyPrice: {\n      description: \'Get Kitty price\',\n      params: [\n        {\n          name: \'at\',\n          type: \'BlockHash\',\n          isHistoric: true,\n          isOptional: false,\n        },\n        {\n          name: \'kittyIndex\',\n          type: \'KittyIndex\',\n          isOptional: false,\n        },\n      ],\n      type: \'Balance\',\n    },\n  },\n};\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n    // this is the package name we use (in the interface imports, --package for generators) */\n    "kitty-birthinfo/*": ["src/*"],\n    // here we replace the @polkadot/api augmentation with our own, generated from chain\n    "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n    // replace the augmented types with our own, as generated from definitions\n    "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n  //return the KittyIndex type\n  const nextKittyId = await api.query.kitties.nextKittyId();\n  // return the Kitty type, input parameters types are AccountId and KittyIndex\n  const allKitties = await api.query.kitties.kitties(\'xxxxxxxxx\', 123);\n  logger.info(`Next kitty id ${nextKittyId}`);\n  //Custom rpc, set undefined to blockhash\n  const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined, nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from \'@subql/types\';\n\nexport async function handleblock(block: substrateblock): promise<void> {\n  // create a new starterentity with the block hash as it\'s id\n  const record = new starterentity(block.block.header.hash.tostring());\n  record.field1 = block.block.header.number.tonumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nsubstrateblock- це розширении тип інтерфеису підписании блок, але також містить спеціальну версію та мітку часу.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n  const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n  record.field4 = extrinsic.block.timestamp;\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from \'ethers/lib/utils\'; //good way\nimport {utils} from \'ethers\'; //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n  const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n  record.field1 = hashmessage(\'hello\');\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. однак, якщо інші бібліотеки залежать від будь -яких модулів у форматі **esm **, віртуальна машина **не ** скомпілює та покаже помилку.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport {default as kitties} from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n  // custom types\n  types: {\n    address: \'accountid\',\n    lookupsource: \'accountid\',\n    kittyindex: \'u32\',\n    kitty: \'[u8; 16]\',\n  },\n  // custom rpc : api.rpc.kitties.getkittyprice\n  rpc: {\n    getkittyprice: {\n      description: \'get kitty price\',\n      params: [\n        {\n          name: \'at\',\n          type: \'blockhash\',\n          ishistoric: true,\n          isoptional: false,\n        },\n        {\n          name: \'kittyindex\',\n          type: \'kittyindex\',\n          isoptional: false,\n        },\n      ],\n      type: \'balance\',\n    },\n  },\n};\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n    // this is the package name we use (in the interface imports, --package for generators) */\n    "kitty-birthinfo/*": ["src/*"],\n    // here we replace the @polkadot/api augmentation with our own, generated from chain\n    "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n    // replace the augmented types with our own, as generated from definitions\n    "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n  //return the kittyindex type\n  const nextkittyid = await api.query.kitties.nextkittyid();\n  // return the kitty type, input parameters types are accountid and kittyindex\n  const allkitties = await api.query.kitties.kitties(\'xxxxxxxxx\', 123);\n  logger.info(`next kitty id ${nextkittyid}`);\n  //custom rpc, set undefined to blockhash\n  const kittyprice = await api.rpc.kitties.getkittyprice(undefined, nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cyrillic:!0,cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/uk/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/faqs/faqs.html",relativePath:"uk/faqs/faqs.md",key:"v-6e8c87ed",path:"/uk/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/uk/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/install/install.html",relativePath:"uk/install/install.md",key:"v-30ad7ebd",path:"/uk/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/uk/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/miscellaneous/ambassadors.html",relativePath:"uk/miscellaneous/ambassadors.md",key:"v-0841246e",path:"/uk/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/uk/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/miscellaneous/branding.html",relativePath:"uk/miscellaneous/branding.md",key:"v-daa61166",path:"/uk/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/uk/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/miscellaneous/contributing.html",relativePath:"uk/miscellaneous/contributing.md",key:"v-392eb7ed",path:"/uk/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/uk/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/miscellaneous/social_media.html",relativePath:"uk/miscellaneous/social_media.md",key:"v-6191ba26",path:"/uk/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.47,words:140},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. Please be careful of scams as SubQuery is not responsible for what happens within them.",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. please be careful of scams as subquery is not responsible for what happens within them.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/uk/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/publish/connect.html",relativePath:"uk/publish/connect.md",key:"v-420ef137",path:"/uk/publish/connect/",readingTime:{minutes:.54,words:163},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nВи можете слідувати офіційному посібнику GraphQL тут , щоб дізнатися більше про GraphQL, як він працює та як ним користуватися:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nви можете слідувати офіціиному посібнику graphql тут , щоб дізнатися більше про graphql, як він працює та як ним користуватися:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/uk/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/publish/publish.html",relativePath:"uk/publish/publish.md",key:"v-306008ed",path:"/uk/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1134},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. _We're almost there! We just need to deploy a new version of it. _\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. _we're almost there! we just need to deploy a new version of it. _\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Deploy a New Version of your SubQuery Project",frontmatter:{summary:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur",meta:[{property:"og:url",content:"/uk/publish/upgrade.html"},{property:"og:title",content:"Deploy a New Version of your SubQuery Project"},{property:"og:description",content:"Deploy a New Version of your SubQuery Project Guidelines Although you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate dur"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/publish/upgrade.html",relativePath:"uk/publish/upgrade.md",key:"v-21e7225a",path:"/uk/publish/upgrade/",headers:[{level:2,title:"Guidelines",slug:"guidelines",normalizedTitle:"guidelines",charIndex:52},{level:2,title:"Deploy Changes",slug:"deploy-changes",normalizedTitle:"deploy changes",charIndex:604},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:1470}],readingTime:{minutes:1.24,words:372},headersStr:"Guidelines Deploy Changes Next Steps - Connect to your Project",content:"# Deploy a New Version of your SubQuery Project\n\n\n# Guidelines\n\nAlthough you have the freedom to always upgrade and deploy new versions of your SubQuery project, please be considerate during this process if your SubQuery project is public for the world. Some key points to note:\n\n * If your upgrade is a breaking change, either create a new project (e.g. My SubQuery Project V2) or give your community plenty of warning of the change through social media channels.\n * Deploying a new SubQuery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# Deploy Changes\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# deploy a new version of your subquery project\n\n\n# guidelines\n\nalthough you have the freedom to always upgrade and deploy new versions of your subquery project, please be considerate during this process if your subquery project is public for the world. some key points to note:\n\n * if your upgrade is a breaking change, either create a new project (e.g. my subquery project v2) or give your community plenty of warning of the change through social media channels.\n * deploying a new subquery project version causes some downtime as the new version indexes the complete chain from the genesis block.\n\n\n# deploy changes\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL Ви можете слідувати офіційному посібнику GraphQL тут , щоб дізнатися більше про GraphQL, як він працює та як ним користуватися: There are libraries to help",meta:[{property:"og:url",content:"/uk/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL Ви можете слідувати офіційному посібнику GraphQL тут , щоб дізнатися більше про GraphQL, як він працює та як ним користуватися: There are libraries to help"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/query/graphql.html",relativePath:"uk/query/graphql.md",key:"v-ada9f2f2",path:"/uk/query/graphql/",readingTime:{minutes:.23,words:68},headersStr:null,content:"# Learn more about GraphQL\n\nВи можете слідувати офіційному посібнику GraphQL тут , щоб дізнатися більше про GraphQL, як він працює та як ним користуватися:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nви можете слідувати офіціиному посібнику graphql тут , щоб дізнатися більше про graphql, як він працює та як ним користуватися:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/uk/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/query/query.html",relativePath:"uk/query/query.md",key:"v-7bc99189",path:"/uk/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (SubQuery hosted)",frontmatter:{summary:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st",meta:[{property:"og:url",content:"/uk/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (SubQuery hosted)"},{property:"og:description",content:"Hello World (SubQuery hosted) The aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy st"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/quickstart/helloworld-hosted.html",relativePath:"uk/quickstart/helloworld-hosted.md",key:"v-01b4cdcd",path:"/uk/quickstart/helloworld-hosted/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:495},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:830},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:986},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:1002},{level:2,title:"Step 1: Create your project",slug:"step-1-create-your-project",normalizedTitle:"step 1: create your project",charIndex:1058},{level:2,title:"Step 2: Create a GitHub repo",slug:"step-2-create-a-github-repo",normalizedTitle:"step 2: create a github repo",charIndex:1354},{level:2,title:"Step 3: Push to GitHub",slug:"step-3-push-to-github",normalizedTitle:"step 3: push to github",charIndex:1612},{level:2,title:"Step 4: Create your project",slug:"step-4-create-your-project",normalizedTitle:"step 4: create your project",charIndex:3361},{level:2,title:"Step 5: Deploy your project",slug:"step-5-deploy-your-project",normalizedTitle:"step 5: deploy your project",charIndex:4579},{level:2,title:"Step 6: Testing your project",slug:"step-6-testing-your-project",normalizedTitle:"step 6: testing your project",charIndex:6093},{level:2,title:"Step 7: Bonus step",slug:"step-7-bonus-step",normalizedTitle:"step 7: bonus step",charIndex:6341},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:7798}],readingTime:{minutes:4.68,words:1405},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Create your project Step 2: Create a GitHub repo Step 3: Push to GitHub Step 4: Create your project Step 5: Deploy your project Step 6: Testing your project Step 7: Bonus step Summary",content:'# Hello World (SubQuery hosted)\n\nThe aim of this quick start is to show how you can get the default starter project running in SubQuery Projects (our managed service) in a few easy steps.\n\nWe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within Docker, we\'ll take advantage of SubQuery\'s managed hosting infrastructure. In other words, we let SubQuery do all the heavy lifting, running and managing production infrastructure.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in SubQuery Projects\n * run a simple query to get the block height of the Polkadot mainnet using the playground\n * run a simple GET query to get the block height of the Polkadot mainnet using cURL\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * a GitHub account\n\n\n# Step 1: Create your project\n\nLet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nDo NOT run the docker commands though.\n\n\n# Step 2: Create a GitHub repo\n\nIn GitHub, create a new public repository. Provide a name and set your visibility to public. Here, everything is kept as the default for now.\n\n\n\nTake note of your GitHub URL, this must be public for SubQuery to access it.\n\n\n\n\n# Step 3: Push to GitHub\n\nBack in your project directory, initialise it as a git directory. Otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nThen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nThis basically sets your remote repository to “https://github.com/seandotau/subqlHelloWorld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in GitHub.\n\nNext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nThe push command means "please push my code TO the origin repo FROM my master local repo". Refreshing GitHub should show all the code in GitHub.\n\n\n\nNow that you have got your code into GitHub, let\'s look at how we can host it in SubQuery Projects.\n\n\n# Step 4: Create your project\n\nNavigate to https://project.subquery.network and log in with your GitHub account.\n\n\n\nThen create a new project,\n\n\n\nAnd fill in the various fields with the appropriate details.\n\n * GitHub account: If you have more than one GitHub account, select what account this project will be created under. Projects created in an GitHub organisation account are shared between members in that organisation.\n * Project Name: Give your project a name here.\n * Subtitle: Provide a subtitle for your project.\n * Description: Explain what your SubQuery project does.\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that contains your SubQuery project. The schema.graphql file must be in the root of your directory.\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\n\n\nWhen you click create, you\'ll be taken to your dashboard.\n\n\n\nThe dashboard contains lots of useful information such as the network it is using, the GitHub repository URL of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# Step 5: Deploy your project\n\nNow that you have created your project within SubQuery Projects, setting up the display behaviour, the next step is to deploy your project making it operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nYou can choose to deploy to various environments such as a production slot or a staging slot. Here we\'ll deploy to a production slot. Clicking on the "Deploy" button brings up a screen with the following fields:\n\n\n\n * Commit Hash of new Version: From GitHub select the correct commit of the SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery\'s node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery\'s query service that you want to run this SubQuery on. See @subql/query\n\nBecause we only have one commit, there is only a single option in the drop down. We\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "Deploy Update".\n\nYou’ll then see your deployment in “Processing” status. Here, your code is getting deployed onto the SubQuery\'s managed infrastructure. Basically a server is getting spun up on demand and being provisioned for you. This will take a few minutes so time to grab a coffee!\n\n\n\nThe deployment is now running.\n\n\n\n\n# Step 6: Testing your project\n\nTo test your project, click on the 3 ellipsis and select "View on SubQuery Explorer".\n\n\n\nThis will take you to the ever familiar "Playground" where you can click the play button and see the results of the query.\n\n\n\n\n# Step 7: Bonus step\n\nFor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple GET query. To do this, we will need to grab the "Query Endpoint" displayed in the deployment details.\n\n\n\nYou can then send a GET request to this endpoint either using your favourite client such as Postman or Mockoon or via cURL in your terminal. For simplicity, cURL will be shown below.\n\nThe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nReadability is not a concern here as you will probably have some front end code to consume and parse this JSON response.\n\n\n# Summary\n\nIn this SubQuery hosted quick start we showed how quick and easy it was to take a Subql project and deploy it to SubQuery Projects where all the infrastructure is provided for your convenience. There is an inbuilt playground for running various queries as well as an API endpoint for your code to integrate with.',normalizedContent:'# hello world (subquery hosted)\n\nthe aim of this quick start is to show how you can get the default starter project running in subquery projects (our managed service) in a few easy steps.\n\nwe will take the simple starter project (and everything we\'ve learned thus far) but instead of running it locally within docker, we\'ll take advantage of subquery\'s managed hosting infrastructure. in other words, we let subquery do all the heavy lifting, running and managing production infrastructure.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * be able host a project in subquery projects\n * run a simple query to get the block height of the polkadot mainnet using the playground\n * run a simple get query to get the block height of the polkadot mainnet using curl\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * a github account\n\n\n# step 1: create your project\n\nlet\'s create a project called subql_hellowworld and run the obligatory install, codegen and build with your favourite package manager.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\ndo not run the docker commands though.\n\n\n# step 2: create a github repo\n\nin github, create a new public repository. provide a name and set your visibility to public. here, everything is kept as the default for now.\n\n\n\ntake note of your github url, this must be public for subquery to access it.\n\n\n\n\n# step 3: push to github\n\nback in your project directory, initialise it as a git directory. otherwise, you might get the error "fatal: not a git repository (or any of the parent directories): .git"\n\ngit init\n\n\n1\n\n\nthen add a remote repository with the command:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nthis basically sets your remote repository to “https://github.com/seandotau/subqlhelloworld.git” and gives it the name “origin” which is the standard nomenclature for a remote repository in github.\n\nnext we add the code to our repo with the following commands:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nthe push command means "please push my code to the origin repo from my master local repo". refreshing github should show all the code in github.\n\n\n\nnow that you have got your code into github, let\'s look at how we can host it in subquery projects.\n\n\n# step 4: create your project\n\nnavigate to https://project.subquery.network and log in with your github account.\n\n\n\nthen create a new project,\n\n\n\nand fill in the various fields with the appropriate details.\n\n * github account: if you have more than one github account, select what account this project will be created under. projects created in an github organisation account are shared between members in that organisation.\n * project name: give your project a name here.\n * subtitle: provide a subtitle for your project.\n * description: explain what your subquery project does.\n * github repository url: this must be a valid github url to a public repository that contains your subquery project. the schema.graphql file must be in the root of your directory.\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\n\n\nwhen you click create, you\'ll be taken to your dashboard.\n\n\n\nthe dashboard contains lots of useful information such as the network it is using, the github repository url of the source code it is running, when it was created and last updated, and in particular the deployment details.\n\n\n# step 5: deploy your project\n\nnow that you have created your project within subquery projects, setting up the display behaviour, the next step is to deploy your project making it operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nyou can choose to deploy to various environments such as a production slot or a staging slot. here we\'ll deploy to a production slot. clicking on the "deploy" button brings up a screen with the following fields:\n\n\n\n * commit hash of new version: from github select the correct commit of the subquery project codebase that you want deployed\n * indexer version: this is the version of subquery\'s node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery\'s query service that you want to run this subquery on. see @subql/query\n\nbecause we only have one commit, there is only a single option in the drop down. we\'ll also work with the latest version of the indexer and query version so we will accept the defaults and then click "deploy update".\n\nyou’ll then see your deployment in “processing” status. here, your code is getting deployed onto the subquery\'s managed infrastructure. basically a server is getting spun up on demand and being provisioned for you. this will take a few minutes so time to grab a coffee!\n\n\n\nthe deployment is now running.\n\n\n\n\n# step 6: testing your project\n\nto test your project, click on the 3 ellipsis and select "view on subquery explorer".\n\n\n\nthis will take you to the ever familiar "playground" where you can click the play button and see the results of the query.\n\n\n\n\n# step 7: bonus step\n\nfor the astute amongst us, you will recall that in the learning objectives, the last point was to run a simple get query. to do this, we will need to grab the "query endpoint" displayed in the deployment details.\n\n\n\nyou can then send a get request to this endpoint either using your favourite client such as postman or mockoon or via curl in your terminal. for simplicity, curl will be shown below.\n\nthe curl command to run is:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\ngiving the results of:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nreadability is not a concern here as you will probably have some front end code to consume and parse this json response.\n\n\n# summary\n\nin this subquery hosted quick start we showed how quick and easy it was to take a subql project and deploy it to subquery projects where all the infrastructure is provided for your convenience. there is an inbuilt playground for running various queries as well as an api endpoint for your code to integrate with.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f",meta:[{property:"og:url",content:"/uk/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Welcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a f"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/quickstart/helloworld-localhost.html",relativePath:"uk/quickstart/helloworld-localhost.md",key:"v-9ea17eea",path:"/uk/quickstart/helloworld-localhost/",headers:[{level:2,title:"Learning objectives",slug:"learning-objectives",normalizedTitle:"learning objectives",charIndex:204},{level:2,title:"Intended audience",slug:"intended-audience",normalizedTitle:"intended audience",charIndex:491},{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:647},{level:2,title:"Pre-requisites",slug:"pre-requisites",normalizedTitle:"pre-requisites",charIndex:663},{level:2,title:"Step 1: Initialise project",slug:"step-1-initialise-project",normalizedTitle:"step 1: initialise project",charIndex:1455},{level:2,title:"Step 2: Install dependencies",slug:"step-2-install-dependencies",normalizedTitle:"step 2: install dependencies",charIndex:2035},{level:2,title:"Step 3: Generate code",slug:"step-3-generate-code",normalizedTitle:"step 3: generate code",charIndex:2477},{level:2,title:"Step 4: Build code",slug:"step-4-build-code",normalizedTitle:"step 4: build code",charIndex:3087},{level:2,title:"Step 5: Run Docker",slug:"step-5-run-docker",normalizedTitle:"step 5: run docker",charIndex:3319},{level:2,title:"Step 6: Browse playground",slug:"step-6-browse-playground",normalizedTitle:"step 6: browse playground",charIndex:4586},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:5027}],readingTime:{minutes:2.85,words:855},headersStr:"Learning objectives Intended audience Video guide Pre-requisites Step 1: Initialise project Step 2: Install dependencies Step 3: Generate code Step 4: Build code Step 5: Run Docker Step 6: Browse playground Summary",content:'# Hello World (localhost + Docker)\n\nWelcome to this SubQuery Hello World quick start. The quick start aims to show you how you get the default starter project running in Docker in a few simple steps.\n\n\n# Learning objectives\n\nAt the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the Polkadot mainnet\n\n\n# Intended audience\n\nThis guide is geared towards new developers who have some development experience and are interested in learning more about SubQuery.\n\n\n# Video guide\n\n\n# Pre-requisites\n\nYou will need:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nYou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nFor more advanced users, copy and paste the following:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nThis should return: (for npm users, replace yarn with npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nIf you get the above, then you are good to go. If not, follow these links to install them:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Step 1: Initialise project\n\nThe first step when starting off with SubQuery is to run the subql init command. Let\'s initialise a start project with the name subqlHelloWorld. Note that only author is mandatory. Everything else is left empty below.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nDon\'t forget to change into this new directory.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Step 2: Install dependencies\n\nNow do a yarn or node install to install the various dependencies.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Step 3: Generate code\n\nNow run yarn codegen to generate Typescript from the GraphQL schema.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# Step 4: Build code\n\nThe next step is to build the code with yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Step 5: Run Docker\n\nUsing Docker allows you to run this example very quickly because all the required infrastructure can be provided within the Docker image. Run docker-compose pull && docker-compose up.\n\nThis will kick everything into life where eventually you will get blocks being fetched.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Step 6: Browse playground\n\nNavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSubQuery playground on localhost.\n\n\n\nThe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# Summary\n\nIn this quick start, we demonstrated the basic steps to get a starter project up and running within a Docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet Polkadot network.',normalizedContent:'# hello world (localhost + docker)\n\nwelcome to this subquery hello world quick start. the quick start aims to show you how you get the default starter project running in docker in a few simple steps.\n\n\n# learning objectives\n\nat the end of this quick start, you should:\n\n * understand the required pre-requisites\n * understand the basic common commands\n * be able to navigate to localhost:3000 and view the playground\n * run a simple query to get the block height of the polkadot mainnet\n\n\n# intended audience\n\nthis guide is geared towards new developers who have some development experience and are interested in learning more about subquery.\n\n\n# video guide\n\n\n# pre-requisites\n\nyou will need:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nyou can run the following commands in a terminal to see if you already have any of these pre-requisites.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nfor more advanced users, copy and paste the following:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nthis should return: (for npm users, replace yarn with npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nif you get the above, then you are good to go. if not, follow these links to install them:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# step 1: initialise project\n\nthe first step when starting off with subquery is to run the subql init command. let\'s initialise a start project with the name subqlhelloworld. note that only author is mandatory. everything else is left empty below.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ndon\'t forget to change into this new directory.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# step 2: install dependencies\n\nnow do a yarn or node install to install the various dependencies.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# step 3: generate code\n\nnow run yarn codegen to generate typescript from the graphql schema.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# step 4: build code\n\nthe next step is to build the code with yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# step 5: run docker\n\nusing docker allows you to run this example very quickly because all the required infrastructure can be provided within the docker image. run docker-compose pull && docker-compose up.\n\nthis will kick everything into life where eventually you will get blocks being fetched.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# step 6: browse playground\n\nnavigate to http://localhost:3000/ and paste the query below into the left side of the screen and then hit the play button.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsubquery playground on localhost.\n\n\n\nthe block count in the playground should match the block count (technically the block height) in the terminal as well.\n\n\n# summary\n\nin this quick start, we demonstrated the basic steps to get a starter project up and running within a docker environment and then navigated to localhost:3000 and ran a query to return the block number of the mainnet polkadot network.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Quick Start Guide",frontmatter:{summary:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end",meta:[{property:"og:url",content:"/uk/quickstart/quickstart.html"},{property:"og:title",content:"Quick Start Guide"},{property:"og:description",content:"Quick Start Guide In this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project. At the end"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/quickstart/quickstart.html",relativePath:"uk/quickstart/quickstart.md",key:"v-77c86fed",path:"/uk/quickstart/quickstart/",headers:[{level:2,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:429},{level:3,title:"Local Development Environment",slug:"local-development-environment",normalizedTitle:"local development environment",charIndex:445},{level:3,title:"Install the SubQuery CLI",slug:"install-the-subquery-cli",normalizedTitle:"install the subquery cli",charIndex:672},{level:2,title:"Initialise the Starter SubQuery Project",slug:"initialise-the-starter-subquery-project",normalizedTitle:"initialise the starter subquery project",charIndex:1036},{level:2,title:"Configure and Build the Starter Project",slug:"configure-and-build-the-starter-project",normalizedTitle:"configure and build the starter project",charIndex:2566},{level:3,title:"GraphQL Model Generation",slug:"graphql-model-generation",normalizedTitle:"graphql model generation",charIndex:3009},{level:2,title:"Build the Project",slug:"build-the-project",normalizedTitle:"build the project",charIndex:3388},{level:2,title:"Running and Querying your Starter Project",slug:"running-and-querying-your-starter-project",normalizedTitle:"running and querying your starter project",charIndex:3628},{level:3,title:"Run your SubQuery Project",slug:"run-your-subquery-project",normalizedTitle:"run your subquery project",charIndex:3981},{level:3,title:"Query your Project",slug:"query-your-project",normalizedTitle:"query your project",charIndex:4548},{level:2,title:"Next Steps",slug:"next-steps",normalizedTitle:"next steps",charIndex:5235}],readingTime:{minutes:3.22,words:967},headersStr:"Preparation Local Development Environment Install the SubQuery CLI Initialise the Starter SubQuery Project Configure and Build the Starter Project GraphQL Model Generation Build the Project Running and Querying your Starter Project Run your SubQuery Project Query your Project Next Steps",content:"# Quick Start Guide\n\nIn this Quick Start guide, we're going to create a simple starter project that you can be used as a framework for developing your own SubQuery Project.\n\nAt the end of this guide, you'll have a working SubQuery project running on a SubQuery node with a GraphQL endpoint that you can query data from.\n\nIf you haven't already, we suggest that you familiarise yourself with the terminology used in SubQuery.\n\n\n# Preparation\n\n\n# Local Development Environment\n\n * Typescript is required to compile project and define types.\n * Both SubQuery CLI and generated Project have dependencies and require a modern version Node.\n * SubQuery Nodes require Docker\n\n\n# Install the SubQuery CLI\n\nInstall SubQuery CLI globally on your terminal by using NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nYou can then run help to see available commands and usage provide by CLI\n\nsubql help\n\n\n1\n\n\n\n# Initialise the Starter SubQuery Project\n\nInside the directory in which you want to create a SubQuery project, simply replace PROJECT_NAME with your own and run the command:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nYou'll be asked certain questions as the SubQuery project is initalised:\n\n * Git repository (Optional): Provide a Git URL to a repo that this SubQuery project will be hosted in (when hosted in SubQuery Explorer)\n * RPC endpoint (Required): Provide a wss URL to a running RPC endpoint that will be used by default for this project. You can quickly access public endpoints for different Polkadot networks or even create your own private dedicated node using OnFinality or just use the default Polkadot endpoint.\n * Authors (Required): Enter the owner of this SubQuery project here\n * Description (Optional): You can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * Version (Required): Enter a custom version number or use the default (1.0.0)\n * License (Required): Provide the software license for this project or accept the default (Apache-2.0)\n\nAfter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. The contents of this directoy should be identical to what's listed in the Directory Structure.\n\nLast, under the project directory, run following command to install the new project's dependencies.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Configure and Build the Starter Project\n\nIn the starter package that you just initialised, we have provided a standard configuration for your new project. You will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\nFor more information on how to write your own SubQuery, check out our documentation under Create a Project\n\n\n# GraphQL Model Generation\n\nIn order to index your SubQuery project, you must first generate the required GraphQL models that you have defined in your GraphQL Schema file (schema.graphql). Run this command in the root of the project directory.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nYou'll find the generated models in the /src/types/models directory\n\n\n# Build the Project\n\nIn order run your SubQuery Project on a locally hosted SubQuery Node, you need to build your work.\n\nRun the build command from the project's root directory.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Running and Querying your Starter Project\n\nAlthough you can quickly publish your new project to SubQuery Projects and query it using our Explorer, the easiest way to run SubQuery nodes locally is in a Docker container, if you don't already have Docker you can install it from docker.com.\n\nSkip this and publish your new project to SubQuery Projects\n\n\n# Run your SubQuery Project\n\nAll configuration that controls how a SubQuery node is run is defined in this docker-compose.yml file. For a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our Run a Project section\n\nUnder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Query your Project\n\nOpen your browser and head to http://localhost:3000.\n\nYou should see a GraphQL playground is showing in the explorer and the schemas that are ready to query. On the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query.\n\nFor a new SubQuery starter project, you can try the following query to get a taste of how it works or learn more about the GraphQL Query language.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Next Steps\n\nCongratulations, you now have a locally running SubQuery project that accepts GraphQL API requests for sample data. In the next guide, we'll show you how to publish your new project to SubQuery Projects and query it using our Explorer\n\nPublish your new project to SubQuery Projects",normalizedContent:"# quick start guide\n\nin this quick start guide, we're going to create a simple starter project that you can be used as a framework for developing your own subquery project.\n\nat the end of this guide, you'll have a working subquery project running on a subquery node with a graphql endpoint that you can query data from.\n\nif you haven't already, we suggest that you familiarise yourself with the terminology used in subquery.\n\n\n# preparation\n\n\n# local development environment\n\n * typescript is required to compile project and define types.\n * both subquery cli and generated project have dependencies and require a modern version node.\n * subquery nodes require docker\n\n\n# install the subquery cli\n\ninstall subquery cli globally on your terminal by using npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nyou can then run help to see available commands and usage provide by cli\n\nsubql help\n\n\n1\n\n\n\n# initialise the starter subquery project\n\ninside the directory in which you want to create a subquery project, simply replace project_name with your own and run the command:\n\nsubql init --starter project_name\n\n\n1\n\n\nyou'll be asked certain questions as the subquery project is initalised:\n\n * git repository (optional): provide a git url to a repo that this subquery project will be hosted in (when hosted in subquery explorer)\n * rpc endpoint (required): provide a wss url to a running rpc endpoint that will be used by default for this project. you can quickly access public endpoints for different polkadot networks or even create your own private dedicated node using onfinality or just use the default polkadot endpoint.\n * authors (required): enter the owner of this subquery project here\n * description (optional): you can provide a short paragraph about your project that describe what data it contains and what users can do with it\n * version (required): enter a custom version number or use the default (1.0.0)\n * license (required): provide the software license for this project or accept the default (apache-2.0)\n\nafter the initialisation process is complete, you should see a folder with your project name has been created inside the directory. the contents of this directoy should be identical to what's listed in the directory structure.\n\nlast, under the project directory, run following command to install the new project's dependencies.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# configure and build the starter project\n\nin the starter package that you just initialised, we have provided a standard configuration for your new project. you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\nfor more information on how to write your own subquery, check out our documentation under create a project\n\n\n# graphql model generation\n\nin order to index your subquery project, you must first generate the required graphql models that you have defined in your graphql schema file (schema.graphql). run this command in the root of the project directory.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nyou'll find the generated models in the /src/types/models directory\n\n\n# build the project\n\nin order run your subquery project on a locally hosted subquery node, you need to build your work.\n\nrun the build command from the project's root directory.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# running and querying your starter project\n\nalthough you can quickly publish your new project to subquery projects and query it using our explorer, the easiest way to run subquery nodes locally is in a docker container, if you don't already have docker you can install it from docker.com.\n\nskip this and publish your new project to subquery projects\n\n\n# run your subquery project\n\nall configuration that controls how a subquery node is run is defined in this docker-compose.yml file. for a new project that has been just initalised you won't need to change anything here, but you can read more about the file and the settings in our run a project section\n\nunder the project directory run following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# query your project\n\nopen your browser and head to http://localhost:3000.\n\nyou should see a graphql playground is showing in the explorer and the schemas that are ready to query. on the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query.\n\nfor a new subquery starter project, you can try the following query to get a taste of how it works or learn more about the graphql query language.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# next steps\n\ncongratulations, you now have a locally running subquery project that accepts graphql api requests for sample data. in the next guide, we'll show you how to publish your new project to subquery projects and query it using our explorer\n\npublish your new project to subquery projects",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you ",meta:[{property:"og:url",content:"/uk/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained In the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/quickstart/understanding-helloworld.html",relativePath:"uk/quickstart/understanding-helloworld.md",key:"v-7943c1f6",path:"/uk/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:378},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1161},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1998},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2339},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2566},{level:2,title:"Summary",slug:"summary",normalizedTitle:"summary",charIndex:3247}],readingTime:{minutes:2.28,words:683},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Summary",content:"# Hello World Explained\n\nIn the Hello World quick start guide, we ran through some simple commands and very quickly got an example up and running. This allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from SubQuery. Here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nThe first command we ran was subql init --starter subqlHelloWorld.\n\nThis does the heavy lifting and creates a whole bunch of files for you. As noted in the official documentation, you will mainly be working on the following files:\n\n * The Manifest in project.yaml\n * The GraphQL Schema in schema.graphql\n * The Mapping functions in src/mappings/ directory\n\n\n\nThese files are the core of everything we do. As such, we'll dedicate more time to these files in another article. For now though, just know that the schema contains a description of the data users can request from the SubQuery API, the project yaml file which contains \"configuration\" type parameters and of course the mappingHandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nThe next thing we did was yarn install. npm install can be used as well.\n\n> A short history lesson. Node Package Manager or npm was initially released in 2010 and is a tremendously popular package manager among JavaScript developers. It is the default package that is automatically installed whenever you install Node.js on your system. Yarn was initially released by Facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nWhat yarn does is look at the package.json file and download various other dependencies. Looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. This is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nThen we ran yarn codegen or npm run-script codegen. What this does is fetch the GraphQL schema (in the schema.graphql) and generates the associated typescript model files (Hence the output files will have a .ts extension). You should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. This should be familiar for seasoned programmers. It creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nThe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). The pull command grabs all the required images from Docker Hub and the up command starts the container.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nWhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the GraphQL engine. It's when you see:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nthat you know that the SubQuery node has started to synchronise.\n\n\n# Summary\n\nNow that you've had an insight into what is happening under the covers, the question is where to from here? If you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. The manifest file, the GraphQL schema, and the mappings file.\n\nOtherwise, continue to our tutorials section where we look at how we can run this Hello World example on SubQuery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running SubQuery projects by running readily available and open source projects.",normalizedContent:"# hello world explained\n\nin the hello world quick start guide, we ran through some simple commands and very quickly got an example up and running. this allowed you to ensure that you had all the pre-requisites in place and could use a local playground to make a simple query to get your first data from subquery. here, we take a closer look at what all those commands mean.\n\n\n# subql init\n\nthe first command we ran was subql init --starter subqlhelloworld.\n\nthis does the heavy lifting and creates a whole bunch of files for you. as noted in the official documentation, you will mainly be working on the following files:\n\n * the manifest in project.yaml\n * the graphql schema in schema.graphql\n * the mapping functions in src/mappings/ directory\n\n\n\nthese files are the core of everything we do. as such, we'll dedicate more time to these files in another article. for now though, just know that the schema contains a description of the data users can request from the subquery api, the project yaml file which contains \"configuration\" type parameters and of course the mappinghandlers containing typescript which contains functions that transform the data.\n\n\n# yarn install\n\nthe next thing we did was yarn install. npm install can be used as well.\n\n> a short history lesson. node package manager or npm was initially released in 2010 and is a tremendously popular package manager among javascript developers. it is the default package that is automatically installed whenever you install node.js on your system. yarn was initially released by facebook in 2016 with the intention to address some of the performance and security shortcomings of working with npm (at that time).\n\nwhat yarn does is look at the package.json file and download various other dependencies. looking at the package.json file, it doesn't look like there are many dependencies, but when you run the command, you'll notice that 18,983 files are added. this is because each dependency will also have its own dependencies.\n\n\n\n\n# yarn codegen\n\nthen we ran yarn codegen or npm run-script codegen. what this does is fetch the graphql schema (in the schema.graphql) and generates the associated typescript model files (hence the output files will have a .ts extension). you should never change any of these generated files, only change the source schema.graphql file.\n\n\n\n\n# yarn build\n\nyarn build or npm run-script build was then executed. this should be familiar for seasoned programmers. it creates a distribution folder performing things such as code optimisation preparing for a deployment.\n\n\n\n\n# docker-compose\n\nthe final step was the combined docker command docker-compose pull && docker-compose up (can be run separately as well). the pull command grabs all the required images from docker hub and the up command starts the container.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nwhen the container is started, you'll see the terminal spit out lots of text showing the status of the node and the graphql engine. it's when you see:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nthat you know that the subquery node has started to synchronise.\n\n\n# summary\n\nnow that you've had an insight into what is happening under the covers, the question is where to from here? if you are feeling confident, you can jump into learning about how to create a project and learn more about the three key files. the manifest file, the graphql schema, and the mappings file.\n\notherwise, continue to our tutorials section where we look at how we can run this hello world example on subquery's hosted infrastructure, we'll look at modifying the start block, and we'll take a deeper dive at running subquery projects by running readily available and open source projects.",charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/uk/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/run/run.html",relativePath:"uk/run/run.md",key:"v-47b39cfd",path:"/uk/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3921},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4164}],readingTime:{minutes:2.44,words:731},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\nЗалежно від конфігурації вашої бази даних Postgres (наприклад, іншого пароля бази даних) переконайтеся, що індексатор (subql/node) та служба запитів (subql/query) можуть встановити з’єднання з нею.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Перехід до локальної моделі створює таблиці Postgres у схемі за замовчуванням public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\nзалежно від конфігураціі вашоі бази даних postgres (наприклад, іншого пароля бази даних) переконаитеся, що індексатор (subql/node) та служба запитів (subql/query) можуть встановити з’єднання з нею.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. перехід до локальноі моделі створює таблиці postgres у схемі за замовчуванням public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/uk/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/run/sandbox.html",relativePath:"uk/run/sandbox.md",key:"v-b128a8f6",path:"/uk/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to change the blockchain fetching batch size?",frontmatter:{summary:"How to change the blockchain fetching batch size? Video guide Introduction The default batch size is 100, but this can be changed by using the extra command --batch-size=xx. You ne",meta:[{property:"og:url",content:"/uk/tutorials_examples/batch-size.html"},{property:"og:title",content:"How to change the blockchain fetching batch size?"},{property:"og:description",content:"How to change the blockchain fetching batch size? Video guide Introduction The default batch size is 100, but this can be changed by using the extra command --batch-size=xx. You ne"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/tutorials_examples/batch-size.html",relativePath:"uk/tutorials_examples/batch-size.md",key:"v-b3a7beaa",path:"/uk/tutorials_examples/batch-size/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:56},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:72},{level:2,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:744}],readingTime:{minutes:.47,words:141},headersStr:"Video guide Introduction Why change the batch size?",content:'# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive.',normalizedContent:'# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to start at a different block height?",frontmatter:{summary:"How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from b",meta:[{property:"og:url",content:"/uk/tutorials_examples/block-height.html"},{property:"og:title",content:"How to start at a different block height?"},{property:"og:description",content:"How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from b"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/tutorials_examples/block-height.html",relativePath:"uk/tutorials_examples/block-height.md",key:"v-c4936ff6",path:"/uk/tutorials_examples/block-height/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:48},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:64},{level:2,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:952},{level:2,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1259},{level:2,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1439},{level:2,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1633}],readingTime:{minutes:1.02,words:307},headersStr:"Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen?",content:'# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.',normalizedContent:'# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to debug a SubQuery project?",frontmatter:{summary:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will",meta:[{property:"og:url",content:"/uk/tutorials_examples/debug-projects.html"},{property:"og:title",content:"How to debug a SubQuery project?"},{property:"og:description",content:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/tutorials_examples/debug-projects.html",relativePath:"uk/tutorials_examples/debug-projects.md",key:"v-ee6b2baa",path:"/uk/tutorials_examples/debug-projects/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:39},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:55},{level:2,title:"Node inspector",slug:"node-inspector",normalizedTitle:"node inspector",charIndex:272},{level:2,title:"Chrome devtools",slug:"chrome-devtools",normalizedTitle:"chrome devtools",charIndex:683}],readingTime:{minutes:.65,words:196},headersStr:"Video guide Introduction Node inspector Chrome devtools",content:"# How to debug a SubQuery project?\n\n\n# Video guide\n\n\n# Introduction\n\nIn order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a Node.js inspector in conjunction with Chrome developer tools.\n\n\n# Node inspector\n\nRun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nFor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# Chrome devtools\n\nOpen up Chrome DevTools and navigate to the Sources tab. Note that clicking on the green icon will open up a new window.\n\n\n\nNavigate to Filesystem and add your project folder to the workspace. Then open the dist > mappings folder and select the code you wish to debug. Then step through the code as with any standard debugging tool.\n\n",normalizedContent:"# how to debug a subquery project?\n\n\n# video guide\n\n\n# introduction\n\nin order to debug subquery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a node.js inspector in conjunction with chrome developer tools.\n\n\n# node inspector\n\nrun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nfor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# chrome devtools\n\nopen up chrome devtools and navigate to the sources tab. note that clicking on the green icon will open up a new window.\n\n\n\nnavigate to filesystem and add your project folder to the workspace. then open the dist > mappings folder and select the code you wish to debug. then step through the code as with any standard debugging tool.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How does a SubQuery dictionary work?",frontmatter:{summary:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod",meta:[{property:"og:url",content:"/uk/tutorials_examples/dictionary.html"},{property:"og:title",content:"How does a SubQuery dictionary work?"},{property:"og:description",content:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/tutorials_examples/dictionary.html",relativePath:"uk/tutorials_examples/dictionary.md",key:"v-fcb73f32",path:"/uk/tutorials_examples/dictionary/",headers:[{level:2,title:"How to incorporate a dictionary into your project?",slug:"how-to-incorporate-a-dictionary-into-your-project",normalizedTitle:"how to incorporate a dictionary into your project?",charIndex:1024},{level:2,title:"What happens when a dictionary IS NOT used?",slug:"what-happens-when-a-dictionary-is-not-used",normalizedTitle:"what happens when a dictionary is not used?",charIndex:1350},{level:2,title:"What happens when a dictionary IS used?",slug:"what-happens-when-a-dictionary-is-used",normalizedTitle:"what happens when a dictionary is used?",charIndex:1772},{level:2,title:"When is a dictionary NOT useful?",slug:"when-is-a-dictionary-not-useful",normalizedTitle:"when is a dictionary not useful?",charIndex:2849}],readingTime:{minutes:2,words:601},headersStr:"How to incorporate a dictionary into your project? What happens when a dictionary IS NOT used? What happens when a dictionary IS used? When is a dictionary NOT useful?",content:"# How does a SubQuery dictionary work?\n\nThe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. Another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nThe network.dictionary endpoint is an optional parameter that if present, the SDK will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\nTaking the SubQuery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specVersion. These 3 entities contain 6, 4, and 2 fields respectively. When this project is run, these fields are reflected in the database tables.\n\n\n\nData from the blockchain is then stored in these tables and indexed for performance. The project is then hosted in SubQuery Projects and the API endpoint is available to be added to the manifest file.\n\n\n# How to incorporate a dictionary into your project?\n\nAdd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. Eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# What happens when a dictionary IS NOT used?\n\nWhen a dictionary is NOT used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. Later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# What happens when a dictionary IS used?\n\nWhen a dictionary IS used, the indexer will first take the call and event filters as parameters and merge this into a GraphQL query. It then uses the dictionary's API to obtain a list of relevant block heights only that contains the specific events and extrinsics. Often this is substantially less than 100 if the default is used.\n\nFor example, imagine a situation where you're indexing transfer events. Not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nThe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. This is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nThis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. But compared to the traditional method, it adds an additional step to get data from the dictionary’s API.\n\n\n# When is a dictionary NOT useful?\n\nWhen block handlers are used to grab data from a chain, every block needs to be processed. Therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nAlso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",normalizedContent:"# how does a subquery dictionary work?\n\nthe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nthe network.dictionary endpoint is an optional parameter that if present, the sdk will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\ntaking the subquery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specversion. these 3 entities contain 6, 4, and 2 fields respectively. when this project is run, these fields are reflected in the database tables.\n\n\n\ndata from the blockchain is then stored in these tables and indexed for performance. the project is then hosted in subquery projects and the api endpoint is available to be added to the manifest file.\n\n\n# how to incorporate a dictionary into your project?\n\nadd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# what happens when a dictionary is not used?\n\nwhen a dictionary is not used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# what happens when a dictionary is used?\n\nwhen a dictionary is used, the indexer will first take the call and event filters as parameters and merge this into a graphql query. it then uses the dictionary's api to obtain a list of relevant block heights only that contains the specific events and extrinsics. often this is substantially less than 100 if the default is used.\n\nfor example, imagine a situation where you're indexing transfer events. not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nthe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. this is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nthis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. but compared to the traditional method, it adds an additional step to get data from the dictionary’s api.\n\n\n# when is a dictionary not useful?\n\nwhen block handlers are used to grab data from a chain, every block needs to be processed. therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nalso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/uk/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/tutorials_examples/howto.html",relativePath:"uk/tutorials_examples/howto.md",key:"v-2ca3ee26",path:"/uk/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials & Examples",frontmatter:{summary:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri",meta:[{property:"og:url",content:"/uk/tutorials_examples/introduction.html"},{property:"og:title",content:"Tutorials & Examples"},{property:"og:description",content:"Tutorials & Examples Here we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner. SubQuery Examples Example Descri"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/tutorials_examples/introduction.html",relativePath:"uk/tutorials_examples/introduction.md",key:"v-bd94cac2",path:"/uk/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery Examples",slug:"subquery-examples",normalizedTitle:"subquery examples",charIndex:155}],readingTime:{minutes:.74,words:223},headersStr:"SubQuery Examples",content:"# Tutorials & Examples\n\nHere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# SubQuery Examples\n\nEXAMPLE                     DESCRIPTION                                                    TOPICS\nextrinsic-finalized-block   Indexes extrinsics so they can be queried by their hash        Найпростіший приклад з функцією обробник блоку\nblock-timestamp             Indexes timestamp of each finalized block                      Another simple call handler function\nvalidator-threshold         Indexes the least staking amount required for a validator to   More complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  Indexes staking bond, rewards, and slashes from the events     More complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             Indexes balance transfers between accounts, also indexes       One-to-many and many-to-many relationships and complicated\n                            utility batchAll to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       Indexes birth info of kitties.                                 Complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",normalizedContent:"# tutorials & examples\n\nhere we will list our tutorials and explore various examples to help you get up and running in the easiest and fastest manner.\n\n\n# subquery examples\n\nexample                     description                                                    topics\nextrinsic-finalized-block   indexes extrinsics so they can be queried by their hash        наипростішии приклад з функцією обробник блоку\nblock-timestamp             indexes timestamp of each finalized block                      another simple call handler function\nvalidator-threshold         indexes the least staking amount required for a validator to   more complicated block handler function that makes external\n                            be elected.                                                    calls to the @polkadot/api for additional on-chain data\nsum-reward                  indexes staking bond, rewards, and slashes from the events     more complicated event handlers with a one-to-many\n                            of finalized block                                             relationship\nentity-relation             indexes balance transfers between accounts, also indexes       one-to-many and many-to-many relationships and complicated\n                            utility batchall to find out the content of the extrinsic      extrinsic handling\n                            calls\nkitty                       indexes birth info of kitties.                                 complex call handlers and event handlers, with data indexed\n                                                                                           from a custom chain",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to run an indexer node?",frontmatter:{summary:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r",meta:[{property:"og:url",content:"/uk/tutorials_examples/run-indexer.html"},{property:"og:title",content:"How to run an indexer node?"},{property:"og:description",content:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/tutorials_examples/run-indexer.html",relativePath:"uk/tutorials_examples/run-indexer.md",key:"v-6281452d",path:"/uk/tutorials_examples/run-indexer/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:34},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:50},{level:2,title:"Postgres",slug:"postgres",normalizedTitle:"postgres",charIndex:300},{level:2,title:"Install subql/node",slug:"install-subql-node",normalizedTitle:"install subql/node",charIndex:484},{level:2,title:"Setting DB configs",slug:"setting-db-configs",normalizedTitle:"setting db configs",charIndex:802},{level:2,title:"Indexing a project",slug:"indexing-a-project",normalizedTitle:"indexing a project",charIndex:1380},{level:2,title:"Inspecting Postgres",slug:"inspecting-postgres",normalizedTitle:"inspecting postgres",charIndex:1687}],readingTime:{minutes:1.18,words:353},headersStr:"Video guide Introduction Postgres Install subql/node Setting DB configs Indexing a project Inspecting Postgres",content:"# How to run an indexer node?\n\n\n# Video guide\n\n\n# Introduction\n\nRunning an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It requires more time and effort but will enhance your understanding of how SubQuery works under the covers.\n\n\n# Postgres\n\nRunning an indexer node on your infrastructure will require the setup of a Postgres database. You can install Postgres from here and ensure the version is 12 or greater.\n\n\n# Install subql/node\n\nThen to run a SubQuery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nThe -g flag means to install it globally which means on OSX, the location will be /usr/local/lib/node_modules.\n\nOnce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# Setting DB configs\n\nNext, you need to set the following environmental variables:\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\n\n\n1\n2\n3\n4\n5\n\n\nOf course, if you have different values for the above keys, please adjust accordingly. Note that the env command will display the current environment variables and that this process only sets these values temporarily. That is, they are only valid for the duration of the terminal session. To set them permanently, store them in your ~/bash_profile instead.\n\n\n# Indexing a project\n\nTo start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nIf you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. You should see the indexer node kick into life and start indexing blocks.\n\n\n# Inspecting Postgres\n\nIf you navigate to Postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. The starter_entities table contains the indexes. To view the data, run select (*) from subquery_1.starter_entities.",normalizedContent:"# how to run an indexer node?\n\n\n# video guide\n\n\n# introduction\n\nrunning an indexer node is another option outside of using docker or having a project hosted for you at subquery projects. it requires more time and effort but will enhance your understanding of how subquery works under the covers.\n\n\n# postgres\n\nrunning an indexer node on your infrastructure will require the setup of a postgres database. you can install postgres from here and ensure the version is 12 or greater.\n\n\n# install subql/node\n\nthen to run a subquery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nthe -g flag means to install it globally which means on osx, the location will be /usr/local/lib/node_modules.\n\nonce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# setting db configs\n\nnext, you need to set the following environmental variables:\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\n\n\n1\n2\n3\n4\n5\n\n\nof course, if you have different values for the above keys, please adjust accordingly. note that the env command will display the current environment variables and that this process only sets these values temporarily. that is, they are only valid for the duration of the terminal session. to set them permanently, store them in your ~/bash_profile instead.\n\n\n# indexing a project\n\nto start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nif you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. you should see the indexer node kick into life and start indexing blocks.\n\n\n# inspecting postgres\n\nif you navigate to postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. the starter_entities table contains the indexes. to view the data, run select (*) from subquery_1.starter_entities.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{frontmatter:{summary:"Chào mừng bạn đến với Tài liệu tiếng Việt của SubQuery Khám phá và chuyển đổi dữ liệu chuỗi của bạn để xây dựng các dApp trực quan nhanh hơn! Hướng Dẫn Nhanh Hiểu SubQuery bằng các",meta:[{property:"og:url",content:"/vi/"},{property:"og:description",content:"Chào mừng bạn đến với Tài liệu tiếng Việt của SubQuery Khám phá và chuyển đổi dữ liệu chuỗi của bạn để xây dựng các dApp trực quan nhanh hơn! Hướng Dẫn Nhanh Hiểu SubQuery bằng các"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/",relativePath:"vi/README.md",key:"v-e894ac04",path:"/vi/",readingTime:{minutes:4.37,words:1312},headersStr:null,content:"Chào mừng bạn đến với Tài liệu tiếng Việt của SubQuery\n\nKhám phá và chuyển đổi dữ liệu chuỗi của bạn để xây dựng các dApp trực quan nhanh hơn!\n\n\nHướng Dẫn Nhanh\n\nHiểu SubQuery bằng cách làm theo ví dụ Hello World truyền thống. Sử dụng dự án mẫu trong môi trường Docker, bạn có thể nhanh chóng thiết lập và chạy một nút và bắt đầu truy vấn chuỗi khối chỉ trong vài phút với một vài lệnh đơn giản.\n\nGet started\n * Hướng dẫn và Ví dụ\n   \n   Học thông qua thực hành. Tutorials and examples on how to build various SubQuery projects.\n\n * Tài liệu tham khảo về vấn đề kỹ thuật\n   \n   Viết bởi developer, dành cho dân developer. Tìm ra thứ bạn cần để nhanh chóng xây dựng một dApp tuyệt đỉnh.\n\n * Mạng SubQuery\n   \n   Tương lai theo cơ chế phi tập trung của SubQuery. Tìm hiểu thêm về cách để người lập Index và người tiêu dùng kiếm được phần thưởng.\n\n\nCâu hỏi thường gặp\n\n * SubQuery là gì?\n   \n   SubQuery là một dự án mã nguồn mở cho phép các nhà phát triển lập chỉ mục, chuyển đổi và truy vấn dữ liệu chuỗi Substrate để cung cấp cho các ứng dụng của họ.\n   \n   ĐỌC THÊM\n * Cách tốt nhất để bắt đầu với SubQuery là gì?\n   \n   Cách tốt nhất để bạn bắt đầu dùng SubQuery là xem qua hướng dẫn Hello World của chúng tôi. Đây là một hướng dẫn đơn giản trong 5 phút để tải xuống mẫu khởi động, xây dựng dự án và sau đó sử dụng Docker để chạy một nút trên máy chủ cục bộ của bạn và chạy một truy vấn đơn giản.\n\n * Làm cách nào để tôi có thể đóng góp hoặc đưa ra phản hồi cho SubQuery?\n   \n   Chúng tôi rất mong nhận được ý kiến đóng góp hoặc phản hồi từ cộng đồng. Khi muốn đóng góp code, hãy tạo fork (bản sao) cho repository bạn quan tâm và đưa ra những thay đổi. Sau đó hãy sử dụng chức năng Pull Request hay gọi tắt là PR. À, nhớ đừng quên test thử đấy nhé! Ngoài ra, bạn có thể xem các nguyên tắc về vấn đề đóng góp của chúng tôi (sẽ sớm được công khai).\n   \n   ĐỌC THÊM\n * Chi phí để lưu trữ dự án của tôi trong Dự án SubQuery là bao nhiêu?\n   \n   Việc lưu trữ dự án trên SubQuery là hoàn toàn miễn phí - đây là cách chúng tôi cống hiến cho cộng đồng. Để tìm hiểu cách lưu trữ dự án của bạn trên SubQuery, vui lòng xem hướng dẫn Hello World (SubQuery Hosted) của chúng tôi.\n   \n   LƯU TRỮ DỰ ÁN CỦA BẠN\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\nTích hợp với Chuỗi tùy chỉnh của bạn?\n\nCho dù bạn đang xây dựng một parachain hay một blockchain hoàn toàn mới trên Substrate - SubQuery đều có thể giúp bạn lập Index và khắc phục sự cố dữ liệu trên chuỗi. SubQuery được thiết kế để dễ dàng tích hợp với blockchain tùy chỉnh dựa trên Substrate.\n\nTÌM HIỂU CÁCH TÍCH HỢP VỚI BLOCKCHAIN CỦA BẠN\n\nHỗ trợ và đóng góp\n\nBạn có câu hỏi, cần thêm thông tin hoặc muốn đóng góp? Chúng tôi rất mong nhận được tin của bạn. Vui lòng liên hệ với chúng tôi qua email hoặc các tài khoản mạng xã hội được cung cấp ở bên dưới. Bạn cần tư vấn chuyên môn? Hãy tham gia kênh Discord để nhận được sự hỗ trợ từ các thành viên đầy nhiệt tình trong cộng đồng của chúng tôi.\n\nTHAM GIA TRAO ĐỔI TRÊN DISCORD\nLiên hệ với chúng tôi hello@subquery.network\nTheo dõi chúng tôi trên mạng xã hội\ndiscord twitter medium telegram github matrix linkedin\nSubQuery © 2021",normalizedContent:"chao mung ban đen voi tai lieu tieng viet cua subquery\n\nkham pha va chuyen đoi du lieu chuoi cua ban đe xay dung cac dapp truc quan nhanh hon!\n\n\nhuong dan nhanh\n\nhieu subquery bang cach lam theo vi du hello world truyen thong. su dung du an mau trong moi truong docker, ban co the nhanh chong thiet lap va chay mot nut va bat đau truy van chuoi khoi chi trong vai phut voi mot vai lenh đon gian.\n\nget started\n * huong dan va vi du\n   \n   hoc thong qua thuc hanh. tutorials and examples on how to build various subquery projects.\n\n * tai lieu tham khao ve van đe ky thuat\n   \n   viet boi developer, danh cho dan developer. tim ra thu ban can đe nhanh chong xay dung mot dapp tuyet đinh.\n\n * mang subquery\n   \n   tuong lai theo co che phi tap trung cua subquery. tim hieu them ve cach đe nguoi lap index va nguoi tieu dung kiem đuoc phan thuong.\n\n\ncau hoi thuong gap\n\n * subquery la gi?\n   \n   subquery la mot du an ma nguon mo cho phep cac nha phat trien lap chi muc, chuyen đoi va truy van du lieu chuoi substrate đe cung cap cho cac ung dung cua ho.\n   \n   đoc them\n * cach tot nhat đe bat đau voi subquery la gi?\n   \n   cach tot nhat đe ban bat đau dung subquery la xem qua huong dan hello world cua chung toi. đay la mot huong dan đon gian trong 5 phut đe tai xuong mau khoi đong, xay dung du an va sau đo su dung docker đe chay mot nut tren may chu cuc bo cua ban va chay mot truy van đon gian.\n\n * lam cach nao đe toi co the đong gop hoac đua ra phan hoi cho subquery?\n   \n   chung toi rat mong nhan đuoc y kien đong gop hoac phan hoi tu cong đong. khi muon đong gop code, hay tao fork (ban sao) cho repository ban quan tam va đua ra nhung thay đoi. sau đo hay su dung chuc nang pull request hay goi tat la pr. a, nho đung quen test thu đay nhe! ngoai ra, ban co the xem cac nguyen tac ve van đe đong gop cua chung toi (se som đuoc cong khai).\n   \n   đoc them\n * chi phi đe luu tru du an cua toi trong du an subquery la bao nhieu?\n   \n   viec luu tru du an tren subquery la hoan toan mien phi - đay la cach chung toi cong hien cho cong đong. đe tim hieu cach luu tru du an cua ban tren subquery, vui long xem huong dan hello world (subquery hosted) cua chung toi.\n   \n   luu tru du an cua ban\n\n\nfor further frequently asked questions, please see our faq's page.\n\ntich hop voi chuoi tuy chinh cua ban?\n\ncho du ban đang xay dung mot parachain hay mot blockchain hoan toan moi tren substrate - subquery đeu co the giup ban lap index va khac phuc su co du lieu tren chuoi. subquery đuoc thiet ke đe de dang tich hop voi blockchain tuy chinh dua tren substrate.\n\ntim hieu cach tich hop voi blockchain cua ban\n\nho tro va đong gop\n\nban co cau hoi, can them thong tin hoac muon đong gop? chung toi rat mong nhan đuoc tin cua ban. vui long lien he voi chung toi qua email hoac cac tai khoan mang xa hoi đuoc cung cap o ben duoi. ban can tu van chuyen mon? hay tham gia kenh discord đe nhan đuoc su ho tro tu cac thanh vien đay nhiet tinh trong cong đong cua chung toi.\n\ntham gia trao đoi tren discord\nlien he voi chung toi hello@subquery.network\ntheo doi chung toi tren mang xa hoi\ndiscord twitter medium telegram github matrix linkedin\nsubquery © 2021",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Terminology",frontmatter:{summary:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th",meta:[{property:"og:url",content:"/uk/tutorials_examples/terminology.html"},{property:"og:title",content:"Terminology"},{property:"og:description",content:"Terminology SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should th"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/uk/tutorials_examples/terminology.html",relativePath:"uk/tutorials_examples/terminology.md",key:"v-3b041b6d",path:"/uk/tutorials_examples/terminology/",headers:[{level:2,title:"Terminology",slug:"terminology",normalizedTitle:"terminology",charIndex:2}],readingTime:{minutes:.41,words:124},headersStr:"Terminology",content:"# Terminology\n\n * SubQuery Project (where the magic happens): A definition (@subql/cli) of how a SubQuery Node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful GraphQL queries\n * SubQuery Node (where the work is done): A package (@subql/node) that will accept a SubQuery project definiton, and run a node that constantly indexes a connected network to a database\n * Служба запитів SubQuery (_ звідки ми отримуємо дані _): Пакет (@subql/query), який взаємодіє з API GraphQL розгорнутого вузла (ноди) SubQuery для здійснення запитів та перегляду індексованих даних\n * GraphQL (how we query the data): A query langage for APIs that is specifically suited for flexible graph based data - see graphql.org",normalizedContent:"# terminology\n\n * subquery project (where the magic happens): a definition (@subql/cli) of how a subquery node should traverse and aggregate a projects network and how the data should the transformed and stored to enable useful graphql queries\n * subquery node (where the work is done): a package (@subql/node) that will accept a subquery project definiton, and run a node that constantly indexes a connected network to a database\n * служба запитів subquery (_ звідки ми отримуємо дані _): пакет (@subql/query), якии взаємодіє з api graphql розгорнутого вузла (ноди) subquery для здіиснення запитів та перегляду індексованих даних\n * graphql (how we query the data): a query langage for apis that is specifically suited for flexible graph based data - see graphql.org",charsets:{cyrillic:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Lược đồ GraphQL",frontmatter:{summary:"Lược đồ GraphQL Xác định các thực thể Tệp schema.graphql xác định các lược đồ GraphQL khác nhau. Do cách thức hoạt động của ngôn ngữ truy vấn GraphQL, tệp lược đồ về cơ bản chỉ ra ",meta:[{property:"og:url",content:"/vi/create/graphql.html"},{property:"og:title",content:"Lược đồ GraphQL"},{property:"og:description",content:"Lược đồ GraphQL Xác định các thực thể Tệp schema.graphql xác định các lược đồ GraphQL khác nhau. Do cách thức hoạt động của ngôn ngữ truy vấn GraphQL, tệp lược đồ về cơ bản chỉ ra "},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/create/graphql.html",relativePath:"vi/create/graphql.md",key:"v-9cd12ba6",path:"/vi/create/graphql/",headers:[{level:2,title:"Xác định các thực thể",slug:"xac-đinh-cac-thuc-the",normalizedTitle:"xac đinh cac thuc the",charIndex:22},{level:3,title:"Thực thể",slug:"thuc-the",normalizedTitle:"thuc the",charIndex:491},{level:3,title:"Các loại và vô hướng được hỗ trợ",slug:"cac-loai-va-vo-huong-đuoc-ho-tro",normalizedTitle:"cac loai va vo huong đuoc ho tro",charIndex:944},{level:2,title:"Lập chỉ mục theo trường không phải khóa chính",slug:"lap-chi-muc-theo-truong-khong-phai-khoa-chinh",normalizedTitle:"lap chi muc theo truong khong phai khoa chinh",charIndex:1337},{level:2,title:"Mối quan hệ thực thể",slug:"moi-quan-he-thuc-the",normalizedTitle:"moi quan he thuc the",charIndex:1229},{level:3,title:"Mối quan hệ một-một",slug:"moi-quan-he-mot-mot",normalizedTitle:"moi quan he mot-mot",charIndex:3491},{level:3,title:"Mối quan hệ một-nhiều",slug:"moi-quan-he-mot-nhieu",normalizedTitle:"moi quan he mot-nhieu",charIndex:3952},{level:3,title:"Mối quan hệ nhiều-nhiều",slug:"moi-quan-he-nhieu-nhieu",normalizedTitle:"moi quan he nhieu-nhieu",charIndex:4253},{level:3,title:"Tra cứu ngược",slug:"tra-cuu-nguoc",normalizedTitle:"tra cuu nguoc",charIndex:5252},{level:2,title:"Loại JSON",slug:"loai-json",normalizedTitle:"loai json",charIndex:5977},{level:3,title:"Xác định chiều JSON",slug:"xac-đinh-chieu-json",normalizedTitle:"xac đinh chieu json",charIndex:6656},{level:3,title:"Truy vấn các trường JSON",slug:"truy-van-cac-truong-json",normalizedTitle:"truy van cac truong json",charIndex:7393}],readingTime:{minutes:6.5,words:1950},headersStr:"Xác định các thực thể Thực thể Các loại và vô hướng được hỗ trợ Lập chỉ mục theo trường không phải khóa chính Mối quan hệ thực thể Mối quan hệ một-một Mối quan hệ một-nhiều Mối quan hệ nhiều-nhiều Tra cứu ngược Loại JSON Xác định chiều JSON Truy vấn các trường JSON",content:"# Lược đồ GraphQL\n\n\n# Xác định các thực thể\n\nTệp schema.graphql xác định các lược đồ GraphQL khác nhau. Do cách thức hoạt động của ngôn ngữ truy vấn GraphQL, tệp lược đồ về cơ bản chỉ ra hình dạng dữ liệu của bạn từ SubQuery. Để tìm hiểu thêm về cách viết bằng ngôn ngữ lược đồ GraphQL, chúng tôi khuyên bạn nên xem Lược đồ và Các Loại.\n\nQuan trọng: Khi bạn thực hiện bất kỳ thay đổi nào đối với tệp lược đồ, hãy đảm bảo rằng bạn tạo lại thư mục loại của mình bằng lệnh sau yarn codegen\n\n\n# Thực thể\n\nMỗi thực thể phải xác định các trường bắt buộc của nó id với loại ID!. Nó được sử dụng làm khóa chính và duy nhất giữa tất cả các thực thể cùng loại.\n\nCác trường không thể nullable trong thực thể được biểu thị bằng !. Vui lòng xem ví dụ dưới đây:\n\ntype Example @entity {\n  id: ID! # id field is always required and must look like this\n  name: String! # This is a required field\n  address: String # This is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# Các loại và vô hướng được hỗ trợ\n\nChúng tôi hiện đang hỗ trợ các loại vô hướng sau:\n\n * ID\n * Int\n * String\n * BigInt\n * Date\n * Boolean\n * <EntityName>đối với các thực thể quan hệ lồng nhau, bạn có thể sử dụng tên của thực thể đã xác định làm một trong các trường. Vui lòng xem trong Mối quan hệ thực thể.\n * JSON có thể lưu trữ dữ liệu có cấu trúc theo cách khác, vui lòng xem loại JSON\n\n\n# Lập chỉ mục theo trường không phải khóa chính\n\nĐể cải thiện hiệu suất truy vấn, chỉ cần lập chỉ mục trường thực thể bằng cách thêm chú thích @index trên trường không phải khóa chính.\n\nTuy nhiên, chúng tôi không cho phép người dùng thêm chú thích @index trên bất kỳ đối tượng JSON nào. Theo mặc định, các chỉ mục được tự động thêm vào khóa ngoại và cho các trường JSON trong cơ sở dữ liệu, nhưng chỉ để nâng cao hiệu suất truy vấn.\n\nĐây là một ví dụ.\n\ntype User @entity {\n  id: ID!\n  name: String! @index(unique: true) # unique can be set to true or false\n  title: Title! # Indexes are automatically added to foreign key field\n}\n\ntype Title @entity {\n  id: ID!\n  name: String! @index(unique: true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nGiả sử chúng tôi biết tên của người dùng này, nhưng chúng tôi không biết giá trị id chính xác, thay vì trích xuất tất cả người dùng và sau đó lọc theo tên, chúng tôi có thể thêm @index vào phía sau trường tên. Điều này làm cho việc truy vấn nhanh hơn nhiều và chúng tôi cũng có thể chuyển unique: true để đảm bảo tính duy nhất.\n\nNếu một trường không phải là duy nhất, kích thước danh sách kết quả tối đa là 100\n\nKhi quá trình tạo mã được chạy, thao tác này sẽ tự động tạo getByName theo mô hình Người dùng và trường khóa ngoại title sẽ tạo phương thức getByTitleId, mà cả hai đều có thể được truy cập trực tiếp trong chức năng ánh xạ.\n\n/* Prepare a record for title entity */\nINSERT INTO titles (id, name) VALUES ('id_1', 'Captain')\n\n\n1\n2\n\n\n// Handler in mapping function\nimport {User} from '../types/models/User';\nimport {Title} from '../types/models/Title';\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Mối quan hệ thực thể\n\nMột thực thể thường có các mối quan hệ lồng nhau với các thực thể khác. Đặt giá trị trường thành một tên thực thể khác sẽ xác định mối quan hệ một-một giữa hai thực thể này theo mặc định.\n\nCác mối quan hệ thực thể khác nhau (một-một, một-nhiều và nhiều-nhiều) có thể được định cấu hình bằng cách sử dụng các ví dụ bên dưới.\n\n\n# Mối quan hệ một-một\n\nMối quan hệ một-một là mặc định khi chỉ một thực thể duy nhất được ánh xạ tới một thực thể khác.\n\nVí dụ: Hộ chiếu sẽ chỉ thuộc về một người và một người chỉ có một hộ chiếu (trong ví dụ này):\n\ntype Person @entity {\n  id: ID!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  owner: Person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Mối quan hệ một-nhiều\n\nBạn có thể sử dụng dấu ngoặc vuông để chỉ ra rằng một loại trường bao gồm nhiều thực thể.\n\nVí dụ: Một người có thể có nhiều tài khoản.\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account]\n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Mối quan hệ nhiều-nhiều\n\nMối quan hệ nhiều-nhiều có thể đạt được bằng cách triển khai một thực thể ánh xạ để kết nối hai thực thể khác.\n\nVí dụ: Mỗi người là một phần của nhiều nhóm (PersonGroup) và nhóm có nhiều người khác nhau (PersonGroup).\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  persons: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nNgoài ra, có thể tạo kết nối của cùng một thực thể trong nhiều trường của thực thể giữa.\n\nVí dụ: một tài khoản có thể có nhiều lần chuyển tiền và mỗi lần chuyển có một tài khoản nguồn và tài khoản đích.\n\nĐiều này sẽ thiết lập mối quan hệ hai chiều giữa hai Tài khoản (từ và đến) thông qua bảng Chuyển khoản.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Tra cứu ngược\n\nĐể kích hoạt tra cứu ngược đối với một thực thể theo một mối quan hệ, hãy đính kèm @derivedFrom vào trường và trỏ đến trường tra cứu ngược của thực thể khác.\n\nĐiều này tạo ra một trường ảo trên thực thể có thể được truy vấn.\n\nChuyển \"từ\" một Tài khoản có thể truy cập được từ thực thể Tài khoản bằng cách đặt sentTransfer hoặc receivedTransfer có giá trị của chúng bắt nguồn từ các trường từ hoặc đến tương ứng.\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Loại JSON\n\nChúng tôi đang hỗ trợ lưu dữ liệu dưới dạng JSON, đây là một cách nhanh chóng để lưu trữ dữ liệu có cấu trúc. Chúng tôi sẽ tự động tạo các giao diện JSON tương ứng để truy vấn dữ liệu này và giúp bạn tiết kiệm thời gian xác định và quản lý các thực thể.\n\nChúng tôi khuyên người dùng sử dụng loại JSON trong các trường hợp sau:\n\n * Khi lưu trữ dữ liệu có cấu trúc trong một trường sẽ dễ quản lý hơn so với việc tạo nhiều thực thể riêng biệt.\n * Lưu tùy chọn khóa/giá trị tùy ý của người dùng (trong đó giá trị có thể là boolean, văn bản hoặc số và bạn không muốn có các cột riêng biệt cho các kiểu dữ liệu khác nhau)\n * Lược đồ dễ thay đổi và thay đổi thường xuyên\n\n\n# Xác định chiều JSON\n\nXác định thuộc tính dưới dạng kiểu JSON bằng cách thêm chú thích jsonField trong thực thể. Thao tác này sẽ tự động tạo giao diện cho tất cả các đối tượng JSON trong dự án của bạn dưới type/interface.ts và bạn có thể truy cập chúng trong chức năng ánh xạ của mình.\n\nKhông giống như thực thể, đối tượng chỉ thị jsonField không yêu cầu bất kỳ trường id nào. Một đối tượng JSON cũng có thể lồng ghép với các đối tượng JSON khác.\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID!\n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Truy vấn các trường JSON\n\nHạn chế của việc sử dụng các loại JSON ảnh hưởng nhỏ đến hiệu quả truy vấn khi lọc, vì mỗi lần nó thực hiện tìm kiếm văn bản, nó sẽ nằm trên toàn bộ thực thể.\n\nTuy nhiên, tác động vẫn có thể chấp nhận được trong dịch vụ truy vấn của chúng tôi. Dưới đây là ví dụ về cách sử dụng toán tử chứa trong truy vấn GraphQL trên trường JSON để tìm 5 người dùng đầu tiên sở hữu số điện thoại có chứa '0064'.\n\n# Để tìm 5 số điện thoại của người dùng đầu tiên có chứa '0064'.\n\nquery {\n  user(first: 5, filter: {contactCard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",normalizedContent:"# luoc đo graphql\n\n\n# xac đinh cac thuc the\n\ntep schema.graphql xac đinh cac luoc đo graphql khac nhau. do cach thuc hoat đong cua ngon ngu truy van graphql, tep luoc đo ve co ban chi ra hinh dang du lieu cua ban tu subquery. đe tim hieu them ve cach viet bang ngon ngu luoc đo graphql, chung toi khuyen ban nen xem luoc đo va cac loai.\n\nquan trong: khi ban thuc hien bat ky thay đoi nao đoi voi tep luoc đo, hay đam bao rang ban tao lai thu muc loai cua minh bang lenh sau yarn codegen\n\n\n# thuc the\n\nmoi thuc the phai xac đinh cac truong bat buoc cua no id voi loai id!. no đuoc su dung lam khoa chinh va duy nhat giua tat ca cac thuc the cung loai.\n\ncac truong khong the nullable trong thuc the đuoc bieu thi bang !. vui long xem vi du duoi đay:\n\ntype example @entity {\n  id: id! # id field is always required and must look like this\n  name: string! # this is a required field\n  address: string # this is an optional field\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# cac loai va vo huong đuoc ho tro\n\nchung toi hien đang ho tro cac loai vo huong sau:\n\n * id\n * int\n * string\n * bigint\n * date\n * boolean\n * <entityname>đoi voi cac thuc the quan he long nhau, ban co the su dung ten cua thuc the đa xac đinh lam mot trong cac truong. vui long xem trong moi quan he thuc the.\n * json co the luu tru du lieu co cau truc theo cach khac, vui long xem loai json\n\n\n# lap chi muc theo truong khong phai khoa chinh\n\nđe cai thien hieu suat truy van, chi can lap chi muc truong thuc the bang cach them chu thich @index tren truong khong phai khoa chinh.\n\ntuy nhien, chung toi khong cho phep nguoi dung them chu thich @index tren bat ky đoi tuong json nao. theo mac đinh, cac chi muc đuoc tu đong them vao khoa ngoai va cho cac truong json trong co so du lieu, nhung chi đe nang cao hieu suat truy van.\n\nđay la mot vi du.\n\ntype user @entity {\n  id: id!\n  name: string! @index(unique: true) # unique can be set to true or false\n  title: title! # indexes are automatically added to foreign key field\n}\n\ntype title @entity {\n  id: id!\n  name: string! @index(unique: true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\ngia su chung toi biet ten cua nguoi dung nay, nhung chung toi khong biet gia tri id chinh xac, thay vi trich xuat tat ca nguoi dung va sau đo loc theo ten, chung toi co the them @index vao phia sau truong ten. đieu nay lam cho viec truy van nhanh hon nhieu va chung toi cung co the chuyen unique: true đe đam bao tinh duy nhat.\n\nneu mot truong khong phai la duy nhat, kich thuoc danh sach ket qua toi đa la 100\n\nkhi qua trinh tao ma đuoc chay, thao tac nay se tu đong tao getbyname theo mo hinh nguoi dung va truong khoa ngoai title se tao phuong thuc getbytitleid, ma ca hai đeu co the đuoc truy cap truc tiep trong chuc nang anh xa.\n\n/* prepare a record for title entity */\ninsert into titles (id, name) values ('id_1', 'captain')\n\n\n1\n2\n\n\n// handler in mapping function\nimport {user} from '../types/models/user';\nimport {title} from '../types/models/title';\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# moi quan he thuc the\n\nmot thuc the thuong co cac moi quan he long nhau voi cac thuc the khac. đat gia tri truong thanh mot ten thuc the khac se xac đinh moi quan he mot-mot giua hai thuc the nay theo mac đinh.\n\ncac moi quan he thuc the khac nhau (mot-mot, mot-nhieu va nhieu-nhieu) co the đuoc đinh cau hinh bang cach su dung cac vi du ben duoi.\n\n\n# moi quan he mot-mot\n\nmoi quan he mot-mot la mac đinh khi chi mot thuc the duy nhat đuoc anh xa toi mot thuc the khac.\n\nvi du: ho chieu se chi thuoc ve mot nguoi va mot nguoi chi co mot ho chieu (trong vi du nay):\n\ntype person @entity {\n  id: id!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nor\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  owner: person!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# moi quan he mot-nhieu\n\nban co the su dung dau ngoac vuong đe chi ra rang mot loai truong bao gom nhieu thuc the.\n\nvi du: mot nguoi co the co nhieu tai khoan.\n\ntype person @entity {\n  id: id!\n  accounts: [account]\n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# moi quan he nhieu-nhieu\n\nmoi quan he nhieu-nhieu co the đat đuoc bang cach trien khai mot thuc the anh xa đe ket noi hai thuc the khac.\n\nvi du: moi nguoi la mot phan cua nhieu nhom (persongroup) va nhom co nhieu nguoi khac nhau (persongroup).\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  persons: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nngoai ra, co the tao ket noi cua cung mot thuc the trong nhieu truong cua thuc the giua.\n\nvi du: mot tai khoan co the co nhieu lan chuyen tien va moi lan chuyen co mot tai khoan nguon va tai khoan đich.\n\nđieu nay se thiet lap moi quan he hai chieu giua hai tai khoan (tu va đen) thong qua bang chuyen khoan.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# tra cuu nguoc\n\nđe kich hoat tra cuu nguoc đoi voi mot thuc the theo mot moi quan he, hay đinh kem @derivedfrom vao truong va tro đen truong tra cuu nguoc cua thuc the khac.\n\nđieu nay tao ra mot truong ao tren thuc the co the đuoc truy van.\n\nchuyen \"tu\" mot tai khoan co the truy cap đuoc tu thuc the tai khoan bang cach đat senttransfer hoac receivedtransfer co gia tri cua chung bat nguon tu cac truong tu hoac đen tuong ung.\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# loai json\n\nchung toi đang ho tro luu du lieu duoi dang json, đay la mot cach nhanh chong đe luu tru du lieu co cau truc. chung toi se tu đong tao cac giao dien json tuong ung đe truy van du lieu nay va giup ban tiet kiem thoi gian xac đinh va quan ly cac thuc the.\n\nchung toi khuyen nguoi dung su dung loai json trong cac truong hop sau:\n\n * khi luu tru du lieu co cau truc trong mot truong se de quan ly hon so voi viec tao nhieu thuc the rieng biet.\n * luu tuy chon khoa/gia tri tuy y cua nguoi dung (trong đo gia tri co the la boolean, van ban hoac so va ban khong muon co cac cot rieng biet cho cac kieu du lieu khac nhau)\n * luoc đo de thay đoi va thay đoi thuong xuyen\n\n\n# xac đinh chieu json\n\nxac đinh thuoc tinh duoi dang kieu json bang cach them chu thich jsonfield trong thuc the. thao tac nay se tu đong tao giao dien cho tat ca cac đoi tuong json trong du an cua ban duoi type/interface.ts va ban co the truy cap chung trong chuc nang anh xa cua minh.\n\nkhong giong nhu thuc the, đoi tuong chi thi jsonfield khong yeu cau bat ky truong id nao. mot đoi tuong json cung co the long ghep voi cac đoi tuong json khac.\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id!\n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# truy van cac truong json\n\nhan che cua viec su dung cac loai json anh huong nho đen hieu qua truy van khi loc, vi moi lan no thuc hien tim kiem van ban, no se nam tren toan bo thuc the.\n\ntuy nhien, tac đong van co the chap nhan đuoc trong dich vu truy van cua chung toi. duoi đay la vi du ve cach su dung toan tu chua trong truy van graphql tren truong json đe tim 5 nguoi dung đau tien so huu so đien thoai co chua '0064'.\n\n# đe tim 5 so đien thoai cua nguoi dung đau tien co chua '0064'.\n\nquery {\n  user(first: 5, filter: {contactcard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tạo một dự án SubQuery",frontmatter:{summary:"Tạo một dự án SubQuery Trong hướng dẫn bắt đầu nhan, chúng tôi đã xem nhanh một ví dụ để bạn hiểu SubQuery là gì và nó hoạt động như thế nào. Ở đây chúng ta sẽ xem xét kỹ hơn quy t",meta:[{property:"og:url",content:"/vi/create/introduction.html"},{property:"og:title",content:"Tạo một dự án SubQuery"},{property:"og:description",content:"Tạo một dự án SubQuery Trong hướng dẫn bắt đầu nhan, chúng tôi đã xem nhanh một ví dụ để bạn hiểu SubQuery là gì và nó hoạt động như thế nào. Ở đây chúng ta sẽ xem xét kỹ hơn quy t"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/create/introduction.html",relativePath:"vi/create/introduction.md",key:"v-62e23092",path:"/vi/create/introduction/",headers:[{level:2,title:"Quy trình làm việc cơ bản",slug:"quy-trinh-lam-viec-co-ban",normalizedTitle:"quy trinh lam viec co ban",charIndex:260},{level:2,title:"Cấu trúc thư mục",slug:"cau-truc-thu-muc",normalizedTitle:"cau truc thu muc",charIndex:1227},{level:2,title:"Tạo mã",slug:"tao-ma",normalizedTitle:"tao ma",charIndex:1591},{level:2,title:"Xây dựng",slug:"xay-dung",normalizedTitle:"xay dung",charIndex:2064},{level:2,title:"Ghi nhật ký",slug:"ghi-nhat-ky",normalizedTitle:"ghi nhat ky",charIndex:2307}],readingTime:{minutes:2.93,words:880},headersStr:"Quy trình làm việc cơ bản Cấu trúc thư mục Tạo mã Xây dựng Ghi nhật ký",content:"# Tạo một dự án SubQuery\n\nTrong hướng dẫn bắt đầu nhan, chúng tôi đã xem nhanh một ví dụ để bạn hiểu SubQuery là gì và nó hoạt động như thế nào. Ở đây chúng ta sẽ xem xét kỹ hơn quy trình làm việc khi tạo dự án của bạn và các tệp chính mà bạn sẽ làm việc.\n\n\n# Quy trình làm việc cơ bản\n\nMột số ví dụ sau sẽ giả sử bạn đã khởi tạo thành công gói khởi động trong phần Bắt đầu nhanh. Từ gói khởi động đó, chúng tôi sẽ hướng dẫn quy trình chuẩn để tùy chỉnh và triển khai dự án SubQuery của bạn.\n\n 1. Khởi tạo dự án của bạn bằng subql init PROJECT_NAME\n 2. Cập nhật tệp kê khai (project.yaml) để bao gồm thông tin về chuỗi khối của bạn và các thực thể mà bạn sẽ ánh xạ - xem Manifest File\n 3. Tạo các thực thể GraphQL trong lược đồ của bạn (schema.graphql) xác định hình dạng của dữ liệu mà bạn sẽ trích xuất và duy trì để truy vấn - xem Lược đồ GraphQL\n 4. Thêm tất cả các hàm ánh xạ (ví dụ: mappingHandlers.ts) mà bạn muốn gọi để chuyển đổi dữ liệu chuỗi thành các thực thể GraphQL mà bạn đã xác định - xem Ánh xạ\n 5. Tạo, xây dựng và xuất code của bạn lên Dự án SubQuery (hoặc chạy trong node cục bộ của riêng bạn) - xem Chạy và truy vấn Dự án dành cho người mới bắt đầu của bạn trong hướng dẫn bắt đầu nhanh của chúng tôi.\n\n\n# Cấu trúc thư mục\n\nBản đồ sau cung cấp tổng quan về cấu trúc thư mục của một dự án SubQuery khi lệnh init được chạy.\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nVí dụ:\n\n\n\n\n# Tạo mã\n\nBất cứ khi nào bạn thay đổi các thực thể GraphQL của mình, bạn phải tạo lại thư mục loại của mình bằng lệnh sau.\n\nyarn codegen\n\n\n1\n\n\nThao tác này sẽ tạo một thư mục mới (hoặc cập nhật thư mục src/styles hiện có chứa các lớp thực thể được tạo cho mỗi loại mà bạn đã xác định trước đó trong schema.graphql. Các lớp này cung cấp quyền truy cập tải, đọc và ghi thực thể an toàn về kiểu đối với các trường thực thể - xem thêm về quy trình này trong Lược đồ GraphQL.\n\n\n# Xây dựng\n\nĐể chạy Dự án SubQuery của bạn trên một Node SubQuery được lưu trữ cục bộ, trước tiên bạn cần xây dựng công việc của mình.\n\nChạy lệnh xây dựng từ thư mục gốc của dự án.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Ghi nhật ký\n\nPhương thức console.log không còn được hỗ trợ. Thay vào đó, mô-đun logger đã được đưa vào các loại, có nghĩa là chúng tôi có thể hỗ trợ trình ghi nhật ký có thể chấp nhận các cấp độ ghi nhật ký khác nhau.\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\nĐể sử dụng logger.info hoặc logger.warn, chỉ cần đặt dòng vào tệp ánh xạ của bạn.\n\n\n\nĐể sử dụng logger.debug, cần thực hiện thêm một bước. Thêm --log-level = debug vào dòng lệnh của bạn.\n\nNếu bạn đang chạy vùng chứa docker, hãy thêm dòng này vào tệp docker-comp.yaml của bạn.\n\n\n\nBây giờ bạn sẽ thấy đăng nhập mới trong màn hình đầu cuối.\n\n",normalizedContent:"# tao mot du an subquery\n\ntrong huong dan bat đau nhan, chung toi đa xem nhanh mot vi du đe ban hieu subquery la gi va no hoat đong nhu the nao. o đay chung ta se xem xet ky hon quy trinh lam viec khi tao du an cua ban va cac tep chinh ma ban se lam viec.\n\n\n# quy trinh lam viec co ban\n\nmot so vi du sau se gia su ban đa khoi tao thanh cong goi khoi đong trong phan bat đau nhanh. tu goi khoi đong đo, chung toi se huong dan quy trinh chuan đe tuy chinh va trien khai du an subquery cua ban.\n\n 1. khoi tao du an cua ban bang subql init project_name\n 2. cap nhat tep ke khai (project.yaml) đe bao gom thong tin ve chuoi khoi cua ban va cac thuc the ma ban se anh xa - xem manifest file\n 3. tao cac thuc the graphql trong luoc đo cua ban (schema.graphql) xac đinh hinh dang cua du lieu ma ban se trich xuat va duy tri đe truy van - xem luoc đo graphql\n 4. them tat ca cac ham anh xa (vi du: mappinghandlers.ts) ma ban muon goi đe chuyen đoi du lieu chuoi thanh cac thuc the graphql ma ban đa xac đinh - xem anh xa\n 5. tao, xay dung va xuat code cua ban len du an subquery (hoac chay trong node cuc bo cua rieng ban) - xem chay va truy van du an danh cho nguoi moi bat đau cua ban trong huong dan bat đau nhanh cua chung toi.\n\n\n# cau truc thu muc\n\nban đo sau cung cap tong quan ve cau truc thu muc cua mot du an subquery khi lenh init đuoc chay.\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nvi du:\n\n\n\n\n# tao ma\n\nbat cu khi nao ban thay đoi cac thuc the graphql cua minh, ban phai tao lai thu muc loai cua minh bang lenh sau.\n\nyarn codegen\n\n\n1\n\n\nthao tac nay se tao mot thu muc moi (hoac cap nhat thu muc src/styles hien co chua cac lop thuc the đuoc tao cho moi loai ma ban đa xac đinh truoc đo trong schema.graphql. cac lop nay cung cap quyen truy cap tai, đoc va ghi thuc the an toan ve kieu đoi voi cac truong thuc the - xem them ve quy trinh nay trong luoc đo graphql.\n\n\n# xay dung\n\nđe chay du an subquery cua ban tren mot node subquery đuoc luu tru cuc bo, truoc tien ban can xay dung cong viec cua minh.\n\nchay lenh xay dung tu thu muc goc cua du an.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# ghi nhat ky\n\nphuong thuc console.log khong con đuoc ho tro. thay vao đo, mo-đun logger đa đuoc đua vao cac loai, co nghia la chung toi co the ho tro trinh ghi nhat ky co the chap nhan cac cap đo ghi nhat ky khac nhau.\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\nđe su dung logger.info hoac logger.warn, chi can đat dong vao tep anh xa cua ban.\n\n\n\nđe su dung logger.debug, can thuc hien them mot buoc. them --log-level = debug vao dong lenh cua ban.\n\nneu ban đang chay vung chua docker, hay them dong nay vao tep docker-comp.yaml cua ban.\n\n\n\nbay gio ban se thay đang nhap moi trong man hinh đau cuoi.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Lập bản đồ",frontmatter:{summary:"Lập bản đồ Các hàm ánh xạ xác định cách dữ liệu chuỗi được chuyển đổi thành các thực thể GraphQL được tối ưu hóa mà chúng tôi đã xác định trước đó trong tệp schema.graphql. Các ánh",meta:[{property:"og:url",content:"/vi/create/mapping.html"},{property:"og:title",content:"Lập bản đồ"},{property:"og:description",content:"Lập bản đồ Các hàm ánh xạ xác định cách dữ liệu chuỗi được chuyển đổi thành các thực thể GraphQL được tối ưu hóa mà chúng tôi đã xác định trước đó trong tệp schema.graphql. Các ánh"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/create/mapping.html",relativePath:"vi/create/mapping.md",key:"v-674aad0d",path:"/vi/create/mapping/",headers:[{level:2,title:"Trình xử lý khối",slug:"trinh-xu-ly-khoi",normalizedTitle:"trinh xu ly khoi",charIndex:558},{level:2,title:"Xử lý sự kiện",slug:"xu-ly-su-kien",normalizedTitle:"xu ly su kien",charIndex:1309},{level:2,title:"Trình xử lý cuộc gọi",slug:"trinh-xu-ly-cuoc-goi",normalizedTitle:"trinh xu ly cuoc goi",charIndex:599},{level:2,title:"Các trạng thái truy vấn",slug:"cac-trang-thai-truy-van",normalizedTitle:"cac trang thai truy van",charIndex:3155},{level:2,title:"Cuộc gọi RPC",slug:"cuoc-goi-rpc",normalizedTitle:"cuoc goi rpc",charIndex:4208},{level:2,title:"Mô-đun và Thư viện",slug:"mo-đun-va-thu-vien",normalizedTitle:"mo-đun va thu vien",charIndex:5188},{level:3,title:"Mô-đun tích hợp",slug:"mo-đun-tich-hop",normalizedTitle:"mo-đun tich hop",charIndex:5635},{level:3,title:"Thư viện bên thứ ba",slug:"thu-vien-ben-thu-ba",normalizedTitle:"thu vien ben thu ba",charIndex:6310},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:6684},{level:3,title:"Sự chuẩn bị",slug:"su-chuan-bi",normalizedTitle:"su chuan bi",charIndex:7092},{level:3,title:"Gõ generation",slug:"go-generation",normalizedTitle:"go generation",charIndex:10368},{level:3,title:"Sử dụng",slug:"su-dung",normalizedTitle:"su dung",charIndex:11610},{level:3,title:"Lệnh gọi rpc chuỗi tùy chỉnh",slug:"lenh-goi-rpc-chuoi-tuy-chinh",normalizedTitle:"lenh goi rpc chuoi tuy chinh",charIndex:12510}],readingTime:{minutes:10.28,words:3085},headersStr:"Trình xử lý khối Xử lý sự kiện Trình xử lý cuộc gọi Các trạng thái truy vấn Cuộc gọi RPC Mô-đun và Thư viện Mô-đun tích hợp Thư viện bên thứ ba Custom Substrate Chains Sự chuẩn bị Gõ generation Sử dụng Lệnh gọi rpc chuỗi tùy chỉnh",content:'# Lập bản đồ\n\nCác hàm ánh xạ xác định cách dữ liệu chuỗi được chuyển đổi thành các thực thể GraphQL được tối ưu hóa mà chúng tôi đã xác định trước đó trong tệp schema.graphql.\n\nCác ánh xạ được viết trong một tập hợp con của TypeScript được gọi là AssemblyScript có thể được biên dịch thành WASM (WebAssembly).\n\n * Các ánh xạ được định nghĩa trong thư mục src / mappings và được xuất dưới dạng một hàm\n * Các ánh xạ này cũng được xuất dưới dạng src / index.ts\n * Các tệp ánh xạ là tham chiếu trong project.yaml dưới trình xử lý ánh xạ.\n\nCó ba lớp hàm ánh xạ; Trình xử lý khối, Trình xử lý sự kiện và Trình xử lý cuộc gọi.\n\n\n# Trình xử lý khối\n\nBạn có thể sử dụng trình xử lý khối để nắm bắt thông tin mỗi khi khối mới được gắn vào chuỗi Chất nền, ví dụ: chặn số. Để đạt được điều này, một BlockHandler đã xác định sẽ được gọi một lần cho mỗi khối.\n\nimport {SubstrateBlock} from \'@subql/types\';\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n  // Create a new StarterEntity with the block hash as it\'s ID\n  const record = new starterEntity(block.block.header.hash.toString());\n  record.field1 = block.block.header.number.toNumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nSubstrateBlock là kiểu giao diện mở rộng của signBlock, nhưng cũng bao gồm specVersion và timestamp.\n\n\n# Xử lý sự kiện\n\nBạn có thể sử dụng trình xử lý sự kiện để nắm bắt thông tin khi các sự kiện nhất định được đưa vào một khối mới. Các sự kiện là một phần của thời gian chạy Substrate mặc định và một khối có thể chứa nhiều sự kiện.\n\nTrong quá trình xử lý, trình xử lý sự kiện sẽ nhận một sự kiện cơ chất như một đối số với các đầu vào và đầu ra đã nhập của sự kiện. Bất kỳ loại sự kiện nào cũng sẽ kích hoạt ánh xạ, cho phép ghi lại hoạt động với nguồn dữ liệu. Bạn nên sử dụng Bộ lọc ánh xạ trong tệp kê khai của mình để lọc các sự kiện nhằm giảm thời gian lập chỉ mục dữ liệu và cải thiện hiệu suất ánh xạ.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nSubstrateEvent là kiểu giao diện mở rộng của EventRecord. Bên cạnh dữ liệu sự kiện, nó cũng bao gồm một id (khối chứa sự kiện này) và phần bên ngoài bên trong của khối này.\n\n\n# Trình xử lý cuộc gọi\n\nTrình xử lý cuộc gọi được sử dụng khi bạn muốn nắm bắt thông tin về một số ngoại vi chất nền nhất định.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n  const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n  record.field4 = extrinsic.block.timestamp;\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nSubstrateExtrinsic mở rộng GenericExtriuality. Nó được gán một id (khối mà khối bên ngoài này thuộc về) và cung cấp một thuộc tính bên ngoài để mở rộng các sự kiện giữa khối này. Ngoài ra, nó ghi lại trạng thái thành công của ngoại cảnh này.\n\n\n# Các trạng thái truy vấn\n\nMục tiêu của chúng tôi là cung cấp tất cả các nguồn dữ liệu cho người dùng để xử lý ánh xạ (không chỉ là ba loại sự kiện giao diện ở trên). Do đó, chúng tôi đã đưa ra một số giao diện @ polkadot / api để tăng khả năng.\n\nĐây là những giao diện chúng tôi hiện đang hỗ trợ:\n\n * api.query. <module>. <method>() sẽ truy vấn khối hiện tại.\n * api.query. <module>. <method>.multi () sẽ thực hiện nhiều truy vấn loại giống nhau tại khối hiện tại.\n * api.queryMulti() sẽ thực hiện nhiều truy vấn thuộc loại different tại khối hiện tại.\n\nĐây là những giao diện mà chúng tôi KHÔNG hỗ trợ hiện tại:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nXem ví dụ về cách sử dụng API này trong trường hợp sử dụng mẫu validator-threshold của chúng tôi.\n\n\n# Cuộc gọi RPC\n\nChúng tôi cũng hỗ trợ một số phương thức API RPC là các lệnh gọi từ xa cho phép hàm ánh xạ tương tác với node, truy vấn và trình thực tế. Tiền đề cốt lõi của SubQuery là nó có tính xác định và do đó, để giữ kết quả nhất quán, chúng tôi chỉ cho phép các lệnh gọi RPC lịch sử.\n\nCác tài liệu trong JSON-RPC cung cấp một số phương thức sử dụng BlockHash làm tham số đầu vào (ví dụ: at?:BlockHash), hiện được cho phép. Chúng tôi cũng đã sửa đổi các phương pháp này để lấy băm khối lập chỉ mục hiện tại theo mặc định.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * Đối với Chuỗi chất nền tùy chỉnh lệnh gọi RPC, hãy xem usage.\n\n\n# Mô-đun và Thư viện\n\nĐể cải thiện khả năng xử lý dữ liệu của SubQuery, chúng tôi đã cho phép một số mô-đun tích hợp của NodeJS chạy các chức năng ánh xạ trong sandbox và cho phép người dùng gọi các thư viện của bên thứ ba.\n\nXin lưu ý rằng đây là một tính năng thử nghiệm và bạn có thể gặp phải lỗi hoặc sự cố có thể ảnh hưởng tiêu cực đến chức năng ánh xạ của bạn. Vui lòng báo cáo bất kỳ lỗi nào bạn tìm thấy bằng cách tạo sự cố trong GitHub.\n\n\n# Mô-đun tích hợp\n\nHiện tại, chúng tôi cho phép các mô-đun NodeJS sau: assert, buffer, crypto, util và path.\n\nThay vì nhập toàn bộ mô-đun, chúng tôi khuyên bạn chỉ nên nhập (các) phương pháp bắt buộc mà bạn cần. Một số phương thức trong các mô-đun này có thể có các phụ thuộc không được hỗ trợ và sẽ không thành công khi nhập.\n\nimport {hashMessage} from \'ethers/lib/utils\'; //Good way\nimport {utils} from \'ethers\'; //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n  const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n  record.field1 = hashMessage(\'Hello\');\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Thư viện bên thứ ba\n\nDo các hạn chế của máy ảo trong hộp cát của chúng tôi, hiện tại, chúng tôi chỉ hỗ trợ các thư viện của bên thứ ba được viết bởi CommonJS.\n\nChúng tôi cũng hỗ trợ thư viện hybrid như @polkadot/* sử dụng ESM làm mặc định. Tuy nhiên, nếu bất kỳ thư viện nào khác phụ thuộc vào bất kỳ mô-đun nào ở định dạng ESM, máy ảo sẽ KHÔNG biên dịch và trả về lỗi.\n\n\n# Custom Substrate Chains\n\nSubQuery có thể được sử dụng trên bất kỳ chuỗi nào dựa trên Substrate, không chỉ Polkadot hoặc Kusama.\n\nBạn có thể sử dụng chuỗi dựa trên Chất nền tùy chỉnh và chúng tôi cung cấp các công cụ để tự động nhập các loại, giao diện và các phương pháp bổ sung bằng cách sử dụng @polkadot/typegen.\n\nTrong các phần sau, chúng tôi sử dụng ví dụ về kitty để giải thích quá trình tích hợp.\n\n\n# Sự chuẩn bị\n\nTạo một thư mục mới api-interface trong thư mục src của dự án để lưu trữ tất cả các tệp được yêu cầu và được tạo. Chúng tôi cũng tạo một thư mục api-interface/kitties khi chúng tôi muốn thêm trang trí trong API từ mô-đun kitties.\n\n# Metadata\n\nChúng tôi cần siêu dữ liệu để tạo các điểm cuối API thực tế. Trong ví dụ về kitty, chúng tôi sử dụng một điểm cuối từ một mạng thử nghiệm cục bộ và nó cung cấp các loại bổ sung. Làm theo các bước trong thiết lập siêu dữ liệu PolkadotJS để truy xuất siêu dữ liệu của nút từ điểm cuối ** HTTP ** của nó.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nhoặc từ điểm cuối ** websocket ** của nó với sự trợ giúp từ websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nTiếp theo, sao chép và dán đầu ra vào tệp JSON. Trong ví dụ về kitty, chúng tôi đã tạo api-interface/kitty.json.\n\n# Loại định nghĩa\n\nChúng tôi giả định rằng người dùng biết các loại cụ thể và hỗ trợ RPC từ chuỗi và nó được định nghĩa trong Manifest.\n\nSau khi thiết lập types setup, chúng tôi tạo:\n\n * src/api-interface/define.ts - điều này xuất tất cả các định folder definitions\n\nexport {default as kitties} from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interface/kitties/Definition.ts - định nghĩa cho mô-đun kitties\n\nexport default {\n  // custom types\n  types: {\n    Address: \'AccountId\',\n    LookupSource: \'AccountId\',\n    KittyIndex: \'u32\',\n    Kitty: \'[u8; 16]\',\n  },\n  // custom rpc : api.rpc.kitties.getKittyPrice\n  rpc: {\n    getKittyPrice: {\n      description: \'Get Kitty price\',\n      params: [\n        {\n          name: \'at\',\n          type: \'BlockHash\',\n          isHistoric: true,\n          isOptional: false,\n        },\n        {\n          name: \'kittyIndex\',\n          type: \'KittyIndex\',\n          isOptional: false,\n        },\n      ],\n      type: \'Balance\',\n    },\n  },\n};\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Các gói\n\n * Trong tệp package.json, hãy đảm bảo thêm @polkadot/typegen làm phụ thuộc phát triển và @polkadot/api làm phụ thuộc thông thường ( lý tưởng là cùng một phiên bản). Chúng tôi cũng cần ts-node như một phụ thuộc phát triển để giúp chúng tôi chạy các tập lệnh.\n * Chúng tôi thêm các tập lệnh để chạy cả hai loại; generate:defs và siêu dữ liệu generate:meta (theo thứ tự đó, vì vậy siêu dữ liệu có thể sử dụng các loại).\n\nĐây là phiên bản đơn giản của package.json. Đảm bảo trong phần scripts, tên gói là chính xác và các thư mục hợp lệ.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Gõ generation\n\nBây giờ việc chuẩn bị đã hoàn tất, chúng tôi đã sẵn sàng tạo các loại và metadata. Chạy các lệnh dưới đây:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nTrong mỗi thư mục mô-đun (ví dụ: /kitties), bây giờ sẽ có styles.ts được tạo để xác định tất cả các giao diện từ định nghĩa của mô-đun này, cũng là một chỉ mục tệp index.ts xuất tất cả chúng.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nLệnh này sẽ tạo metadata và một api-augment mới cho các API. Vì chúng tôi không muốn sử dụng API tích hợp sẵn, chúng tôi sẽ cần thay thế chúng bằng cách thêm ghi đè rõ ràng trong tsconfig.json của chúng tôi. Sau khi cập nhật, các đường dẫn trong cấu hình sẽ trông như thế này (không có chú thích):\n\n{\n  "compilerOptions": {\n    // this is the package name we use (in the interface imports, --package for generators) */\n    "kitty-birthinfo/*": ["src/*"],\n    // here we replace the @polkadot/api augmentation with our own, generated from chain\n    "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n    // replace the augmented types with our own, as generated from definitions\n    "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Sử dụng\n\nBây giờ trong chức năng ánh xạ, chúng tôi có thể hiển thị cách siêu dữ liệu và các loại thực sự trang trí API. Điểm cuối RPC sẽ hỗ trợ các mô-đun và phương thức mà chúng tôi đã khai báo ở trên. Và để sử dụng lệnh gọi rpc tùy chỉnh, vui lòng xem phầnCustom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n  //return the KittyIndex type\n  const nextKittyId = await api.query.kitties.nextKittyId();\n  // return the Kitty type, input parameters types are AccountId and KittyIndex\n  const allKitties = await api.query.kitties.kitties(\'xxxxxxxxx\', 123);\n  logger.info(`Next kitty id ${nextKittyId}`);\n  //Custom rpc, set undefined to blockhash\n  const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined, nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nNếu bạn muốn xuất bản dự án này cho người khám phá của chúng tôi, vui lòng đưa các tệp đã tạo vào src/api-interface.\n\n\n# Lệnh gọi rpc chuỗi tùy chỉnh\n\nĐể hỗ trợ các lệnh gọi RPC chuỗi tùy chỉnh, chúng tôi phải đưa các định nghĩa RPC cho typesBundle theo cách thủ công, cho phép cấu hình theo từng thông số kỹ thuật. Bạn có thể xác định stylesBundle trong project.yml. Và hãy nhớ chỉ hỗ trợ loại cuộc gọi isHistoric.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# lap ban đo\n\ncac ham anh xa xac đinh cach du lieu chuoi đuoc chuyen đoi thanh cac thuc the graphql đuoc toi uu hoa ma chung toi đa xac đinh truoc đo trong tep schema.graphql.\n\ncac anh xa đuoc viet trong mot tap hop con cua typescript đuoc goi la assemblyscript co the đuoc bien dich thanh wasm (webassembly).\n\n * cac anh xa đuoc đinh nghia trong thu muc src / mappings va đuoc xuat duoi dang mot ham\n * cac anh xa nay cung đuoc xuat duoi dang src / index.ts\n * cac tep anh xa la tham chieu trong project.yaml duoi trinh xu ly anh xa.\n\nco ba lop ham anh xa; trinh xu ly khoi, trinh xu ly su kien va trinh xu ly cuoc goi.\n\n\n# trinh xu ly khoi\n\nban co the su dung trinh xu ly khoi đe nam bat thong tin moi khi khoi moi đuoc gan vao chuoi chat nen, vi du: chan so. đe đat đuoc đieu nay, mot blockhandler đa xac đinh se đuoc goi mot lan cho moi khoi.\n\nimport {substrateblock} from \'@subql/types\';\n\nexport async function handleblock(block: substrateblock): promise<void> {\n  // create a new starterentity with the block hash as it\'s id\n  const record = new starterentity(block.block.header.hash.tostring());\n  record.field1 = block.block.header.number.tonumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nsubstrateblock la kieu giao dien mo rong cua signblock, nhung cung bao gom specversion va timestamp.\n\n\n# xu ly su kien\n\nban co the su dung trinh xu ly su kien đe nam bat thong tin khi cac su kien nhat đinh đuoc đua vao mot khoi moi. cac su kien la mot phan cua thoi gian chay substrate mac đinh va mot khoi co the chua nhieu su kien.\n\ntrong qua trinh xu ly, trinh xu ly su kien se nhan mot su kien co chat nhu mot đoi so voi cac đau vao va đau ra đa nhap cua su kien. bat ky loai su kien nao cung se kich hoat anh xa, cho phep ghi lai hoat đong voi nguon du lieu. ban nen su dung bo loc anh xa trong tep ke khai cua minh đe loc cac su kien nham giam thoi gian lap chi muc du lieu va cai thien hieu suat anh xa.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nsubstrateevent la kieu giao dien mo rong cua eventrecord. ben canh du lieu su kien, no cung bao gom mot id (khoi chua su kien nay) va phan ben ngoai ben trong cua khoi nay.\n\n\n# trinh xu ly cuoc goi\n\ntrinh xu ly cuoc goi đuoc su dung khi ban muon nam bat thong tin ve mot so ngoai vi chat nen nhat đinh.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n  const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n  record.field4 = extrinsic.block.timestamp;\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nsubstrateextrinsic mo rong genericextriuality. no đuoc gan mot id (khoi ma khoi ben ngoai nay thuoc ve) va cung cap mot thuoc tinh ben ngoai đe mo rong cac su kien giua khoi nay. ngoai ra, no ghi lai trang thai thanh cong cua ngoai canh nay.\n\n\n# cac trang thai truy van\n\nmuc tieu cua chung toi la cung cap tat ca cac nguon du lieu cho nguoi dung đe xu ly anh xa (khong chi la ba loai su kien giao dien o tren). do đo, chung toi đa đua ra mot so giao dien @ polkadot / api đe tang kha nang.\n\nđay la nhung giao dien chung toi hien đang ho tro:\n\n * api.query. <module>. <method>() se truy van khoi hien tai.\n * api.query. <module>. <method>.multi () se thuc hien nhieu truy van loai giong nhau tai khoi hien tai.\n * api.querymulti() se thuc hien nhieu truy van thuoc loai different tai khoi hien tai.\n\nđay la nhung giao dien ma chung toi khong ho tro hien tai:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nxem vi du ve cach su dung api nay trong truong hop su dung mau validator-threshold cua chung toi.\n\n\n# cuoc goi rpc\n\nchung toi cung ho tro mot so phuong thuc api rpc la cac lenh goi tu xa cho phep ham anh xa tuong tac voi node, truy van va trinh thuc te. tien đe cot loi cua subquery la no co tinh xac đinh va do đo, đe giu ket qua nhat quan, chung toi chi cho phep cac lenh goi rpc lich su.\n\ncac tai lieu trong json-rpc cung cap mot so phuong thuc su dung blockhash lam tham so đau vao (vi du: at?:blockhash), hien đuoc cho phep. chung toi cung đa sua đoi cac phuong phap nay đe lay bam khoi lap chi muc hien tai theo mac đinh.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * đoi voi chuoi chat nen tuy chinh lenh goi rpc, hay xem usage.\n\n\n# mo-đun va thu vien\n\nđe cai thien kha nang xu ly du lieu cua subquery, chung toi đa cho phep mot so mo-đun tich hop cua nodejs chay cac chuc nang anh xa trong sandbox va cho phep nguoi dung goi cac thu vien cua ben thu ba.\n\nxin luu y rang đay la mot tinh nang thu nghiem va ban co the gap phai loi hoac su co co the anh huong tieu cuc đen chuc nang anh xa cua ban. vui long bao cao bat ky loi nao ban tim thay bang cach tao su co trong github.\n\n\n# mo-đun tich hop\n\nhien tai, chung toi cho phep cac mo-đun nodejs sau: assert, buffer, crypto, util va path.\n\nthay vi nhap toan bo mo-đun, chung toi khuyen ban chi nen nhap (cac) phuong phap bat buoc ma ban can. mot so phuong thuc trong cac mo-đun nay co the co cac phu thuoc khong đuoc ho tro va se khong thanh cong khi nhap.\n\nimport {hashmessage} from \'ethers/lib/utils\'; //good way\nimport {utils} from \'ethers\'; //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n  const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n  record.field1 = hashmessage(\'hello\');\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# thu vien ben thu ba\n\ndo cac han che cua may ao trong hop cat cua chung toi, hien tai, chung toi chi ho tro cac thu vien cua ben thu ba đuoc viet boi commonjs.\n\nchung toi cung ho tro thu vien hybrid nhu @polkadot/* su dung esm lam mac đinh. tuy nhien, neu bat ky thu vien nao khac phu thuoc vao bat ky mo-đun nao o đinh dang esm, may ao se khong bien dich va tra ve loi.\n\n\n# custom substrate chains\n\nsubquery co the đuoc su dung tren bat ky chuoi nao dua tren substrate, khong chi polkadot hoac kusama.\n\nban co the su dung chuoi dua tren chat nen tuy chinh va chung toi cung cap cac cong cu đe tu đong nhap cac loai, giao dien va cac phuong phap bo sung bang cach su dung @polkadot/typegen.\n\ntrong cac phan sau, chung toi su dung vi du ve kitty đe giai thich qua trinh tich hop.\n\n\n# su chuan bi\n\ntao mot thu muc moi api-interface trong thu muc src cua du an đe luu tru tat ca cac tep đuoc yeu cau va đuoc tao. chung toi cung tao mot thu muc api-interface/kitties khi chung toi muon them trang tri trong api tu mo-đun kitties.\n\n# metadata\n\nchung toi can sieu du lieu đe tao cac điem cuoi api thuc te. trong vi du ve kitty, chung toi su dung mot điem cuoi tu mot mang thu nghiem cuc bo va no cung cap cac loai bo sung. lam theo cac buoc trong thiet lap sieu du lieu polkadotjs đe truy xuat sieu du lieu cua nut tu điem cuoi ** http ** cua no.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nhoac tu điem cuoi ** websocket ** cua no voi su tro giup tu websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\ntiep theo, sao chep va dan đau ra vao tep json. trong vi du ve kitty, chung toi đa tao api-interface/kitty.json.\n\n# loai đinh nghia\n\nchung toi gia đinh rang nguoi dung biet cac loai cu the va ho tro rpc tu chuoi va no đuoc đinh nghia trong manifest.\n\nsau khi thiet lap types setup, chung toi tao:\n\n * src/api-interface/define.ts - đieu nay xuat tat ca cac đinh folder definitions\n\nexport {default as kitties} from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interface/kitties/definition.ts - đinh nghia cho mo-đun kitties\n\nexport default {\n  // custom types\n  types: {\n    address: \'accountid\',\n    lookupsource: \'accountid\',\n    kittyindex: \'u32\',\n    kitty: \'[u8; 16]\',\n  },\n  // custom rpc : api.rpc.kitties.getkittyprice\n  rpc: {\n    getkittyprice: {\n      description: \'get kitty price\',\n      params: [\n        {\n          name: \'at\',\n          type: \'blockhash\',\n          ishistoric: true,\n          isoptional: false,\n        },\n        {\n          name: \'kittyindex\',\n          type: \'kittyindex\',\n          isoptional: false,\n        },\n      ],\n      type: \'balance\',\n    },\n  },\n};\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# cac goi\n\n * trong tep package.json, hay đam bao them @polkadot/typegen lam phu thuoc phat trien va @polkadot/api lam phu thuoc thong thuong ( ly tuong la cung mot phien ban). chung toi cung can ts-node nhu mot phu thuoc phat trien đe giup chung toi chay cac tap lenh.\n * chung toi them cac tap lenh đe chay ca hai loai; generate:defs va sieu du lieu generate:meta (theo thu tu đo, vi vay sieu du lieu co the su dung cac loai).\n\nđay la phien ban đon gian cua package.json. đam bao trong phan scripts, ten goi la chinh xac va cac thu muc hop le.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# go generation\n\nbay gio viec chuan bi đa hoan tat, chung toi đa san sang tao cac loai va metadata. chay cac lenh duoi đay:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\ntrong moi thu muc mo-đun (vi du: /kitties), bay gio se co styles.ts đuoc tao đe xac đinh tat ca cac giao dien tu đinh nghia cua mo-đun nay, cung la mot chi muc tep index.ts xuat tat ca chung.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nlenh nay se tao metadata va mot api-augment moi cho cac api. vi chung toi khong muon su dung api tich hop san, chung toi se can thay the chung bang cach them ghi đe ro rang trong tsconfig.json cua chung toi. sau khi cap nhat, cac đuong dan trong cau hinh se trong nhu the nay (khong co chu thich):\n\n{\n  "compileroptions": {\n    // this is the package name we use (in the interface imports, --package for generators) */\n    "kitty-birthinfo/*": ["src/*"],\n    // here we replace the @polkadot/api augmentation with our own, generated from chain\n    "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n    // replace the augmented types with our own, as generated from definitions\n    "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# su dung\n\nbay gio trong chuc nang anh xa, chung toi co the hien thi cach sieu du lieu va cac loai thuc su trang tri api. điem cuoi rpc se ho tro cac mo-đun va phuong thuc ma chung toi đa khai bao o tren. va đe su dung lenh goi rpc tuy chinh, vui long xem phancustom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n  //return the kittyindex type\n  const nextkittyid = await api.query.kitties.nextkittyid();\n  // return the kitty type, input parameters types are accountid and kittyindex\n  const allkitties = await api.query.kitties.kitties(\'xxxxxxxxx\', 123);\n  logger.info(`next kitty id ${nextkittyid}`);\n  //custom rpc, set undefined to blockhash\n  const kittyprice = await api.rpc.kitties.getkittyprice(undefined, nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nneu ban muon xuat ban du an nay cho nguoi kham pha cua chung toi, vui long đua cac tep đa tao vao src/api-interface.\n\n\n# lenh goi rpc chuoi tuy chinh\n\nđe ho tro cac lenh goi rpc chuoi tuy chinh, chung toi phai đua cac đinh nghia rpc cho typesbundle theo cach thu cong, cho phep cau hinh theo tung thong so ky thuat. ban co the xac đinh stylesbundle trong project.yml. va hay nho chi ho tro loai cuoc goi ishistoric.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File Tệp Manifest project.yaml có thể được xem như một điểm đầu vào của dự án của bạn và nó xác định hầu hết các chi tiết về cách SubQuery sẽ lập chỉ mục và chuyển đổi dữ ",meta:[{property:"og:url",content:"/vi/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File Tệp Manifest project.yaml có thể được xem như một điểm đầu vào của dự án của bạn và nó xác định hầu hết các chi tiết về cách SubQuery sẽ lập chỉ mục và chuyển đổi dữ "},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/create/manifest.html",relativePath:"vi/create/manifest.md",key:"v-e7c9cde6",path:"/vi/create/manifest/",headers:[{level:2,title:"Bộ lọc mạng",slug:"bo-loc-mang",normalizedTitle:"bo loc mang",charIndex:1973},{level:2,title:"Bộ lọc ánh xạ",slug:"bo-loc-anh-xa",normalizedTitle:"bo loc anh xa",charIndex:3215},{level:2,title:"Chuỗi tùy chỉnh",slug:"chuoi-tuy-chinh",normalizedTitle:"chuoi tuy chinh",charIndex:4524}],readingTime:{minutes:3.8,words:1141},headersStr:"Bộ lọc mạng Bộ lọc ánh xạ Chuỗi tùy chỉnh",content:"# Manifest File\n\nTệp Manifest project.yaml có thể được xem như một điểm đầu vào của dự án của bạn và nó xác định hầu hết các chi tiết về cách SubQuery sẽ lập chỉ mục và chuyển đổi dữ liệu chuỗi.\n\nTệp kê khai có thể ở định dạng YAML hoặc JSON. Trong tài liệu này, chúng tôi sẽ sử dụng YAML trong tất cả các ví dụ. Dưới đây là ví dụ tiêu chuẩn về project.yaml cơ bản.\n\nspecVersion: '0.0.1'\ndescription: ''\nrepository: 'https://github.com/subquery/subql-starter'\n\nschema: './schema.graphql'\n\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: 'https://api.subquery.network/sq/subquery/dictionary-polkadot'\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint xác định điểm cuối wss hoặc ws của chuỗi khối sẽ được lập chỉ mục - Đây phải là một node lưu trữ đầy đủ.\n * network.dictionary tùy chọn cung cấp điểm cuối HTTP của từ điển chuỗi đầy đủ để tăng tốc độ xử lý - xem Chạy Trình lập chỉ mục\n * dataSources xác định dữ liệu sẽ được lọc và trích xuất và vị trí của trình xử lý hàm ánh xạ để áp dụng chuyển đổi dữ liệu.\n   * kind hiện chỉ hỗ trợ substrate/Runtime.\n   * startBlock chỉ định chiều cao khối để bắt đầu lập chỉ mục.\n   * filter sẽ lọc nguồn dữ liệu để thực thi theo tên thông số điểm cuối của mạng, hãy xem bộ lọc mạng\n   * mapping.handlers sẽ liệt kê tất cả các hàm ánh xạ và các loại trình xử lý tương ứng của chúng, với các bộ lọc ánh xạ bổ sung.\n\n\n# Bộ lọc mạng\n\nThông thường người dùng sẽ tạo một SubQuery và mong muốn sử dụng lại nó cho cả môi trường testnet và mainnet của họ (ví dụ: Polkadot và Kusama). Giữa các mạng, các tùy chọn khác nhau có thể khác nhau (ví dụ: khối bắt đầu lập chỉ mục). Do đó, chúng tôi cho phép người dùng xác định các chi tiết khác nhau cho từng nguồn dữ liệu, có nghĩa là một dự án SubQuery vẫn có thể được sử dụng trên nhiều mạng.\n\nNgười dùng có thể thêm filter trên dataSources để quyết định nguồn dữ liệu nào sẽ chạy trên mỗi mạng.\n\nDưới đây là một ví dụ hiển thị các nguồn dữ liệu khác nhau cho cả mạng Polkadot và Kusama.\n\n\n---\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter: #Optional\n      specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter:\n      specName: kusama\n    startBlock: 12000\n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# Bộ lọc ánh xạ\n\nBộ lọc ánh xạ là một tính năng cực kỳ hữu ích để quyết định khối, sự kiện hoặc bên ngoài nào sẽ kích hoạt trình xử lý ánh xạ.\n\nChỉ dữ liệu đến thỏa mãn các điều kiện lọc sẽ được xử lý bởi các hàm ánh xạ. Bộ lọc ánh xạ là tùy chọn nhưng được khuyến nghị vì chúng làm giảm đáng kể lượng dữ liệu được xử lý bởi dự án SubQuery của bạn và sẽ cải thiện hiệu suất lập chỉ mục.\n\n#Example filter from callHandler\nfilter:\n  module: balances\n  method: Deposit\n  success: true\n\n\n1\n2\n3\n4\n5\n\n\nBảng sau giải thích các bộ lọc được hỗ trợ bởi các trình xử lý khác nhau.\n\nHANDLER        BỘ LỌC ĐƯỢC HỖ TRỢ\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Bộ lọc mô-đun và phương pháp được hỗ trợ trên bất kỳ chuỗi dựa trên chất nền nào.\n * Bộ lọc success nhận một giá trị boolean và có thể được sử dụng để lọc phần bên ngoài theo trạng thái thành công của nó.\n * Bộ lọc specVersion chỉ định phạm vi phiên bản cụ thể cho khối chất nền. Các ví dụ sau đây mô tả cách đặt phạm vi phiên bản.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Chuỗi tùy chỉnh\n\nBạn có thể lập chỉ mục dữ liệu từ các chuỗi tùy chỉnh bằng cách bao gồm các loại chuỗi trong project.yaml. Khai báo các loại cụ thể được blockchain này hỗ trợ trong network.types. Chúng tôi hỗ trợ các loại bổ sung được sử dụng bởi các mô-đun thời gian chạy chất nền.\n\nstylesAlias, stylesBundle, stylesChain và stylesSpec cũng được hỗ trợ.\n\nspecVersion: '0.0.1'\ndescription: \"This subquery indexes kitty's birth info\"\nrepository: 'https://github.com/onfinality-io/subql-examples'\nschema: './schema.graphql'\nnetwork:\n  endpoint: 'ws://host.kittychain.io/public-ws'\n  types: {'KittyIndex': 'u32', 'Kitty': '[u8; 16]'}\n# typesChain: { chain: { Type5: 'example' } }\n# typesSpec: { spec: { Type6: 'example' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter: #Optional\n      specName: kitty-chain\n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n",normalizedContent:"# manifest file\n\ntep manifest project.yaml co the đuoc xem nhu mot điem đau vao cua du an cua ban va no xac đinh hau het cac chi tiet ve cach subquery se lap chi muc va chuyen đoi du lieu chuoi.\n\ntep ke khai co the o đinh dang yaml hoac json. trong tai lieu nay, chung toi se su dung yaml trong tat ca cac vi du. duoi đay la vi du tieu chuan ve project.yaml co ban.\n\nspecversion: '0.0.1'\ndescription: ''\nrepository: 'https://github.com/subquery/subql-starter'\n\nschema: './schema.graphql'\n\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: 'https://api.subquery.network/sq/subquery/dictionary-polkadot'\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint xac đinh điem cuoi wss hoac ws cua chuoi khoi se đuoc lap chi muc - đay phai la mot node luu tru đay đu.\n * network.dictionary tuy chon cung cap điem cuoi http cua tu đien chuoi đay đu đe tang toc đo xu ly - xem chay trinh lap chi muc\n * datasources xac đinh du lieu se đuoc loc va trich xuat va vi tri cua trinh xu ly ham anh xa đe ap dung chuyen đoi du lieu.\n   * kind hien chi ho tro substrate/runtime.\n   * startblock chi đinh chieu cao khoi đe bat đau lap chi muc.\n   * filter se loc nguon du lieu đe thuc thi theo ten thong so điem cuoi cua mang, hay xem bo loc mang\n   * mapping.handlers se liet ke tat ca cac ham anh xa va cac loai trinh xu ly tuong ung cua chung, voi cac bo loc anh xa bo sung.\n\n\n# bo loc mang\n\nthong thuong nguoi dung se tao mot subquery va mong muon su dung lai no cho ca moi truong testnet va mainnet cua ho (vi du: polkadot va kusama). giua cac mang, cac tuy chon khac nhau co the khac nhau (vi du: khoi bat đau lap chi muc). do đo, chung toi cho phep nguoi dung xac đinh cac chi tiet khac nhau cho tung nguon du lieu, co nghia la mot du an subquery van co the đuoc su dung tren nhieu mang.\n\nnguoi dung co the them filter tren datasources đe quyet đinh nguon du lieu nao se chay tren moi mang.\n\nduoi đay la mot vi du hien thi cac nguon du lieu khac nhau cho ca mang polkadot va kusama.\n\n\n---\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter: #optional\n      specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter:\n      specname: kusama\n    startblock: 12000\n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# bo loc anh xa\n\nbo loc anh xa la mot tinh nang cuc ky huu ich đe quyet đinh khoi, su kien hoac ben ngoai nao se kich hoat trinh xu ly anh xa.\n\nchi du lieu đen thoa man cac đieu kien loc se đuoc xu ly boi cac ham anh xa. bo loc anh xa la tuy chon nhung đuoc khuyen nghi vi chung lam giam đang ke luong du lieu đuoc xu ly boi du an subquery cua ban va se cai thien hieu suat lap chi muc.\n\n#example filter from callhandler\nfilter:\n  module: balances\n  method: deposit\n  success: true\n\n\n1\n2\n3\n4\n5\n\n\nbang sau giai thich cac bo loc đuoc ho tro boi cac trinh xu ly khac nhau.\n\nhandler        bo loc đuoc ho tro\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * bo loc mo-đun va phuong phap đuoc ho tro tren bat ky chuoi dua tren chat nen nao.\n * bo loc success nhan mot gia tri boolean va co the đuoc su dung đe loc phan ben ngoai theo trang thai thanh cong cua no.\n * bo loc specversion chi đinh pham vi phien ban cu the cho khoi chat nen. cac vi du sau đay mo ta cach đat pham vi phien ban.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# chuoi tuy chinh\n\nban co the lap chi muc du lieu tu cac chuoi tuy chinh bang cach bao gom cac loai chuoi trong project.yaml. khai bao cac loai cu the đuoc blockchain nay ho tro trong network.types. chung toi ho tro cac loai bo sung đuoc su dung boi cac mo-đun thoi gian chay chat nen.\n\nstylesalias, stylesbundle, styleschain va stylesspec cung đuoc ho tro.\n\nspecversion: '0.0.1'\ndescription: \"this subquery indexes kitty's birth info\"\nrepository: 'https://github.com/onfinality-io/subql-examples'\nschema: './schema.graphql'\nnetwork:\n  endpoint: 'ws://host.kittychain.io/public-ws'\n  types: {'kittyindex': 'u32', 'kitty': '[u8; 16]'}\n# typeschain: { chain: { type5: 'example' } }\n# typesspec: { spec: { type6: 'example' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter: #optional\n      specname: kitty-chain\n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Cài đặt SubQuery",frontmatter:{summary:"Cài đặt SubQuery Có nhiều thành phần được yêu cầu để tạo một dự án SubQuery. Thành phần @subql/node là bắt buộc để chạy trình chỉ mục. Thư viện @subql/query là bắt buộc để tạo các ",meta:[{property:"og:url",content:"/vi/install/install.html"},{property:"og:title",content:"Cài đặt SubQuery"},{property:"og:description",content:"Cài đặt SubQuery Có nhiều thành phần được yêu cầu để tạo một dự án SubQuery. Thành phần @subql/node là bắt buộc để chạy trình chỉ mục. Thư viện @subql/query là bắt buộc để tạo các "},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/install/install.html",relativePath:"vi/install/install.md",key:"v-fac8dafa",path:"/vi/install/install/",headers:[{level:2,title:"Cài đặt @subql/cli",slug:"cai-đat-subql-cli",normalizedTitle:"cai đat @subql/cli",charIndex:197},{level:2,title:"Cài đặt @subql/node",slug:"cai-đat-subql-node",normalizedTitle:"cai đat @subql/node",charIndex:616},{level:2,title:"Cài đặt @subql/query",slug:"cai-đat-subql-query",normalizedTitle:"cai đat @subql/query",charIndex:1251}],readingTime:{minutes:1.71,words:514},headersStr:"Cài đặt @subql/cli Cài đặt @subql/node Cài đặt @subql/query",content:'# Cài đặt SubQuery\n\nCó nhiều thành phần được yêu cầu để tạo một dự án SubQuery. Thành phần @subql/node là bắt buộc để chạy trình chỉ mục. Thư viện @subql/query là bắt buộc để tạo các truy vấn.\n\n\n# Cài đặt @subql/cli\n\nThư viện @subql/cli giúp tạo khung hoặc giàn cho dự án, nghĩa là bạn không phải bắt đầu từ đầu.\n\nCài đặt SubQuery CLI trên toàn cầu trên thiết bị đầu cuối (terminal) của bạn bằng cách sử dụng Yarn hoặc NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nSau đó, bạn có thể chạy trợ giúp để xem các lệnh có sẵn và cách sử dụng do CLI cung cấp:\n\nsubql help\n\n\n1\n\n\n\n# Cài đặt @subql/node\n\nNút SubQuery là một hành động trích xuất dữ liệu blockchain dựa trên chất nền cho mỗi dự án SubQuery và lưu nó vào cơ sở dữ liệu Postgres.\n\nCài đặt nút SubQuery trên toàn cầu trên thiết bị đầu cuối của bạn bằng cách sử dụng Yarn hoặc NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nSau khi cài đặt, bạn có thể tạo một nút bằng cách nhập:\n\nsubql-node <command>\n\n\n1\n\n\n> Lưu ý: Nếu bạn đang sử dụng Docker hoặc lưu trữ dự án của mình trên SubQuery Projects, bạn có thể bỏ qua bước này. Bởi vì nút SubQuery đã được cung cấp trong vùng chứa Docker và cơ sở hạ tầng lưu trữ.\n\n\n# Cài đặt @subql/query\n\nThư viện truy vấn SubQuery cung cấp dịch vụ cho phép bạn truy vấn dự án của mình trong môi trường "sân chơi" thông qua trình duyệt của bạn.\n\nCài đặt truy vấn SubQuery trên toàn cầu trên thiết bị đầu cuối của bạn bằng cách sử dụng Yarn hoặc NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Lưu ý: Nếu bạn đang sử dụng Docker hoặc lưu trữ dự án của mình trên SubQuery Projects, bạn cũng có thể bỏ qua bước này. Bởi vì nút SubQuery đã được cung cấp trong vùng chứa Docker và cơ sở hạ tầng lưu trữ.',normalizedContent:'# cai đat subquery\n\nco nhieu thanh phan đuoc yeu cau đe tao mot du an subquery. thanh phan @subql/node la bat buoc đe chay trinh chi muc. thu vien @subql/query la bat buoc đe tao cac truy van.\n\n\n# cai đat @subql/cli\n\nthu vien @subql/cli giup tao khung hoac gian cho du an, nghia la ban khong phai bat đau tu đau.\n\ncai đat subquery cli tren toan cau tren thiet bi đau cuoi (terminal) cua ban bang cach su dung yarn hoac npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nsau đo, ban co the chay tro giup đe xem cac lenh co san va cach su dung do cli cung cap:\n\nsubql help\n\n\n1\n\n\n\n# cai đat @subql/node\n\nnut subquery la mot hanh đong trich xuat du lieu blockchain dua tren chat nen cho moi du an subquery va luu no vao co so du lieu postgres.\n\ncai đat nut subquery tren toan cau tren thiet bi đau cuoi cua ban bang cach su dung yarn hoac npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nsau khi cai đat, ban co the tao mot nut bang cach nhap:\n\nsubql-node <command>\n\n\n1\n\n\n> luu y: neu ban đang su dung docker hoac luu tru du an cua minh tren subquery projects, ban co the bo qua buoc nay. boi vi nut subquery đa đuoc cung cap trong vung chua docker va co so ha tang luu tru.\n\n\n# cai đat @subql/query\n\nthu vien truy van subquery cung cap dich vu cho phep ban truy van du an cua minh trong moi truong "san choi" thong qua trinh duyet cua ban.\n\ncai đat truy van subquery tren toan cau tren thiet bi đau cuoi cua ban bang cach su dung yarn hoac npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> luu y: neu ban đang su dung docker hoac luu tru du an cua minh tren subquery projects, ban cung co the bo qua buoc nay. boi vi nut subquery đa đuoc cung cap trong vung chua docker va co so ha tang luu tru.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Các câu hỏi thường gặp",frontmatter:{summary:"Các câu hỏi thường gặp SubQuery là gì? SubQuery là một dự án mã nguồn mở cho phép các nhà phát triển chạy trình lập chỉ mục, chuyển đổi và truy vấn dữ liệu trên chuỗi Substrate để ",meta:[{property:"og:url",content:"/vi/faqs/faqs.html"},{property:"og:title",content:"Các câu hỏi thường gặp"},{property:"og:description",content:"Các câu hỏi thường gặp SubQuery là gì? SubQuery là một dự án mã nguồn mở cho phép các nhà phát triển chạy trình lập chỉ mục, chuyển đổi và truy vấn dữ liệu trên chuỗi Substrate để "},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/faqs/faqs.html",relativePath:"vi/faqs/faqs.md",key:"v-6989e673",path:"/vi/faqs/faqs/",headers:[{level:2,title:"SubQuery là gì?",slug:"subquery-la-gi",normalizedTitle:"subquery la gi?",charIndex:29},{level:2,title:"Cách tốt nhất để bắt đầu sử dụng SubQuery là gì?",slug:"cach-tot-nhat-đe-bat-đau-su-dung-subquery-la-gi",normalizedTitle:"cach tot nhat đe bat đau su dung subquery la gi?",charIndex:450},{level:2,title:"Làm cách nào để tôi có thể đóng góp hoặc gửi phản hồi cho SubQuery?",slug:"lam-cach-nao-đe-toi-co-the-đong-gop-hoac-gui-phan-hoi-cho-subquery",normalizedTitle:"lam cach nao đe toi co the đong gop hoac gui phan hoi cho subquery?",charIndex:776},{level:2,title:"Chi phí để lưu trữ dự án của tôi trong SubQuery Projects là bao nhiêu?",slug:"chi-phi-đe-luu-tru-du-an-cua-toi-trong-subquery-projects-la-bao-nhieu",normalizedTitle:"chi phi đe luu tru du an cua toi trong subquery projects la bao nhieu?",charIndex:1254},{level:2,title:"Các vị trí triển khai là gì?",slug:"cac-vi-tri-trien-khai-la-gi",normalizedTitle:"cac vi tri trien khai la gi?",charIndex:1553},{level:2,title:"Ưu điểm của vị trí dàn dựng là gì?",slug:"uu-điem-cua-vi-tri-dan-dung-la-gi",normalizedTitle:"uu điem cua vi tri dan dung la gi?",charIndex:2290},{level:2,title:"Thông tin ngoại lai (extrinsics) là gì?",slug:"thong-tin-ngoai-lai-extrinsics-la-gi",normalizedTitle:"thong tin ngoai lai (extrinsics) la gi?",charIndex:2820}],readingTime:{minutes:3.81,words:1144},headersStr:"SubQuery là gì? Cách tốt nhất để bắt đầu sử dụng SubQuery là gì? Làm cách nào để tôi có thể đóng góp hoặc gửi phản hồi cho SubQuery? Chi phí để lưu trữ dự án của tôi trong SubQuery Projects là bao nhiêu? Các vị trí triển khai là gì? Ưu điểm của vị trí dàn dựng là gì? Thông tin ngoại lai (extrinsics) là gì?",content:'# Các câu hỏi thường gặp\n\n\n# SubQuery là gì?\n\nSubQuery là một dự án mã nguồn mở cho phép các nhà phát triển chạy trình lập chỉ mục, chuyển đổi và truy vấn dữ liệu trên chuỗi Substrate để chạy các ứng dụng của họ.\n\nSubQuery cũng cung cấp dịch vụ lưu trữ miễn phí, công suất lớn cho các dự án của các nhà phát triển; trút bỏ trách nhiệm của các nhà sản xuất trong việc quản lý cơ sở hạ tầng nữa, để họ tập trung làm việc mình giỏi nhất: lập trình.\n\n\n# Cách tốt nhất để bắt đầu sử dụng SubQuery là gì?\n\nCách tốt nhất để bắt đầu sử dụng SubQuery là thực hiện Hướng dẫn Hello World của chúng tôi. Đây là một hướng dẫn 5 phút đơn giản để tải xuống mẫu khởi động, xây dựng dự án và sau đó sử dụng Docker để chạy một nút trên máy chủ cục bộ của bạn và chạy một truy vấn đơn giản.\n\n\n# Làm cách nào để tôi có thể đóng góp hoặc gửi phản hồi cho SubQuery?\n\nChúng tôi rất trân trọng những đóng góp và phản hồi từ cộng đồng. Để đóng góp mã, hãy chia nhỏ kho lưu trữ quan tâm và thực hiện các thay đổi của bạn. Sau đó gửi PR hoặc Pull Request. Ồ, đừng quên kiểm tra lại nhé! Bạn nên tham khảo hướng dẫn đóng góp của chúng tôi (TBA/thông báo sau).\n\nĐể gửi phản hồi, hãy liên hệ với chúng tôi qua email hello@subquery.network hoặc truy cập kênh discord của chúng tôi\n\n\n# Chi phí để lưu trữ dự án của tôi trong SubQuery Projects là bao nhiêu?\n\nBạn có thể lưu trữ dự án trong SubQuery Projects hoàn toàn miễn phí - đó là cách chúng tôi đóng góp cho cộng đồng. Để tìm hiểu cách lưu trữ dự án của bạn với chúng tôi, vui lòng xem hướng dẫn Hello World (SubQuery hosted).\n\n\n# Các vị trí triển khai là gì?\n\nVị trí triển khai là một tính năng trong SubQuery Projects gần giống với môi trường phát triển. Ví dụ, trong bất kỳ tổ chức phần mềm nào tối thiểu đều có môi trường phát triển và môi trường sản xuất (không tính localhost). Thông thường, nó bao gồm các môi trường bổ sung như staging (dàn dựng) và pre-pod (tiền sản xuất) hoặc thậm chí là QA, tùy thuộc vào nhu cầu của tổ chức và sự phát triển của chúng được thiết lập.\n\nSubQuery hiện có sẵn hai vị trí. Một vị trí dàn dựng (staging slot) và một vị trí sản xuất (production slot). Điều này cho phép các nhà phát triển triển khai SubQuery của họ vào môi trường dàn dựng và để mọi thứ diễn ra tốt đẹp, sau đó chọn "thúc đẩy sản xuất" chỉ bằng một nút bấm.\n\n\n# Ưu điểm của vị trí dàn dựng là gì?\n\nLợi ích chính của việc sử dụng vị trí dàn dựng là nó cho phép bạn chuẩn bị một bản phát hành mới cho dự án SubQuery của mình không cần công khai. Bạn có thể đợi vị trí dàn dựng lập chỉ mục lại tất cả dữ liệu mà không ảnh hưởng đến các ứng dụng sản xuất của bạn.\n\nVị trí dàn dựng không được hiển thị công khai trong Explorer và có một URL duy nhất chỉ hiển thị cho bạn. Và tất nhiên, môi trường riêng biệt này cho phép bạn kiểm tra mã mới của mình mà không ảnh hưởng đến quá trình sản xuất.\n\n\n# Thông tin ngoại lai (extrinsics) là gì?\n\nNếu bạn đã quen thuộc với các khái niệm blockchain, bạn có thể nghĩ thông tin ngoại lai gần giống với các giao dịch. Tuy nhiên, về mặt chính thức, thông tin ngoại lai là một đoạn thông tin đến từ bên ngoài chuỗi và được bao gồm trong một block. Có ba loại thông tin ngoại lai. Bao gồm: thông tin cố hữu, giao dịch đã ký và giao dịch chưa ký.\n\nThông tin ngoại lai cố hữu là những phần thông tin không được ký và chỉ được thêm vào block bởi tác giả của block.\n\nGiao dịch ngoại lai có chữ ký là các giao dịch có chứa chữ ký của tài khoản thực hiện giao dịch. Họ phải trả một khoản phí để giao dịch được đưa vào chuỗi.\n\nCác giao dịch ngoại lai không có chữ ký là các giao dịch không có chữ ký của tài khoản đã thực hiện giao dịch. Các giao dịch ngoại lai chưa được ký kết nên sử dụng cẩn thận vì không ai trả phí, vì nó đã được ký. Vì thế, danh sách chờ giao dịch không có logic kinh tế để tránh bị spam.\n\nĐể biết thêm thông tin chi tiết, hãy nhấp vào đây.',normalizedContent:'# cac cau hoi thuong gap\n\n\n# subquery la gi?\n\nsubquery la mot du an ma nguon mo cho phep cac nha phat trien chay trinh lap chi muc, chuyen đoi va truy van du lieu tren chuoi substrate đe chay cac ung dung cua ho.\n\nsubquery cung cung cap dich vu luu tru mien phi, cong suat lon cho cac du an cua cac nha phat trien; trut bo trach nhiem cua cac nha san xuat trong viec quan ly co so ha tang nua, đe ho tap trung lam viec minh gioi nhat: lap trinh.\n\n\n# cach tot nhat đe bat đau su dung subquery la gi?\n\ncach tot nhat đe bat đau su dung subquery la thuc hien huong dan hello world cua chung toi. đay la mot huong dan 5 phut đon gian đe tai xuong mau khoi đong, xay dung du an va sau đo su dung docker đe chay mot nut tren may chu cuc bo cua ban va chay mot truy van đon gian.\n\n\n# lam cach nao đe toi co the đong gop hoac gui phan hoi cho subquery?\n\nchung toi rat tran trong nhung đong gop va phan hoi tu cong đong. đe đong gop ma, hay chia nho kho luu tru quan tam va thuc hien cac thay đoi cua ban. sau đo gui pr hoac pull request. o, đung quen kiem tra lai nhe! ban nen tham khao huong dan đong gop cua chung toi (tba/thong bao sau).\n\nđe gui phan hoi, hay lien he voi chung toi qua email hello@subquery.network hoac truy cap kenh discord cua chung toi\n\n\n# chi phi đe luu tru du an cua toi trong subquery projects la bao nhieu?\n\nban co the luu tru du an trong subquery projects hoan toan mien phi - đo la cach chung toi đong gop cho cong đong. đe tim hieu cach luu tru du an cua ban voi chung toi, vui long xem huong dan hello world (subquery hosted).\n\n\n# cac vi tri trien khai la gi?\n\nvi tri trien khai la mot tinh nang trong subquery projects gan giong voi moi truong phat trien. vi du, trong bat ky to chuc phan mem nao toi thieu đeu co moi truong phat trien va moi truong san xuat (khong tinh localhost). thong thuong, no bao gom cac moi truong bo sung nhu staging (dan dung) va pre-pod (tien san xuat) hoac tham chi la qa, tuy thuoc vao nhu cau cua to chuc va su phat trien cua chung đuoc thiet lap.\n\nsubquery hien co san hai vi tri. mot vi tri dan dung (staging slot) va mot vi tri san xuat (production slot). đieu nay cho phep cac nha phat trien trien khai subquery cua ho vao moi truong dan dung va đe moi thu dien ra tot đep, sau đo chon "thuc đay san xuat" chi bang mot nut bam.\n\n\n# uu điem cua vi tri dan dung la gi?\n\nloi ich chinh cua viec su dung vi tri dan dung la no cho phep ban chuan bi mot ban phat hanh moi cho du an subquery cua minh khong can cong khai. ban co the đoi vi tri dan dung lap chi muc lai tat ca du lieu ma khong anh huong đen cac ung dung san xuat cua ban.\n\nvi tri dan dung khong đuoc hien thi cong khai trong explorer va co mot url duy nhat chi hien thi cho ban. va tat nhien, moi truong rieng biet nay cho phep ban kiem tra ma moi cua minh ma khong anh huong đen qua trinh san xuat.\n\n\n# thong tin ngoai lai (extrinsics) la gi?\n\nneu ban đa quen thuoc voi cac khai niem blockchain, ban co the nghi thong tin ngoai lai gan giong voi cac giao dich. tuy nhien, ve mat chinh thuc, thong tin ngoai lai la mot đoan thong tin đen tu ben ngoai chuoi va đuoc bao gom trong mot block. co ba loai thong tin ngoai lai. bao gom: thong tin co huu, giao dich đa ky va giao dich chua ky.\n\nthong tin ngoai lai co huu la nhung phan thong tin khong đuoc ky va chi đuoc them vao block boi tac gia cua block.\n\ngiao dich ngoai lai co chu ky la cac giao dich co chua chu ky cua tai khoan thuc hien giao dich. ho phai tra mot khoan phi đe giao dich đuoc đua vao chuoi.\n\ncac giao dich ngoai lai khong co chu ky la cac giao dich khong co chu ky cua tai khoan đa thuc hien giao dich. cac giao dich ngoai lai chua đuoc ky ket nen su dung can than vi khong ai tra phi, vi no đa đuoc ky. vi the, danh sach cho giao dich khong co logic kinh te đe tranh bi spam.\n\nđe biet them thong tin chi tiet, hay nhap vao đay.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Chương trình Đại sứ SubQuery",frontmatter:{summary:"Chương trình Đại sứ SubQuery Chúng tôi hiểu rằng, một trong những thế mạnh lớn nhất của chúng tôi là cộng đồng, và với sự hỗ trợ của bạn, chúng tôi mong muốn xây dựng và phát triển",meta:[{property:"og:url",content:"/vi/miscellaneous/ambassadors.html"},{property:"og:title",content:"Chương trình Đại sứ SubQuery"},{property:"og:description",content:"Chương trình Đại sứ SubQuery Chúng tôi hiểu rằng, một trong những thế mạnh lớn nhất của chúng tôi là cộng đồng, và với sự hỗ trợ của bạn, chúng tôi mong muốn xây dựng và phát triển"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/miscellaneous/ambassadors.html",relativePath:"vi/miscellaneous/ambassadors.md",key:"v-8b57cb62",path:"/vi/miscellaneous/ambassadors/",headers:[{level:2,title:"Giá trị của chúng tôi",slug:"gia-tri-cua-chung-toi",normalizedTitle:"gia tri cua chung toi",charIndex:275},{level:2,title:"Chương trình Đại sứ của Chúng tôi",slug:"chuong-trinh-đai-su-cua-chung-toi",normalizedTitle:"chuong trinh đai su cua chung toi",charIndex:1586},{level:3,title:"Quyền lợi của Đại sứ",slug:"quyen-loi-cua-đai-su",normalizedTitle:"quyen loi cua đai su",charIndex:1994},{level:2,title:"Cách thực hoạt động của Chương trình",slug:"cach-thuc-hoat-đong-cua-chuong-trinh",normalizedTitle:"cach thuc hoat đong cua chuong trinh",charIndex:3409},{level:2,title:"Các Hoạt động của Đại sứ",slug:"cac-hoat-đong-cua-đai-su",normalizedTitle:"cac hoat đong cua đai su",charIndex:4422}],readingTime:{minutes:6.45,words:1935},headersStr:"Giá trị của chúng tôi Chương trình Đại sứ của Chúng tôi Quyền lợi của Đại sứ Cách thực hoạt động của Chương trình Các Hoạt động của Đại sứ",content:"# Chương trình Đại sứ SubQuery\n\n\n\nChúng tôi hiểu rằng, một trong những thế mạnh lớn nhất của chúng tôi là cộng đồng, và với sự hỗ trợ của bạn, chúng tôi mong muốn xây dựng và phát triển mạng lưới các đại sứ địa phương tại các cộng đồng trên toàn thế giới.\n\nĐăng ký Ngay!\n\n\n# Giá trị của chúng tôi\n\nNhóm chúng tôi đã cùng nhau hợp tác với tầm nhìn chung là xây dựng nền tảng dịch vụ dữ liệu linh hoạt và toàn diện cho hệ sinh thái Polkadot.\n\n** Xây dựng bởi các nhà phát triển, dành cho các nhà phát triển:** SubQuery là một cộng đồng đang phát triển tập trung vào việc cung cấp các sản phẩm và dịch vụ tốt nhất cho các nhà phát triển và xây dựng trong hệ sinh thái của chúng tôi. Thành công của SubQuery phụ thuộc vào sự thành công của hệ sinh thái Polkadot, vì vậy mọi thứ chúng tôi làm đều hướng đến khách hàng của mình.\n\nMinh bạch và Trách nhiệm: Chúng tôi có các thành viên trong nhóm ở Auckland, Thượng Hải và Sydney nên làm việc từ xa rất quan trọng. Chúng tôi mong rằng cả nhóm luôn có động lực cùng nhau làm việc một cách tự chủ, độc lập để đạt được mục tiêu. Nhiệm vụ quan trọng để đạt được điều này là cả nhóm phải tự chịu trách nhiệm và luôn minh bạch đối với các hoạt động của họ.\n\nHướng dẫn và Hỗ trợ Toàn diện: Blockchain là một lĩnh vực rất khó, và nhều khi mọi người cũng cần được hỗ trợ. Trong cộng đồng của chúng tôi, không có câu hỏi nào là ngu ngốc, tất cả mọi người trong nhóm đều có trách nhiệm hỗ trợ các người dùng. Chúng tôi biết được rất nhiều thông tin giá trị về dịch vụ (và cách chúng tôi có thể cải thiện dịch vụ) trực tiếp từ cộng đồng của chúng tôi.\n\n\n# Chương trình Đại sứ của Chúng tôi\n\nChương trình SubQuery Ambassador của chúng tôi nhằm mục đích tìm kiếm những nhà lãnh đạo cộng đồng có đam mê với Polkadot và SubQuery. Chúng tôi đang tìm kiếm những người có hoài bão, chủ động có thể lan toả giá trị của SubQuery trong cộng đồng của họ, và hỗ trợ các nhà phát triển mới muốn sử dụng SubQuery để xây dựng các ứng dụng và dịch vụ tuyệt vời trên Polkadot.\n\n\n# Quyền lợi của Đại sứ\n\nTại SubQuery, chúng tôi làm việc chăm chỉ để đạt được mục tiêu. Tương tự, các nhà Đại sứ cần phải đóng góp công sức khi gia nhập nhóm của chúng tôi, nhưng bạn sẽ được hưởng nhiều quyền lợi tương xứng.\n\nCác khản Trợ cấp và Hỗ trợ: Bạn có thể được thưởng do làm việc tốt và có cơ hội tham gia sớm vào các chương trình sale và bounty kín. Ngoài ra, chúng tôi sẽ cung cấp các khoản trợ cấp để bạn điều hành các buổi gặp mặt cộng đồng.\n\nQuyền truy cập vào nhóm SubQuery: Bạn sẽ có quyền truy cập trực tiếp vào core team của SubQuery và có cơ hội được đào tạo thực hành, tham gia AMA (giải đáp) độc quyền với các nhà lãnh đạo và nhà phát triển của chúng tôi, cũng như thông tin chi tiết về lộ trình phát triển của chúng tôi.\n\nPhát triển Mạng lưới: Bạn chắc chắn sẽ mở rộng mạng lưới chuyên nghiệp của mình khi trở thành Đại sứ của một trong những dự án hàng đầu của Polkadot. Gặp gỡ các đại sứ khác trên toàn thế giới và được giới thiệu về các dự án Polkadot khác mà chúng tôi cần sự hỗ trợ địa phương. Bạn còn được tham gia miễn phí để đại diện SubQuery trong các sự kiện ở khu vực của bạn.\n\n**Swag và Đồ miễn phí khác:**Ai cũng thích đồ miễn phí! Nhận được lượng SubQuery swag phân phối hàng năm và trở nên thật nổi bật giữa đám đông. Bên cạnh đó là lượng phân phối khác bạn có thể chia sẻ tại các hoạt động cộng đồng. Bạn cũng sẽ nhận được một NFT độc quyền cho trong vai trò Đại sứ của bạn.\n\n\n# Cách thực hoạt động của Chương trình\n\nChương trình Đại sứ của chúng tôi có nhiều cấp, mỗi cấp có những lợi ích và năng lực khác nhau. Bạn có thể thăng hạng bằng cách tham gia các hoạt động của Đại sứ và làm việc chăm chỉ.\n\nSau khi bạn gửi đơn đăng ký, chúng tôi sẽ chọn những ứng viên phù hợp với giá trị của chúng tôi. Nếu được chọn, bạn sẽ được tham gia chương trình đào tạo của chúng tôi và nhận tài liệu tham khảo để mở rộng hiểu biết của bạn về SubQuery. Sau đó, bạn có thể bắt đầu làm việc thông qua chương trình đào tạo bằng cách hoàn thành một số nhiệm vụ làm quen công việc (ví dụ: tạo SubQuery Project). Chúng tôi sẽ tổ chức các workshop trong suốt quá trình này để hỗ trợ bạn.\n\nSau khi hoàn thành chương trình đào tạo, bạn có thể tự gọi mình là Đại sứ SubQuery và sẽ được tham gia vào chương trình đầy đủ của chúng tôi. Từ đây trở đi, bạn có thể tiếp tục công việc thông qua chương trình đại sứ và thăng hạng dần dần, kiếm thêm nhiều phần thưởng và quyền lợi với mỗi lần thăng hạng.\n\nĐăng ký Ngay!\n\n\n# Các Hoạt động của Đại sứ\n\nĐại sứ SubQuery có thể đóng góp qua bốn lĩnh vực chính, bao gồm quản lý sự kiện, sáng tạo nội dung, dịch thuật và kiểm duyệt cộng đồng. Bạn có thể tham gia nhiều lĩnh vực tùy thích, không bị ràng buộc vào bất kỳ lĩnh vực nào.\n\nQuản lý sự kiện: Xây dựng các cộng đồng địa phương bằng cách tổ chức và quản lý các sự kiện khác nhau. Xây dựng cộng đồng tại địa phương là một phần rất quan trọng trong việc phát triển cộng đồng SubQuery. SubQuery sẽ hỗ trợ bạn bằng cách cung cấp tài chính cho các sự kiện, gửi swag/quà tặng để tặng tại các sự kiện, và tham dự các sự kiện Hỏi đáp Q&A, các sự kiện trực tuyến với tư cách là diễn giả hoặc tham dự các buổi Chia sẻ AMA.\n\nSáng tạo Nội dung: Chúng tôi có một danh sách dài các nội dung và tài liệu tham khảo cần được tạo. Xin nhớ rằng, thành công của chúng tôi dựa vào khả năng xây dựng những điều tuyệt vời của khách hàng dựa trên nền tảng dịch vụ của chúng tôi, vì vậy chúng tôi cần sự giúp đỡ của bạn để thực hiện điều đó dễ dàng hơn. Các nội dung bao gồm video, infographics, hướng dẫn, animation hoặc bất kỳ tài liệu liên quan nào khác, để giúp thông báo, cung cấp kiến thức hoặc truyền cảm hứng cho các thành viên trong cộng đồng Hệ sinh thái SubQuery. SubQuery sẽ hỗ trợ các Nhà Sáng tạo Nội dung bằng cách cung cấp các tài sản thương hiệu và kiến thức chuyên môn. Chúng tôi cũng sẽ sử dụng các kênh quảng cáo của SubQuery để tăng sự biết đến rộng rãi cho nội dung của bạn (và cả bạn nữa).\n\nDịch thuật Khách hàng của chúng tôi không chỉ nói tiếng Anh! Chúng tôi cần sự trợ giúp của bạn để khiến SubQuery trở nên dễ tiếp cận hơn bằng cách dịch nội dung của chúng tôi sang ngôn ngữ của bạn, cũng như giúp chia sẻ SubQuery với cộng đồng quốc tế.\n\nKiểm duyệt cộng đồng: Người kiểm duyệt sẽ giúp phát triển cộng đồng SubQuery bằng cách đảm bảo rằng các kênh cộng đồng chính thức hoạt động tích cực và thu hút. SubQuery sẽ hỗ trợ Người kiểm duyệt bằng cách quảng cáo các kênh mà họ giám sát, và cung cấp các danh sách các kỳ vọng của chúng tôi.\n\nĐăng ký Ngay!",normalizedContent:"# chuong trinh đai su subquery\n\n\n\nchung toi hieu rang, mot trong nhung the manh lon nhat cua chung toi la cong đong, va voi su ho tro cua ban, chung toi mong muon xay dung va phat trien mang luoi cac đai su đia phuong tai cac cong đong tren toan the gioi.\n\nđang ky ngay!\n\n\n# gia tri cua chung toi\n\nnhom chung toi đa cung nhau hop tac voi tam nhin chung la xay dung nen tang dich vu du lieu linh hoat va toan dien cho he sinh thai polkadot.\n\n** xay dung boi cac nha phat trien, danh cho cac nha phat trien:** subquery la mot cong đong đang phat trien tap trung vao viec cung cap cac san pham va dich vu tot nhat cho cac nha phat trien va xay dung trong he sinh thai cua chung toi. thanh cong cua subquery phu thuoc vao su thanh cong cua he sinh thai polkadot, vi vay moi thu chung toi lam đeu huong đen khach hang cua minh.\n\nminh bach va trach nhiem: chung toi co cac thanh vien trong nhom o auckland, thuong hai va sydney nen lam viec tu xa rat quan trong. chung toi mong rang ca nhom luon co đong luc cung nhau lam viec mot cach tu chu, đoc lap đe đat đuoc muc tieu. nhiem vu quan trong đe đat đuoc đieu nay la ca nhom phai tu chiu trach nhiem va luon minh bach đoi voi cac hoat đong cua ho.\n\nhuong dan va ho tro toan dien: blockchain la mot linh vuc rat kho, va nheu khi moi nguoi cung can đuoc ho tro. trong cong đong cua chung toi, khong co cau hoi nao la ngu ngoc, tat ca moi nguoi trong nhom đeu co trach nhiem ho tro cac nguoi dung. chung toi biet đuoc rat nhieu thong tin gia tri ve dich vu (va cach chung toi co the cai thien dich vu) truc tiep tu cong đong cua chung toi.\n\n\n# chuong trinh đai su cua chung toi\n\nchuong trinh subquery ambassador cua chung toi nham muc đich tim kiem nhung nha lanh đao cong đong co đam me voi polkadot va subquery. chung toi đang tim kiem nhung nguoi co hoai bao, chu đong co the lan toa gia tri cua subquery trong cong đong cua ho, va ho tro cac nha phat trien moi muon su dung subquery đe xay dung cac ung dung va dich vu tuyet voi tren polkadot.\n\n\n# quyen loi cua đai su\n\ntai subquery, chung toi lam viec cham chi đe đat đuoc muc tieu. tuong tu, cac nha đai su can phai đong gop cong suc khi gia nhap nhom cua chung toi, nhung ban se đuoc huong nhieu quyen loi tuong xung.\n\ncac khan tro cap va ho tro: ban co the đuoc thuong do lam viec tot va co co hoi tham gia som vao cac chuong trinh sale va bounty kin. ngoai ra, chung toi se cung cap cac khoan tro cap đe ban đieu hanh cac buoi gap mat cong đong.\n\nquyen truy cap vao nhom subquery: ban se co quyen truy cap truc tiep vao core team cua subquery va co co hoi đuoc đao tao thuc hanh, tham gia ama (giai đap) đoc quyen voi cac nha lanh đao va nha phat trien cua chung toi, cung nhu thong tin chi tiet ve lo trinh phat trien cua chung toi.\n\nphat trien mang luoi: ban chac chan se mo rong mang luoi chuyen nghiep cua minh khi tro thanh đai su cua mot trong nhung du an hang đau cua polkadot. gap go cac đai su khac tren toan the gioi va đuoc gioi thieu ve cac du an polkadot khac ma chung toi can su ho tro đia phuong. ban con đuoc tham gia mien phi đe đai dien subquery trong cac su kien o khu vuc cua ban.\n\n**swag va đo mien phi khac:**ai cung thich đo mien phi! nhan đuoc luong subquery swag phan phoi hang nam va tro nen that noi bat giua đam đong. ben canh đo la luong phan phoi khac ban co the chia se tai cac hoat đong cong đong. ban cung se nhan đuoc mot nft đoc quyen cho trong vai tro đai su cua ban.\n\n\n# cach thuc hoat đong cua chuong trinh\n\nchuong trinh đai su cua chung toi co nhieu cap, moi cap co nhung loi ich va nang luc khac nhau. ban co the thang hang bang cach tham gia cac hoat đong cua đai su va lam viec cham chi.\n\nsau khi ban gui đon đang ky, chung toi se chon nhung ung vien phu hop voi gia tri cua chung toi. neu đuoc chon, ban se đuoc tham gia chuong trinh đao tao cua chung toi va nhan tai lieu tham khao đe mo rong hieu biet cua ban ve subquery. sau đo, ban co the bat đau lam viec thong qua chuong trinh đao tao bang cach hoan thanh mot so nhiem vu lam quen cong viec (vi du: tao subquery project). chung toi se to chuc cac workshop trong suot qua trinh nay đe ho tro ban.\n\nsau khi hoan thanh chuong trinh đao tao, ban co the tu goi minh la đai su subquery va se đuoc tham gia vao chuong trinh đay đu cua chung toi. tu đay tro đi, ban co the tiep tuc cong viec thong qua chuong trinh đai su va thang hang dan dan, kiem them nhieu phan thuong va quyen loi voi moi lan thang hang.\n\nđang ky ngay!\n\n\n# cac hoat đong cua đai su\n\nđai su subquery co the đong gop qua bon linh vuc chinh, bao gom quan ly su kien, sang tao noi dung, dich thuat va kiem duyet cong đong. ban co the tham gia nhieu linh vuc tuy thich, khong bi rang buoc vao bat ky linh vuc nao.\n\nquan ly su kien: xay dung cac cong đong đia phuong bang cach to chuc va quan ly cac su kien khac nhau. xay dung cong đong tai đia phuong la mot phan rat quan trong trong viec phat trien cong đong subquery. subquery se ho tro ban bang cach cung cap tai chinh cho cac su kien, gui swag/qua tang đe tang tai cac su kien, va tham du cac su kien hoi đap q&a, cac su kien truc tuyen voi tu cach la dien gia hoac tham du cac buoi chia se ama.\n\nsang tao noi dung: chung toi co mot danh sach dai cac noi dung va tai lieu tham khao can đuoc tao. xin nho rang, thanh cong cua chung toi dua vao kha nang xay dung nhung đieu tuyet voi cua khach hang dua tren nen tang dich vu cua chung toi, vi vay chung toi can su giup đo cua ban đe thuc hien đieu đo de dang hon. cac noi dung bao gom video, infographics, huong dan, animation hoac bat ky tai lieu lien quan nao khac, đe giup thong bao, cung cap kien thuc hoac truyen cam hung cho cac thanh vien trong cong đong he sinh thai subquery. subquery se ho tro cac nha sang tao noi dung bang cach cung cap cac tai san thuong hieu va kien thuc chuyen mon. chung toi cung se su dung cac kenh quang cao cua subquery đe tang su biet đen rong rai cho noi dung cua ban (va ca ban nua).\n\ndich thuat khach hang cua chung toi khong chi noi tieng anh! chung toi can su tro giup cua ban đe khien subquery tro nen de tiep can hon bang cach dich noi dung cua chung toi sang ngon ngu cua ban, cung nhu giup chia se subquery voi cong đong quoc te.\n\nkiem duyet cong đong: nguoi kiem duyet se giup phat trien cong đong subquery bang cach đam bao rang cac kenh cong đong chinh thuc hoat đong tich cuc va thu hut. subquery se ho tro nguoi kiem duyet bang cach quang cao cac kenh ma ho giam sat, va cung cap cac danh sach cac ky vong cua chung toi.\n\nđang ky ngay!",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Vật liệu xây dựng thương hiệu",frontmatter:{summary:"Vật liệu xây dựng thương hiệu Tất cả các đặc điểm thương hiệu của SubQuery là độc quyền và chúng tôi rất coi trọng thương hiệu của mình. Nếu bạn chọn sử dụng bất kỳ nhãn hiệu, biểu",meta:[{property:"og:url",content:"/vi/miscellaneous/branding.html"},{property:"og:title",content:"Vật liệu xây dựng thương hiệu"},{property:"og:description",content:"Vật liệu xây dựng thương hiệu Tất cả các đặc điểm thương hiệu của SubQuery là độc quyền và chúng tôi rất coi trọng thương hiệu của mình. Nếu bạn chọn sử dụng bất kỳ nhãn hiệu, biểu"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/miscellaneous/branding.html",relativePath:"vi/miscellaneous/branding.md",key:"v-3795786d",path:"/vi/miscellaneous/branding/",headers:[{level:2,title:"Tệp Figma có thể xuất",slug:"tep-figma-co-the-xuat",normalizedTitle:"tep figma co the xuat",charIndex:416},{level:2,title:"Gói tài sản thương hiệu",slug:"goi-tai-san-thuong-hieu",normalizedTitle:"goi tai san thuong hieu",charIndex:623}],readingTime:{minutes:.76,words:227},headersStr:"Tệp Figma có thể xuất Gói tài sản thương hiệu",content:"# Vật liệu xây dựng thương hiệu\n\nTất cả các đặc điểm thương hiệu của SubQuery là độc quyền và chúng tôi rất coi trọng thương hiệu của mình.\n\nNếu bạn chọn sử dụng bất kỳ nhãn hiệu, biểu tượng, thiết kế hoặc đặc điểm nhãn hiệu nào khác, vui lòng thực hiện nghiêm túc các hướng dẫn tại đây hoặc liên hệ với chúng tôi qua phương tiện truyền thông xã hội để được giải thích rõ.\n\nNếu có thắc mắc, xin hãy đặt câu hỏi!\n\n\n# Tệp Figma có thể xuất\n\nTệp Figma của chúng tôi có một bộ sưu tập đầy đủ tất cả các tài sản thương hiệu (biểu trưng, phông chữ, màu sắc, hình ảnh, v. v.) để xuất.\n\nFigma - Tài nguyên thương hiệu SubQuery\n\n\n# Gói tài sản thương hiệu\n\nMột gói tài sản thương hiệu ZIP nhỏ hơn\n\npublic_branding.zip",normalizedContent:"# vat lieu xay dung thuong hieu\n\ntat ca cac đac điem thuong hieu cua subquery la đoc quyen va chung toi rat coi trong thuong hieu cua minh.\n\nneu ban chon su dung bat ky nhan hieu, bieu tuong, thiet ke hoac đac điem nhan hieu nao khac, vui long thuc hien nghiem tuc cac huong dan tai đay hoac lien he voi chung toi qua phuong tien truyen thong xa hoi đe đuoc giai thich ro.\n\nneu co thac mac, xin hay đat cau hoi!\n\n\n# tep figma co the xuat\n\ntep figma cua chung toi co mot bo suu tap đay đu tat ca cac tai san thuong hieu (bieu trung, phong chu, mau sac, hinh anh, v. v.) đe xuat.\n\nfigma - tai nguyen thuong hieu subquery\n\n\n# goi tai san thuong hieu\n\nmot goi tai san thuong hieu zip nho hon\n\npublic_branding.zip",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Đóng góp cho SubQuery",frontmatter:{summary:'Đóng góp cho SubQuery Chào mừng và cảm ơn bạn đã cân nhắc đóng góp cho dự án SubQuery! Cùng nhau, chúng ta có thể mở ra một tương lai phi tập trung hơn. " Tài liệu này được duy trì',meta:[{property:"og:url",content:"/vi/miscellaneous/contributing.html"},{property:"og:title",content:"Đóng góp cho SubQuery"},{property:"og:description",content:'Đóng góp cho SubQuery Chào mừng và cảm ơn bạn đã cân nhắc đóng góp cho dự án SubQuery! Cùng nhau, chúng ta có thể mở ra một tương lai phi tập trung hơn. " Tài liệu này được duy trì'},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/miscellaneous/contributing.html",relativePath:"vi/miscellaneous/contributing.md",key:"v-fbfd20e6",path:"/vi/miscellaneous/contributing/",headers:[{level:2,title:"Quy tắc ứng xử",slug:"quy-tac-ung-xu",normalizedTitle:"quy tac ung xu",charIndex:917},{level:2,title:"Bắt đầu",slug:"bat-đau",normalizedTitle:"bat đau",charIndex:1191},{level:2,title:"Cách đóng góp",slug:"cach-đong-gop",normalizedTitle:"cach đong gop",charIndex:1720},{level:3,title:"Báo cáo lỗi",slug:"bao-cao-loi",normalizedTitle:"bao cao loi",charIndex:1738},{level:3,title:"Gửi yêu cầu kéo",slug:"gui-yeu-cau-keo",normalizedTitle:"gui yeu cau keo",charIndex:2182},{level:2,title:"Quy ước mã hóa",slug:"quy-uoc-ma-hoa",normalizedTitle:"quy uoc ma hoa",charIndex:2629},{level:3,title:"Thông báo cam kết Git",slug:"thong-bao-cam-ket-git",normalizedTitle:"thong bao cam ket git",charIndex:2648},{level:3,title:"Hướng dẫn định kiểu JavaScript",slug:"huong-dan-đinh-kieu-javascript",normalizedTitle:"huong dan đinh kieu javascript",charIndex:2908}],readingTime:{minutes:2.93,words:879},headersStr:"Quy tắc ứng xử Bắt đầu Cách đóng góp Báo cáo lỗi Gửi yêu cầu kéo Quy ước mã hóa Thông báo cam kết Git Hướng dẫn định kiểu JavaScript",content:'# Đóng góp cho SubQuery\n\nChào mừng và cảm ơn bạn đã cân nhắc đóng góp cho dự án SubQuery! Cùng nhau, chúng ta có thể mở ra một tương lai phi tập trung hơn.\n\n> Tài liệu này được duy trì tích cực bởi nhóm SubQuery. Chúng tôi hoan nghênh những đóng góp của bạn, bạn có thể làm như vậy bằng cách tạo ra dự án GitHub của chúng tôi và thực hiện các thay đổi đối với tất cả các tệp đánh dấu tài liệu trong danh mục docs.\n\nSau đây là một tập hợp các nguyên tắc (không phải quy tắc) trong việc đóng góp vào SubQuery. Việc tuân theo các nguyên tắc này sẽ giúp chúng tôi thực hiện quá trình đóng góp dễ dàng và hiệu quả cho người tham gia. Nó có mang nghĩa rằng bạn đồng ý tôn trọng thời gian của các nhà phát triển quản lý và phát triển dự án này. Đổi lại, chúng tôi sẽ đáp lại sự tôn trọng đó bằng cách giải quyết vấn đề của bạn, xem xét các thay đổi, cộng tác để cải tiến và giúp bạn hoàn thiện các yêu cầu kéo của mình.\n\n\n# Quy tắc ứng xử\n\nChúng tôi coi trọng các dự án và trách nhiệm cộng đồng nguồn mở của mình, đồng thời tuân theo các tiêu chuẩn cao về giao tiếp cùng những người đóng góp khác. Bằng cách tham gia và đóng góp vào dự án này, bạn đồng ý tuân thủ Quy tắc ứng xử của chúng tôi.\n\n\n# Bắt đầu\n\nCác khoản đóng góp cho kho lưu trữ của chúng tôi được thực hiện thông qua Sự cố và Yêu cầu kéo (PR). Một số nguyên tắc chung bao gồm cả hai:\n\n * Tìm kiếm các Vấn đề và PR hiện có trước khi tự làm.\n * Chúng tôi làm việc chăm chỉ để đảm bảo các vấn đề được xử lý kịp thời nhưng có thể mất một khoảng thời gian để điều tra nguyên nhân gốc rễ tùy thuộc vào mức độ ảnh hưởng,. Đề cập @ thiện chí trong chuỗi bình luận dưới bài viết của người gửi hoặc người đóng góp giúp thu hút sự chú ý nếu vấn đề của bạn đang bị chặn.\n\n\n# Cách đóng góp\n\n\n# Báo cáo lỗi\n\nLỗi được theo dõi là sự cố GitHub. Khi ghi nhật ký sự cố, hãy giải thích sự cố và bao gồm các chi tiết bổ sung để giúp người bảo trì tái tạo sự cố:\n\n * Sử dụng tiêu đề rõ ràng và mang tính mô tả cho vấn đề để xác định vấn đề.\n * Mô tả các bước chính xác để tái tạo vấn đề.\n * Mô tả hành vi bạn đã quan sát được sau khi làm theo các bước.\n * Giải thích hành vi nào bạn muốn thấy và tại sao.\n * Bao gồm ảnh chụp màn hình nếu có.\n\n\n# Gửi yêu cầu kéo\n\nNói chung, chúng tôi tuân theo quy trình làm việc Git "fork-and-pull"\n\n * Chuyển kho lưu trữ vào tài khoản Github của riêng bạn\n * Sao chép dự án vào máy của bạn\n * Tạo một nhánh cục bộ với tên ngắn gọn nhưng mô tả đầy đủ\n * Cam kết các thay đổi đối với chi nhánh\n * Tuân theo mọi nguyên tắc định dạng và kiểm tra cụ thể cho repo này\n * Đẩy các thay đổi đối với ngã ba của bạn\n * Mở một bài PR trong kho lưu trữ của chúng tôi\n\n\n# Quy ước mã hóa\n\n\n# Thông báo cam kết Git\n\n * Sử dụng thì hiện tại ("Thêm tính năng" không phải "Đã thêm tính năng")\n * Sử dụng tâm trạng bắt buộc ("Di chuyển con trỏ tới ..." chứ không phải "Di chuyển con trỏ tới ...")\n * Giới hạn dòng đầu tiên trong vòng 72 ký tự trở xuống\n\n\n# Hướng dẫn định kiểu JavaScript\n\n * Tất cả mã JavaScript được in bằng Prettier và ESLint',normalizedContent:'# đong gop cho subquery\n\nchao mung va cam on ban đa can nhac đong gop cho du an subquery! cung nhau, chung ta co the mo ra mot tuong lai phi tap trung hon.\n\n> tai lieu nay đuoc duy tri tich cuc boi nhom subquery. chung toi hoan nghenh nhung đong gop cua ban, ban co the lam nhu vay bang cach tao ra du an github cua chung toi va thuc hien cac thay đoi đoi voi tat ca cac tep đanh dau tai lieu trong danh muc docs.\n\nsau đay la mot tap hop cac nguyen tac (khong phai quy tac) trong viec đong gop vao subquery. viec tuan theo cac nguyen tac nay se giup chung toi thuc hien qua trinh đong gop de dang va hieu qua cho nguoi tham gia. no co mang nghia rang ban đong y ton trong thoi gian cua cac nha phat trien quan ly va phat trien du an nay. đoi lai, chung toi se đap lai su ton trong đo bang cach giai quyet van đe cua ban, xem xet cac thay đoi, cong tac đe cai tien va giup ban hoan thien cac yeu cau keo cua minh.\n\n\n# quy tac ung xu\n\nchung toi coi trong cac du an va trach nhiem cong đong nguon mo cua minh, đong thoi tuan theo cac tieu chuan cao ve giao tiep cung nhung nguoi đong gop khac. bang cach tham gia va đong gop vao du an nay, ban đong y tuan thu quy tac ung xu cua chung toi.\n\n\n# bat đau\n\ncac khoan đong gop cho kho luu tru cua chung toi đuoc thuc hien thong qua su co va yeu cau keo (pr). mot so nguyen tac chung bao gom ca hai:\n\n * tim kiem cac van đe va pr hien co truoc khi tu lam.\n * chung toi lam viec cham chi đe đam bao cac van đe đuoc xu ly kip thoi nhung co the mat mot khoang thoi gian đe đieu tra nguyen nhan goc re tuy thuoc vao muc đo anh huong,. đe cap @ thien chi trong chuoi binh luan duoi bai viet cua nguoi gui hoac nguoi đong gop giup thu hut su chu y neu van đe cua ban đang bi chan.\n\n\n# cach đong gop\n\n\n# bao cao loi\n\nloi đuoc theo doi la su co github. khi ghi nhat ky su co, hay giai thich su co va bao gom cac chi tiet bo sung đe giup nguoi bao tri tai tao su co:\n\n * su dung tieu đe ro rang va mang tinh mo ta cho van đe đe xac đinh van đe.\n * mo ta cac buoc chinh xac đe tai tao van đe.\n * mo ta hanh vi ban đa quan sat đuoc sau khi lam theo cac buoc.\n * giai thich hanh vi nao ban muon thay va tai sao.\n * bao gom anh chup man hinh neu co.\n\n\n# gui yeu cau keo\n\nnoi chung, chung toi tuan theo quy trinh lam viec git "fork-and-pull"\n\n * chuyen kho luu tru vao tai khoan github cua rieng ban\n * sao chep du an vao may cua ban\n * tao mot nhanh cuc bo voi ten ngan gon nhung mo ta đay đu\n * cam ket cac thay đoi đoi voi chi nhanh\n * tuan theo moi nguyen tac đinh dang va kiem tra cu the cho repo nay\n * đay cac thay đoi đoi voi nga ba cua ban\n * mo mot bai pr trong kho luu tru cua chung toi\n\n\n# quy uoc ma hoa\n\n\n# thong bao cam ket git\n\n * su dung thi hien tai ("them tinh nang" khong phai "đa them tinh nang")\n * su dung tam trang bat buoc ("di chuyen con tro toi ..." chu khong phai "di chuyen con tro toi ...")\n * gioi han dong đau tien trong vong 72 ky tu tro xuong\n\n\n# huong dan đinh kieu javascript\n\n * tat ca ma javascript đuoc in bang prettier va eslint',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Liên kết truyền thông xã hội",frontmatter:{summary:"Liên kết truyền thông xã hội SubQuery là một dự án đang hoạt động nhằm duy trì và giao tiếp với những người theo dõi qua nhiều kênh truyền thông xã hội. Mục đích của chúng tôi là l",meta:[{property:"og:url",content:"/vi/miscellaneous/social_media.html"},{property:"og:title",content:"Liên kết truyền thông xã hội"},{property:"og:description",content:"Liên kết truyền thông xã hội SubQuery là một dự án đang hoạt động nhằm duy trì và giao tiếp với những người theo dõi qua nhiều kênh truyền thông xã hội. Mục đích của chúng tôi là l"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/miscellaneous/social_media.html",relativePath:"vi/miscellaneous/social_media.md",key:"v-1809da8d",path:"/vi/miscellaneous/social_media/",headers:[{level:2,title:"Cộng đồng SubQuery chính thức",slug:"cong-đong-subquery-chinh-thuc",normalizedTitle:"cong đong subquery chinh thuc",charIndex:333},{level:2,title:"Cộng đồng SubQuery không chính thức",slug:"cong-đong-subquery-khong-chinh-thuc",normalizedTitle:"cong đong subquery khong chinh thuc",charIndex:569}],readingTime:{minutes:.84,words:253},headersStr:"Cộng đồng SubQuery chính thức Cộng đồng SubQuery không chính thức",content:"# Liên kết truyền thông xã hội\n\nSubQuery là một dự án đang hoạt động nhằm duy trì và giao tiếp với những người theo dõi qua nhiều kênh truyền thông xã hội.\n\nMục đích của chúng tôi là lắng nghe và tương tác với cộng đồng trung thành của mình, vì vậy hãy tham gia cuộc trò chuyện và gửi cho chúng tôi ý tưởng hoặc câu hỏi của bạn!\n\n\n# Cộng đồng SubQuery chính thức\n\n * Discord (Cộng đồng chính với các kênh hỗ trợ kỹ thuật chuyên dụng)\n * Medium (Kênh thông báo chính)\n * Twitter\n * WeChat\n * Telegram (Chỉ kênh thông báo)\n * GitHub\n * Ma trận / Bạo loạn\n * LinkedIn\n\n\n# Cộng đồng SubQuery không chính thức\n\nNhững cộng đồng này không được kiểm duyệt bởi nhóm SubQuery, nhưng sẽ được hỗ trợ bởi các đại sứ của chúng tôi. Hãy cẩn thận với các trò gian lận vì SubQuery ** không ** chịu trách nhiệm về những gì xảy ra bên trong.",normalizedContent:"# lien ket truyen thong xa hoi\n\nsubquery la mot du an đang hoat đong nham duy tri va giao tiep voi nhung nguoi theo doi qua nhieu kenh truyen thong xa hoi.\n\nmuc đich cua chung toi la lang nghe va tuong tac voi cong đong trung thanh cua minh, vi vay hay tham gia cuoc tro chuyen va gui cho chung toi y tuong hoac cau hoi cua ban!\n\n\n# cong đong subquery chinh thuc\n\n * discord (cong đong chinh voi cac kenh ho tro ky thuat chuyen dung)\n * medium (kenh thong bao chinh)\n * twitter\n * wechat\n * telegram (chi kenh thong bao)\n * github\n * ma tran / bao loan\n * linkedin\n\n\n# cong đong subquery khong chinh thuc\n\nnhung cong đong nay khong đuoc kiem duyet boi nhom subquery, nhung se đuoc ho tro boi cac đai su cua chung toi. hay can than voi cac tro gian lan vi subquery ** khong ** chiu trach nhiem ve nhung gi xay ra ben trong.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Xuất bản Dự Án SubQuery của bạn",frontmatter:{summary:"Xuất bản Dự Án SubQuery của bạn Các lợi ích của việc hosting dự án của bạn bằng SubQuery Chúng tôi sẽ chạy các dự án SubQuery của bạn trong một dịch vụ công được quản lý có hiệu su",meta:[{property:"og:url",content:"/vi/publish/publish.html"},{property:"og:title",content:"Xuất bản Dự Án SubQuery của bạn"},{property:"og:description",content:"Xuất bản Dự Án SubQuery của bạn Các lợi ích của việc hosting dự án của bạn bằng SubQuery Chúng tôi sẽ chạy các dự án SubQuery của bạn trong một dịch vụ công được quản lý có hiệu su"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/publish/publish.html",relativePath:"vi/publish/publish.md",key:"v-fb63c69a",path:"/vi/publish/publish/",headers:[{level:2,title:"Các lợi ích của việc hosting dự án của bạn bằng SubQuery",slug:"cac-loi-ich-cua-viec-hosting-du-an-cua-ban-bang-subquery",normalizedTitle:"cac loi ich cua viec hosting du an cua ban bang subquery",charIndex:38},{level:2,title:"Tạo Dự Án Đầu Tiên",slug:"tao-du-an-đau-tien",normalizedTitle:"tao du an đau tien",charIndex:565},{level:2,title:"Các Bước Tiếp Theo - Kết nối đến Dự Án của bạn",slug:"cac-buoc-tiep-theo-ket-noi-đen-du-an-cua-ban",normalizedTitle:"cac buoc tiep theo - ket noi đen du an cua ban",charIndex:4072},{level:2,title:"Thêm Tài Khoản GitHub Organization vào các Dự Án SubQuery",slug:"them-tai-khoan-github-organization-vao-cac-du-an-subquery",normalizedTitle:"them tai khoan github organization vao cac du an subquery",charIndex:4554}],readingTime:{minutes:6.88,words:2064},headersStr:"Các lợi ích của việc hosting dự án của bạn bằng SubQuery Tạo Dự Án Đầu Tiên Các Bước Tiếp Theo - Kết nối đến Dự Án của bạn Thêm Tài Khoản GitHub Organization vào các Dự Án SubQuery",content:'# Xuất bản Dự Án SubQuery của bạn\n\n\n# Các lợi ích của việc hosting dự án của bạn bằng SubQuery\n\n * Chúng tôi sẽ chạy các dự án SubQuery của bạn trong một dịch vụ công được quản lý có hiệu suất cao, có thể mở rộng\n * Dịch vụ này đang được cung cấp đến cộng đồng miễn phí!\n * Bạn có thể tạo ra các dự án công khai do đó chúng sẽ được liệt kê trong SubQuery Explorer và bất cứ ai trên khắp thế giới cũng đều có thể xem chúng\n * Chúng tôi được tích hợp với GitHub, vì thế bất kỳ ai trong các tổ chức GitHub của bạn cũng sẽ xem được các dự án đã chia sẻ của tổ chức\n\n\n# Tạo Dự Án Đầu Tiên\n\n# Đăng nhập vào Các Dự Án SubQuery\n\nTrước khi bắt đầu, vui lòng đảm bảo rằng dự án SubQuery của bạn trực tuyến trong kho lưu trữ GitHub công khai. Tệp tin schema.graphql phải được nằm trong thư mục gốc của bạn.\n\nĐể tạo ra dự án đầu tiên, hãy đến project.subquery.network. Bạn sẽ cần xác thực tài khoản GitHub của mình để đăng nhập.\n\nTrong lần đăng nhập đầu tiên, bạn sẽ được yêu cầu cấp quyền cho SubQuery. Chúng tôi chỉ cần địa chỉ email của bạn để định dạnh tài khoản của bạn, và chúng tôi không sử dụng bất kỳ dữ liệu nào từ tài khoản GitHub của bạn vì bất kỳ lý do gì. Trong bước này, bạn cũng có thể yêu cầu cấp quyền truy cập đến tài khoản GitHub Organization của bạn để đăng các dự án SubQuery dưới GitHub Organization của mình thay vì tài khoản cá nhân.\n\n\n\nSubQuery Projects là nơi bạn quản lý tất cả các dự án của bạn đã được tải lên nền tảng SubQuery. Bạn có thể tạo, xóa, và thậm chí nâng cấp các dự án từ ứng dụng này.\n\n\n\nNếu bạn có kết nối các tài khoản GitHub Organization, bạn có thể sử dụng tính năng chuyển đổi ở đầu trang để thay đổi giữa tài khoản cá nhân và tài khoản GitHub Organization. Các dự án được tạo ra trong tài khoản GitHub Organization đều được chia sẻ giữa các thành viên trong GitHub Organization đó. Để kết nối tài khoản GitHub Organization của bạn, bạn có thể làm theo các bước tại đây.\n\n\n\n# Tạo Dữ Án Đầu Tiên của bạn\n\nChúng ta hãy bắt đầu bằng cách nhấp vào "Create Project". Bạn sẽ được đưa đến biểu mẫu Dự Án Mới. Vui lòng nhập vào những thứ sau đây (bạn có thể thay đổi trong tương lai):\n\n * Tài khoản GitHub: Nếu bạn có nhiều hơn một tài khoản GitHub, hãy chọn ra tài khoản mà dự án này được tạo ra bên dưới. Các dự án được tạo ra trong tài khoản GitHub Organization đều được chia sẻ giữa các thành viên trong cùng tổ chức.\n * Tên\n * Phụ đề\n * Mô tả\n * URL Kho Lưu Trữ GitHub: Đây phải là một URL GitHub hợp lệ chỉ đến kho lưu trữ công khai có chứa dự án SubQuery của bạn. Tập tin schema.graphql phải nằm trong thư mục gốc của bạn (tìm hiểu thêm về cấu trúc thư mục gốc).\n * Ẩn dự án: Nếu được chọn, tính năng này sẽ ẩn dự án khỏi SubQuery Explorer công khai. Bỏ trống không chọn nếu bạn muốn chia sẻ SubQuery của mình với cộng đồng!\n\nHãy tạo dự án cho riêng mình và bạn sẽ thấy nó trong danh sách Các Dự Án SubQuery của bạn. _Chúng ta sắp xong rồi! Chúng ta chỉ cần thực thi một phiên bản mới của nó. _\n\n# Thực thi Phiên Bản đầu tiên của bạn\n\nTrong khi đang khởi tạo, dự án sẽ thiết lập hành vi hiển thị của nó, bạn phải triển khai một phiên bản của nó trước khi dự án đi vào vận hành. Triển khai một phiên bản sẽ kích hoạt khởi động lập chỉ mục SubQuery mới để bắt đầu, và cài đặt dịch vụ query bắt buộc để chấp nhận các yêu cầu từ GraphQl. Bạn cũng có thể triển khai các phiên bản mới đối với các dự án hiện tại tại đây.\n\nCùng với dự án mới của mình, bạn sẽ thấy một nút bấm Deploy New Version. Nhấp vào nút này, và điền vào các thông tin bắt buộc để thực hiện triển khai:\n\n * Commit Hash của Phiên Bản mới: Từ GitHub, sao chép commit hash của phiên bản codebase dự án SubQuery mà bạn muốn triển khai\n * Phiên Bản Indexer: Đây là phiên bản dịch vụ node của SubQuery mà bạn muốn chạy SubQuery này trên đó. Xem @subql/node\n * Phiên Bản Query: Đây là phiên bản dịch vụ query của SubQuery mà bạn muốn chạy SubQuery này trên đó. Xem @subql/query\n\n\n\nNếu được triển khai thành công, bạn sẽ thấy indexer bắt đầu hoạt động và báo cáo về tiến độ lập chỉ mục cho chuỗi hiện tại. Tiến trình này có thể mất nhiều thời gian cho tới khi nó đạt đến 100%.\n\n\n# Các Bước Tiếp Theo - Kết nối đến Dự Án của bạn\n\nSau khi việc triển khai đã thành công và các node đã lập chỉ mục dữ liệu của bạn trên chuỗi, bạn sẽ có thể kết nối với dự án của mình thông qua endpoint được hiển thị của GraphQL Query.\n\n\n\nBạn cũng có thể nhấp vào ba dấu chấm bên cạnh đề mục dự án của mình, và xem nó trong SubQuery Explorer. Tại đó bạn có thể sử dụng nền tảng trong trình duyệt để tiến hành - tìm hiểu nhiều hơn về cách sử dụng Explorer của chúng tôi tại đây.\n\n\n\n\n# Thêm Tài Khoản GitHub Organization vào các Dự Án SubQuery\n\nXuất bản dự án SubQuery dưới tên tài khoản GitHub Organization của bạn thay vì dùng tài khoản GitHub cá nhân là điều phổ biến. Bạn có thể thay đổi tài khoản hiện đang chọn trên SubQuery Projects bất cứ lúc nào bằng cách sử dụng tính năng chuyển đổi tài khoản.\n\n\n\nNếu bạn không thể nhìn thấy tài khoản GitHub Organization của mình được liệt kê trong phần chuyển đổi tài khoản, bạn có thể cần phải cấp quyền truy cập vào SubQuery đối với GitHub Organization của bạn (hoặc yêu cầu quyền này từ một quản trị viên). Để thực hiện việc này, trước tiên bạn cần thu hồi quyền từ tài khoản GitHub của mình đối với Ứng dụng SubQuery. Để thực hiện việc này, hãy đăng nhập vào phần cài đặt tài khoản của bạn trong GitHub, đến Applications, và bên dưới thẻ Authorized Oauth Apps, thu hồi SubQuery - bạn có thể làm theo các bước chính xác tại đây . Đừng lo, việc này sẽ không xóa đi dự án SubQuery của bạn và bạn sẽ không bị mất bất kỳ dữ liệu nào.\n\n\n\nSau khi bạn đã thu hồi quyền truy cập, hãy đăng xuất ra khỏi SubQuery Projects và đăng nhập vào lại. Bạn sẽ được đưa đến một trang có tiêu đề Authorize SubQuery đây là trang bạn có thể yêu cầu cấp quyền truy cập SubQuerry đến tài khoản GitHub Organization của bạn. Nếu bạn không có các quyền quản trị, bạn cần phải yêu cầu một quản trị quyên cấp các quyền này cho bạn.\n\n\n\nSau khi yêu cầu đã được chấp thuận bởi quản trị viên (hoặc nếu bạn có thể tự cấp quyền cho mình), bạn sẽ thấy tài khoản GitHub Organization chính xác trong khu vực chuyển đổi tài khoản.',normalizedContent:'# xuat ban du an subquery cua ban\n\n\n# cac loi ich cua viec hosting du an cua ban bang subquery\n\n * chung toi se chay cac du an subquery cua ban trong mot dich vu cong đuoc quan ly co hieu suat cao, co the mo rong\n * dich vu nay đang đuoc cung cap đen cong đong mien phi!\n * ban co the tao ra cac du an cong khai do đo chung se đuoc liet ke trong subquery explorer va bat cu ai tren khap the gioi cung đeu co the xem chung\n * chung toi đuoc tich hop voi github, vi the bat ky ai trong cac to chuc github cua ban cung se xem đuoc cac du an đa chia se cua to chuc\n\n\n# tao du an đau tien\n\n# đang nhap vao cac du an subquery\n\ntruoc khi bat đau, vui long đam bao rang du an subquery cua ban truc tuyen trong kho luu tru github cong khai. tep tin schema.graphql phai đuoc nam trong thu muc goc cua ban.\n\nđe tao ra du an đau tien, hay đen project.subquery.network. ban se can xac thuc tai khoan github cua minh đe đang nhap.\n\ntrong lan đang nhap đau tien, ban se đuoc yeu cau cap quyen cho subquery. chung toi chi can đia chi email cua ban đe đinh danh tai khoan cua ban, va chung toi khong su dung bat ky du lieu nao tu tai khoan github cua ban vi bat ky ly do gi. trong buoc nay, ban cung co the yeu cau cap quyen truy cap đen tai khoan github organization cua ban đe đang cac du an subquery duoi github organization cua minh thay vi tai khoan ca nhan.\n\n\n\nsubquery projects la noi ban quan ly tat ca cac du an cua ban đa đuoc tai len nen tang subquery. ban co the tao, xoa, va tham chi nang cap cac du an tu ung dung nay.\n\n\n\nneu ban co ket noi cac tai khoan github organization, ban co the su dung tinh nang chuyen đoi o đau trang đe thay đoi giua tai khoan ca nhan va tai khoan github organization. cac du an đuoc tao ra trong tai khoan github organization đeu đuoc chia se giua cac thanh vien trong github organization đo. đe ket noi tai khoan github organization cua ban, ban co the lam theo cac buoc tai đay.\n\n\n\n# tao du an đau tien cua ban\n\nchung ta hay bat đau bang cach nhap vao "create project". ban se đuoc đua đen bieu mau du an moi. vui long nhap vao nhung thu sau đay (ban co the thay đoi trong tuong lai):\n\n * tai khoan github: neu ban co nhieu hon mot tai khoan github, hay chon ra tai khoan ma du an nay đuoc tao ra ben duoi. cac du an đuoc tao ra trong tai khoan github organization đeu đuoc chia se giua cac thanh vien trong cung to chuc.\n * ten\n * phu đe\n * mo ta\n * url kho luu tru github: đay phai la mot url github hop le chi đen kho luu tru cong khai co chua du an subquery cua ban. tap tin schema.graphql phai nam trong thu muc goc cua ban (tim hieu them ve cau truc thu muc goc).\n * an du an: neu đuoc chon, tinh nang nay se an du an khoi subquery explorer cong khai. bo trong khong chon neu ban muon chia se subquery cua minh voi cong đong!\n\nhay tao du an cho rieng minh va ban se thay no trong danh sach cac du an subquery cua ban. _chung ta sap xong roi! chung ta chi can thuc thi mot phien ban moi cua no. _\n\n# thuc thi phien ban đau tien cua ban\n\ntrong khi đang khoi tao, du an se thiet lap hanh vi hien thi cua no, ban phai trien khai mot phien ban cua no truoc khi du an đi vao van hanh. trien khai mot phien ban se kich hoat khoi đong lap chi muc subquery moi đe bat đau, va cai đat dich vu query bat buoc đe chap nhan cac yeu cau tu graphql. ban cung co the trien khai cac phien ban moi đoi voi cac du an hien tai tai đay.\n\ncung voi du an moi cua minh, ban se thay mot nut bam deploy new version. nhap vao nut nay, va đien vao cac thong tin bat buoc đe thuc hien trien khai:\n\n * commit hash cua phien ban moi: tu github, sao chep commit hash cua phien ban codebase du an subquery ma ban muon trien khai\n * phien ban indexer: đay la phien ban dich vu node cua subquery ma ban muon chay subquery nay tren đo. xem @subql/node\n * phien ban query: đay la phien ban dich vu query cua subquery ma ban muon chay subquery nay tren đo. xem @subql/query\n\n\n\nneu đuoc trien khai thanh cong, ban se thay indexer bat đau hoat đong va bao cao ve tien đo lap chi muc cho chuoi hien tai. tien trinh nay co the mat nhieu thoi gian cho toi khi no đat đen 100%.\n\n\n# cac buoc tiep theo - ket noi đen du an cua ban\n\nsau khi viec trien khai đa thanh cong va cac node đa lap chi muc du lieu cua ban tren chuoi, ban se co the ket noi voi du an cua minh thong qua endpoint đuoc hien thi cua graphql query.\n\n\n\nban cung co the nhap vao ba dau cham ben canh đe muc du an cua minh, va xem no trong subquery explorer. tai đo ban co the su dung nen tang trong trinh duyet đe tien hanh - tim hieu nhieu hon ve cach su dung explorer cua chung toi tai đay.\n\n\n\n\n# them tai khoan github organization vao cac du an subquery\n\nxuat ban du an subquery duoi ten tai khoan github organization cua ban thay vi dung tai khoan github ca nhan la đieu pho bien. ban co the thay đoi tai khoan hien đang chon tren subquery projects bat cu luc nao bang cach su dung tinh nang chuyen đoi tai khoan.\n\n\n\nneu ban khong the nhin thay tai khoan github organization cua minh đuoc liet ke trong phan chuyen đoi tai khoan, ban co the can phai cap quyen truy cap vao subquery đoi voi github organization cua ban (hoac yeu cau quyen nay tu mot quan tri vien). đe thuc hien viec nay, truoc tien ban can thu hoi quyen tu tai khoan github cua minh đoi voi ung dung subquery. đe thuc hien viec nay, hay đang nhap vao phan cai đat tai khoan cua ban trong github, đen applications, va ben duoi the authorized oauth apps, thu hoi subquery - ban co the lam theo cac buoc chinh xac tai đay . đung lo, viec nay se khong xoa đi du an subquery cua ban va ban se khong bi mat bat ky du lieu nao.\n\n\n\nsau khi ban đa thu hoi quyen truy cap, hay đang xuat ra khoi subquery projects va đang nhap vao lai. ban se đuoc đua đen mot trang co tieu đe authorize subquery đay la trang ban co the yeu cau cap quyen truy cap subquerry đen tai khoan github organization cua ban. neu ban khong co cac quyen quan tri, ban can phai yeu cau mot quan tri quyen cap cac quyen nay cho ban.\n\n\n\nsau khi yeu cau đa đuoc chap thuan boi quan tri vien (hoac neu ban co the tu cap quyen cho minh), ban se thay tai khoan github organization chinh xac trong khu vuc chuyen đoi tai khoan.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Triển Khai Phiên Bản Mới cho Dự Án SubQuery của bạn",frontmatter:{summary:"Triển Khai Phiên Bản Mới cho Dự Án SubQuery của bạn Hướng Dẫn Mặc dù bạn được tự do để luôn nâng cấp và triển khai các phiên bản mới cho dự án SubQuery của mình, vui lòng cân nhắc ",meta:[{property:"og:url",content:"/vi/publish/upgrade.html"},{property:"og:title",content:"Triển Khai Phiên Bản Mới cho Dự Án SubQuery của bạn"},{property:"og:description",content:"Triển Khai Phiên Bản Mới cho Dự Án SubQuery của bạn Hướng Dẫn Mặc dù bạn được tự do để luôn nâng cấp và triển khai các phiên bản mới cho dự án SubQuery của mình, vui lòng cân nhắc "},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/publish/upgrade.html",relativePath:"vi/publish/upgrade.md",key:"v-40fa8299",path:"/vi/publish/upgrade/",headers:[{level:2,title:"Hướng Dẫn",slug:"huong-dan",normalizedTitle:"huong dan",charIndex:58},{level:2,title:"Các Thay Đổi Triển Khai",slug:"cac-thay-đoi-trien-khai",normalizedTitle:"cac thay đoi trien khai",charIndex:656},{level:2,title:"Các Bước Tiếp Theo - Kết nối đến Dự Án của bạn",slug:"cac-buoc-tiep-theo-ket-noi-đen-du-an-cua-ban",normalizedTitle:"cac buoc tiep theo - ket noi đen du an cua ban",charIndex:1558}],readingTime:{minutes:2.26,words:678},headersStr:"Hướng Dẫn Các Thay Đổi Triển Khai Các Bước Tiếp Theo - Kết nối đến Dự Án của bạn",content:"# Triển Khai Phiên Bản Mới cho Dự Án SubQuery của bạn\n\n\n# Hướng Dẫn\n\nMặc dù bạn được tự do để luôn nâng cấp và triển khai các phiên bản mới cho dự án SubQuery của mình, vui lòng cân nhắc trong suốt quá trình này nếu dự án SubQuery của bạn đang công khai với thế giới. Một vài điểm quan trọng cần lưu ý:\n\n * Nếu nâng cấp của bạn là một thay đổi mang tính đột phá, hãy tạo một dự án mới (ví dụ Dự Án SubQuery V2 Của Tôi) hoặc đưa ra nhiều cảnh báo đến cộng đồng về sự thay đổi này thông qua các kênh mạng xã hội.\n * Việc triển khai phiên bản dự án SubQuery mới có thể dẫn đến thời gian chết vì phiên bản mới lập chỉ mục chuỗi hoàn chỉnh từ khối genesis.\n\n\n# Các Thay Đổi Triển Khai\n\nĐăng nhập vào Các Dự Án SubQuery, và tìm dự án mà bạn muốn triển khai phiên bản mới. Dưới Phần Thông Tin Triển Khai bạn sẽ thấy ba dấu chấm trên cùng bên phải, nhấp vào nút Deploy New Version.\n\n\n\n# Nâng cấp lên Dịch Vụ Query và Trình Lập Chỉ Mục Mới Nhất\n\nNếu bạn muốn nâng cấp lên trình lập chỉ mục mới nhất (@subql/node) hoặc dịch vụ query (@subql/query) để có lợi thế về khả năng cải thiện độ ổn định và hiệu năng thông thường của chúng tôi. Chỉ cần chọn ra các phiên bản mới hơn trong các gói của chúng tôi và lưu. Bước này sẽ chỉ tốn vài phút.\n\n# Triển Khai Phiên Bản Mới Dự Án SubQuery của bạn\n\nĐiền vào Commit Hash từ GitHub (sao chép toàn bộ commit hash) của phiên bản codebase dự án SubQuery mà bạn muốn triển khai. Bước này sẽ làm tốn nhiều thời gian hơn nữa tùy thuộc vào thời gian cần để lập chỉ mục chuỗi hiện tại. Bạn luôn có thể báo cáo tiến độ lại tại đây.\n\n\n# Các Bước Tiếp Theo - Kết nối đến Dự Án của bạn\n\nSau khi quá trình triển khai hoàn tất thành công và các node đã lập chỉ mục dữ liệu của bạn từ chuỗi, bạn có thể kết nối đến dự án của mình thông qua endpoint GraphQL Query được hiển thị.\n\n\n\nBạn cũng có thể nhấp vào ba dấu chấm bên cạnh tiêu đề dự án của mình, và xem nó trên SubQuery Explorer. Tại đó bạn có thể sử dụng nền tảng trong trình duyệt để bắt đầu - đọc thêm về cách thức sử dụng Explorer của chúng tôi tại đây.",normalizedContent:"# trien khai phien ban moi cho du an subquery cua ban\n\n\n# huong dan\n\nmac du ban đuoc tu do đe luon nang cap va trien khai cac phien ban moi cho du an subquery cua minh, vui long can nhac trong suot qua trinh nay neu du an subquery cua ban đang cong khai voi the gioi. mot vai điem quan trong can luu y:\n\n * neu nang cap cua ban la mot thay đoi mang tinh đot pha, hay tao mot du an moi (vi du du an subquery v2 cua toi) hoac đua ra nhieu canh bao đen cong đong ve su thay đoi nay thong qua cac kenh mang xa hoi.\n * viec trien khai phien ban du an subquery moi co the dan đen thoi gian chet vi phien ban moi lap chi muc chuoi hoan chinh tu khoi genesis.\n\n\n# cac thay đoi trien khai\n\nđang nhap vao cac du an subquery, va tim du an ma ban muon trien khai phien ban moi. duoi phan thong tin trien khai ban se thay ba dau cham tren cung ben phai, nhap vao nut deploy new version.\n\n\n\n# nang cap len dich vu query va trinh lap chi muc moi nhat\n\nneu ban muon nang cap len trinh lap chi muc moi nhat (@subql/node) hoac dich vu query (@subql/query) đe co loi the ve kha nang cai thien đo on đinh va hieu nang thong thuong cua chung toi. chi can chon ra cac phien ban moi hon trong cac goi cua chung toi va luu. buoc nay se chi ton vai phut.\n\n# trien khai phien ban moi du an subquery cua ban\n\nđien vao commit hash tu github (sao chep toan bo commit hash) cua phien ban codebase du an subquery ma ban muon trien khai. buoc nay se lam ton nhieu thoi gian hon nua tuy thuoc vao thoi gian can đe lap chi muc chuoi hien tai. ban luon co the bao cao tien đo lai tai đay.\n\n\n# cac buoc tiep theo - ket noi đen du an cua ban\n\nsau khi qua trinh trien khai hoan tat thanh cong va cac node đa lap chi muc du lieu cua ban tu chuoi, ban co the ket noi đen du an cua minh thong qua endpoint graphql query đuoc hien thi.\n\n\n\nban cung co the nhap vao ba dau cham ben canh tieu đe du an cua minh, va xem no tren subquery explorer. tai đo ban co the su dung nen tang trong trinh duyet đe bat đau - đoc them ve cach thuc su dung explorer cua chung toi tai đay.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tìm hiểu thêm về GraphQL",frontmatter:{summary:"Tìm hiểu thêm về GraphQL Bạn có thể theo dõi hướng dẫn GraphQL chính thức tại đây để tìm hiểu thêm về GraphQL, cách thức hoạt động và cách sử dụng: Có nhiều thư viện giúp bạn thực ",meta:[{property:"og:url",content:"/vi/query/graphql.html"},{property:"og:title",content:"Tìm hiểu thêm về GraphQL"},{property:"og:description",content:"Tìm hiểu thêm về GraphQL Bạn có thể theo dõi hướng dẫn GraphQL chính thức tại đây để tìm hiểu thêm về GraphQL, cách thức hoạt động và cách sử dụng: Có nhiều thư viện giúp bạn thực "},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/query/graphql.html",relativePath:"vi/query/graphql.md",key:"v-7636cee6",path:"/vi/query/graphql/",readingTime:{minutes:.42,words:127},headersStr:null,content:"# Tìm hiểu thêm về GraphQL\n\nBạn có thể theo dõi hướng dẫn GraphQL chính thức tại đây để tìm hiểu thêm về GraphQL, cách thức hoạt động và cách sử dụng:\n\n * Có nhiều thư viện giúp bạn thực thi GraphQL bằng nhiều ngôn ngữ khác nhau\n * Để hiểu sâu hơn bằng các hướng dẫn thực hành, hãy xem qua Cách để GraphQL.\n * Xem qua khóa học online miễn phí, Khám Phá GraphQL: Một Ngôn Ngữ Query cho APIs.",normalizedContent:"# tim hieu them ve graphql\n\nban co the theo doi huong dan graphql chinh thuc tai đay đe tim hieu them ve graphql, cach thuc hoat đong va cach su dung:\n\n * co nhieu thu vien giup ban thuc thi graphql bang nhieu ngon ngu khac nhau\n * đe hieu sau hon bang cac huong dan thuc hanh, hay xem qua cach đe graphql.\n * xem qua khoa hoc online mien phi, kham pha graphql: mot ngon ngu query cho apis.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Query Dự Án của bạn trong SubQuery Explorer",frontmatter:{summary:"Query Dự Án của bạn trong SubQuery Explorer SubQuery Explorer là một dịch vụ được host online (tại explorer.subquery.network) cung cấp truy cập đến các dự án SubQuery được tạo ra b",meta:[{property:"og:url",content:"/vi/query/query.html"},{property:"og:title",content:"Query Dự Án của bạn trong SubQuery Explorer"},{property:"og:description",content:"Query Dự Án của bạn trong SubQuery Explorer SubQuery Explorer là một dịch vụ được host online (tại explorer.subquery.network) cung cấp truy cập đến các dự án SubQuery được tạo ra b"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/query/query.html",relativePath:"vi/query/query.md",key:"v-290cdc62",path:"/vi/query/query/",readingTime:{minutes:1.63,words:489},headersStr:null,content:"# Query Dự Án của bạn trong SubQuery Explorer\n\nSubQuery Explorer là một dịch vụ được host online (tại explorer.subquery.network) cung cấp truy cập đến các dự án SubQuery được tạo ra bởi những người đóng góp trong cộng đồng và được quản lý bởi đội ngũ SubQuery. Bạn có thể xuất bản các dự án SubQuery của riêng mình đến explorer của chúng tôi bằng cách làm theo hướng dẫn sau đây của chúng tôi để Xuất bản Dự Án SubQuery của bạn.\n\n\n\nSubQuery explorer giúp khởi đầu trở nên dễ dàng. Chúng tôi đang host các dự án SubQuery online và cho phép tất cả mọi người query từng cái miễn phí. Các node được quản lý sẽ do đội ngũ SubQuery giám sát và vận hành với mức hiệu năng cho phép các ứng dụng sản xuất sử dụng và phụ thuộc vào chúng.\n\n\n\nBạn cũng sẽ thấy rằng SubQuery Explorer cung cấp một playground nhằm khám phá dữ liệu hiện có với nhiều query mẫu - bạn có thể kiểm tra các query trực tiếp trong trình duyệt mà không phải chạy code. Ngoài ra, chúng tôi đã thực hiện một số cải tiến nhỏ đối với tài liệu của mình để hỗ trợ tốt hơn cho các nhà phát triển trong hành trình truy vấn và phân tích dữ liệu Polkadot của thế giới.\n\nTrên cùng bên phải của playground, bạn sẽ tìm thấy nút Docs giúp mở ra một mẫu tài liệu. Tài liệu này được tự động tạo ra và giúp bạn tìm kiếm các thực thể và phương pháp mà bạn có thể query. Trong ví dụ bên dưới chúng tôi đang sử dụng Sum Rewards SubQuery để lấy ra 5 tài khoản được thưởng nhiều nhất (liên quan đến stake doanh thu) trên Polkadot mà chưa từng bị cắt giảm.\n\n\n\nTìm hiểu thêm về ngôn ngữ GraphQL Query.",normalizedContent:"# query du an cua ban trong subquery explorer\n\nsubquery explorer la mot dich vu đuoc host online (tai explorer.subquery.network) cung cap truy cap đen cac du an subquery đuoc tao ra boi nhung nguoi đong gop trong cong đong va đuoc quan ly boi đoi ngu subquery. ban co the xuat ban cac du an subquery cua rieng minh đen explorer cua chung toi bang cach lam theo huong dan sau đay cua chung toi đe xuat ban du an subquery cua ban.\n\n\n\nsubquery explorer giup khoi đau tro nen de dang. chung toi đang host cac du an subquery online va cho phep tat ca moi nguoi query tung cai mien phi. cac node đuoc quan ly se do đoi ngu subquery giam sat va van hanh voi muc hieu nang cho phep cac ung dung san xuat su dung va phu thuoc vao chung.\n\n\n\nban cung se thay rang subquery explorer cung cap mot playground nham kham pha du lieu hien co voi nhieu query mau - ban co the kiem tra cac query truc tiep trong trinh duyet ma khong phai chay code. ngoai ra, chung toi đa thuc hien mot so cai tien nho đoi voi tai lieu cua minh đe ho tro tot hon cho cac nha phat trien trong hanh trinh truy van va phan tich du lieu polkadot cua the gioi.\n\ntren cung ben phai cua playground, ban se tim thay nut docs giup mo ra mot mau tai lieu. tai lieu nay đuoc tu đong tao ra va giup ban tim kiem cac thuc the va phuong phap ma ban co the query. trong vi du ben duoi chung toi đang su dung sum rewards subquery đe lay ra 5 tai khoan đuoc thuong nhieu nhat (lien quan đen stake doanh thu) tren polkadot ma chua tung bi cat giam.\n\n\n\ntim hieu them ve ngon ngu graphql query.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (được lưu trữ trên SubQuery)",frontmatter:{summary:"Hello World (được lưu trữ trên SubQuery) Mục đích của bài quick start này là hướng dẫn cách bạn có thể chạy dự án khởi động mặc định trong SubQuery Projects (dịch vụ được quản lý c",meta:[{property:"og:url",content:"/vi/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (được lưu trữ trên SubQuery)"},{property:"og:description",content:"Hello World (được lưu trữ trên SubQuery) Mục đích của bài quick start này là hướng dẫn cách bạn có thể chạy dự án khởi động mặc định trong SubQuery Projects (dịch vụ được quản lý c"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/quickstart/helloworld-hosted.html",relativePath:"vi/quickstart/helloworld-hosted.md",key:"v-19ad78ad",path:"/vi/quickstart/helloworld-hosted/",headers:[{level:2,title:"Mục tiêu học tập",slug:"muc-tieu-hoc-tap",normalizedTitle:"muc tieu hoc tap",charIndex:561},{level:2,title:"Đối tượng mục tiêu",slug:"đoi-tuong-muc-tieu",normalizedTitle:"đoi tuong muc tieu",charIndex:929},{level:2,title:"Video hướng dẫn",slug:"video-huong-dan",normalizedTitle:"video huong dan",charIndex:1071},{level:2,title:"Điều kiện tiên quyết",slug:"đieu-kien-tien-quyet",normalizedTitle:"đieu kien tien quyet",charIndex:1091},{level:2,title:"Bước 1: Tạo dự án của bạn",slug:"buoc-1-tao-du-an-cua-ban",normalizedTitle:"buoc 1: tao du an cua ban",charIndex:1154},{level:2,title:"Bước 2: Tạo repo GitHub",slug:"buoc-2-tao-repo-github",normalizedTitle:"buoc 2: tao repo github",charIndex:1435},{level:2,title:"Bước 3: Push tới GitHub",slug:"buoc-3-push-toi-github",normalizedTitle:"buoc 3: push toi github",charIndex:1712},{level:2,title:"Bước 4: Tạo dự án của bạn",slug:"buoc-4-tao-du-an-cua-ban",normalizedTitle:"buoc 4: tao du an cua ban",charIndex:3495},{level:2,title:"Bước 5: Triển khai dự án của bạn",slug:"buoc-5-trien-khai-du-an-cua-ban",normalizedTitle:"buoc 5: trien khai du an cua ban",charIndex:4679},{level:2,title:"Bước 6: Kiểm tra dự án của bạn",slug:"buoc-6-kiem-tra-du-an-cua-ban",normalizedTitle:"buoc 6: kiem tra du an cua ban",charIndex:6302},{level:2,title:"Bước 7: Bước thêm",slug:"buoc-7-buoc-them",normalizedTitle:"buoc 7: buoc them",charIndex:6551},{level:2,title:"Tóm lược",slug:"tom-luoc",normalizedTitle:"tom luoc",charIndex:8091}],readingTime:{minutes:7.64,words:2293},headersStr:"Mục tiêu học tập Đối tượng mục tiêu Video hướng dẫn Điều kiện tiên quyết Bước 1: Tạo dự án của bạn Bước 2: Tạo repo GitHub Bước 3: Push tới GitHub Bước 4: Tạo dự án của bạn Bước 5: Triển khai dự án của bạn Bước 6: Kiểm tra dự án của bạn Bước 7: Bước thêm Tóm lược",content:'# Hello World (được lưu trữ trên SubQuery)\n\nMục đích của bài quick start này là hướng dẫn cách bạn có thể chạy dự án khởi động mặc định trong SubQuery Projects (dịch vụ được quản lý của chúng tôi) trong một vài bước đơn giản.\n\nChúng tôi sẽ sử dụng dự án khởi động đơn giản (và mọi thứ chúng tôi đã học được cho đến nay) nhưng thay vì chạy nó cục bộ trong Docker, chúng tôi sẽ tận dụng cơ sở hạ tầng lưu trữ được quản lý của SubQuery. Nói cách khác, chúng tôi để SubQuery thực hiện tất cả các công việc nặng nhọc, vận hành và quản lý cơ sở hạ tầng sản xuất.\n\n\n# Mục tiêu học tập\n\nKhi kết thúc quá trình quick start này, bạn sẽ:\n\n * hiểu các điều kiện tiên quyết cần thiết\n * có thể host một dự án trong Dự án SubQuery\n * chạy một truy vấn đơn giản để lấy chiều cao khối của mạng chính Polkadot bằng cách sử dụng playground\n * chạy một truy vấn GET đơn giản để lấy chiều cao khối của mạng chính Polkadot bằng cách sử dụng cURL\n\n\n# Đối tượng mục tiêu\n\nHướng dẫn này hướng tới các nhà phát triển mới đã có một số kinh nghiệm phát triển và muốn tìm hiểu thêm về SubQuery.\n\n\n# Video hướng dẫn\n\n\n# Điều kiện tiên quyết\n\nBạn sẽ cần:\n\n * một tài khoản GitHub\n\n\n# Bước 1: Tạo dự án của bạn\n\nHãy tạo một dự án có tên là subql_hellowworld và chạy cài đặt bắt buộc, codegen và xây dựng với trình quản lý gói yêu thích của bạn.\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nKHÔNG chạy các lệnh docker.\n\n\n# Bước 2: Tạo repo GitHub\n\nTrong GitHub, hãy tạo một repository công khai mới. Cung cấp tên và đặt khả năng hiển thị của bạn ở chế độ công khai. Ở đây, mọi thứ được giữ làm mặc định.\n\n\n\nHãy lưu ý URL GitHub của bạn, URL này phải được công khai để SubQuery có thể truy cập.\n\n\n\n\n# Bước 3: Push tới GitHub\n\nQuay lại thư mục dự án của bạn, khởi tạo nó dưới dạng thư mục git. Nếu không, bạn có thể gặp lỗi "nghiêm trọng: không phải là kho lưu trữ git (hoặc bất kỳ thư mục mẹ nào): .git"\n\ngit init\n\n\n1\n\n\nSau đó, thêm một repository từ xa bằng lệnh:\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\nVề cơ bản, điều này đặt kho lưu trữ từ xa của bạn thành “https://github.com/seandotau/subqlHelloWorld.git” và đặt cho nó tên “origin” là danh pháp tiêu chuẩn cho repository từ xa trong GitHub.\n\nTiếp theo, chúng tôi thêm code vào repo của chúng tôi bằng các lệnh sau:\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nLệnh push có nghĩa là "vui lòng đẩy mã của tôi ĐẾN kho lưu trữ gốc TỪ kho lưu trữ cục bộ chính của tôi". Làm mới GitHub sẽ hiển thị tất cả mã trong GitHub.\n\n\n\nBây giờ bạn đã có code của mình vào GitHub, hãy xem cách chúng tôi có thể lưu trữ code đó trong Dự án SubQuery.\n\n\n# Bước 4: Tạo dự án của bạn\n\nĐiều hướng đến https://project.subquery.network và đăng nhập bằng tài khoản GitHub của bạn.\n\n\n\nSau đó, tạo một dự án mới,\n\n\n\nVà điền vào các trường khác nhau với các chi tiết thích hợp.\n\n * Tài khoản GitHub: Nếu bạn có nhiều tài khoản GitHub, hãy chọn tài khoản mà dự án này sẽ được tạo. Các dự án được tạo trong tài khoản tổ chức GitHub được chia sẻ giữa các thành viên trong tổ chức đó.\n * Tên dự án: Đặt tên cho dự án của bạn ở đây.\n * Phụ đề: Cung cấp phụ đề cho dự án của bạn.\n * Mô tả: Giải thích những gì dự án SubQuery của bạn thực hiện.\n * GitHub Repository URL: Đây phải là URL GitHub hợp lệ tới kho lưu trữ công cộng có chứa dự án SubQuery của bạn. Tệp schema.graphql phải nằm trong thư mục root của bạn.\n * Ẩn dự án: Nếu được chọn, điều này sẽ ẩn dự án khỏi trình khám phá SubQuery công khai. Hãy bỏ chọn mục này nếu bạn muốn chia sẻ SubQuery của mình với cộng đồng!\n\n\n\nKhi bạn nhấp vào tạo, bạn sẽ được đưa đến trang tổng quan của mình.\n\n\n\nTrang tổng quan chứa nhiều thông tin hữu ích như mạng mà nó đang sử dụng, URL kho lưu trữ GitHub của mã nguồn đang chạy, thời điểm nó được tạo và cập nhật lần cuối và đặc biệt là chi tiết triển khai.\n\n\n# Bước 5: Triển khai dự án của bạn\n\nBây giờ bạn đã tạo dự án của mình trong SubQuery Projects, thiết lập hành vi hiển thị, bước tiếp theo là triển khai dự án của bạn để làm cho nó hoạt động. Việc triển khai một phiên bản sẽ kích hoạt hoạt động lập chỉ mục SubQuery mới bắt đầu và thiết lập dịch vụ truy vấn bắt buộc để bắt đầu chấp nhận các yêu cầu GraphQL. Bạn cũng có thể triển khai các phiên bản mới cho các dự án hiện có tại đây.\n\nBạn có thể chọn triển khai cho các môi trường khác nhau như production slot hoặc staging slot. Ở đây, chúng tôi sẽ triển khai cho 1 production slot. Nhấp vào nút "Triển khai" sẽ xuất hiện màn hình với các trường sau:\n\n\n\n * Commit Hash of new Version: Từ GitHub, chọn cam kết chính xác của cơ sở mã dự án SubQuery mà bạn muốn triển khai\n * Indexer Version: Đây là phiên bản của dịch vụ nút SubQuery mà bạn muốn chạy SubQuery này. Xem @subql/node\n * Query Version: Đây là phiên bản của dịch vụ truy vấn SubQuery mà bạn muốn chạy SubQuery này. Xem @subql/query\n\nBởi vì chúng tôi chỉ có một commit, chỉ có một tùy chọn duy nhất trong trình đơn thả xuống. Chúng tôi cũng sẽ làm việc với phiên bản mới nhất của trình lập chỉ mục và phiên bản truy vấn, vì vậy chúng tôi sẽ chấp nhận các giá trị mặc định và sau đó nhấp vào "Deploy Update".\n\nSau đó, bạn sẽ thấy việc triển khai của mình ở trạng thái “Processing”. Tại đây, mã của bạn đang được triển khai trên cơ sở hạ tầng được quản lý của SubQuery. Về cơ bản, một máy chủ đang hoạt động theo yêu cầu và được cung cấp cho bạn. Quá trình này sẽ mất vài phút vì vậy hãy dành thời gian để uống một ly cà phê!\n\n\n\nViệc triển khai hiện đang chạy.\n\n\n\n\n# Bước 6: Kiểm tra dự án của bạn\n\nĐể kiểm tra dự án của bạn, hãy nhấp vào 3 dấu chấm lửng và chọn "View on SubQuery Explorer".\n\n\n\nThao tác này sẽ đưa bạn đến "Playground" quen thuộc, nơi bạn có thể nhấp vào nút play và xem kết quả của truy vấn.\n\n\n\n\n# Bước 7: Bước thêm\n\nĐối với những người sắc sảo trong số chúng ta, bạn sẽ nhớ lại rằng trong mục tiêu học tập, điểm cuối cùng là chạy một truy vấn GET đơn giản. Để làm điều này, chúng tôi sẽ cần lấy "Query Endpoint" được hiển thị trong chi tiết triển khai.\n\n\n\nSau đó, bạn có thể gửi một yêu cầu GET tới điểm cuối này bằng cách sử dụng ứng dụng khách yêu thích của bạn như Postman hoặc Mockoon hoặc qua cURL trong thiết bị đầu cuối của bạn. Để đơn giản, cURL sẽ được hiển thị bên dưới.\n\nLệnh curl để chạy là:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\nđưa ra kết quả của:\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nKhả năng đọc không phải là mối quan tâm ở đây vì bạn có thể sẽ có một số mã giao diện người dùng để sử dụng và phân tích cú pháp phản hồi JSON này.\n\n\n# Tóm lược\n\nTrong phần khởi động nhanh được lưu trữ trên SubQuery này, chúng tôi đã cho thấy việc thực hiện một dự án Subql và triển khai nó cho Dự án SubQuery nhanh chóng và dễ dàng như thế nào để thuận tiện cho bạn. Có một inbuilt playground có để chạy các truy vấn khác nhau cũng như một điểm cuối API để tích hợp mã của bạn.',normalizedContent:'# hello world (đuoc luu tru tren subquery)\n\nmuc đich cua bai quick start nay la huong dan cach ban co the chay du an khoi đong mac đinh trong subquery projects (dich vu đuoc quan ly cua chung toi) trong mot vai buoc đon gian.\n\nchung toi se su dung du an khoi đong đon gian (va moi thu chung toi đa hoc đuoc cho đen nay) nhung thay vi chay no cuc bo trong docker, chung toi se tan dung co so ha tang luu tru đuoc quan ly cua subquery. noi cach khac, chung toi đe subquery thuc hien tat ca cac cong viec nang nhoc, van hanh va quan ly co so ha tang san xuat.\n\n\n# muc tieu hoc tap\n\nkhi ket thuc qua trinh quick start nay, ban se:\n\n * hieu cac đieu kien tien quyet can thiet\n * co the host mot du an trong du an subquery\n * chay mot truy van đon gian đe lay chieu cao khoi cua mang chinh polkadot bang cach su dung playground\n * chay mot truy van get đon gian đe lay chieu cao khoi cua mang chinh polkadot bang cach su dung curl\n\n\n# đoi tuong muc tieu\n\nhuong dan nay huong toi cac nha phat trien moi đa co mot so kinh nghiem phat trien va muon tim hieu them ve subquery.\n\n\n# video huong dan\n\n\n# đieu kien tien quyet\n\nban se can:\n\n * mot tai khoan github\n\n\n# buoc 1: tao du an cua ban\n\nhay tao mot du an co ten la subql_hellowworld va chay cai đat bat buoc, codegen va xay dung voi trinh quan ly goi yeu thich cua ban.\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\nkhong chay cac lenh docker.\n\n\n# buoc 2: tao repo github\n\ntrong github, hay tao mot repository cong khai moi. cung cap ten va đat kha nang hien thi cua ban o che đo cong khai. o đay, moi thu đuoc giu lam mac đinh.\n\n\n\nhay luu y url github cua ban, url nay phai đuoc cong khai đe subquery co the truy cap.\n\n\n\n\n# buoc 3: push toi github\n\nquay lai thu muc du an cua ban, khoi tao no duoi dang thu muc git. neu khong, ban co the gap loi "nghiem trong: khong phai la kho luu tru git (hoac bat ky thu muc me nao): .git"\n\ngit init\n\n\n1\n\n\nsau đo, them mot repository tu xa bang lenh:\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\nve co ban, đieu nay đat kho luu tru tu xa cua ban thanh “https://github.com/seandotau/subqlhelloworld.git” va đat cho no ten “origin” la danh phap tieu chuan cho repository tu xa trong github.\n\ntiep theo, chung toi them code vao repo cua chung toi bang cac lenh sau:\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\nlenh push co nghia la "vui long đay ma cua toi đen kho luu tru goc tu kho luu tru cuc bo chinh cua toi". lam moi github se hien thi tat ca ma trong github.\n\n\n\nbay gio ban đa co code cua minh vao github, hay xem cach chung toi co the luu tru code đo trong du an subquery.\n\n\n# buoc 4: tao du an cua ban\n\nđieu huong đen https://project.subquery.network va đang nhap bang tai khoan github cua ban.\n\n\n\nsau đo, tao mot du an moi,\n\n\n\nva đien vao cac truong khac nhau voi cac chi tiet thich hop.\n\n * tai khoan github: neu ban co nhieu tai khoan github, hay chon tai khoan ma du an nay se đuoc tao. cac du an đuoc tao trong tai khoan to chuc github đuoc chia se giua cac thanh vien trong to chuc đo.\n * ten du an: đat ten cho du an cua ban o đay.\n * phu đe: cung cap phu đe cho du an cua ban.\n * mo ta: giai thich nhung gi du an subquery cua ban thuc hien.\n * github repository url: đay phai la url github hop le toi kho luu tru cong cong co chua du an subquery cua ban. tep schema.graphql phai nam trong thu muc root cua ban.\n * an du an: neu đuoc chon, đieu nay se an du an khoi trinh kham pha subquery cong khai. hay bo chon muc nay neu ban muon chia se subquery cua minh voi cong đong!\n\n\n\nkhi ban nhap vao tao, ban se đuoc đua đen trang tong quan cua minh.\n\n\n\ntrang tong quan chua nhieu thong tin huu ich nhu mang ma no đang su dung, url kho luu tru github cua ma nguon đang chay, thoi điem no đuoc tao va cap nhat lan cuoi va đac biet la chi tiet trien khai.\n\n\n# buoc 5: trien khai du an cua ban\n\nbay gio ban đa tao du an cua minh trong subquery projects, thiet lap hanh vi hien thi, buoc tiep theo la trien khai du an cua ban đe lam cho no hoat đong. viec trien khai mot phien ban se kich hoat hoat đong lap chi muc subquery moi bat đau va thiet lap dich vu truy van bat buoc đe bat đau chap nhan cac yeu cau graphql. ban cung co the trien khai cac phien ban moi cho cac du an hien co tai đay.\n\nban co the chon trien khai cho cac moi truong khac nhau nhu production slot hoac staging slot. o đay, chung toi se trien khai cho 1 production slot. nhap vao nut "trien khai" se xuat hien man hinh voi cac truong sau:\n\n\n\n * commit hash of new version: tu github, chon cam ket chinh xac cua co so ma du an subquery ma ban muon trien khai\n * indexer version: đay la phien ban cua dich vu nut subquery ma ban muon chay subquery nay. xem @subql/node\n * query version: đay la phien ban cua dich vu truy van subquery ma ban muon chay subquery nay. xem @subql/query\n\nboi vi chung toi chi co mot commit, chi co mot tuy chon duy nhat trong trinh đon tha xuong. chung toi cung se lam viec voi phien ban moi nhat cua trinh lap chi muc va phien ban truy van, vi vay chung toi se chap nhan cac gia tri mac đinh va sau đo nhap vao "deploy update".\n\nsau đo, ban se thay viec trien khai cua minh o trang thai “processing”. tai đay, ma cua ban đang đuoc trien khai tren co so ha tang đuoc quan ly cua subquery. ve co ban, mot may chu đang hoat đong theo yeu cau va đuoc cung cap cho ban. qua trinh nay se mat vai phut vi vay hay danh thoi gian đe uong mot ly ca phe!\n\n\n\nviec trien khai hien đang chay.\n\n\n\n\n# buoc 6: kiem tra du an cua ban\n\nđe kiem tra du an cua ban, hay nhap vao 3 dau cham lung va chon "view on subquery explorer".\n\n\n\nthao tac nay se đua ban đen "playground" quen thuoc, noi ban co the nhap vao nut play va xem ket qua cua truy van.\n\n\n\n\n# buoc 7: buoc them\n\nđoi voi nhung nguoi sac sao trong so chung ta, ban se nho lai rang trong muc tieu hoc tap, điem cuoi cung la chay mot truy van get đon gian. đe lam đieu nay, chung toi se can lay "query endpoint" đuoc hien thi trong chi tiet trien khai.\n\n\n\nsau đo, ban co the gui mot yeu cau get toi điem cuoi nay bang cach su dung ung dung khach yeu thich cua ban nhu postman hoac mockoon hoac qua curl trong thiet bi đau cuoi cua ban. đe đon gian, curl se đuoc hien thi ben duoi.\n\nlenh curl đe chay la:\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\nđua ra ket qua cua:\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\nkha nang đoc khong phai la moi quan tam o đay vi ban co the se co mot so ma giao dien nguoi dung đe su dung va phan tich cu phap phan hoi json nay.\n\n\n# tom luoc\n\ntrong phan khoi đong nhanh đuoc luu tru tren subquery nay, chung toi đa cho thay viec thuc hien mot du an subql va trien khai no cho du an subquery nhanh chong va de dang nhu the nao đe thuan tien cho ban. co mot inbuilt playground co đe chay cac truy van khac nhau cung nhu mot điem cuoi api đe tich hop ma cua ban.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) Chào mừng bạn đến với SubQuery Hello World quick start. Việc bắt đầu nhanh nhằm mục đích chỉ cho bạn cách bạn có được dự án khởi động mặc định chạy",meta:[{property:"og:url",content:"/vi/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) Chào mừng bạn đến với SubQuery Hello World quick start. Việc bắt đầu nhanh nhằm mục đích chỉ cho bạn cách bạn có được dự án khởi động mặc định chạy"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/quickstart/helloworld-localhost.html",relativePath:"vi/quickstart/helloworld-localhost.md",key:"v-33ab2251",path:"/vi/quickstart/helloworld-localhost/",headers:[{level:2,title:"Mục tiêu học tập",slug:"muc-tieu-hoc-tap",normalizedTitle:"muc tieu hoc tap",charIndex:230},{level:2,title:"Đối tượng mục tiêu",slug:"đoi-tuong-muc-tieu",normalizedTitle:"đoi tuong muc tieu",charIndex:482},{level:2,title:"Video hướng dẫn",slug:"video-huong-dan",normalizedTitle:"video huong dan",charIndex:624},{level:2,title:"Điều kiện tiên quyết",slug:"đieu-kien-tien-quyet",normalizedTitle:"đieu kien tien quyet",charIndex:644},{level:2,title:"Bước 1: Khởi tạo dự án",slug:"buoc-1-khoi-tao-du-an",normalizedTitle:"buoc 1: khoi tao du an",charIndex:1510},{level:2,title:"Bước 2: Cài đặt phần phụ thuộc",slug:"buoc-2-cai-đat-phan-phu-thuoc",normalizedTitle:"buoc 2: cai đat phan phu thuoc",charIndex:2055},{level:2,title:"Bước 3: Tạo mã",slug:"buoc-3-tao-ma",normalizedTitle:"buoc 3: tao ma",charIndex:2487},{level:2,title:"Bước 4: Build code",slug:"buoc-4-build-code",normalizedTitle:"buoc 4: build code",charIndex:3087},{level:2,title:"Bước 5: Chạy Docker",slug:"buoc-5-chay-docker",normalizedTitle:"buoc 5: chay docker",charIndex:3305},{level:2,title:"Bước 6: Duyệt qua playground",slug:"buoc-6-duyet-qua-playground",normalizedTitle:"buoc 6: duyet qua playground",charIndex:4577},{level:2,title:"Tóm lược",slug:"tom-luoc",normalizedTitle:"tom luoc",charIndex:4994}],readingTime:{minutes:3.9,words:1170},headersStr:"Mục tiêu học tập Đối tượng mục tiêu Video hướng dẫn Điều kiện tiên quyết Bước 1: Khởi tạo dự án Bước 2: Cài đặt phần phụ thuộc Bước 3: Tạo mã Bước 4: Build code Bước 5: Chạy Docker Bước 6: Duyệt qua playground Tóm lược",content:'# Hello World (localhost + Docker)\n\nChào mừng bạn đến với SubQuery Hello World quick start. Việc bắt đầu nhanh nhằm mục đích chỉ cho bạn cách bạn có được dự án khởi động mặc định chạy trong Docker trong một vài bước đơn giản.\n\n\n# Mục tiêu học tập\n\nKhi kết thúc phần quick start này, bạn sẽ:\n\n * hiểu các yêu cầu bắt buộc\n * hiểu các lệnh phổ biến cơ bản\n * có thể xem localhost: 3000 và xem playground\n * chạy một truy vấn đơn giản để lấy chiều cao khối của mạng chính Polkadot\n\n\n# Đối tượng mục tiêu\n\nHướng dẫn này hướng tới các nhà phát triển mới đã có một số kinh nghiệm phát triển và muốn tìm hiểu thêm về SubQuery.\n\n\n# Video hướng dẫn\n\n\n# Điều kiện tiên quyết\n\nBạn sẽ cần:\n\n * yarn or npm package manager\n * SubQuery CLI (@subql/cli)\n * Docker\n\nBạn có thể chạy các lệnh sau trong một thiết bị đầu cuối để xem liệu bạn đã có bất kỳ điều kiện tiên quyết nào trong số này chưa.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nĐối với người dùng nâng cao hơn, hãy sao chép và dán nội dung sau:\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\nĐiều này sẽ trả về: (đối với người dùng npm, thay thế yarn bằng npm)\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nNếu bạn đạt được những điều trên, thì bạn đã tốt để đi. Nếu không, hãy nhấp vào các liên kết sau để cài đặt chúng:\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# Bước 1: Khởi tạo dự án\n\nBước đầu tiên khi bắt đầu với SubQuery là chạy lệnh subql init. Hãy khởi tạo một dự án bắt đầu với tên subqlHelloWorld. Lưu ý rằng chỉ tác giả là bắt buộc. Mọi thứ khác được để trống bên dưới.\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nĐừng quên thay đổi thành thư mục mới này.\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# Bước 2: Cài đặt phần phụ thuộc\n\nBây giờ yarn hoặc node install để cài các phụ thuộc khác nhau.\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nVí dụ yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# Bước 3: Tạo mã\n\nBây giờ, hãy chạy yarn codegen để generate Typescript từ giản đồ GraphQL.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nVí dụ yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nCảnh báo Khi các thay đổi được thực hiện đối với tệp giản đồ, hãy nhớ chạy lại yarn codegen để tạo lại thư mục loại của bạn.\n\n\n# Bước 4: Build code\n\nBước tiếp theo là xây dựng mã với yarn build.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nVí dụ yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# Bước 5: Chạy Docker\n\nSử dụng Docker cho phép bạn chạy ví dụ này rất nhanh vì tất cả cơ sở hạ tầng cần thiết có thể được cung cấp trong hình ảnh Docker. Run docker-compose pull && docker-compose up.\n\nĐiều này sẽ thúc đẩy mọi thứ vào cuộc sống, nơi cuối cùng bạn sẽ nhận được các khối đang được nạp.\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# Bước 6: Duyệt qua playground\n\nVào trang web http://localhost:3000/ và dán truy vấn bên dưới vào bên trái màn hình rồi nhấn nút play.\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nSân chơi SubQuery trên localhost.\n\n\n\nSố khối trong playground cũng phải khớp với số khối (về mặt kỹ thuật là chiều cao khối) trong thiết bị đầu cuối.\n\n\n# Tóm lược\n\nTrong phần quick start này, chúng tôi đã trình bày các bước cơ bản để thiết lập và chạy một dự án mới bắt đầu trong môi trường Docker, sau đó điều hướng đến localhost: 3000 và chạy một truy vấn để trả về số khối của mạng Polkadot mainnet.',normalizedContent:'# hello world (localhost + docker)\n\nchao mung ban đen voi subquery hello world quick start. viec bat đau nhanh nham muc đich chi cho ban cach ban co đuoc du an khoi đong mac đinh chay trong docker trong mot vai buoc đon gian.\n\n\n# muc tieu hoc tap\n\nkhi ket thuc phan quick start nay, ban se:\n\n * hieu cac yeu cau bat buoc\n * hieu cac lenh pho bien co ban\n * co the xem localhost: 3000 va xem playground\n * chay mot truy van đon gian đe lay chieu cao khoi cua mang chinh polkadot\n\n\n# đoi tuong muc tieu\n\nhuong dan nay huong toi cac nha phat trien moi đa co mot so kinh nghiem phat trien va muon tim hieu them ve subquery.\n\n\n# video huong dan\n\n\n# đieu kien tien quyet\n\nban se can:\n\n * yarn or npm package manager\n * subquery cli (@subql/cli)\n * docker\n\nban co the chay cac lenh sau trong mot thiet bi đau cuoi đe xem lieu ban đa co bat ky đieu kien tien quyet nao trong so nay chua.\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\nđoi voi nguoi dung nang cao hon, hay sao chep va dan noi dung sau:\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\nđieu nay se tra ve: (đoi voi nguoi dung npm, thay the yarn bang npm)\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\nneu ban đat đuoc nhung đieu tren, thi ban đa tot đe đi. neu khong, hay nhap vao cac lien ket sau đe cai đat chung:\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# buoc 1: khoi tao du an\n\nbuoc đau tien khi bat đau voi subquery la chay lenh subql init. hay khoi tao mot du an bat đau voi ten subqlhelloworld. luu y rang chi tac gia la bat buoc. moi thu khac đuoc đe trong ben duoi.\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nđung quen thay đoi thanh thu muc moi nay.\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# buoc 2: cai đat phan phu thuoc\n\nbay gio yarn hoac node install đe cai cac phu thuoc khac nhau.\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nvi du yarn install\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# buoc 3: tao ma\n\nbay gio, hay chay yarn codegen đe generate typescript tu gian đo graphql.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nvi du yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\ncanh bao khi cac thay đoi đuoc thuc hien đoi voi tep gian đo, hay nho chay lai yarn codegen đe tao lai thu muc loai cua ban.\n\n\n# buoc 4: build code\n\nbuoc tiep theo la xay dung ma voi yarn build.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nvi du yarn build\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# buoc 5: chay docker\n\nsu dung docker cho phep ban chay vi du nay rat nhanh vi tat ca co so ha tang can thiet co the đuoc cung cap trong hinh anh docker. run docker-compose pull && docker-compose up.\n\nđieu nay se thuc đay moi thu vao cuoc song, noi cuoi cung ban se nhan đuoc cac khoi đang đuoc nap.\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# buoc 6: duyet qua playground\n\nvao trang web http://localhost:3000/ va dan truy van ben duoi vao ben trai man hinh roi nhan nut play.\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nsan choi subquery tren localhost.\n\n\n\nso khoi trong playground cung phai khop voi so khoi (ve mat ky thuat la chieu cao khoi) trong thiet bi đau cuoi.\n\n\n# tom luoc\n\ntrong phan quick start nay, chung toi đa trinh bay cac buoc co ban đe thiet lap va chay mot du an moi bat đau trong moi truong docker, sau đo đieu huong đen localhost: 3000 va chay mot truy van đe tra ve so khoi cua mang polkadot mainnet.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hướng dẫn nhanh",frontmatter:{summary:"Hướng dẫn nhanh Trong hướng dẫn Bắt đầu Nhanh này, chúng ta sẽ tạo một dự án khởi động đơn giản mà bạn có thể được sử dụng làm khuôn khổ để phát triển Dự án SubQuery cho chính mình",meta:[{property:"og:url",content:"/vi/quickstart/quickstart.html"},{property:"og:title",content:"Hướng dẫn nhanh"},{property:"og:description",content:"Hướng dẫn nhanh Trong hướng dẫn Bắt đầu Nhanh này, chúng ta sẽ tạo một dự án khởi động đơn giản mà bạn có thể được sử dụng làm khuôn khổ để phát triển Dự án SubQuery cho chính mình"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/quickstart/quickstart.html",relativePath:"vi/quickstart/quickstart.md",key:"v-3ac4ae1a",path:"/vi/quickstart/quickstart/",headers:[{level:2,title:"Sự chuẩn bị",slug:"su-chuan-bi",normalizedTitle:"su chuan bi",charIndex:429},{level:3,title:"Môi trường phát triển địa phương",slug:"moi-truong-phat-trien-đia-phuong",normalizedTitle:"moi truong phat trien đia phuong",charIndex:445},{level:3,title:"Cài đặt CLI SubQuery",slug:"cai-đat-cli-subquery",normalizedTitle:"cai đat cli subquery",charIndex:675},{level:2,title:"Khởi tạo Dự án SubQuery Starter",slug:"khoi-tao-du-an-subquery-starter",normalizedTitle:"khoi tao du an subquery starter",charIndex:1074},{level:2,title:"Định cấu hình và xây dựng dự án dành cho người mới bắt đầu",slug:"đinh-cau-hinh-va-xay-dung-du-an-danh-cho-nguoi-moi-bat-đau",normalizedTitle:"đinh cau hinh va xay dung du an danh cho nguoi moi bat đau",charIndex:2556},{level:3,title:"Tạo mô hình GraphQL",slug:"tao-mo-hinh-graphql",normalizedTitle:"tao mo hinh graphql",charIndex:3003},{level:2,title:"Xây dựng dự án",slug:"xay-dung-du-an",normalizedTitle:"xay dung du an",charIndex:3363},{level:2,title:"Chạy và truy vấn dự án khởi đầu của bạn",slug:"chay-va-truy-van-du-an-khoi-đau-cua-ban",normalizedTitle:"chay va truy van du an khoi đau cua ban",charIndex:3605},{level:3,title:"Chạy Dự án SubQuery của bạn",slug:"chay-du-an-subquery-cua-ban",normalizedTitle:"chay du an subquery cua ban",charIndex:3980},{level:3,title:"Truy vấn dự án của người dùng cá nhân",slug:"truy-van-du-an-cua-nguoi-dung-ca-nhan",normalizedTitle:"truy van du an cua nguoi dung ca nhan",charIndex:4517},{level:2,title:"Bước tiếp theo",slug:"buoc-tiep-theo",normalizedTitle:"buoc tiep theo",charIndex:5219}],readingTime:{minutes:5.5,words:1649},headersStr:"Sự chuẩn bị Môi trường phát triển địa phương Cài đặt CLI SubQuery Khởi tạo Dự án SubQuery Starter Định cấu hình và xây dựng dự án dành cho người mới bắt đầu Tạo mô hình GraphQL Xây dựng dự án Chạy và truy vấn dự án khởi đầu của bạn Chạy Dự án SubQuery của bạn Truy vấn dự án của người dùng cá nhân Bước tiếp theo",content:"# Hướng dẫn nhanh\n\nTrong hướng dẫn Bắt đầu Nhanh này, chúng ta sẽ tạo một dự án khởi động đơn giản mà bạn có thể được sử dụng làm khuôn khổ để phát triển Dự án SubQuery cho chính mình.\n\nỞ cuối hướng dẫn này, bạn sẽ có một dự án SubQuery đang hoạt động chạy trên nút SubQuery với điểm cuối GraphQL mà có thể truy vấn dữ liệu từ đó.\n\nNếu chưa có, chúng tôi khuyên bạn nên tự làm quen với thuật ngữ được sử dụng trong SubQuery.\n\n\n# Sự chuẩn bị\n\n\n# Môi trường phát triển địa phương\n\n * Chỉ định loại được yêu cầu để biên dịch dự án và xác định các loại.\n * Cả SubQuery CLI và Dự án đã tạo đều có phụ thuộc và yêu cầu phiên bản hiện đại Node.\n * SubQuery Nodes yêu cầu Docker\n\n\n# Cài đặt CLI SubQuery\n\nCài đặt SubQuery CLI trên toàn cầu trên thiết bị đầu cuối của bạn bằng cách sử dụng NPM:\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nXin lưu ý rằng chúng tôi KHÔNG khuyến khích sử dụng yarn toàn cầu do việc quản lý phụ thuộc kém có thể dẫn đến sai sót trong dây chuyền.\n\nSau đó, bạn có thể chạy trợ giúp để xem các lệnh có sẵn và cách sử dụng do CLI cung cấp\n\nsubql help\n\n\n1\n\n\n\n# Khởi tạo Dự án SubQuery Starter\n\nBên trong thư mục mà bạn muốn tạo một dự án SubQuery, chỉ cần thay thế PROJECT_NAME bằng của riêng bạn và chạy lệnh:\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\nBạn sẽ được hỏi một số câu hỏi nhất định khi dự án SubQuery được khởi động:\n\n * Kho lưu trữ Git (Tùy chọn): Cung cấp URL Git cho kho lưu trữ dự án SubQuery này (khi được lưu trữ trong SubQuery Explorer)\n * Điểm cuối RPC (Bắt buộc): Cung cấp URL wss tới điểm cuối RPC đang chạy sẽ được sử dụng theo mặc định cho dự án này. Bạn có thể nhanh chóng truy cập các điểm cuối công khai cho các mạng Polkadot khác nhau hoặc tạo nút chuyên dụng riêng của mình bằng cách sử dụng OnFinality hoặc chỉ điểm cuối Polkadot mặc định.\n * Tác giả (Bắt buộc): Nhập chủ sở hữu của dự án SubQuery này tại đây\n * Mô tả (Tùy chọn): Bạn có thể cung cấp một đoạn văn ngắn về dự án của mình, mô tả dự án chứa dữ liệu gì và người dùng có thể làm gì với dự án\n * Phiên bản (Bắt buộc): Nhập số phiên bản tùy chỉnh hoặc sử dụng giá trị mặc định (1.0.0)\n * Giấy phép (Bắt buộc): Cung cấp giấy phép phần mềm cho dự án này hoặc chấp nhận mặc định (Apache-2.0)\n\nSau khi quá trình khởi tạo hoàn tất, bạn sẽ thấy một thư mục có tên dự án của bạn đã được tạo bên trong thư mục. Nội dung của thư mục này phải giống với những gì được liệt kê trong Cấu trúc Thư mục.\n\nCuối cùng, trong thư mục dự án, chạy lệnh sau để cài đặt các phụ thuộc của dự án mới.\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# Định cấu hình và xây dựng dự án dành cho người mới bắt đầu\n\nTrong gói khởi động mà bạn vừa khởi tạo, chúng tôi đã cung cấp cấu hình tiêu chuẩn cho dự án mới của bạn. Bạn sẽ chủ yếu làm việc trên các tệp sau:\n\n * Tệp kê khai trong project.yaml\n * Lược đồ GraphQL trong schema.graphql\n * Các chức năng ánh xạ trong thư mục src/mappings/\n\nĐể biết thêm thông tin về cách viết SubQuery của riêng bạn, hãy xem tài liệu của chúng tôi trong Tạo dự án\n\n\n# Tạo mô hình GraphQL\n\nĐể lập chỉ mục dự án SubQuery của bạn, trước tiên bạn phải tạo các mô hình GraphQL bắt buộc mà bạn đã xác định trong tệp Sơ đồ GraphQL (schema.graphql). Chạy lệnh này trong thư mục gốc của thư mục dự án.\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nBạn sẽ tìm thấy các mô hình đã tạo trong thư mục /src/type/models\n\n\n# Xây dựng dự án\n\nĐể chạy Dự án SubQuery của bạn trên một Nút SubQuery được lưu trữ cục bộ, bạn cần phải xây dựng công việc của mình.\n\nChạy lệnh xây dựng từ thư mục gốc của dự án.\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# Chạy và truy vấn dự án khởi đầu của bạn\n\nMặc dù bạn có thể nhanh chóng xuất bản dự án mới của mình lên Dự án SubQuery và truy vấn bằng cách sử dụng Explorer của chúng tôi, cách dễ nhất để chạy các nút SubQuery cục bộ là trong vùng chứa Docker, nếu không có Docker, bạn có thể cài đặt nó từ docker.com.\n\nBỏ qua điều này và xuất bản dự án mới của bạn lên SubQuery Projects\n\n\n# Chạy Dự án SubQuery của bạn\n\nTất cả cấu hình kiểm soát cách chạy nút SubQuery được xác định trong tệp docker-comp.yml này. Đối với một dự án mới vừa được khởi tạo, bạn sẽ không cần phải thay đổi bất kỳ điều gì nhưng có thể đọc thêm về tệp và cài đặt trong phần Chạy dự án của chúng tôi\n\nTrong thư mục dự án chạy lệnh sau:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nCó thể mất một chút thời gian để tải xuống các gói bắt buộc (@subql/node, @subql/query và Postgres) lần đầu tiên nhưng bạn sẽ sớm thấy lỗi đang chạy Nút SubQuery.\n\n\n# Truy vấn dự án của người dùng cá nhân\n\nMở trình duyệt của bạn và truy cập http://localhost:3000.\n\nBạn sẽ thấy một sân chơi GraphQL đang hiển thị trong trình thám hiểm và các lược đồ đã sẵn sàng để truy vấn. Ở trên cùng bên phải của sân chơi, bạn sẽ tìm thấy nút Tài liệu sẽ mở bản vẽ tài liệu. Tài liệu này được tạo tự động và giúp bạn tìm thấy những thực thể và phương pháp nào bạn có thể truy vấn.\n\nĐối với dự án khởi động SubQuery mới, bạn có thể thử truy vấn sau để biết cách hoạt động của nó hoặc tìm hiểu thêm về ngôn ngữ Truy vấn GraphQL.\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# Bước tiếp theo\n\nXin chúc mừng, bạn hiện có một dự án SubQuery đang chạy cục bộ chấp nhận các yêu cầu API GraphQL cho dữ liệu mẫu. Trong hướng dẫn tiếp theo, chúng tôi sẽ chỉ cho bạn cách xuất bản dự án mới lên Dự án SubQuery và truy vấn nó bằng cách sử dụng Explorer của chúng tôi\n\nXuất bản dự án mới của bạn lên SubQuery Projects",normalizedContent:"# huong dan nhanh\n\ntrong huong dan bat đau nhanh nay, chung ta se tao mot du an khoi đong đon gian ma ban co the đuoc su dung lam khuon kho đe phat trien du an subquery cho chinh minh.\n\no cuoi huong dan nay, ban se co mot du an subquery đang hoat đong chay tren nut subquery voi điem cuoi graphql ma co the truy van du lieu tu đo.\n\nneu chua co, chung toi khuyen ban nen tu lam quen voi thuat ngu đuoc su dung trong subquery.\n\n\n# su chuan bi\n\n\n# moi truong phat trien đia phuong\n\n * chi đinh loai đuoc yeu cau đe bien dich du an va xac đinh cac loai.\n * ca subquery cli va du an đa tao đeu co phu thuoc va yeu cau phien ban hien đai node.\n * subquery nodes yeu cau docker\n\n\n# cai đat cli subquery\n\ncai đat subquery cli tren toan cau tren thiet bi đau cuoi cua ban bang cach su dung npm:\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\nxin luu y rang chung toi khong khuyen khich su dung yarn toan cau do viec quan ly phu thuoc kem co the dan đen sai sot trong day chuyen.\n\nsau đo, ban co the chay tro giup đe xem cac lenh co san va cach su dung do cli cung cap\n\nsubql help\n\n\n1\n\n\n\n# khoi tao du an subquery starter\n\nben trong thu muc ma ban muon tao mot du an subquery, chi can thay the project_name bang cua rieng ban va chay lenh:\n\nsubql init --starter project_name\n\n\n1\n\n\nban se đuoc hoi mot so cau hoi nhat đinh khi du an subquery đuoc khoi đong:\n\n * kho luu tru git (tuy chon): cung cap url git cho kho luu tru du an subquery nay (khi đuoc luu tru trong subquery explorer)\n * điem cuoi rpc (bat buoc): cung cap url wss toi điem cuoi rpc đang chay se đuoc su dung theo mac đinh cho du an nay. ban co the nhanh chong truy cap cac điem cuoi cong khai cho cac mang polkadot khac nhau hoac tao nut chuyen dung rieng cua minh bang cach su dung onfinality hoac chi điem cuoi polkadot mac đinh.\n * tac gia (bat buoc): nhap chu so huu cua du an subquery nay tai đay\n * mo ta (tuy chon): ban co the cung cap mot đoan van ngan ve du an cua minh, mo ta du an chua du lieu gi va nguoi dung co the lam gi voi du an\n * phien ban (bat buoc): nhap so phien ban tuy chinh hoac su dung gia tri mac đinh (1.0.0)\n * giay phep (bat buoc): cung cap giay phep phan mem cho du an nay hoac chap nhan mac đinh (apache-2.0)\n\nsau khi qua trinh khoi tao hoan tat, ban se thay mot thu muc co ten du an cua ban đa đuoc tao ben trong thu muc. noi dung cua thu muc nay phai giong voi nhung gi đuoc liet ke trong cau truc thu muc.\n\ncuoi cung, trong thu muc du an, chay lenh sau đe cai đat cac phu thuoc cua du an moi.\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# đinh cau hinh va xay dung du an danh cho nguoi moi bat đau\n\ntrong goi khoi đong ma ban vua khoi tao, chung toi đa cung cap cau hinh tieu chuan cho du an moi cua ban. ban se chu yeu lam viec tren cac tep sau:\n\n * tep ke khai trong project.yaml\n * luoc đo graphql trong schema.graphql\n * cac chuc nang anh xa trong thu muc src/mappings/\n\nđe biet them thong tin ve cach viet subquery cua rieng ban, hay xem tai lieu cua chung toi trong tao du an\n\n\n# tao mo hinh graphql\n\nđe lap chi muc du an subquery cua ban, truoc tien ban phai tao cac mo hinh graphql bat buoc ma ban đa xac đinh trong tep so đo graphql (schema.graphql). chay lenh nay trong thu muc goc cua thu muc du an.\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nban se tim thay cac mo hinh đa tao trong thu muc /src/type/models\n\n\n# xay dung du an\n\nđe chay du an subquery cua ban tren mot nut subquery đuoc luu tru cuc bo, ban can phai xay dung cong viec cua minh.\n\nchay lenh xay dung tu thu muc goc cua du an.\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\n\n# chay va truy van du an khoi đau cua ban\n\nmac du ban co the nhanh chong xuat ban du an moi cua minh len du an subquery va truy van bang cach su dung explorer cua chung toi, cach de nhat đe chay cac nut subquery cuc bo la trong vung chua docker, neu khong co docker, ban co the cai đat no tu docker.com.\n\nbo qua đieu nay va xuat ban du an moi cua ban len subquery projects\n\n\n# chay du an subquery cua ban\n\ntat ca cau hinh kiem soat cach chay nut subquery đuoc xac đinh trong tep docker-comp.yml nay. đoi voi mot du an moi vua đuoc khoi tao, ban se khong can phai thay đoi bat ky đieu gi nhung co the đoc them ve tep va cai đat trong phan chay du an cua chung toi\n\ntrong thu muc du an chay lenh sau:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nco the mat mot chut thoi gian đe tai xuong cac goi bat buoc (@subql/node, @subql/query va postgres) lan đau tien nhung ban se som thay loi đang chay nut subquery.\n\n\n# truy van du an cua nguoi dung ca nhan\n\nmo trinh duyet cua ban va truy cap http://localhost:3000.\n\nban se thay mot san choi graphql đang hien thi trong trinh tham hiem va cac luoc đo đa san sang đe truy van. o tren cung ben phai cua san choi, ban se tim thay nut tai lieu se mo ban ve tai lieu. tai lieu nay đuoc tao tu đong va giup ban tim thay nhung thuc the va phuong phap nao ban co the truy van.\n\nđoi voi du an khoi đong subquery moi, ban co the thu truy van sau đe biet cach hoat đong cua no hoac tim hieu them ve ngon ngu truy van graphql.\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# buoc tiep theo\n\nxin chuc mung, ban hien co mot du an subquery đang chay cuc bo chap nhan cac yeu cau api graphql cho du lieu mau. trong huong dan tiep theo, chung toi se chi cho ban cach xuat ban du an moi len du an subquery va truy van no bang cach su dung explorer cua chung toi\n\nxuat ban du an moi cua ban len subquery projects",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Giải thích Hello World",frontmatter:{summary:"Giải thích Hello World Trong hướng dẫn bắt đầu nhanh Hello World, chúng tôi đã chạy qua một số lệnh đơn giản và rất nhanh chóng có một ví dụ về thiết lập và chạy. Điều này cho phép",meta:[{property:"og:url",content:"/vi/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Giải thích Hello World"},{property:"og:description",content:"Giải thích Hello World Trong hướng dẫn bắt đầu nhanh Hello World, chúng tôi đã chạy qua một số lệnh đơn giản và rất nhanh chóng có một ví dụ về thiết lập và chạy. Điều này cho phép"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/quickstart/understanding-helloworld.html",relativePath:"vi/quickstart/understanding-helloworld.md",key:"v-7c7a576a",path:"/vi/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:424},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:1167},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:1988},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:2343},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:2596},{level:2,title:"Tóm lược",slug:"tom-luoc",normalizedTitle:"tom luoc",charIndex:3239}],readingTime:{minutes:3.82,words:1145},headersStr:"subql init yarn install yarn codegen yarn build docker-compose Tóm lược",content:'# Giải thích Hello World\n\nTrong hướng dẫn bắt đầu nhanh Hello World, chúng tôi đã chạy qua một số lệnh đơn giản và rất nhanh chóng có một ví dụ về thiết lập và chạy. Điều này cho phép bạn đảm bảo rằng bạn đã có sẵn tất cả các điều kiện tiên quyết và có thể sử dụng một sân chơi cục bộ để thực hiện một truy vấn đơn giản để lấy dữ liệu đầu tiên từ SubQuery. Ở đây, chúng ta xem xét kỹ hơn ý nghĩa của tất cả các lệnh đó.\n\n\n# subql init\n\nLệnh đầu tiên chúng tôi chạy là subql init --starter subqlHelloWorld.\n\nĐiều này tạo ra công việc nặng nhọc và một loạt các tệp cho bạn. Như đã lưu ý trong tài liệu chính thức, bạn chủ yếu sẽ làm việc trên các tệp sau:\n\n * Tệp kê khai trong project.yaml\n * Lược đồ GraphQL trong schema.graphql\n * Các chức năng ánh xạ trong thư mục src/mappings/\n\n\n\nNhững tệp này là cốt lõi của mọi thứ chúng tôi làm. Do đó, chúng tôi sẽ dành nhiều thời gian hơn cho các tệp này trong một bài viết khác. Mặc dù vậy, giờ bạn chỉ cần biết rằng lược đồ chứa mô tả dữ liệu mà người dùng có thể yêu cầu từ API SubQuery, tệp dự án yaml chứa các tham số kiểu "cấu hình" và tất nhiên là mappingHandlers chứa các typecript chứa các hàm biến đổi dữ liệu.\n\n\n# yarn install\n\nĐiều tiếp theo chúng tôi làm là yarn install. npm install cũng có thể được sử dụng.\n\n> Một bài học lịch sử ngắn. Node Package Manager hay npm lần đầu tiên được phát hành vào năm 2010 và là một trình quản lý gói cực kỳ phổ biến trong số các nhà phát triển JavaScript. Đây là gói mặc định được cài đặt tự động bất cứ khi nào bạn cài đặt Node.js trên hệ thống của mình. Yarn ban đầu được Facebook phát hành vào năm 2016 với mục đích giải quyết một số thiếu sót về hiệu suất và bảo mật khi làm việc với npm (tại thời điểm đó).\n\nNhững gì yarn làm là xem tệp package.json và tải xuống nhiều phần phụ thuộc khác. Khi nhìn vào tệp package.json, có vẻ như không có nhiều tệp phụ thuộc, nhưng khi bạn chạy lệnh sẽ thấy 18,983 tệp đã được thêm vào. Điều này là do mỗi phụ thuộc sẽ có các phụ thuộc riêng của nó.\n\n\n\n\n# yarn codegen\n\nSau đó, chúng tôi chạy mã tạo yarn hoặc npm run-script codegen. Điều này giúp tìm nạp giản đồ GraphQL (trong schema.graphql) và tạo các tệp mô hình typecript được liên kết (Do đó, các tệp đầu ra sẽ có phần mở rộng .ts). Bạn không bao giờ được thay đổi bất kỳ tệp nào trong số các tệp đã tạo này, chỉ thay đổi tệp schema.graphql nguồn.\n\n\n\n\n# yarn build\n\nSau đó, yarn build hoặc npm run-script build đã được thực thi. Điều này sẽ quen thuộc đối với các lập trình viên dày dạn kinh nghiệm. Nó tạo ra một thư mục phân phối thực hiện những việc như tối ưu hóa mã chuẩn bị cho việc triển khai.\n\n\n\n\n# docker-compose\n\nBước cuối cùng là lệnh docker kết hợp docker-compose kéo && docker-compose lên (cũng có thể chạy riêng). Lệnh pull lấy tất cả các hình ảnh cần thiết từ Docker Hub và lệnh up khởi động vùng chứa.\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nKhi vùng chứa được khởi động, bạn sẽ thấy thiết bị đầu cuối xuất ra rất nhiều văn bản hiển thị trạng thái của nút và công cụ GraphQL. Đó là khi bạn thấy:\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\nmà bạn biết rằng nút SubQuery đã bắt đầu đồng bộ hóa.\n\n\n# Tóm lược\n\nBây giờ bạn đã có một cái nhìn sâu sắc về những gì đang xảy ra bên dưới, câu hỏi đặt ra là bắt đầu từ đâu? Nếu bạn cảm thấy tự tin, bạn có thể bắt đầu tìm hiểu về cách tạo một dự án và tìm hiểu thêm về ba tệp chính. Tệp kê khai, lược đồ GraphQL và tệp ánh xạ.\n\nNếu không, hãy tiếp tục xem hướng dẫn, nơi chúng tôi xem xét cách có thể chạy ví dụ Hello World này trên cơ sở hạ tầng được lưu trữ của SubQuery, chúng tôi sẽ xem xét việc sửa đổi khối bắt đầu và sẽ đi sâu hơn về việc chạy các dự án SubQuery bằng cách chạy sẵn có và các dự án mã nguồn mở.',normalizedContent:'# giai thich hello world\n\ntrong huong dan bat đau nhanh hello world, chung toi đa chay qua mot so lenh đon gian va rat nhanh chong co mot vi du ve thiet lap va chay. đieu nay cho phep ban đam bao rang ban đa co san tat ca cac đieu kien tien quyet va co the su dung mot san choi cuc bo đe thuc hien mot truy van đon gian đe lay du lieu đau tien tu subquery. o đay, chung ta xem xet ky hon y nghia cua tat ca cac lenh đo.\n\n\n# subql init\n\nlenh đau tien chung toi chay la subql init --starter subqlhelloworld.\n\nđieu nay tao ra cong viec nang nhoc va mot loat cac tep cho ban. nhu đa luu y trong tai lieu chinh thuc, ban chu yeu se lam viec tren cac tep sau:\n\n * tep ke khai trong project.yaml\n * luoc đo graphql trong schema.graphql\n * cac chuc nang anh xa trong thu muc src/mappings/\n\n\n\nnhung tep nay la cot loi cua moi thu chung toi lam. do đo, chung toi se danh nhieu thoi gian hon cho cac tep nay trong mot bai viet khac. mac du vay, gio ban chi can biet rang luoc đo chua mo ta du lieu ma nguoi dung co the yeu cau tu api subquery, tep du an yaml chua cac tham so kieu "cau hinh" va tat nhien la mappinghandlers chua cac typecript chua cac ham bien đoi du lieu.\n\n\n# yarn install\n\nđieu tiep theo chung toi lam la yarn install. npm install cung co the đuoc su dung.\n\n> mot bai hoc lich su ngan. node package manager hay npm lan đau tien đuoc phat hanh vao nam 2010 va la mot trinh quan ly goi cuc ky pho bien trong so cac nha phat trien javascript. đay la goi mac đinh đuoc cai đat tu đong bat cu khi nao ban cai đat node.js tren he thong cua minh. yarn ban đau đuoc facebook phat hanh vao nam 2016 voi muc đich giai quyet mot so thieu sot ve hieu suat va bao mat khi lam viec voi npm (tai thoi điem đo).\n\nnhung gi yarn lam la xem tep package.json va tai xuong nhieu phan phu thuoc khac. khi nhin vao tep package.json, co ve nhu khong co nhieu tep phu thuoc, nhung khi ban chay lenh se thay 18,983 tep đa đuoc them vao. đieu nay la do moi phu thuoc se co cac phu thuoc rieng cua no.\n\n\n\n\n# yarn codegen\n\nsau đo, chung toi chay ma tao yarn hoac npm run-script codegen. đieu nay giup tim nap gian đo graphql (trong schema.graphql) va tao cac tep mo hinh typecript đuoc lien ket (do đo, cac tep đau ra se co phan mo rong .ts). ban khong bao gio đuoc thay đoi bat ky tep nao trong so cac tep đa tao nay, chi thay đoi tep schema.graphql nguon.\n\n\n\n\n# yarn build\n\nsau đo, yarn build hoac npm run-script build đa đuoc thuc thi. đieu nay se quen thuoc đoi voi cac lap trinh vien day dan kinh nghiem. no tao ra mot thu muc phan phoi thuc hien nhung viec nhu toi uu hoa ma chuan bi cho viec trien khai.\n\n\n\n\n# docker-compose\n\nbuoc cuoi cung la lenh docker ket hop docker-compose keo && docker-compose len (cung co the chay rieng). lenh pull lay tat ca cac hinh anh can thiet tu docker hub va lenh up khoi đong vung chua.\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\nkhi vung chua đuoc khoi đong, ban se thay thiet bi đau cuoi xuat ra rat nhieu van ban hien thi trang thai cua nut va cong cu graphql. đo la khi ban thay:\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\nma ban biet rang nut subquery đa bat đau đong bo hoa.\n\n\n# tom luoc\n\nbay gio ban đa co mot cai nhin sau sac ve nhung gi đang xay ra ben duoi, cau hoi đat ra la bat đau tu đau? neu ban cam thay tu tin, ban co the bat đau tim hieu ve cach tao mot du an va tim hieu them ve ba tep chinh. tep ke khai, luoc đo graphql va tep anh xa.\n\nneu khong, hay tiep tuc xem huong dan, noi chung toi xem xet cach co the chay vi du hello world nay tren co so ha tang đuoc luu tru cua subquery, chung toi se xem xet viec sua đoi khoi bat đau va se đi sau hon ve viec chay cac du an subquery bang cach chay san co va cac du an ma nguon mo.',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Chạy SubQuery trên môi trường local",frontmatter:{summary:"Chạy SubQuery trên môi trường local Hướng dẫn này sẽ chỉ dẫn cách khởi chạy một node SubQuery một cách cục bộ trên cơ sở hạ tầng của bạn, bao gồm cả trình lập index và dịch vụ truy",meta:[{property:"og:url",content:"/vi/run/run.html"},{property:"og:title",content:"Chạy SubQuery trên môi trường local"},{property:"og:description",content:"Chạy SubQuery trên môi trường local Hướng dẫn này sẽ chỉ dẫn cách khởi chạy một node SubQuery một cách cục bộ trên cơ sở hạ tầng của bạn, bao gồm cả trình lập index và dịch vụ truy"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/run/run.html",relativePath:"vi/run/run.md",key:"v-258149c3",path:"/vi/run/run/",headers:[{level:2,title:"Sử dụng Docker",slug:"su-dung-docker",normalizedTitle:"su dung docker",charIndex:430},{level:2,title:"Khởi chạy bộ lập chỉ mục (Indexer) (subql/node)",slug:"khoi-chay-bo-lap-chi-muc-indexer-subql-node",normalizedTitle:"khoi chay bo lap chi muc (indexer) (subql/node)",charIndex:925},{level:3,title:"Cài đặt",slug:"cai-đat",normalizedTitle:"cai đat",charIndex:1346},{level:3,title:"Các lệnh chính",slug:"cac-lenh-chinh",normalizedTitle:"cac lenh chinh",charIndex:1637},{level:2,title:"Khởi chạy Dịch vụ Truy vấn (subql/query)",slug:"khoi-chay-dich-vu-truy-van-subql-query",normalizedTitle:"khoi chay dich vu truy van (subql/query)",charIndex:4188},{level:3,title:"Cài đặt",slug:"cai-đat-2",normalizedTitle:"cai đat",charIndex:1346},{level:3,title:"Menjalankan layanan Kueri",slug:"menjalankan-layanan-kueri",normalizedTitle:"menjalankan layanan kueri",charIndex:4435}],readingTime:{minutes:4.4,words:1319},headersStr:"Sử dụng Docker Khởi chạy bộ lập chỉ mục (Indexer) (subql/node) Cài đặt Các lệnh chính Khởi chạy Dịch vụ Truy vấn (subql/query) Cài đặt Menjalankan layanan Kueri",content:"# Chạy SubQuery trên môi trường local\n\nHướng dẫn này sẽ chỉ dẫn cách khởi chạy một node SubQuery một cách cục bộ trên cơ sở hạ tầng của bạn, bao gồm cả trình lập index và dịch vụ truy vấn. Bạn không muốn phải lo lắng khi khởi chạy SubQuery trên môi trường của riêng mình? SubQuery cung cấp dịch vụ lưu trữ có quản lý miễn phí cho cộng đồng. Hãy làm theo hướng dẫn của chúng tôi để biết cách upload dự án của bạn lên SubQuery.\n\n\n# Sử dụng Docker\n\nMột giải pháp thay thế là chạy trên môi trường Docker Container được quy định bởi tệp docker-comp.yml. Đối với một dự án mới vừa được khởi tạo, bạn sẽ không cần phải thay đổi bất cứ điều gì trong đó.\n\nTrong thư mục dự án, hãy chạy lệnh sau:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nTrong lần đầu tiên có thể bạn sẽ mất chút thời gian để tải xuống các package cần thiết (@subql/node, @subql/query và Postgres), nhưng sau đó node SubQuery sẽ nhanh chóng được khởi chạy.\n\n\n# Khởi chạy bộ lập chỉ mục (Indexer) (subql/node)\n\nCần có:\n\n * Cơ sở dữ liệu Postgres (phiên bản 12 trở lên). Trong lúc node SubQuery đang lập index cho blockchain, dữ liệu trích xuất sẽ được lưu trữ trong một phiên bản cơ sở dữ liệu (database instance) bên ngoài.\n\nMột node SubQuery sẽ triển khai trích xuất dữ liệu blockchain dựa trên chất nền (substrate) cho mỗi dự án SubQuery và lưu nó vào cơ sở dữ liệu Postgres.\n\n\n# Cài đặt\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nXin lưu ý rằng chúng tôi KHÔNG khuyến khích sử dụng yarn global vì khâu quản lý phụ thuộc của nó rất kém, có thể dẫn đến sai sót trong dây chuyền.\n\nSau khi cài đặt, bạn có thể khởi chạy một node bằng lệnh sau:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Các lệnh chính\n\nCác lệnh sau sẽ hỗ trợ bạn hoàn thành việc cài đặt cấu hình cho node SubQuery và bắt đầu lập chỉ mục. Để tìm hiểu thêm, bạn có thể gõ lệnh --help.\n\n# Trỏ đến đường dẫn dự án trên môi trường local\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Sử dụng Từ điển\n\nViệc sử dụng từ điển đầy đủ cho blockchain có thể tăng tốc đáng kể thời gian xử lý dự án SubQuery trong quá trình thử nghiệm hoặc trong lần lập chỉ mục đầu tiên của bạn. Trong một số trường hợp, hiệu suất lập chỉ mục có thể tăng gấp 10 lần.\n\nBộ từ điển này sẽ lập sẵn đầy đủ chỉ mục về vị trí của tất cả các sự kiện và yếu tố ngoại vi (extrinsics) trong blockchain liên quan và cho phép dịch vụ node của bạn chuyển đến các vị trí hợp lý khi lập chỉ mục thay vì phải kiểm tra từng block.\n\nBạn có thể trực tiếp thêm điểm cuối (endpoint) của từ điển vào tệp project.yaml (xem Tệp kê khai (Manifest)) hoặc chỉ định điểm cuối tại thời điểm chạy bằng lệnh sau:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Kết nối với cơ sở dữ liệu\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\nTùy thuộc vào cấu hình cơ sở dữ liệu Postgres của bạn (ví dụ: có một mật khẩu cơ sở dữ liệu khác), hãy đảm bảo rằng cả trình lập chỉ mục (subql/node) và dịch vụ truy vấn (subql/query) đều có thể kết nối với CSDL ấy.\n\n# Chỉ định tệp cấu hình\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThao tác này sẽ trỏ node truy vấn đến tệp cấu hình có định dạng YAML hoặc JSON. Lihat contoh di bawah ini.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Thay đổi kích thước lô tìm nạp block\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nKhi chain được lập chỉ mục lần đầu tiên, việc tìm nạp (fetching) các block đơn lẻ sẽ làm giảm đáng kể hiệu suất. Phương thức tăng batch size để điều chỉnh số lượng block được tìm nạp sẽ giúp làm giảm thời gian xử lý tổng thể. Batch size mặc định hiện đang là 100.\n\n# Chế độ local\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nNgười dùng có thể để node chạy ở chế độ local nhằm phục vụ việc gỡ bug. Viêc chuyển sang chế độ local sẽ tạo các bảng Postgres trong sơ đồ công khai mặc định.\n\nNếu chế độ local không được sử dụng, một sơ đồ Postgres mới (với dữ liệu subquery_ ban đầu) và các bảng dự án tương ứng sẽ được khởi tạo.\n\n\n# Khởi chạy Dịch vụ Truy vấn (subql/query)\n\n\n# Cài đặt\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nXin lưu ý rằng chúng tôi KHÔNG khuyến khích sử dụng yarn global vì khâu quản lý phụ thuộc của nó rất kém, có thể dẫn đến sai sót trong dây chuyền.\n\n\n# Menjalankan layanan Kueri\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nĐảm bảo rằng tên dự án này trùng với tên bạn đã đặt từ lúc khởi tạo dự án. Ngoài ra, hãy kiểm tra xem các biến môi trường đã chuẩn hay chưa.\n\nSau khi chạy thành công dịch vụ truy vấn subql, hãy mở trình duyệt và truy cập địa chỉ http://localhost:3000. Bạn sẽ thấy một GraphQL Playground hiển thị trong trình duyệt với sơ đồ đã sẵn sàng để truy vấn.",normalizedContent:"# chay subquery tren moi truong local\n\nhuong dan nay se chi dan cach khoi chay mot node subquery mot cach cuc bo tren co so ha tang cua ban, bao gom ca trinh lap index va dich vu truy van. ban khong muon phai lo lang khi khoi chay subquery tren moi truong cua rieng minh? subquery cung cap dich vu luu tru co quan ly mien phi cho cong đong. hay lam theo huong dan cua chung toi đe biet cach upload du an cua ban len subquery.\n\n\n# su dung docker\n\nmot giai phap thay the la chay tren moi truong docker container đuoc quy đinh boi tep docker-comp.yml. đoi voi mot du an moi vua đuoc khoi tao, ban se khong can phai thay đoi bat cu đieu gi trong đo.\n\ntrong thu muc du an, hay chay lenh sau:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\ntrong lan đau tien co the ban se mat chut thoi gian đe tai xuong cac package can thiet (@subql/node, @subql/query va postgres), nhung sau đo node subquery se nhanh chong đuoc khoi chay.\n\n\n# khoi chay bo lap chi muc (indexer) (subql/node)\n\ncan co:\n\n * co so du lieu postgres (phien ban 12 tro len). trong luc node subquery đang lap index cho blockchain, du lieu trich xuat se đuoc luu tru trong mot phien ban co so du lieu (database instance) ben ngoai.\n\nmot node subquery se trien khai trich xuat du lieu blockchain dua tren chat nen (substrate) cho moi du an subquery va luu no vao co so du lieu postgres.\n\n\n# cai đat\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nxin luu y rang chung toi khong khuyen khich su dung yarn global vi khau quan ly phu thuoc cua no rat kem, co the dan đen sai sot trong day chuyen.\n\nsau khi cai đat, ban co the khoi chay mot node bang lenh sau:\n\nsubql-node <command>\n\n\n1\n\n\n\n# cac lenh chinh\n\ncac lenh sau se ho tro ban hoan thanh viec cai đat cau hinh cho node subquery va bat đau lap chi muc. đe tim hieu them, ban co the go lenh --help.\n\n# tro đen đuong dan du an tren moi truong local\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# su dung tu đien\n\nviec su dung tu đien đay đu cho blockchain co the tang toc đang ke thoi gian xu ly du an subquery trong qua trinh thu nghiem hoac trong lan lap chi muc đau tien cua ban. trong mot so truong hop, hieu suat lap chi muc co the tang gap 10 lan.\n\nbo tu đien nay se lap san đay đu chi muc ve vi tri cua tat ca cac su kien va yeu to ngoai vi (extrinsics) trong blockchain lien quan va cho phep dich vu node cua ban chuyen đen cac vi tri hop ly khi lap chi muc thay vi phai kiem tra tung block.\n\nban co the truc tiep them điem cuoi (endpoint) cua tu đien vao tep project.yaml (xem tep ke khai (manifest)) hoac chi đinh điem cuoi tai thoi điem chay bang lenh sau:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# ket noi voi co so du lieu\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\ntuy thuoc vao cau hinh co so du lieu postgres cua ban (vi du: co mot mat khau co so du lieu khac), hay đam bao rang ca trinh lap chi muc (subql/node) va dich vu truy van (subql/query) đeu co the ket noi voi csdl ay.\n\n# chi đinh tep cau hinh\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthao tac nay se tro node truy van đen tep cau hinh co đinh dang yaml hoac json. lihat contoh di bawah ini.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# thay đoi kich thuoc lo tim nap block\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nkhi chain đuoc lap chi muc lan đau tien, viec tim nap (fetching) cac block đon le se lam giam đang ke hieu suat. phuong thuc tang batch size đe đieu chinh so luong block đuoc tim nap se giup lam giam thoi gian xu ly tong the. batch size mac đinh hien đang la 100.\n\n# che đo local\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nnguoi dung co the đe node chay o che đo local nham phuc vu viec go bug. viec chuyen sang che đo local se tao cac bang postgres trong so đo cong khai mac đinh.\n\nneu che đo local khong đuoc su dung, mot so đo postgres moi (voi du lieu subquery_ ban đau) va cac bang du an tuong ung se đuoc khoi tao.\n\n\n# khoi chay dich vu truy van (subql/query)\n\n\n# cai đat\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nxin luu y rang chung toi khong khuyen khich su dung yarn global vi khau quan ly phu thuoc cua no rat kem, co the dan đen sai sot trong day chuyen.\n\n\n# menjalankan layanan kueri\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nđam bao rang ten du an nay trung voi ten ban đa đat tu luc khoi tao du an. ngoai ra, hay kiem tra xem cac bien moi truong đa chuan hay chua.\n\nsau khi chay thanh cong dich vu truy van subql, hay mo trinh duyet va truy cap đia chi http://localhost:3000. ban se thay mot graphql playground hien thi trong trinh duyet voi so đo đa san sang đe truy van.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Sandbox",frontmatter:{summary:"Sandbox Theo hình dung của chúng tôi về cách sử dụng, node SubQuery thường được chạy trên một máy chủ đáng tin cậy, còn mã nguồn của dự án SubQuery do người dùng gửi đến node thì l",meta:[{property:"og:url",content:"/vi/run/sandbox.html"},{property:"og:title",content:"Sandbox"},{property:"og:description",content:"Sandbox Theo hình dung của chúng tôi về cách sử dụng, node SubQuery thường được chạy trên một máy chủ đáng tin cậy, còn mã nguồn của dự án SubQuery do người dùng gửi đến node thì l"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/run/sandbox.html",relativePath:"vi/run/sandbox.md",key:"v-171babcb",path:"/vi/run/sandbox/",headers:[{level:2,title:"Hạn chế",slug:"han-che",normalizedTitle:"han che",charIndex:847}],readingTime:{minutes:1.17,words:352},headersStr:"Hạn chế",content:"# Sandbox\n\nTheo hình dung của chúng tôi về cách sử dụng, node SubQuery thường được chạy trên một máy chủ đáng tin cậy, còn mã nguồn của dự án SubQuery do người dùng gửi đến node thì lại không thể tin cậy tuyệt đối.\n\nMột số mã độc có khả năng tấn công hoặc thậm chí xâm phạm máy chủ và gây tổn hại tới dữ liệu của các dự án khác trong cùng máy chủ đó. Do đó, chúng tôi sử dụng cơ chế bảo mật sandbox VM2 để giảm thiểu rủi ro. Cơ chế Sandbox này có thể:\n\n * Khởi chạy những đoạn code có rủi ro một cách an toàn trong môi trường biệt lập, mã độc sẽ không thể truy cập vào mạng và hệ thống tệp của máy chủ lưu trữ trừ khi thông qua giao diện tiếp xúc mà chúng tôi đã đưa vào sandbox.\n\n * Gọi các phương thức, trao đổi dữ liệu và gọi lại function giữa các sandbox một cách an toàn.\n\n * Có khả năng miễn dịch với nhiều phương pháp tấn công đã biết.\n\n\n# Hạn chế\n\n * Để giới hạn quyền truy cập vào một số modul tích hợp sẵn, chỉ có modul assert, buffer, crypto,util và path mới được đưa vào danh sách trắng (whitelist).\n\n * Chúng tôi hỗ trợ các modul của bên thứ 3 được viết trong các thư viện CommonJS và lai (hybrid) như @polkadot/* (sử dụng ESM làm mặc định).\n\n * Bất kỳ modul nào sử dụng HTTP và WebSocket đều bị cấm.",normalizedContent:"# sandbox\n\ntheo hinh dung cua chung toi ve cach su dung, node subquery thuong đuoc chay tren mot may chu đang tin cay, con ma nguon cua du an subquery do nguoi dung gui đen node thi lai khong the tin cay tuyet đoi.\n\nmot so ma đoc co kha nang tan cong hoac tham chi xam pham may chu va gay ton hai toi du lieu cua cac du an khac trong cung may chu đo. do đo, chung toi su dung co che bao mat sandbox vm2 đe giam thieu rui ro. co che sandbox nay co the:\n\n * khoi chay nhung đoan code co rui ro mot cach an toan trong moi truong biet lap, ma đoc se khong the truy cap vao mang va he thong tep cua may chu luu tru tru khi thong qua giao dien tiep xuc ma chung toi đa đua vao sandbox.\n\n * goi cac phuong thuc, trao đoi du lieu va goi lai function giua cac sandbox mot cach an toan.\n\n * co kha nang mien dich voi nhieu phuong phap tan cong đa biet.\n\n\n# han che\n\n * đe gioi han quyen truy cap vao mot so modul tich hop san, chi co modul assert, buffer, crypto,util va path moi đuoc đua vao danh sach trang (whitelist).\n\n * chung toi ho tro cac modul cua ben thu 3 đuoc viet trong cac thu vien commonjs va lai (hybrid) nhu @polkadot/* (su dung esm lam mac đinh).\n\n * bat ky modul nao su dung http va websocket đeu bi cam.",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Làm cách nào để thay đổi kích thước lô tìm nạp blockchain?",frontmatter:{summary:"Làm cách nào để thay đổi kích thước lô tìm nạp blockchain? Video hướng dẫn Giới thiệu Kích thước lô mặc định là 100, nhưng điều này có thể được thay đổi bằng cách sử dụng lệnh bổ s",meta:[{property:"og:url",content:"/vi/tutorials_examples/batch-size.html"},{property:"og:title",content:"Làm cách nào để thay đổi kích thước lô tìm nạp blockchain?"},{property:"og:description",content:"Làm cách nào để thay đổi kích thước lô tìm nạp blockchain? Video hướng dẫn Giới thiệu Kích thước lô mặc định là 100, nhưng điều này có thể được thay đổi bằng cách sử dụng lệnh bổ s"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/tutorials_examples/batch-size.html",relativePath:"vi/tutorials_examples/batch-size.md",key:"v-d867fe9e",path:"/vi/tutorials_examples/batch-size/",headers:[{level:2,title:"Video hướng dẫn",slug:"video-huong-dan",normalizedTitle:"video huong dan",charIndex:65},{level:2,title:"Giới thiệu",slug:"gioi-thieu",normalizedTitle:"gioi thieu",charIndex:85},{level:2,title:"Tại sao phải thay đổi kích thước lô?",slug:"tai-sao-phai-thay-đoi-kich-thuoc-lo",normalizedTitle:"tai sao phai thay đoi kich thuoc lo?",charIndex:779}],readingTime:{minutes:.75,words:226},headersStr:"Video hướng dẫn Giới thiệu Tại sao phải thay đổi kích thước lô?",content:'# Làm cách nào để thay đổi kích thước lô tìm nạp blockchain?\n\n\n# Video hướng dẫn\n\n\n# Giới thiệu\n\nKích thước lô mặc định là 100, nhưng điều này có thể được thay đổi bằng cách sử dụng lệnh bổ sung --batch-size = xx.\n\nBạn cần làm điều này bằng dòng lệnh như một cờ bổ sung hoặc nếu bạn đang sử dụng Docker, hãy sửa đổi docker-compos.yml thành:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nVí dụ này đặt kích thước lô thành 50.\n\n\n# Tại sao phải thay đổi kích thước lô?\n\nViệc sử dụng kích thước lô nhỏ hơn có thể làm giảm mức sử dụng bộ nhớ và không khiến người dùng bị treo cho các truy vấn lớn. Nói cách khác, ứng dụng của bạn có thể phản hồi nhanh hơn.',normalizedContent:'# lam cach nao đe thay đoi kich thuoc lo tim nap blockchain?\n\n\n# video huong dan\n\n\n# gioi thieu\n\nkich thuoc lo mac đinh la 100, nhung đieu nay co the đuoc thay đoi bang cach su dung lenh bo sung --batch-size = xx.\n\nban can lam đieu nay bang dong lenh nhu mot co bo sung hoac neu ban đang su dung docker, hay sua đoi docker-compos.yml thanh:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nvi du nay đat kich thuoc lo thanh 50.\n\n\n# tai sao phai thay đoi kich thuoc lo?\n\nviec su dung kich thuoc lo nho hon co the lam giam muc su dung bo nho va khong khien nguoi dung bi treo cho cac truy van lon. noi cach khac, ung dung cua ban co the phan hoi nhanh hon.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Làm thế nào để bắt đầu ở một block height khác?",frontmatter:{summary:"Làm thế nào để bắt đầu ở một block height khác? Video hướng dẫn Giới thiệu Theo mặc định, tất cả các dự án khởi động bắt đầu đồng bộ hóa chuỗi khối từ khối khởi đầu. Nói cách khác,",meta:[{property:"og:url",content:"/vi/tutorials_examples/block-height.html"},{property:"og:title",content:"Làm thế nào để bắt đầu ở một block height khác?"},{property:"og:description",content:"Làm thế nào để bắt đầu ở một block height khác? Video hướng dẫn Giới thiệu Theo mặc định, tất cả các dự án khởi động bắt đầu đồng bộ hóa chuỗi khối từ khối khởi đầu. Nói cách khác,"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/tutorials_examples/block-height.html",relativePath:"vi/tutorials_examples/block-height.md",key:"v-20b229cb",path:"/vi/tutorials_examples/block-height/",headers:[{level:2,title:"Video hướng dẫn",slug:"video-huong-dan",normalizedTitle:"video huong dan",charIndex:54},{level:2,title:"Giới thiệu",slug:"gioi-thieu",normalizedTitle:"gioi thieu",charIndex:74},{level:2,title:"Tại sao không bắt đầu từ con số không?",slug:"tai-sao-khong-bat-đau-tu-con-so-khong",normalizedTitle:"tai sao khong bat đau tu con so khong?",charIndex:984},{level:2,title:"Hạn chế của việc không bắt đầu từ con số 0 là gì?",slug:"han-che-cua-viec-khong-bat-đau-tu-con-so-0-la-gi",normalizedTitle:"han che cua viec khong bat đau tu con so 0 la gi?",charIndex:1315},{level:2,title:"Làm thế nào để tìm ra chiều cao blockchain hiện tại?",slug:"lam-the-nao-đe-tim-ra-chieu-cao-blockchain-hien-tai",normalizedTitle:"lam the nao đe tim ra chieu cao blockchain hien tai?",charIndex:1477},{level:2,title:"Tôi có phải xây dựng lại hoặc tạo mã không?",slug:"toi-co-phai-xay-dung-lai-hoac-tao-ma-khong",normalizedTitle:"toi co phai xay dung lai hoac tao ma khong?",charIndex:1668}],readingTime:{minutes:1.62,words:487},headersStr:"Video hướng dẫn Giới thiệu Tại sao không bắt đầu từ con số không? Hạn chế của việc không bắt đầu từ con số 0 là gì? Làm thế nào để tìm ra chiều cao blockchain hiện tại? Tôi có phải xây dựng lại hoặc tạo mã không?",content:'# Làm thế nào để bắt đầu ở một block height khác?\n\n\n# Video hướng dẫn\n\n\n# Giới thiệu\n\nTheo mặc định, tất cả các dự án khởi động bắt đầu đồng bộ hóa chuỗi khối từ khối khởi đầu. Nói cách khác, từ khối 1. Đối với các blockchains lớn, điều này thường có thể mất vài ngày hoặc thậm chí vài tuần để đồng bộ hóa hoàn toàn.\n\nĐể bắt đầu đồng bộ hóa nút SubQuery từ height khác 0, tất cả những gì bạn phải làm là sửa đổi tệp project.yaml của mình và thay đổi khóa startBlock.\n\nDưới đây là tệp project.yaml trong đó khối bắt đầu đã được đặt thành 1.000.000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Tại sao không bắt đầu từ con số không?\n\nLý do chính là nó có thể giảm thời gian đồng bộ hóa blockchain. Điều này có nghĩa là nếu bạn chỉ quan tâm đến các giao dịch trong 3 tháng gần nhất, bạn chỉ có thể đồng bộ hóa giá trị 3 tháng gần nhất nghĩa là thời gian chờ đợi ít hơn và bạn có thể bắt đầu phát triển của mình nhanh hơn.\n\n\n# Hạn chế của việc không bắt đầu từ con số 0 là gì?\n\nHạn chế rõ ràng nhất sẽ là bạn sẽ không thể truy vấn dữ liệu trên blockchain cho các khối mà bạn không có.\n\n\n# Làm thế nào để tìm ra chiều cao blockchain hiện tại?\n\nNếu bạn đang sử dụng mạng Polkadot, bạn có thể truy cập https://polkascan.io/ , chọn mạng và sau đó xem hình "Khối được hoàn thiện".\n\n\n# Tôi có phải xây dựng lại hoặc tạo mã không?\n\nKhông. Bởi vì bạn đang sửa đổi tệp project.yaml, về cơ bản là tệp cấu hình, bạn sẽ không phải xây dựng lại hoặc tạo lại mã typecript.',normalizedContent:'# lam the nao đe bat đau o mot block height khac?\n\n\n# video huong dan\n\n\n# gioi thieu\n\ntheo mac đinh, tat ca cac du an khoi đong bat đau đong bo hoa chuoi khoi tu khoi khoi đau. noi cach khac, tu khoi 1. đoi voi cac blockchains lon, đieu nay thuong co the mat vai ngay hoac tham chi vai tuan đe đong bo hoa hoan toan.\n\nđe bat đau đong bo hoa nut subquery tu height khac 0, tat ca nhung gi ban phai lam la sua đoi tep project.yaml cua minh va thay đoi khoa startblock.\n\nduoi đay la tep project.yaml trong đo khoi bat đau đa đuoc đat thanh 1.000.000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# tai sao khong bat đau tu con so khong?\n\nly do chinh la no co the giam thoi gian đong bo hoa blockchain. đieu nay co nghia la neu ban chi quan tam đen cac giao dich trong 3 thang gan nhat, ban chi co the đong bo hoa gia tri 3 thang gan nhat nghia la thoi gian cho đoi it hon va ban co the bat đau phat trien cua minh nhanh hon.\n\n\n# han che cua viec khong bat đau tu con so 0 la gi?\n\nhan che ro rang nhat se la ban se khong the truy van du lieu tren blockchain cho cac khoi ma ban khong co.\n\n\n# lam the nao đe tim ra chieu cao blockchain hien tai?\n\nneu ban đang su dung mang polkadot, ban co the truy cap https://polkascan.io/ , chon mang va sau đo xem hinh "khoi đuoc hoan thien".\n\n\n# toi co phai xay dung lai hoac tao ma khong?\n\nkhong. boi vi ban đang sua đoi tep project.yaml, ve co ban la tep cau hinh, ban se khong phai xay dung lai hoac tao lai ma typecript.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Làm thế nào để gỡ lỗi một dự án SubQuery?",frontmatter:{summary:"Làm thế nào để gỡ lỗi một dự án SubQuery? Video hướng dẫn Giới thiệu Để gỡ lỗi các dự án SubQuery, chẳng hạn như bước qua mã, đặt điểm ngắt và kiểm tra các biến, bạn sẽ phải sử dụn",meta:[{property:"og:url",content:"/vi/tutorials_examples/debug-projects.html"},{property:"og:title",content:"Làm thế nào để gỡ lỗi một dự án SubQuery?"},{property:"og:description",content:"Làm thế nào để gỡ lỗi một dự án SubQuery? Video hướng dẫn Giới thiệu Để gỡ lỗi các dự án SubQuery, chẳng hạn như bước qua mã, đặt điểm ngắt và kiểm tra các biến, bạn sẽ phải sử dụn"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/tutorials_examples/debug-projects.html",relativePath:"vi/tutorials_examples/debug-projects.md",key:"v-e87d849e",path:"/vi/tutorials_examples/debug-projects/",headers:[{level:2,title:"Video hướng dẫn",slug:"video-huong-dan",normalizedTitle:"video huong dan",charIndex:48},{level:2,title:"Giới thiệu",slug:"gioi-thieu",normalizedTitle:"gioi thieu",charIndex:68},{level:2,title:"Node inspector",slug:"node-inspector",normalizedTitle:"node inspector",charIndex:276},{level:2,title:"Chrome devtools",slug:"chrome-devtools",normalizedTitle:"chrome devtools",charIndex:696}],readingTime:{minutes:.99,words:297},headersStr:"Video hướng dẫn Giới thiệu Node inspector Chrome devtools",content:"# Làm thế nào để gỡ lỗi một dự án SubQuery?\n\n\n# Video hướng dẫn\n\n\n# Giới thiệu\n\nĐể gỡ lỗi các dự án SubQuery, chẳng hạn như bước qua mã, đặt điểm ngắt và kiểm tra các biến, bạn sẽ phải sử dụng trình kiểm tra Node.js kết hợp với các công cụ dành cho nhà phát triển Chrome.\n\n\n# Node inspector\n\nChạy lệnh sau trong màn hình đầu cuối.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nVí dụ:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nĐang nghe trình gỡ lỗi ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nĐể được trợ giúp, hãy xem: https://nodejs.org/en/docs/ins Inspector\nĐã đính kèm trình gỡ lỗi.\n\n\n1\n2\n3\n4\n\n\n\n# Chrome devtools\n\nMở Chrome DevTools và điều hướng đến tab Sources. Lưu ý rằng nhấp vào biểu tượng màu xanh lá cây sẽ mở ra một cửa sổ mới.\n\n\n\nĐiều hướng đến Filesystem và thêm thư mục dự án của bạn vào không gian làm việc. Sau đó, mở dist > thư mục ánh xạ và chọn mã bạn muốn gỡ lỗi. Sau đó, bước qua mã như với bất kỳ công cụ gỡ lỗi tiêu chuẩn nào.\n\n",normalizedContent:"# lam the nao đe go loi mot du an subquery?\n\n\n# video huong dan\n\n\n# gioi thieu\n\nđe go loi cac du an subquery, chang han nhu buoc qua ma, đat điem ngat va kiem tra cac bien, ban se phai su dung trinh kiem tra node.js ket hop voi cac cong cu danh cho nha phat trien chrome.\n\n\n# node inspector\n\nchay lenh sau trong man hinh đau cuoi.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nvi du:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\nđang nghe trinh go loi ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nđe đuoc tro giup, hay xem: https://nodejs.org/en/docs/ins inspector\nđa đinh kem trinh go loi.\n\n\n1\n2\n3\n4\n\n\n\n# chrome devtools\n\nmo chrome devtools va đieu huong đen tab sources. luu y rang nhap vao bieu tuong mau xanh la cay se mo ra mot cua so moi.\n\n\n\nđieu huong đen filesystem va them thu muc du an cua ban vao khong gian lam viec. sau đo, mo dist > thu muc anh xa va chon ma ban muon go loi. sau đo, buoc qua ma nhu voi bat ky cong cu go loi tieu chuan nao.\n\n",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Từ điển SubQuery hoạt động như thế nào?",frontmatter:{summary:"Từ điển SubQuery hoạt động như thế nào? Toàn bộ ý tưởng của một dự án từ điển chung là lập chỉ mục tất cả dữ liệu từ một chuỗi khối và ghi lại các sự kiện, ngoại diên và các loại c",meta:[{property:"og:url",content:"/vi/tutorials_examples/dictionary.html"},{property:"og:title",content:"Từ điển SubQuery hoạt động như thế nào?"},{property:"og:description",content:"Từ điển SubQuery hoạt động như thế nào? Toàn bộ ý tưởng của một dự án từ điển chung là lập chỉ mục tất cả dữ liệu từ một chuỗi khối và ghi lại các sự kiện, ngoại diên và các loại c"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/tutorials_examples/dictionary.html",relativePath:"vi/tutorials_examples/dictionary.md",key:"v-6f44406d",path:"/vi/tutorials_examples/dictionary/",headers:[{level:2,title:"Làm thế nào để kết hợp một từ điển vào dự án của bạn?",slug:"lam-the-nao-đe-ket-hop-mot-tu-đien-vao-du-an-cua-ban",normalizedTitle:"lam the nao đe ket hop mot tu đien vao du an cua ban?",charIndex:1011},{level:2,title:"Điều gì xảy ra khi từ điển KHÔNG được sử dụng?",slug:"đieu-gi-xay-ra-khi-tu-đien-khong-đuoc-su-dung",normalizedTitle:"đieu gi xay ra khi tu đien khong đuoc su dung?",charIndex:1335},{level:2,title:"Điều gì xảy ra khi sử dụng từ điển?",slug:"đieu-gi-xay-ra-khi-su-dung-tu-đien",normalizedTitle:"đieu gi xay ra khi su dung tu đien?",charIndex:1751},{level:2,title:"Khi nào một từ điển KHÔNG hữu ích?",slug:"khi-nao-mot-tu-đien-khong-huu-ich",normalizedTitle:"khi nao mot tu đien khong huu ich?",charIndex:2887}],readingTime:{minutes:3.5,words:1049},headersStr:"Làm thế nào để kết hợp một từ điển vào dự án của bạn? Điều gì xảy ra khi từ điển KHÔNG được sử dụng? Điều gì xảy ra khi sử dụng từ điển? Khi nào một từ điển KHÔNG hữu ích?",content:'# Từ điển SubQuery hoạt động như thế nào?\n\nToàn bộ ý tưởng của một dự án từ điển chung là lập chỉ mục tất cả dữ liệu từ một chuỗi khối và ghi lại các sự kiện, ngoại diên và các loại của nó (mô-đun và phương pháp) trong cơ sở dữ liệu theo thứ tự chiều cao của khối. Sau đó, một dự án khác có thể truy vấn điểm cuối network.dictionary này thay vì network.endpoint mặc định được xác định trong tệp kê khai.\n\nĐiểm cuối network.dictionary là một tham số tùy chọn mà nếu có, SDK sẽ tự động phát hiện và sử dụng. network.endpoint là bắt buộc và sẽ không biên dịch nếu không có.\n\nLấy dự án từ điển SubQuery làm ví dụ, tệp schema xác định 3 thực thể; bên ngoài, sự kiện, specVersion. 3 thực thể này lần lượt chứa 6, 4 và 2 trường. Khi dự án này được chạy, các trường này được phản ánh trong các bảng cơ sở dữ liệu.\n\n\n\nDữ liệu từ blockchain sau đó được lưu trữ trong các bảng này và được lập chỉ mục cho hiệu suất. Sau đó, dự án được lưu trữ trong Dự án SubQuery và điểm cuối API có sẵn để được thêm vào tệp kê khai.\n\n\n# Làm thế nào để kết hợp một từ điển vào dự án của bạn?\n\nThêm dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot vào phần mạng của tệp kê khai. Ví dụ:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# Điều gì xảy ra khi từ điển KHÔNG được sử dụng?\n\nKhi KHÔNG sử dụng từ điển, trình lập chỉ mục sẽ tìm nạp mọi dữ liệu khối thông qua api polkadot theo cờ batch-size là 100 theo mặc định và đặt nó vào bộ đệm để xử lý. Sau đó, trình lập chỉ mục lấy tất cả các khối này từ bộ đệm và trong khi xử lý dữ liệu khối, kiểm tra xem sự kiện và nội tại trong các khối này có khớp với bộ lọc do người dùng xác định hay không.\n\n\n# Điều gì xảy ra khi sử dụng từ điển?\n\nKhi từ điển được sử dụng, trình lập chỉ mục trước tiên sẽ lấy bộ lọc cuộc gọi và sự kiện làm tham số và hợp nhất nó thành một truy vấn GraphQL. Sau đó, nó sử dụng API của từ điển để lấy danh sách các chiều cao khối có liên quan chỉ chứa các sự kiện và ngoại diên cụ thể. Thường thì giá trị này về cơ bản nhỏ hơn 100 nếu sử dụng mặc định.\n\nVí dụ: hãy tưởng tượng một tình huống mà bạn đang lập chỉ mục các sự kiện chuyển giao. Không phải tất cả các khối đều có sự kiện này (trong hình bên dưới không có sự kiện chuyển giao ở khối 3 và 4).\n\n\n\nTừ điển cho phép dự án của bạn bỏ qua điều này, vì vậy thay vì tìm kiếm từng khối để tìm sự kiện chuyển giao, nó sẽ bỏ qua chỉ các khối 1, 2 và 5. Điều này là do từ điển là một tham chiếu được tính toán trước cho tất cả các cuộc gọi và sự kiện trong mỗi khối.\n\nĐiều này có nghĩa là việc sử dụng từ điển có thể giảm lượng dữ liệu mà trình lập chỉ mục thu được từ chuỗi và giảm số lượng khối "không mong muốn" được lưu trữ trong bộ đệm cục bộ. Nhưng so với phương pháp truyền thống, phương pháp này bổ sung thêm một bước để lấy dữ liệu từ API của từ điển.\n\n\n# Khi nào một từ điển KHÔNG hữu ích?\n\nKhi block handlers được sử dụng để lấy dữ liệu từ một chuỗi, mọi khối cần được xử lý. Do đó, việc sử dụng từ điển trong trường hợp này không mang lại bất kỳ lợi thế nào và trình lập chỉ mục sẽ tự động chuyển sang cách tiếp cận không dùng từ điển mặc định.\n\nNgoài ra, khi xử lý các sự kiện hoặc nội tại xảy ra hoặc tồn tại trong mọi khối như timestamp.set, việc sử dụng từ điển sẽ không mang lại bất kỳ lợi thế nào.',normalizedContent:'# tu đien subquery hoat đong nhu the nao?\n\ntoan bo y tuong cua mot du an tu đien chung la lap chi muc tat ca du lieu tu mot chuoi khoi va ghi lai cac su kien, ngoai dien va cac loai cua no (mo-đun va phuong phap) trong co so du lieu theo thu tu chieu cao cua khoi. sau đo, mot du an khac co the truy van điem cuoi network.dictionary nay thay vi network.endpoint mac đinh đuoc xac đinh trong tep ke khai.\n\nđiem cuoi network.dictionary la mot tham so tuy chon ma neu co, sdk se tu đong phat hien va su dung. network.endpoint la bat buoc va se khong bien dich neu khong co.\n\nlay du an tu đien subquery lam vi du, tep schema xac đinh 3 thuc the; ben ngoai, su kien, specversion. 3 thuc the nay lan luot chua 6, 4 va 2 truong. khi du an nay đuoc chay, cac truong nay đuoc phan anh trong cac bang co so du lieu.\n\n\n\ndu lieu tu blockchain sau đo đuoc luu tru trong cac bang nay va đuoc lap chi muc cho hieu suat. sau đo, du an đuoc luu tru trong du an subquery va điem cuoi api co san đe đuoc them vao tep ke khai.\n\n\n# lam the nao đe ket hop mot tu đien vao du an cua ban?\n\nthem dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot vao phan mang cua tep ke khai. vi du:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# đieu gi xay ra khi tu đien khong đuoc su dung?\n\nkhi khong su dung tu đien, trinh lap chi muc se tim nap moi du lieu khoi thong qua api polkadot theo co batch-size la 100 theo mac đinh va đat no vao bo đem đe xu ly. sau đo, trinh lap chi muc lay tat ca cac khoi nay tu bo đem va trong khi xu ly du lieu khoi, kiem tra xem su kien va noi tai trong cac khoi nay co khop voi bo loc do nguoi dung xac đinh hay khong.\n\n\n# đieu gi xay ra khi su dung tu đien?\n\nkhi tu đien đuoc su dung, trinh lap chi muc truoc tien se lay bo loc cuoc goi va su kien lam tham so va hop nhat no thanh mot truy van graphql. sau đo, no su dung api cua tu đien đe lay danh sach cac chieu cao khoi co lien quan chi chua cac su kien va ngoai dien cu the. thuong thi gia tri nay ve co ban nho hon 100 neu su dung mac đinh.\n\nvi du: hay tuong tuong mot tinh huong ma ban đang lap chi muc cac su kien chuyen giao. khong phai tat ca cac khoi đeu co su kien nay (trong hinh ben duoi khong co su kien chuyen giao o khoi 3 va 4).\n\n\n\ntu đien cho phep du an cua ban bo qua đieu nay, vi vay thay vi tim kiem tung khoi đe tim su kien chuyen giao, no se bo qua chi cac khoi 1, 2 va 5. đieu nay la do tu đien la mot tham chieu đuoc tinh toan truoc cho tat ca cac cuoc goi va su kien trong moi khoi.\n\nđieu nay co nghia la viec su dung tu đien co the giam luong du lieu ma trinh lap chi muc thu đuoc tu chuoi va giam so luong khoi "khong mong muon" đuoc luu tru trong bo đem cuc bo. nhung so voi phuong phap truyen thong, phuong phap nay bo sung them mot buoc đe lay du lieu tu api cua tu đien.\n\n\n# khi nao mot tu đien khong huu ich?\n\nkhi block handlers đuoc su dung đe lay du lieu tu mot chuoi, moi khoi can đuoc xu ly. do đo, viec su dung tu đien trong truong hop nay khong mang lai bat ky loi the nao va trinh lap chi muc se tu đong chuyen sang cach tiep can khong dung tu đien mac đinh.\n\nngoai ra, khi xu ly cac su kien hoac noi tai xay ra hoac ton tai trong moi khoi nhu timestamp.set, viec su dung tu đien se khong mang lai bat ky loi the nao.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hướng dẫn",frontmatter:{summary:"Hướng dẫn Làm sao để bắt đầu tại một block khác với mặc định? Video hướng dẫn Giới thiệu Theo mặc định, tất cả các dự án khởi động bắt đầu đồng bộ hóa blockchain từ khối nguyên thủ",meta:[{property:"og:url",content:"/vi/tutorials_examples/howto.html"},{property:"og:title",content:"Hướng dẫn"},{property:"og:description",content:"Hướng dẫn Làm sao để bắt đầu tại một block khác với mặc định? Video hướng dẫn Giới thiệu Theo mặc định, tất cả các dự án khởi động bắt đầu đồng bộ hóa blockchain từ khối nguyên thủ"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/tutorials_examples/howto.html",relativePath:"vi/tutorials_examples/howto.md",key:"v-131f5d4d",path:"/vi/tutorials_examples/howto/",headers:[{level:2,title:"Làm sao để bắt đầu tại một block khác với mặc định?",slug:"lam-sao-đe-bat-đau-tai-mot-block-khac-voi-mac-đinh",normalizedTitle:"lam sao đe bat đau tai mot block khac voi mac đinh?",charIndex:16},{level:3,title:"Video hướng dẫn",slug:"video-huong-dan",normalizedTitle:"video huong dan",charIndex:72},{level:3,title:"Giới thiệu",slug:"gioi-thieu",normalizedTitle:"gioi thieu",charIndex:92},{level:3,title:"Tại sao lại không bắt đầu từ block 0?",slug:"tai-sao-lai-khong-bat-đau-tu-block-0",normalizedTitle:"tai sao lai khong bat đau tu block 0?",charIndex:1040},{level:3,title:"Hạn chế của việc này là gì?",slug:"han-che-cua-viec-nay-la-gi",normalizedTitle:"han che cua viec nay la gi?",charIndex:1409},{level:3,title:"Làm sao để biết blockchain hiện đang có nấc độ cao là bao nhiêu?",slug:"lam-sao-đe-biet-blockchain-hien-đang-co-nac-đo-cao-la-bao-nhieu",normalizedTitle:"lam sao đe biet blockchain hien đang co nac đo cao la bao nhieu?",charIndex:1554},{level:3,title:"Tôi có cần xây dựng hoặc tạo lại code không?",slug:"toi-co-can-xay-dung-hoac-tao-lai-code-khong",normalizedTitle:"toi co can xay dung hoac tao lai code khong?",charIndex:1762},{level:2,title:"Làm cách nào để thay đổi kích thước lô (batch size) khi tìm nạp blockchain?",slug:"lam-cach-nao-đe-thay-đoi-kich-thuoc-lo-batch-size-khi-tim-nap-blockchain",normalizedTitle:"lam cach nao đe thay đoi kich thuoc lo (batch size) khi tim nap blockchain?",charIndex:1961},{level:3,title:"Video hướng dẫn",slug:"video-huong-dan-2",normalizedTitle:"video huong dan",charIndex:72},{level:3,title:"Giới thiệu",slug:"gioi-thieu-2",normalizedTitle:"gioi thieu",charIndex:92},{level:3,title:"Tại sao lại cần thay đổi batch size?",slug:"tai-sao-lai-can-thay-đoi-batch-size",normalizedTitle:"tai sao lai can thay đoi batch size?",charIndex:2770}],readingTime:{minutes:2.72,words:815},headersStr:"Làm sao để bắt đầu tại một block khác với mặc định? Video hướng dẫn Giới thiệu Tại sao lại không bắt đầu từ block 0? Hạn chế của việc này là gì? Làm sao để biết blockchain hiện đang có nấc độ cao là bao nhiêu? Tôi có cần xây dựng hoặc tạo lại code không? Làm cách nào để thay đổi kích thước lô (batch size) khi tìm nạp blockchain? Video hướng dẫn Giới thiệu Tại sao lại cần thay đổi batch size?",content:'# Hướng dẫn\n\n\n# Làm sao để bắt đầu tại một block khác với mặc định?\n\n\n# Video hướng dẫn\n\n\n# Giới thiệu\n\nTheo mặc định, tất cả các dự án khởi động bắt đầu đồng bộ hóa blockchain từ khối nguyên thủy (Genesis Block). Nói cách khác, từ block số 1. Đối với các blockchain lớn, quá trình đồng bộ hóa này thường mất vài ngày, thậm chí là vài tuần để hoàn thành.\n\nĐể bắt đầu đồng bộ hóa node (nút) SubQuery từ một nấc độ cao block khác 0, bạn cần phải sửa đổi tệp project.yaml của mình và thay đổi key về block khởi đầu (startBlock).\n\nTrong tệp project.yaml dưới đây, block khởi đầu đã được đặt thành 1.000.000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Tại sao lại không bắt đầu từ block 0?\n\nNguyên nhân chủ yếu là vì làm vậy sẽ giúp giảm thời gian đồng bộ hóa blockchain. Điều này nghĩa là nếu chỉ quan tâm đến các giao dịch trong 3 tháng gần nhất, bạn có thể chỉ đồng bộ hóa những block trong 3 tháng gần nhất - như vậy thời gian đồng bộ sẽ ngắn hơn và bạn có thể nhanh chóng bắt tay vào công đoạn phát triển dự án.\n\n\n# Hạn chế của việc này là gì?\n\nHạn chế rõ ràng nhất sẽ là bạn sẽ không thể truy vấn dữ liệu trên blockchain đối với các block mà bạn không có.\n\n\n# Làm sao để biết blockchain hiện đang có nấc độ cao là bao nhiêu?\n\nNếu đang sử dụng mạng Polkadot, bạn có thể truy cập vào trang https://polkascan.io/, chọn mạng, sau đó xem tại mục "Block đã hoàn thiện".\n\n\n# Tôi có cần xây dựng hoặc tạo lại code không?\n\nKhông. Bởi vì bạn đang sửa đổi tệp project.yaml (về cơ bản thì đây là tệp cấu hình), vậy nên bạn sẽ không phải xây dựng hoặc tạo lại code typecript.\n\n\n# Làm cách nào để thay đổi kích thước lô (batch size) khi tìm nạp blockchain?\n\n\n# Video hướng dẫn\n\n\n# Giới thiệu\n\nKích thước mặc định là 100, nhưng bạn có thể thay đổi bằng cách sử dụng lệnh bổ sung --batch-size=xx.\n\nBạn cần thêm đoạn trên vào dòng lệnh để tạo thành một flag bổ sung, còn nếu bạn đang sử dụng Docker, hãy sửa đổi tệp docker-compos.yml như sau:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nTrong ví dụ này, batch size đã được đổi thành 50.\n\n\n# Tại sao lại cần thay đổi batch size?\n\nViệc sử dụng batch size nhỏ hơn có thể làm giảm mức sử dụng bộ nhớ và không khiến người dùng bị treo khi muốn thực hiện các truy vấn lớn. Nói cách khác, ứng dụng của bạn sẽ có tốc độ phản hồi nhanh hơn. Tuy nhiên, làm vậy sẽ khiến có thêm nhiều lệnh gọi API được thực hiện, vậy nên nếu bạn bị tính phí trên cơ sở đầu vào/đầu ra hoặc blockchain của bạn có giới hạn API ở đâu đó thì điều này có thể gây bất lợi cho bạn.',normalizedContent:'# huong dan\n\n\n# lam sao đe bat đau tai mot block khac voi mac đinh?\n\n\n# video huong dan\n\n\n# gioi thieu\n\ntheo mac đinh, tat ca cac du an khoi đong bat đau đong bo hoa blockchain tu khoi nguyen thuy (genesis block). noi cach khac, tu block so 1. đoi voi cac blockchain lon, qua trinh đong bo hoa nay thuong mat vai ngay, tham chi la vai tuan đe hoan thanh.\n\nđe bat đau đong bo hoa node (nut) subquery tu mot nac đo cao block khac 0, ban can phai sua đoi tep project.yaml cua minh va thay đoi key ve block khoi đau (startblock).\n\ntrong tep project.yaml duoi đay, block khoi đau đa đuoc đat thanh 1.000.000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# tai sao lai khong bat đau tu block 0?\n\nnguyen nhan chu yeu la vi lam vay se giup giam thoi gian đong bo hoa blockchain. đieu nay nghia la neu chi quan tam đen cac giao dich trong 3 thang gan nhat, ban co the chi đong bo hoa nhung block trong 3 thang gan nhat - nhu vay thoi gian đong bo se ngan hon va ban co the nhanh chong bat tay vao cong đoan phat trien du an.\n\n\n# han che cua viec nay la gi?\n\nhan che ro rang nhat se la ban se khong the truy van du lieu tren blockchain đoi voi cac block ma ban khong co.\n\n\n# lam sao đe biet blockchain hien đang co nac đo cao la bao nhieu?\n\nneu đang su dung mang polkadot, ban co the truy cap vao trang https://polkascan.io/, chon mang, sau đo xem tai muc "block đa hoan thien".\n\n\n# toi co can xay dung hoac tao lai code khong?\n\nkhong. boi vi ban đang sua đoi tep project.yaml (ve co ban thi đay la tep cau hinh), vay nen ban se khong phai xay dung hoac tao lai code typecript.\n\n\n# lam cach nao đe thay đoi kich thuoc lo (batch size) khi tim nap blockchain?\n\n\n# video huong dan\n\n\n# gioi thieu\n\nkich thuoc mac đinh la 100, nhung ban co the thay đoi bang cach su dung lenh bo sung --batch-size=xx.\n\nban can them đoan tren vao dong lenh đe tao thanh mot flag bo sung, con neu ban đang su dung docker, hay sua đoi tep docker-compos.yml nhu sau:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\ntrong vi du nay, batch size đa đuoc đoi thanh 50.\n\n\n# tai sao lai can thay đoi batch size?\n\nviec su dung batch size nho hon co the lam giam muc su dung bo nho va khong khien nguoi dung bi treo khi muon thuc hien cac truy van lon. noi cach khac, ung dung cua ban se co toc đo phan hoi nhanh hon. tuy nhien, lam vay se khien co them nhieu lenh goi api đuoc thuc hien, vay nen neu ban bi tinh phi tren co so đau vao/đau ra hoac blockchain cua ban co gioi han api o đau đo thi đieu nay co the gay bat loi cho ban.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hướng dẫn & Ví dụ",frontmatter:{summary:"Hướng dẫn & Ví dụ Dưới đây chúng tôi sẽ liệt kê các bài hướng dẫn và ví dụ đa dạng để giúp bạn thiết lập và chạy dự án một cách nhanh chóng, dễ dàng nhất có thể. Ví dụ SubQuery Ví ",meta:[{property:"og:url",content:"/vi/tutorials_examples/introduction.html"},{property:"og:title",content:"Hướng dẫn & Ví dụ"},{property:"og:description",content:"Hướng dẫn & Ví dụ Dưới đây chúng tôi sẽ liệt kê các bài hướng dẫn và ví dụ đa dạng để giúp bạn thiết lập và chạy dự án một cách nhanh chóng, dễ dàng nhất có thể. Ví dụ SubQuery Ví "},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/tutorials_examples/introduction.html",relativePath:"vi/tutorials_examples/introduction.md",key:"v-24317c65",path:"/vi/tutorials_examples/introduction/",headers:[{level:2,title:"Ví dụ SubQuery",slug:"vi-du-subquery",normalizedTitle:"vi du subquery",charIndex:169}],readingTime:{minutes:1.43,words:430},headersStr:"Ví dụ SubQuery",content:"# Hướng dẫn & Ví dụ\n\nDưới đây chúng tôi sẽ liệt kê các bài hướng dẫn và ví dụ đa dạng để giúp bạn thiết lập và chạy dự án một cách nhanh chóng, dễ dàng nhất có thể.\n\n\n# Ví dụ SubQuery\n\nVÍ DỤ                       MÔ TẢ                                                          CHỦ ĐỀ\nextrinsic-finalized-block   Lập Index về các yếu tố bên ngoài để có thể truy vấn bằng      Ví dụ đơn giản nhất về function block handler (xử lý block)\n                            hash của chúng\nblock-timestamp             Lập Index theo dấu thời gian cho từng block đã được hoàn       Một ví dụ đơn giản khác về function call handler (xử lý lệnh\n                            thiện                                                          gọi)\nvalidator-threshold         Lập Index về mức staking tối thiểu để người xác nhận đủ điều   Một ví dụ phức tạp hơn về function block handler có tác dụng\n                            kiện để được bầu chọn.                                         tạo lệnh gọi bên ngoài tới cho @polkadot/api để lấy thêm dữ\n                                                                                           liệu on-chain\nsum-reward                  Lập Index về số tiền ràng buộc để staking, phần thưởng         Function event handlers phức tạp hơn với quan hệ one-to-many\n                            staking và khoản phạt (slash) từ các sự kiện của block đã\n                            hoàn thiện\nentity-relation             Lập Index về việc chuyển số dư giữa các tài khoản và cũng      Mối quan hệ One-to-many và many-to-many cùng với function\n                            lập chỉ mục lô tiện ích, nhằm tìm hiểu nội dung của các lệnh   extrinsic handling\n                            gọi bên ngoài\nkitty                       Lập Index thông tin ra đời của các kitty.                      Function phức tạp để xử lý lệnh gọi và xử lý sự kiện, với dữ\n                                                                                           liệu được lập Index từ chuỗi tùy chỉnh",normalizedContent:"# huong dan & vi du\n\nduoi đay chung toi se liet ke cac bai huong dan va vi du đa dang đe giup ban thiet lap va chay du an mot cach nhanh chong, de dang nhat co the.\n\n\n# vi du subquery\n\nvi du                       mo ta                                                          chu đe\nextrinsic-finalized-block   lap index ve cac yeu to ben ngoai đe co the truy van bang      vi du đon gian nhat ve function block handler (xu ly block)\n                            hash cua chung\nblock-timestamp             lap index theo dau thoi gian cho tung block đa đuoc hoan       mot vi du đon gian khac ve function call handler (xu ly lenh\n                            thien                                                          goi)\nvalidator-threshold         lap index ve muc staking toi thieu đe nguoi xac nhan đu đieu   mot vi du phuc tap hon ve function block handler co tac dung\n                            kien đe đuoc bau chon.                                         tao lenh goi ben ngoai toi cho @polkadot/api đe lay them du\n                                                                                           lieu on-chain\nsum-reward                  lap index ve so tien rang buoc đe staking, phan thuong         function event handlers phuc tap hon voi quan he one-to-many\n                            staking va khoan phat (slash) tu cac su kien cua block đa\n                            hoan thien\nentity-relation             lap index ve viec chuyen so du giua cac tai khoan va cung      moi quan he one-to-many va many-to-many cung voi function\n                            lap chi muc lo tien ich, nham tim hieu noi dung cua cac lenh   extrinsic handling\n                            goi ben ngoai\nkitty                       lap index thong tin ra đoi cua cac kitty.                      function phuc tap đe xu ly lenh goi va xu ly su kien, voi du\n                                                                                           lieu đuoc lap index tu chuoi tuy chinh",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Làm thế nào để chạy một nút chỉ mục?",frontmatter:{summary:"Làm thế nào để chạy một nút chỉ mục? Video hướng dẫn Giới thiệu Chạy một nút chỉ mục là một tùy chọn khác ngoài việc sử dụng Docker hoặc có một dự án được lưu trữ cho bạn tại Dự án",meta:[{property:"og:url",content:"/vi/tutorials_examples/run-indexer.html"},{property:"og:title",content:"Làm thế nào để chạy một nút chỉ mục?"},{property:"og:description",content:"Làm thế nào để chạy một nút chỉ mục? Video hướng dẫn Giới thiệu Chạy một nút chỉ mục là một tùy chọn khác ngoài việc sử dụng Docker hoặc có một dự án được lưu trữ cho bạn tại Dự án"},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/tutorials_examples/run-indexer.html",relativePath:"vi/tutorials_examples/run-indexer.md",key:"v-c95f1966",path:"/vi/tutorials_examples/run-indexer/",headers:[{level:2,title:"Video hướng dẫn",slug:"video-huong-dan",normalizedTitle:"video huong dan",charIndex:43},{level:2,title:"Giới thiệu",slug:"gioi-thieu",normalizedTitle:"gioi thieu",charIndex:63},{level:2,title:"Postgres",slug:"postgres",normalizedTitle:"postgres",charIndex:312},{level:2,title:"Cài đặt subql / node",slug:"cai-đat-subql-node",normalizedTitle:"cai đat subql / node",charIndex:488},{level:2,title:"Đặt cấu hình DB",slug:"đat-cau-hinh-db",normalizedTitle:"đat cau hinh db",charIndex:818},{level:2,title:"Lập chỉ mục một dự án",slug:"lap-chi-muc-mot-du-an",normalizedTitle:"lap chi muc mot du an",charIndex:1381},{level:2,title:"Kiểm tra Postgres",slug:"kiem-tra-postgres",normalizedTitle:"kiem tra postgres",charIndex:1699}],readingTime:{minutes:1.98,words:594},headersStr:"Video hướng dẫn Giới thiệu Postgres Cài đặt subql / node Đặt cấu hình DB Lập chỉ mục một dự án Kiểm tra Postgres",content:'# Làm thế nào để chạy một nút chỉ mục?\n\n\n# Video hướng dẫn\n\n\n# Giới thiệu\n\nChạy một nút chỉ mục là một tùy chọn khác ngoài việc sử dụng Docker hoặc có một dự án được lưu trữ cho bạn tại Dự án SubQuery . Nó đòi hỏi nhiều thời gian và nỗ lực hơn nhưng sẽ nâng cao hiểu biết của bạn về cách SubQuery hoạt động.\n\n\n# Postgres\n\nChạy một nút chỉ mục trên cơ sở hạ tầng của bạn sẽ yêu cầu thiết lập cơ sở dữ liệu Postgres. Bạn có thể cài đặt Postgres tại đây và đảm bảo phiên bản 12 trở lên.\n\n\n# Cài đặt subql / node\n\nSau đó, để chạy một nút SubQuery, hãy chạy lệnh sau:\n\nnpm install -g @subql/node\n\n\n1\n\n\nCờ -g có nghĩa là cài đặt nó trên toàn cầu, có nghĩa là trên OSX, vị trí sẽ là / usr / local / lib / node_modules.\n\nSau khi cài đặt, bạn có thể kiểm tra phiên bản bằng cách chạy:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# Đặt cấu hình DB\n\nTiếp theo, bạn cần đặt các biến môi trường sau:\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\n\n\n1\n2\n3\n4\n5\n\n\nTất nhiên, nếu bạn có các giá trị khác nhau cho các phím trên, vui lòng điều chỉnh cho phù hợp. Lưu ý rằng lệnh env sẽ hiển thị các biến môi trường hiện tại và quá trình này chỉ đặt các giá trị này tạm thời. Có nghĩa là, chúng chỉ có hiệu lực trong khoảng thời gian của phiên đầu cuối. Để đặt chúng vĩnh viễn, hãy lưu trữ chúng trong ~/bash_profile của bạn.\n\n\n# Lập chỉ mục một dự án\n\nĐể bắt đầu lập chỉ mục một dự án, hãy điều hướng vào thư mục dự án của bạn và chạy lệnh sau:\n\nsubql-node -f .\n\n\n1\n\n\nNếu bạn không có dự án nào hữu ích, hãy git clone https://github.com/subquery/subql-helloworld. Bạn sẽ thấy nút lập chỉ mục bắt đầu hoạt động và bắt đầu lập chỉ mục các khối.\n\n\n# Kiểm tra Postgres\n\nNếu bạn điều hướng đến Postgres, bạn sẽ thấy hai bảng được tạo. public.subqueries và subquery_1.starter_entities.\n\npublic.subqueries chỉ chứa 1 hàng mà trình lập chỉ mục kiểm tra khi khởi động để "hiểu trạng thái hiện tại" để nó biết phải tiếp tục từ đâu. Bảng starter_entities chứa các chỉ mục. Để xem dữ liệu, hãy chạy select (*) from subquery_1.starter_entities.',normalizedContent:'# lam the nao đe chay mot nut chi muc?\n\n\n# video huong dan\n\n\n# gioi thieu\n\nchay mot nut chi muc la mot tuy chon khac ngoai viec su dung docker hoac co mot du an đuoc luu tru cho ban tai du an subquery . no đoi hoi nhieu thoi gian va no luc hon nhung se nang cao hieu biet cua ban ve cach subquery hoat đong.\n\n\n# postgres\n\nchay mot nut chi muc tren co so ha tang cua ban se yeu cau thiet lap co so du lieu postgres. ban co the cai đat postgres tai đay va đam bao phien ban 12 tro len.\n\n\n# cai đat subql / node\n\nsau đo, đe chay mot nut subquery, hay chay lenh sau:\n\nnpm install -g @subql/node\n\n\n1\n\n\nco -g co nghia la cai đat no tren toan cau, co nghia la tren osx, vi tri se la / usr / local / lib / node_modules.\n\nsau khi cai đat, ban co the kiem tra phien ban bang cach chay:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# đat cau hinh db\n\ntiep theo, ban can đat cac bien moi truong sau:\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\n\n\n1\n2\n3\n4\n5\n\n\ntat nhien, neu ban co cac gia tri khac nhau cho cac phim tren, vui long đieu chinh cho phu hop. luu y rang lenh env se hien thi cac bien moi truong hien tai va qua trinh nay chi đat cac gia tri nay tam thoi. co nghia la, chung chi co hieu luc trong khoang thoi gian cua phien đau cuoi. đe đat chung vinh vien, hay luu tru chung trong ~/bash_profile cua ban.\n\n\n# lap chi muc mot du an\n\nđe bat đau lap chi muc mot du an, hay đieu huong vao thu muc du an cua ban va chay lenh sau:\n\nsubql-node -f .\n\n\n1\n\n\nneu ban khong co du an nao huu ich, hay git clone https://github.com/subquery/subql-helloworld. ban se thay nut lap chi muc bat đau hoat đong va bat đau lap chi muc cac khoi.\n\n\n# kiem tra postgres\n\nneu ban đieu huong đen postgres, ban se thay hai bang đuoc tao. public.subqueries va subquery_1.starter_entities.\n\npublic.subqueries chi chua 1 hang ma trinh lap chi muc kiem tra khi khoi đong đe "hieu trang thai hien tai" đe no biet phai tiep tuc tu đau. bang starter_entities chua cac chi muc. đe xem du lieu, hay chay select (*) from subquery_1.starter_entities.',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Thuật ngữ",frontmatter:{summary:"Thuật ngữ Dự án SubQuery (nơi phép màu nảy sinh): Định nghĩa (@subql/cli) về cách SubQuery Node sẽ đi qua và tổng hợp một mạng dự án, về cách dữ liệu sẽ được chuyển đổi và lưu trữ ",meta:[{property:"og:url",content:"/vi/tutorials_examples/terminology.html"},{property:"og:title",content:"Thuật ngữ"},{property:"og:description",content:"Thuật ngữ Dự án SubQuery (nơi phép màu nảy sinh): Định nghĩa (@subql/cli) về cách SubQuery Node sẽ đi qua và tổng hợp một mạng dự án, về cách dữ liệu sẽ được chuyển đổi và lưu trữ "},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/tutorials_examples/terminology.html",relativePath:"vi/tutorials_examples/terminology.md",key:"v-73d3498d",path:"/vi/tutorials_examples/terminology/",headers:[{level:2,title:"Thuật ngữ",slug:"thuat-ngu",normalizedTitle:"thuat ngu",charIndex:2}],readingTime:{minutes:.82,words:246},headersStr:"Thuật ngữ",content:"# Thuật ngữ\n\n * Dự án SubQuery (nơi phép màu nảy sinh): Định nghĩa (@subql/cli) về cách SubQuery Node sẽ đi qua và tổng hợp một mạng dự án, về cách dữ liệu sẽ được chuyển đổi và lưu trữ để kích hoạt các truy vấn GraphQL hữu ích\n * SubQuery Node (nơi công việc được hoàn thành): package này (@subql/node) sẽ chấp nhận định nghĩa của dự án SubQuery và chạy một node có tác dụng liên tục lập Index cho mạng được kết nối gắn với một cơ sở dữ liệu\n * Dịch vụ truy vấn SubQuery (nơi để lấy dữ liệu): Package này (@subql/query) tương tác với API GraphQL của một Node SubQuery đã được triển khai để truy vấn và xem dữ liệu được lập Index\n * GraphQL (cách để truy vấn dữ liệu): Đây là một ngôn ngữ truy vấn dành cho các API, đặc biệt phù hợp với dữ liệu dựa trên biểu đồ linh hoạt - xem graphql.org",normalizedContent:"# thuat ngu\n\n * du an subquery (noi phep mau nay sinh): đinh nghia (@subql/cli) ve cach subquery node se đi qua va tong hop mot mang du an, ve cach du lieu se đuoc chuyen đoi va luu tru đe kich hoat cac truy van graphql huu ich\n * subquery node (noi cong viec đuoc hoan thanh): package nay (@subql/node) se chap nhan đinh nghia cua du an subquery va chay mot node co tac dung lien tuc lap index cho mang đuoc ket noi gan voi mot co so du lieu\n * dich vu truy van subquery (noi đe lay du lieu): package nay (@subql/query) tuong tac voi api graphql cua mot node subquery đa đuoc trien khai đe truy van va xem du lieu đuoc lap index\n * graphql (cach đe truy van du lieu): đay la mot ngon ngu truy van danh cho cac api, đac biet phu hop voi du lieu dua tren bieu đo linh hoat - xem graphql.org",charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{frontmatter:{summary:"欢迎使用 SubQuery 的 文档 探索并改造您的链数据以更快地构建直观的 dApp！ 快速启动 指南 借助传统的Hello World 范例来理解SubQuery。 在 Docker 环境中使用模板项目 您可以快速获得一个节点上线并运行运行，并且在短短几分钟内用几个简单的命令开始查询区块链。 Get started Tutorials and Examp",meta:[{property:"og:url",content:"/zh/"},{property:"og:description",content:"欢迎使用 SubQuery 的 文档 探索并改造您的链数据以更快地构建直观的 dApp！ 快速启动 指南 借助传统的Hello World 范例来理解SubQuery。 在 Docker 环境中使用模板项目 您可以快速获得一个节点上线并运行运行，并且在短短几分钟内用几个简单的命令开始查询区块链。 Get started Tutorials and Examp"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/",relativePath:"zh/README.md",key:"v-8fbc73c4",path:"/zh/",readingTime:{minutes:3.65,words:1094},headersStr:null,content:"欢迎使用 SubQuery 的 文档\n\n探索并改造您的链数据以更快地构建直观的 dApp！\n\n\n快速启动 指南\n\n借助传统的Hello World 范例来理解SubQuery。 在 Docker 环境中使用模板项目 您可以快速获得一个节点上线并运行运行，并且在短短几分钟内用几个简单的命令开始查询区块链。\n\nGet started\n * Tutorials and Examples\n   \n   Learning by doing. Tutorials and examples on how to build various SubQuery projects.\n\n * Technical Reference Docs\n   \n   Written by developers for developers. Find what you need to build awesome dApps quickly.\n\n * SubQuery 网络\n   \n   SubQuery 的分散未来。 阅读更多关于如何奖励索引器和消费者的信息。\n\n\n常见问题\n\n * 什么是子查询？\n   \n   SubQuery 是一个开放源代码项目，它允许开发者索引、转换和查询 Substrate 链数据为他们的应用程序提供动力。\n   \n   READ MORE\n * 从SubQuery开始的最佳方式是什么？\n   \n   The best way to get started with SubQuery is to try out our Hello World tutorial. 这是一个简单的5分钟步行来下载启动模板，构建项目。 然后使用 Docker 在您的本地主机上运行一个节点，运行一个简单的查询。\n\n * 我如何向SubQuer贡献或反馈？\n   \n   我们热爱社区的贡献和反馈。 若要贡献代码，请分派感兴趣的仓库并做出更改。 然后提交 PR 或 Pull 请求。 哦，不要忘记测试！ 还查阅我们的贡献指南(即将到来)。\n   \n   READ MORE\n * 在SubQuery项目中托管我的项目需要多少费用？\n   \n   在 SubQuery 项目中托管您的项目是绝对免费的，这是我们回归社区的方式。 To learn how to host your project with us, please check out the Hello World (SubQuery Hosted) tutorial.\n   \n   HOSTING YOUR PROJECT\n\n\nFor further frequently asked questions, please see our FAQ's page.\n\n与您的自定义链集成？\n\n无论您在 Substrate 上构建一个新的 parachain，还是一个全新的区块链——SubQuery 都可以帮助您索引并排除您的链中的数据。 SubQuery 旨在轻松地与基于自定义的 Substrate 链集成。\n\nLEARN HOW TO INTEGRATE WITH YOUR CHAIN\n\n支持和贡献\n\n有问题或有兴趣了解更多信息或如何贡献？ 我们很乐意听到您的声音。 请通过以下链接通过电子邮件或社交媒体联系我们。 需要技术专门知识？ 加入我们的 Discord 社区并得到我们热情的社区成员的支持。\n\n加入禁产条约\n联系我们 hello@subquery.network\n在社交上关注我们\ndiscord twitter medium telegram github linkedin\nSubQuery © 2021",normalizedContent:"欢迎使用 subquery 的 文档\n\n探索并改造您的链数据以更快地构建直观的 dapp！\n\n\n快速启动 指南\n\n借助传统的hello world 范例来理解subquery。 在 docker 环境中使用模板项目 您可以快速获得一个节点上线并运行运行，并且在短短几分钟内用几个简单的命令开始查询区块链。\n\nget started\n * tutorials and examples\n   \n   learning by doing. tutorials and examples on how to build various subquery projects.\n\n * technical reference docs\n   \n   written by developers for developers. find what you need to build awesome dapps quickly.\n\n * subquery 网络\n   \n   subquery 的分散未来。 阅读更多关于如何奖励索引器和消费者的信息。\n\n\n常见问题\n\n * 什么是子查询？\n   \n   subquery 是一个开放源代码项目，它允许开发者索引、转换和查询 substrate 链数据为他们的应用程序提供动力。\n   \n   read more\n * 从subquery开始的最佳方式是什么？\n   \n   the best way to get started with subquery is to try out our hello world tutorial. 这是一个简单的5分钟步行来下载启动模板，构建项目。 然后使用 docker 在您的本地主机上运行一个节点，运行一个简单的查询。\n\n * 我如何向subquer贡献或反馈？\n   \n   我们热爱社区的贡献和反馈。 若要贡献代码，请分派感兴趣的仓库并做出更改。 然后提交 pr 或 pull 请求。 哦，不要忘记测试！ 还查阅我们的贡献指南(即将到来)。\n   \n   read more\n * 在subquery项目中托管我的项目需要多少费用？\n   \n   在 subquery 项目中托管您的项目是绝对免费的，这是我们回归社区的方式。 to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n   \n   hosting your project\n\n\nfor further frequently asked questions, please see our faq's page.\n\n与您的自定义链集成？\n\n无论您在 substrate 上构建一个新的 parachain，还是一个全新的区块链——subquery 都可以帮助您索引并排除您的链中的数据。 subquery 旨在轻松地与基于自定义的 substrate 链集成。\n\nlearn how to integrate with your chain\n\n支持和贡献\n\n有问题或有兴趣了解更多信息或如何贡献？ 我们很乐意听到您的声音。 请通过以下链接通过电子邮件或社交媒体联系我们。 需要技术专门知识？ 加入我们的 discord 社区并得到我们热情的社区成员的支持。\n\n加入禁产条约\n联系我们 hello@subquery.network\n在社交上关注我们\ndiscord twitter medium telegram github linkedin\nsubquery © 2021",charsets:{cjk:!0},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"GraphQL 方案",frontmatter:{summary:"GraphQL 方案 定义实体 schema.graphql 文件定义了各种 GraphQL schemas。 由于 GraphQL 查询语言的工作方式，方案文件基本上决定了您从 SubQuery 获取数据的形状。 要更多地了解如何使用 GraphQL schema 语言写入，我们建议查看 Schemas 和 Type。 重要：当您对模式文件做任何更改时， ",meta:[{property:"og:url",content:"/zh/create/graphql.html"},{property:"og:title",content:"GraphQL 方案"},{property:"og:description",content:"GraphQL 方案 定义实体 schema.graphql 文件定义了各种 GraphQL schemas。 由于 GraphQL 查询语言的工作方式，方案文件基本上决定了您从 SubQuery 获取数据的形状。 要更多地了解如何使用 GraphQL schema 语言写入，我们建议查看 Schemas 和 Type。 重要：当您对模式文件做任何更改时， "},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/create/graphql.html",relativePath:"zh/create/graphql.md",key:"v-4cb5e50d",path:"/zh/create/graphql/",headers:[{level:2,title:"定义实体",slug:"定义实体",normalizedTitle:"定义实体",charIndex:17},{level:3,title:"实体",slug:"实体",normalizedTitle:"实体",charIndex:19},{level:3,title:"支持的标尺和类型",slug:"支持的标尺和类型",normalizedTitle:"支持的标尺和类型",charIndex:408},{level:2,title:"非主键领域索引",slug:"非主键领域索引",normalizedTitle:"非主键领域索引",charIndex:572},{level:2,title:"实体关系",slug:"实体关系",normalizedTitle:"实体关系",charIndex:527},{level:3,title:"一对一关系",slug:"一对一关系",normalizedTitle:"一对一关系",charIndex:1561},{level:3,title:"一对多关系",slug:"一对多关系",normalizedTitle:"一对多关系",charIndex:1895},{level:3,title:"多对多关系",slug:"多对多关系",normalizedTitle:"多对多关系",charIndex:2084},{level:3,title:"反向查询",slug:"反向查询",normalizedTitle:"反向查询",charIndex:2718},{level:2,title:"JSON 类型",slug:"json-类型",normalizedTitle:"json 类型",charIndex:560},{level:3,title:"定义 JSON 指令",slug:"定义-json-指令",normalizedTitle:"定义 json 指令",charIndex:3360},{level:3,title:"查询 JSON 字段",slug:"查询-json-字段",normalizedTitle:"查询 json 字段",charIndex:3819}],readingTime:{minutes:5.46,words:1637},headersStr:"定义实体 实体 支持的标尺和类型 非主键领域索引 实体关系 一对一关系 一对多关系 多对多关系 反向查询 JSON 类型 定义 JSON 指令 查询 JSON 字段",content:"# GraphQL 方案\n\n\n# 定义实体\n\nschema.graphql 文件定义了各种 GraphQL schemas。 由于 GraphQL 查询语言的工作方式，方案文件基本上决定了您从 SubQuery 获取数据的形状。 要更多地了解如何使用 GraphQL schema 语言写入，我们建议查看 Schemas 和 Type。\n\n重要：当您对模式文件做任何更改时， 请确保你重新生成你的类型目录，命令 yarn codegen\n\n\n# 实体\n\n每个实体必须使用 ID! 类型定义其必填字段 id。 它被用作同类所有实体的主要钥匙和独特之处。\n\n实体中不可用字段由 表示！。 请参阅下面的示例：\n\n输入示例 @entity 然后\n  id: ID! # id 字段总是必需的，必须看起来像此\n  名称：字符串！ # 这是必填字段\n  地址：字符串 # 这是一个可选字段\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 支持的标尺和类型\n\n我们目前支持流量缩放类型：\n\n * ID\n * 英寸\n * 字符串\n * BigInt\n * 日期\n * Boolean\n * <EntityName> 对于嵌套关系实体，您可以使用定义实体的名称作为字段之一。 请在 实体关系 中查看。\n * JSON 也可以存储结构化数据，请查看 JSON 类型\n\n\n# 非主键领域索引\n\n为了提高查询性能，只需在非主键字段实现 @index 注解，便可索引实体字段。\n\n但是，我们不允许用户在任何 JSON 对象上添加 @index 注释。 默认情况下，索引会自动添加到外键和 JSON 字段，但只是为了提高查询服务的性能。\n\n这里就是一个例子。\n\n输入用户 @entity 然后\n  id!\n  名称: 字符串 ！ @index(唯一：true) # 唯一可以设置为 true 或 false\n  title: Title! # 索引被自动添加到外国密钥字段\n}\n\n类型标题 @entity 。\n  id: ID！\n  名称: 字符串 ！ @index(唯一:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n假定我们知道这个用户的名字，但我们不知道确切的 id 值。 而不是提取所有用户，然后通过名称过滤，我们可以在名称字段后面添加 @index 这使查询速度更快，我们还可以通过 的唯一性：真的 来确保唯一性。\n\n如果字段不是唯一的，最大结果设置为 100\n\n当代码生成运行时，它将自动在 用户 模型下创建 getByname 。 和外键字段 标题 将创建 getByTitleId 方法 这两者都可以直接访问映射功能。\n\n/* 为标题实体准备记录 */\nINSERT INTO title (id, name) VALUES('id_1', 'Captain')\n\n\n1\n2\n\n\n// 映射函数中的处理程序\nimport {User} from '../types/models/User';\nimport {Title} from '../types/models/Title';\n\nconst jack = await User.getByName('Jack Sparrow');\n\nconst captainTitle = await Title.getByName('Captain');\n\nconst pirateLords = await User.getByTitleId(captainTitle.id); // List of all Captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 实体关系\n\n一个实体往往与其他实体有嵌套的关系。 设置字段值为另一个实体名将默认定义这两个实体之间的一对一关系。\n\n可以使用以下示例配置不同的实体关系(一对一、一对多和多对多)\n\n\n# 一对一关系\n\n只有一个实体被映射到另一个实体时，一对一的关系是缺省的。\n\n例如：护照只属于一人，只有一本护照(例如)：\n\n输入人员 @entity 然后\n  id!\n}\n\n输入 PassPassport @entity Windows\n  id: ID!\n  所有者：个人！\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n或\n\ntype Person @entity {\n  id: ID!\n  passport: Passport!\n}\n\ntype Passport @entity {\n  id: ID!\n  所有者：个人！\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 一对多关系\n\n您可以使用方括号来表示字段类型包含多个实体。\n\n示例：一个人可以有多个帐户。\n\ntype Person @entity {\n  id: ID!\n  accounts: [Account]\n}\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 多对多关系\n\n通过建立一个映射实体，将另外两个实体连接起来，可以实现多对多的关系。\n\n示例：每个人都是多个组的一部分(个人组)，还有多个不同的人(个人组)。\n\ntype Person @entity {\n  id: ID!\n  name: String!\n  groups: [PersonGroup]\n}\n\ntype PersonGroup @entity {\n  id: ID!\n  person: Person!\n  Group: Group!\n}\n\ntype Group @entity {\n  id: ID!\n  name: String!\n  人员: [PersonGroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n此外，还可以在中间实体的多个领域创建同一实体的连接。\n\n例如，一个帐户可能有多次转账，每次转账都有一个来源和目的地帐户。\n\n这将通过 Transfer 表在两个 Accounts (from 和 to) 之间建立双向关系。\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 反向查询\n\n为了启用在一个实体上反向查找关系， 将 @derivedFrom 附加到字段，并指向另一个实体的反向查找字段。\n\n这将在可以查询的实体上创建一个虚拟字段。\n\n“从”账户转账可从账户实体通过设定发送或接收的转账具有从相应字段或字段衍生出的价值。\n\ntype Account @entity {\n  id: ID!\n  publicAddress: String!\n  sentTransfers: [Transfer] @derivedFrom(field: \"from\")\n  receivedTransfers: [Transfer] @derivedFrom(field: \"to\")\n}\n\ntype Transfer @entity {\n  id: ID!\n  amount: BigInt\n  from: Account!\n  to: Account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# JSON 类型\n\n我们支持将数据保存为 JSON 类型，这是存储结构化数据的一个快速方法。 我们会自动生成相应的 JSON 接口来查询此数据，并节省您的时间来定义和管理实体。\n\n我们推荐用户在以下场景中使用 JSON 类型：\n\n * 在一个单一领域储存结构化数据比创建多个单独实体更易管理。\n * 保存任意键/值用户首选项 (其中值可以是布尔值、文本或数字，并且您不希望不同数据类型有单独的列)\n * 模式不稳定且经常变化\n\n\n# 定义 JSON 指令\n\n通过在实体中添加 jsonField 注解来定义属性为 JSON 类型。 这将自动为您项目中 types/interfaces.ts 下的所有 JSON 对象生成接口，您可以在映射函数中访问它们。\n\n与实体不同，jsonField 指令对象不需要 id 字段。 JSON 对象也可以与其他 JSON 对象嵌套。\n\ntype AddressDetail @jsonField {\n  street: String!\n  district: String!\n}\n\ntype ContactCard @jsonField {\n  phone: String!\n  address: AddressDetail # Nested JSON\n}\n\ntype User @entity {\n  id: ID!\n  contact: [ContactCard] # Store a list of JSON objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# 查询 JSON 字段\n\n使用 JSON 类型的缺点对过滤时查询效率有轻微的影响， 每次进行文本搜索时，它都在整个实体上。\n\n然而，我们的查询服务仍然可以接受这种影响。 这里是如何使用 的示例在 JSON 字段的 GraphQL 查询中包含 操作员来找到拥有包含 '0064 ' 的电话号码的前 5 个用户。\n\n#要找到前5个用户自己的电话号码包含 '0064'。\n\nquery {\n  user(first: 5, filter: {contactCard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactCard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",normalizedContent:"# graphql 方案\n\n\n# 定义实体\n\nschema.graphql 文件定义了各种 graphql schemas。 由于 graphql 查询语言的工作方式，方案文件基本上决定了您从 subquery 获取数据的形状。 要更多地了解如何使用 graphql schema 语言写入，我们建议查看 schemas 和 type。\n\n重要：当您对模式文件做任何更改时， 请确保你重新生成你的类型目录，命令 yarn codegen\n\n\n# 实体\n\n每个实体必须使用 id! 类型定义其必填字段 id。 它被用作同类所有实体的主要钥匙和独特之处。\n\n实体中不可用字段由 表示！。 请参阅下面的示例：\n\n输入示例 @entity 然后\n  id: id! # id 字段总是必需的，必须看起来像此\n  名称：字符串！ # 这是必填字段\n  地址：字符串 # 这是一个可选字段\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 支持的标尺和类型\n\n我们目前支持流量缩放类型：\n\n * id\n * 英寸\n * 字符串\n * bigint\n * 日期\n * boolean\n * <entityname> 对于嵌套关系实体，您可以使用定义实体的名称作为字段之一。 请在 实体关系 中查看。\n * json 也可以存储结构化数据，请查看 json 类型\n\n\n# 非主键领域索引\n\n为了提高查询性能，只需在非主键字段实现 @index 注解，便可索引实体字段。\n\n但是，我们不允许用户在任何 json 对象上添加 @index 注释。 默认情况下，索引会自动添加到外键和 json 字段，但只是为了提高查询服务的性能。\n\n这里就是一个例子。\n\n输入用户 @entity 然后\n  id!\n  名称: 字符串 ！ @index(唯一：true) # 唯一可以设置为 true 或 false\n  title: title! # 索引被自动添加到外国密钥字段\n}\n\n类型标题 @entity 。\n  id: id！\n  名称: 字符串 ！ @index(唯一:true)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n假定我们知道这个用户的名字，但我们不知道确切的 id 值。 而不是提取所有用户，然后通过名称过滤，我们可以在名称字段后面添加 @index 这使查询速度更快，我们还可以通过 的唯一性：真的 来确保唯一性。\n\n如果字段不是唯一的，最大结果设置为 100\n\n当代码生成运行时，它将自动在 用户 模型下创建 getbyname 。 和外键字段 标题 将创建 getbytitleid 方法 这两者都可以直接访问映射功能。\n\n/* 为标题实体准备记录 */\ninsert into title (id, name) values('id_1', 'captain')\n\n\n1\n2\n\n\n// 映射函数中的处理程序\nimport {user} from '../types/models/user';\nimport {title} from '../types/models/title';\n\nconst jack = await user.getbyname('jack sparrow');\n\nconst captaintitle = await title.getbyname('captain');\n\nconst piratelords = await user.getbytitleid(captaintitle.id); // list of all captains\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 实体关系\n\n一个实体往往与其他实体有嵌套的关系。 设置字段值为另一个实体名将默认定义这两个实体之间的一对一关系。\n\n可以使用以下示例配置不同的实体关系(一对一、一对多和多对多)\n\n\n# 一对一关系\n\n只有一个实体被映射到另一个实体时，一对一的关系是缺省的。\n\n例如：护照只属于一人，只有一本护照(例如)：\n\n输入人员 @entity 然后\n  id!\n}\n\n输入 passpassport @entity windows\n  id: id!\n  所有者：个人！\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n或\n\ntype person @entity {\n  id: id!\n  passport: passport!\n}\n\ntype passport @entity {\n  id: id!\n  所有者：个人！\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 一对多关系\n\n您可以使用方括号来表示字段类型包含多个实体。\n\n示例：一个人可以有多个帐户。\n\ntype person @entity {\n  id: id!\n  accounts: [account]\n}\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 多对多关系\n\n通过建立一个映射实体，将另外两个实体连接起来，可以实现多对多的关系。\n\n示例：每个人都是多个组的一部分(个人组)，还有多个不同的人(个人组)。\n\ntype person @entity {\n  id: id!\n  name: string!\n  groups: [persongroup]\n}\n\ntype persongroup @entity {\n  id: id!\n  person: person!\n  group: group!\n}\n\ntype group @entity {\n  id: id!\n  name: string!\n  人员: [persongroup]\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n此外，还可以在中间实体的多个领域创建同一实体的连接。\n\n例如，一个帐户可能有多次转账，每次转账都有一个来源和目的地帐户。\n\n这将通过 transfer 表在两个 accounts (from 和 to) 之间建立双向关系。\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 反向查询\n\n为了启用在一个实体上反向查找关系， 将 @derivedfrom 附加到字段，并指向另一个实体的反向查找字段。\n\n这将在可以查询的实体上创建一个虚拟字段。\n\n“从”账户转账可从账户实体通过设定发送或接收的转账具有从相应字段或字段衍生出的价值。\n\ntype account @entity {\n  id: id!\n  publicaddress: string!\n  senttransfers: [transfer] @derivedfrom(field: \"from\")\n  receivedtransfers: [transfer] @derivedfrom(field: \"to\")\n}\n\ntype transfer @entity {\n  id: id!\n  amount: bigint\n  from: account!\n  to: account!\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# json 类型\n\n我们支持将数据保存为 json 类型，这是存储结构化数据的一个快速方法。 我们会自动生成相应的 json 接口来查询此数据，并节省您的时间来定义和管理实体。\n\n我们推荐用户在以下场景中使用 json 类型：\n\n * 在一个单一领域储存结构化数据比创建多个单独实体更易管理。\n * 保存任意键/值用户首选项 (其中值可以是布尔值、文本或数字，并且您不希望不同数据类型有单独的列)\n * 模式不稳定且经常变化\n\n\n# 定义 json 指令\n\n通过在实体中添加 jsonfield 注解来定义属性为 json 类型。 这将自动为您项目中 types/interfaces.ts 下的所有 json 对象生成接口，您可以在映射函数中访问它们。\n\n与实体不同，jsonfield 指令对象不需要 id 字段。 json 对象也可以与其他 json 对象嵌套。\n\ntype addressdetail @jsonfield {\n  street: string!\n  district: string!\n}\n\ntype contactcard @jsonfield {\n  phone: string!\n  address: addressdetail # nested json\n}\n\ntype user @entity {\n  id: id!\n  contact: [contactcard] # store a list of json objects\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# 查询 json 字段\n\n使用 json 类型的缺点对过滤时查询效率有轻微的影响， 每次进行文本搜索时，它都在整个实体上。\n\n然而，我们的查询服务仍然可以接受这种影响。 这里是如何使用 的示例在 json 字段的 graphql 查询中包含 操作员来找到拥有包含 '0064 ' 的电话号码的前 5 个用户。\n\n#要找到前5个用户自己的电话号码包含 '0064'。\n\nquery {\n  user(first: 5, filter: {contactcard: {contains: [{phone: \"0064\"}]}}) {\n    nodes {\n      id\n      contactcard\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n",charsets:{cjk:!0},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"创建子查询项目",frontmatter:{summary:"创建子查询项目 在 快速开始 指南， 我们很快地演示了一个榜样，让您知道什么是 SubQuery 以及它是如何运作的。 我们会在创建您的项目和您将要处理的关键文件时更仔细地查看工作流。 基本工作流 以下一些示例将假定您在 快速启动 部分中成功初始化了启动器包。 从这个启动程序包，我们会走过标准进程来定制和执行您的 SubQuery 项目。 1. 使用 sub",meta:[{property:"og:url",content:"/zh/create/introduction.html"},{property:"og:title",content:"创建子查询项目"},{property:"og:description",content:"创建子查询项目 在 快速开始 指南， 我们很快地演示了一个榜样，让您知道什么是 SubQuery 以及它是如何运作的。 我们会在创建您的项目和您将要处理的关键文件时更仔细地查看工作流。 基本工作流 以下一些示例将假定您在 快速启动 部分中成功初始化了启动器包。 从这个启动程序包，我们会走过标准进程来定制和执行您的 SubQuery 项目。 1. 使用 sub"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/create/introduction.html",relativePath:"zh/create/introduction.md",key:"v-8de7f97e",path:"/zh/create/introduction/",headers:[{level:2,title:"基本工作流",slug:"基本工作流",normalizedTitle:"基本工作流",charIndex:100},{level:2,title:"目录结构",slug:"目录结构",normalizedTitle:"目录结构",charIndex:502},{level:2,title:"代码生成",slug:"代码生成",normalizedTitle:"代码生成",charIndex:786},{level:2,title:"构建...",slug:"构建",normalizedTitle:"构建...",charIndex:985},{level:2,title:"日志记录",slug:"日志记录",normalizedTitle:"日志记录",charIndex:1126}],readingTime:{minutes:2.6,words:779},headersStr:"基本工作流 目录结构 代码生成 构建... 日志记录",content:"# 创建子查询项目\n\n在 快速开始 指南， 我们很快地演示了一个榜样，让您知道什么是 SubQuery 以及它是如何运作的。 我们会在创建您的项目和您将要处理的关键文件时更仔细地查看工作流。\n\n\n# 基本工作流\n\n以下一些示例将假定您在 快速启动 部分中成功初始化了启动器包。 从这个启动程序包，我们会走过标准进程来定制和执行您的 SubQuery 项目。\n\n 1. 使用 subql init PROJECT_NAME 初始化您的项目\n 2. 更新清单文件(个项目。 aml) 以包含关于您的 blockchain 以及您将要映射的实体的信息 - 查看 清单文件\n 3. 在您的架构中创建 GraphQL 实体(架构)。 定义您要提取和持续查询的数据形状的 rapphql- 参见 GraphQL Schema\n 4. 添加所有映射函数 (eg 映射处理器。 s) 您想要调用来将链式数据转换为您已定义的 GraphQL 实体 - 查看 映射\n 5. 生成，构建， 并发布代码到 SubQuery 项目 (或在您自己的本地节点中运行) - 在我们的快速启动指南中查看 运行并查询您的启动项目。\n\n\n# 目录结构\n\n下面的地图提供了运行 init 命令时子查询项目的目录结构概览。\n\n- project-name\n  L package.json\n  L project.yaml\n  L README.md\n  L schema.graphql\n  L tsconfig.json\n  L docker-compose.yml\n  L src\n    L index.ts\n    L mappings\n      L mappingHandlers.ts\n  L .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n例如：\n\n\n\n\n# 代码生成\n\n每当您更改您的 GraphQL 实体时，您必须通过以下命令重新生成您的类型目录。\n\nyarn 编码器\n\n\n1\n\n\n这将创建一个新的目录(或更新现有的目录) src/type 其中包含您之前在 scheme 中定义的每个类型生成的实体类别。 rapphql 这些类别提供了安全类型实体加载， 读取并写入实体字段 - 在 GraphQL Schema 中查看更多关于此进程的信息。\n\n\n# 构建...\n\n为了在本地托管的 SubQuery 节点上运行您的 SubQuery 项目，您需要首先构建您的工作。\n\n从项目的根目录运行构建命令。\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script building\n\n\n1\n2\n3\n4\n5\n\n\n\n# 日志记录\n\nconsole.log 方法不再受支持。 相反， Logger 模块已被注入到类型中，这意味着我们可以支持一个可以接受不同日志级别的日志器。\n\nlogger.info('Info level message');\nlogger.debug('Debugger level message');\nlogger.warn('Warning level message');\n\n\n1\n2\n3\n\n\n要使用 logger.info 或 logger.warn，只需将行放入您的映射文件。\n\n\n\n要使用 logger.debug, 需要一个额外的步骤。 将 --log-level=debug 添加到您的命令行。\n\n如果您正在运行一个停靠容器，请将此行添加到您的 docker-compose.yaml 文件中。\n\n\n\n您现在应该在终端屏幕上看到新的登录。\n\n",normalizedContent:"# 创建子查询项目\n\n在 快速开始 指南， 我们很快地演示了一个榜样，让您知道什么是 subquery 以及它是如何运作的。 我们会在创建您的项目和您将要处理的关键文件时更仔细地查看工作流。\n\n\n# 基本工作流\n\n以下一些示例将假定您在 快速启动 部分中成功初始化了启动器包。 从这个启动程序包，我们会走过标准进程来定制和执行您的 subquery 项目。\n\n 1. 使用 subql init project_name 初始化您的项目\n 2. 更新清单文件(个项目。 aml) 以包含关于您的 blockchain 以及您将要映射的实体的信息 - 查看 清单文件\n 3. 在您的架构中创建 graphql 实体(架构)。 定义您要提取和持续查询的数据形状的 rapphql- 参见 graphql schema\n 4. 添加所有映射函数 (eg 映射处理器。 s) 您想要调用来将链式数据转换为您已定义的 graphql 实体 - 查看 映射\n 5. 生成，构建， 并发布代码到 subquery 项目 (或在您自己的本地节点中运行) - 在我们的快速启动指南中查看 运行并查询您的启动项目。\n\n\n# 目录结构\n\n下面的地图提供了运行 init 命令时子查询项目的目录结构概览。\n\n- project-name\n  l package.json\n  l project.yaml\n  l readme.md\n  l schema.graphql\n  l tsconfig.json\n  l docker-compose.yml\n  l src\n    l index.ts\n    l mappings\n      l mappinghandlers.ts\n  l .gitignore\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n例如：\n\n\n\n\n# 代码生成\n\n每当您更改您的 graphql 实体时，您必须通过以下命令重新生成您的类型目录。\n\nyarn 编码器\n\n\n1\n\n\n这将创建一个新的目录(或更新现有的目录) src/type 其中包含您之前在 scheme 中定义的每个类型生成的实体类别。 rapphql 这些类别提供了安全类型实体加载， 读取并写入实体字段 - 在 graphql schema 中查看更多关于此进程的信息。\n\n\n# 构建...\n\n为了在本地托管的 subquery 节点上运行您的 subquery 项目，您需要首先构建您的工作。\n\n从项目的根目录运行构建命令。\n\n# yarn\nyarn build\n\n# npm\nnpm run-script building\n\n\n1\n2\n3\n4\n5\n\n\n\n# 日志记录\n\nconsole.log 方法不再受支持。 相反， logger 模块已被注入到类型中，这意味着我们可以支持一个可以接受不同日志级别的日志器。\n\nlogger.info('info level message');\nlogger.debug('debugger level message');\nlogger.warn('warning level message');\n\n\n1\n2\n3\n\n\n要使用 logger.info 或 logger.warn，只需将行放入您的映射文件。\n\n\n\n要使用 logger.debug, 需要一个额外的步骤。 将 --log-level=debug 添加到您的命令行。\n\n如果您正在运行一个停靠容器，请将此行添加到您的 docker-compose.yaml 文件中。\n\n\n\n您现在应该在终端屏幕上看到新的登录。\n\n",charsets:{cjk:!0},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/zh/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/create/manifest.html",relativePath:"zh/create/manifest.md",key:"v-541b37d2",path:"/zh/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:1998},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3220},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4533}],readingTime:{minutes:2.51,words:752},headersStr:"Network Filters Mapping Filters Custom Chains",content:"# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: '0.0.1'\ndescription: ''\nrepository: 'https://github.com/subquery/subql-starter'\n\nschema: './schema.graphql'\n\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: 'https://api.subquery.network/sq/subquery/dictionary-polkadot'\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - see Running an Indexer\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n\n---\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter: #Optional\n      specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter:\n      specName: kusama\n    startBlock: 12000\n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter:\n  module: balances\n  method: Deposit\n  success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: '0.0.1'\ndescription: \"This subquery indexes kitty's birth info\"\nrepository: 'https://github.com/onfinality-io/subql-examples'\nschema: './schema.graphql'\nnetwork:\n  endpoint: 'ws://host.kittychain.io/public-ws'\n  types: {'KittyIndex': 'u32', 'Kitty': '[u8; 16]'}\n# typesChain: { chain: { Type5: 'example' } }\n# typesSpec: { spec: { Type6: 'example' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter: #Optional\n      specName: kitty-chain\n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n",normalizedContent:"# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: '0.0.1'\ndescription: ''\nrepository: 'https://github.com/subquery/subql-starter'\n\nschema: './schema.graphql'\n\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: 'https://api.subquery.network/sq/subquery/dictionary-polkadot'\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - see running an indexer\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n\n---\nnetwork:\n  endpoint: 'wss://polkadot.api.onfinality.io/public-ws'\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter: #optional\n      specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter:\n      specname: kusama\n    startblock: 12000\n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter:\n  module: balances\n  method: deposit\n  success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: '0.0.1'\ndescription: \"this subquery indexes kitty's birth info\"\nrepository: 'https://github.com/onfinality-io/subql-examples'\nschema: './schema.graphql'\nnetwork:\n  endpoint: 'ws://host.kittychain.io/public-ws'\n  types: {'kittyindex': 'u32', 'kitty': '[u8; 16]'}\n# typeschain: { chain: { type5: 'example' } }\n# typesspec: { spec: { type6: 'example' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter: #optional\n      specname: kitty-chain\n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n",charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/zh/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/create/mapping.html",relativePath:"zh/create/mapping.md",key:"v-026927ed",path:"/zh/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3127},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4042},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5002},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5432},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6095},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:4952},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6812},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:9823},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11044},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11266}],readingTime:{minutes:6.96,words:2088},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from \'@subql/types\';\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n  // Create a new StarterEntity with the block hash as it\'s ID\n  const record = new starterEntity(block.block.header.hash.toString());\n  record.field1 = block.block.header.number.toNumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n  const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n  record.field4 = extrinsic.block.timestamp;\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() 将在当前块上进行多个 相同 类型的查询。\n * api.queryMulti() 将在当前块进行不同类型的多个查询。\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from \'ethers/lib/utils\'; //Good way\nimport {utils} from \'ethers\'; //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n  const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n  record.field1 = hashMessage(\'Hello\');\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\n在项目 src 文件夹下创建一个新的目录 api-interface 来存储所有需要并生成的文件。 We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport {default as kitties} from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n    // this is the package name we use (in the interface imports, --package for generators) */\n    "kitty-birthinfo/*": ["src/*"],\n    // here we replace the @polkadot/api augmentation with our own, generated from chain\n    "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n    // replace the augmented types with our own, as generated from definitions\n    "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n  //return the KittyIndex type\n  const nextKittyId = await api.query.kitties.nextKittyId();\n  // return the Kitty type, input parameters types are AccountId and KittyIndex\n  const allKitties = await api.query.kitties.kitties(\'xxxxxxxxx\', 123);\n  logger.info(`Next kitty id ${nextKittyId}`);\n  //Custom rpc, set undefined to blockhash\n  const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined, nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. 您可以在 project.yml 中定义 typesBundle。 And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from \'@subql/types\';\n\nexport async function handleblock(block: substrateblock): promise<void> {\n  // create a new starterentity with the block hash as it\'s id\n  const record = new starterentity(block.block.header.hash.tostring());\n  record.field1 = block.block.header.number.tonumber();\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n  const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n  record.field4 = extrinsic.block.timestamp;\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() 将在当前块上进行多个 相同 类型的查询。\n * api.querymulti() 将在当前块进行不同类型的多个查询。\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from \'ethers/lib/utils\'; //good way\nimport {utils} from \'ethers\'; //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n  const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n  record.field1 = hashmessage(\'hello\');\n  await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\n在项目 src 文件夹下创建一个新的目录 api-interface 来存储所有需要并生成的文件。 we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport {default as kitties} from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n    // this is the package name we use (in the interface imports, --package for generators) */\n    "kitty-birthinfo/*": ["src/*"],\n    // here we replace the @polkadot/api augmentation with our own, generated from chain\n    "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n    // replace the augmented types with our own, as generated from definitions\n    "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n  //return the kittyindex type\n  const nextkittyid = await api.query.kitties.nextkittyid();\n  // return the kitty type, input parameters types are accountid and kittyindex\n  const allkitties = await api.query.kitties.kitties(\'xxxxxxxxx\', 123);\n  logger.info(`next kitty id ${nextkittyid}`);\n  //custom rpc, set undefined to blockhash\n  const kittyprice = await api.rpc.kitties.getkittyprice(undefined, nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. 您可以在 project.yml 中定义 typesbundle。 and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n',charsets:{cjk:!0},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Frequently Asked Questions",frontmatter:{summary:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio",meta:[{property:"og:url",content:"/zh/faqs/faqs.html"},{property:"og:title",content:"Frequently Asked Questions"},{property:"og:description",content:"Frequently Asked Questions What is SubQuery? SubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applicatio"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/faqs/faqs.html",relativePath:"zh/faqs/faqs.md",key:"v-39ce30bd",path:"/zh/faqs/faqs/",headers:[{level:2,title:"What is SubQuery?",slug:"what-is-subquery",normalizedTitle:"what is subquery?",charIndex:33},{level:2,title:"What is the best way to get started with SubQuery?",slug:"what-is-the-best-way-to-get-started-with-subquery",normalizedTitle:"what is the best way to get started with subquery?",charIndex:384},{level:2,title:"How can I contribute or give feedback to SubQuery?",slug:"how-can-i-contribute-or-give-feedback-to-subquery",normalizedTitle:"how can i contribute or give feedback to subquery?",charIndex:699},{level:2,title:"How much does it cost to host my project in SubQuery Projects?",slug:"how-much-does-it-cost-to-host-my-project-in-subquery-projects",normalizedTitle:"how much does it cost to host my project in subquery projects?",charIndex:1094},{level:2,title:"What are deployment slots?",slug:"what-are-deployment-slots",normalizedTitle:"what are deployment slots?",charIndex:1378},{level:2,title:"What is the advantage of a staging slot?",slug:"what-is-the-advantage-of-a-staging-slot",normalizedTitle:"what is the advantage of a staging slot?",charIndex:2061},{level:2,title:"What are extrinsics?",slug:"what-are-extrinsics",normalizedTitle:"what are extrinsics?",charIndex:2566}],readingTime:{minutes:2.04,words:612},headersStr:"What is SubQuery? What is the best way to get started with SubQuery? How can I contribute or give feedback to SubQuery? How much does it cost to host my project in SubQuery Projects? What are deployment slots? What is the advantage of a staging slot? What are extrinsics?",content:"# Frequently Asked Questions\n\n\n# What is SubQuery?\n\nSubQuery is an open source project that allows developers to index, transform, and query Substrate chain data to power their applications.\n\nSubQuery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# What is the best way to get started with SubQuery?\n\nThe best way to get started with SubQuery is to try out our Hello World tutorial. This is a simple 5 min walk through of downloading the starter template, building the project, and then using Docker to run a node on your localhost and running a simple query.\n\n\n# How can I contribute or give feedback to SubQuery?\n\nWe love contributions and feedback from the community. To contribute code, fork the repository of interest and make your changes. Then submit a PR or Pull Request. Oh, don't forget to test as well! Also check out our contributions guide lines (TBA).\n\nTo give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# How much does it cost to host my project in SubQuery Projects?\n\nHosting your project in SubQuery Projects is absolutely free - it's is our way of giving back to the community. To learn how to host your project with us, please check out the Hello World (SubQuery hosted) tutorial.\n\n\n# What are deployment slots?\n\nDeployment slots are a feature in SubQuery Projects that is the equivalent of a development environment. For example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). Typically additional environments such as staging and pre-prod or even QA are included depending on the needs of the organisation and their development set up.\n\nSubQuery currently has two slots available. A staging slot and a production slot. This allows developers to deploy their SubQuery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# What is the advantage of a staging slot?\n\nThe main benefit of using a staging slot is that it allows you to prepare a new release of your SubQuery project without exposing it publicly. You can wait for the staging slot to reindex all data without affecting your production applications.\n\nThe staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you. And of course, the separate environment allows you to test your new code without affecting production.\n\n\n# What are extrinsics?\n\nIf you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. More formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. There are three categories of extrinsics. They are inherents, signed transactions, and unsigned transactions.\n\nInherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nSigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. They stands to pay a fee to have the transaction included on chain.\n\nUnsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. Unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. Because of this, the transaction queue lacks economic logic to prevent spam.\n\nFor more information, click here.",normalizedContent:"# frequently asked questions\n\n\n# what is subquery?\n\nsubquery is an open source project that allows developers to index, transform, and query substrate chain data to power their applications.\n\nsubquery also provides free, production grade hosting of projects for developers removing the responsiblity of manging infrastructure, and letting developers do what they do best - build.\n\n\n# what is the best way to get started with subquery?\n\nthe best way to get started with subquery is to try out our hello world tutorial. this is a simple 5 min walk through of downloading the starter template, building the project, and then using docker to run a node on your localhost and running a simple query.\n\n\n# how can i contribute or give feedback to subquery?\n\nwe love contributions and feedback from the community. to contribute code, fork the repository of interest and make your changes. then submit a pr or pull request. oh, don't forget to test as well! also check out our contributions guide lines (tba).\n\nto give feedback, contact us at hello@subquery.network or jump onto our discord channel\n\n\n# how much does it cost to host my project in subquery projects?\n\nhosting your project in subquery projects is absolutely free - it's is our way of giving back to the community. to learn how to host your project with us, please check out the hello world (subquery hosted) tutorial.\n\n\n# what are deployment slots?\n\ndeployment slots are a feature in subquery projects that is the equivalent of a development environment. for example, in any software organisation there is normally a development environment and a production environment as a minimum (ignoring localhost that is). typically additional environments such as staging and pre-prod or even qa are included depending on the needs of the organisation and their development set up.\n\nsubquery currently has two slots available. a staging slot and a production slot. this allows developers to deploy their subquery to the staging environment and all going well, \"promote to production\" at the click of a button.\n\n\n# what is the advantage of a staging slot?\n\nthe main benefit of using a staging slot is that it allows you to prepare a new release of your subquery project without exposing it publicly. you can wait for the staging slot to reindex all data without affecting your production applications.\n\nthe staging slot is not shown to the public in the explorer and has a unique url that is visible only to you. and of course, the separate environment allows you to test your new code without affecting production.\n\n\n# what are extrinsics?\n\nif you are already familiar with blockchain concepts, you can think of extrinsics as comparable to transactions. more formally though, an extrinsic is a piece of information that comes from outside the chain and is included in a block. there are three categories of extrinsics. they are inherents, signed transactions, and unsigned transactions.\n\ninherent extrinsics are pieces of information that are not signed and only inserted into a block by the block author.\n\nsigned transaction extrinsics are transactions that contain a signature of the account that issued the transaction. they stands to pay a fee to have the transaction included on chain.\n\nunsigned transactions extrinsics are transactions that do not contain a signature of the account that issued the transaction. unsigned transactions extrinsics should be used with care because there is nobody paying a fee, becaused it is signed. because of this, the transaction queue lacks economic logic to prevent spam.\n\nfor more information, click here.",charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Installing SubQuery",frontmatter:{summary:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req",meta:[{property:"og:url",content:"/zh/install/install.html"},{property:"og:title",content:"Installing SubQuery"},{property:"og:description",content:"Installing SubQuery There are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is req"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/install/install.html",relativePath:"zh/install/install.md",key:"v-671a44e6",path:"/zh/install/install/",headers:[{level:2,title:"Install @subql/cli",slug:"install-subql-cli",normalizedTitle:"install @subql/cli",charIndex:214},{level:2,title:"Install @subql/node",slug:"install-subql-node",normalizedTitle:"install @subql/node",charIndex:598},{level:2,title:"Install @subql/query",slug:"install-subql-query",normalizedTitle:"install @subql/query",charIndex:1215}],readingTime:{minutes:1.05,words:316},headersStr:"Install @subql/cli Install @subql/node Install @subql/query",content:'# Installing SubQuery\n\nThere are various components required when creating a SubQuery project. The @subql/node component is required to run an indexer. The @subql/query library is required to generate queries.\n\n\n# Install @subql/cli\n\nThe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\nInstall SubQuery CLI globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/cli\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nYou can then run help to see available commands and usage provide by CLI:\n\nsubql help\n\n\n1\n\n\n\n# Install @subql/node\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\nInstall SubQuery node globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/node\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nOnce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.\n\n\n# Install @subql/query\n\nThe SubQuery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\nInstall SubQuery query globally on your terminal by using Yarn or NPM:\n\n# Yarn\nyarn global add @subql/query\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> Note: If you are using Docker or hosting your project in SubQuery Projects, you do can skip this step also. This is because the SubQuery node is already provided in the Docker container and the hosting infrastructure.',normalizedContent:'# installing subquery\n\nthere are various components required when creating a subquery project. the @subql/node component is required to run an indexer. the @subql/query library is required to generate queries.\n\n\n# install @subql/cli\n\nthe @subql/cli library helps to create a project framework or scaffold meaning you don\'t have to start from scratch.\n\ninstall subquery cli globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/cli\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n3\n4\n5\n\n\nyou can then run help to see available commands and usage provide by cli:\n\nsubql help\n\n\n1\n\n\n\n# install @subql/node\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\ninstall subquery node globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/node\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n3\n4\n5\n\n\nonce installed, you can can start a node with:\n\nsubql-node <command>\n\n\n1\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step. this is because the subquery node is already provided in the docker container and the hosting infrastructure.\n\n\n# install @subql/query\n\nthe subquery query library provides a service that allows you to query your project in a "playground" environment via your browser.\n\ninstall subquery query globally on your terminal by using yarn or npm:\n\n# yarn\nyarn global add @subql/query\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n3\n4\n5\n\n\n> note: if you are using docker or hosting your project in subquery projects, you do can skip this step also. this is because the subquery node is already provided in the docker container and the hosting infrastructure.',charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Kết nối đến Dự Án Mới của bạn",frontmatter:{summary:"Kết nối đến Dự Án Mới của bạn Sau khi quá trình triển khai của bạn hoàn tất thành công và các node của chúng tôi đã lập chỉ mục dữ liệu của bạn từ chuỗi, bạn sẽ có thể kết nối đến ",meta:[{property:"og:url",content:"/vi/publish/connect.html"},{property:"og:title",content:"Kết nối đến Dự Án Mới của bạn"},{property:"og:description",content:"Kết nối đến Dự Án Mới của bạn Sau khi quá trình triển khai của bạn hoàn tất thành công và các node của chúng tôi đã lập chỉ mục dữ liệu của bạn từ chuỗi, bạn sẽ có thể kết nối đến "},{property:"og:type",content:"article"},{property:"og:locale",content:"vi"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/vi/publish/connect.html",relativePath:"vi/publish/connect.md",key:"v-d805f606",path:"/vi/publish/connect/",readingTime:{minutes:1.01,words:304},headersStr:null,content:"# Kết nối đến Dự Án Mới của bạn\n\nSau khi quá trình triển khai của bạn hoàn tất thành công và các node của chúng tôi đã lập chỉ mục dữ liệu của bạn từ chuỗi, bạn sẽ có thể kết nối đến dự án của mình thông qua Query endpoint được hiển thị.\n\n\n\nBạn cũng có thể nhấp vào ba dấu chấm bên cạnh đề mục dự án của bạn và xem nó trên SubQuery Explorer. Tại đ1o bạn có thể sử dụng nền tảng trong trình duyệt để bắt đầu.\n\n\n\n\n# Tìm hiểu thêm về GraphQL\n\nBạn có thể làm theo hướng dẫn GraphQL chính thức tại đây để tìm hiểu thêm về GraphQL, cách thức hoạt động và cách sử dụng:\n\n * Có nhiều thư viện để giúp bạn thực thi GraphQL trong nhiều ngôn ngữ khác nhau\n * Để hiểu sâu hơn bằng các hướng dẫn thực hành, hãy xem qua Cách để GraphQL.\n * Tìm hiểu khóa học online miễn phí, Khám phá GraphQL: Một Ngôn Ngữ Query dành cho APIs.",normalizedContent:"# ket noi đen du an moi cua ban\n\nsau khi qua trinh trien khai cua ban hoan tat thanh cong va cac node cua chung toi đa lap chi muc du lieu cua ban tu chuoi, ban se co the ket noi đen du an cua minh thong qua query endpoint đuoc hien thi.\n\n\n\nban cung co the nhap vao ba dau cham ben canh đe muc du an cua ban va xem no tren subquery explorer. tai đ1o ban co the su dung nen tang trong trinh duyet đe bat đau.\n\n\n\n\n# tim hieu them ve graphql\n\nban co the lam theo huong dan graphql chinh thuc tai đay đe tim hieu them ve graphql, cach thuc hoat đong va cach su dung:\n\n * co nhieu thu vien đe giup ban thuc thi graphql trong nhieu ngon ngu khac nhau\n * đe hieu sau hon bang cac huong dan thuc hanh, hay xem qua cach đe graphql.\n * tim hieu khoa hoc online mien phi, kham pha graphql: mot ngon ngu query danh cho apis.",charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Ambassador Program",frontmatter:{summary:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the ",meta:[{property:"og:url",content:"/zh/miscellaneous/ambassadors.html"},{property:"og:title",content:"Ambassador Program"},{property:"og:description",content:"Ambassador Program We understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the "},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/miscellaneous/ambassadors.html",relativePath:"zh/miscellaneous/ambassadors.md",key:"v-3bc0b2ce",path:"/zh/miscellaneous/ambassadors/",headers:[{level:2,title:"What we Believe In",slug:"what-we-believe-in",normalizedTitle:"what we believe in",charIndex:208},{level:2,title:"Our Ambassador Program",slug:"our-ambassador-program",normalizedTitle:"our ambassador program",charIndex:1327},{level:3,title:"Ambassador Benefits",slug:"ambassador-benefits",normalizedTitle:"ambassador benefits",charIndex:1663},{level:2,title:"How does it work",slug:"how-does-it-work",normalizedTitle:"how does it work",charIndex:2855},{level:2,title:"Ambassador Activities",slug:"ambassador-activities",normalizedTitle:"ambassador activities",charIndex:3770}],readingTime:{minutes:2.98,words:893},headersStr:"What we Believe In Our Ambassador Program Ambassador Benefits How does it work Ambassador Activities",content:"# Ambassador Program\n\n\n\nWe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\nApply Now!\n\n\n# What we Believe In\n\nOur team came together with the shared vision to build the foundations of a flexible and inclusive data service for the Polkadot ecosystem.\n\nBuilt by developers, for developers: SubQuery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. SubQuery is only successful if the Polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nIntegrity and Accountability: We have team members in Auckland, Shanghai, and Sydney so remote work is important to us. We expect that our team is empowered and works autonomously together to achieve our goals. A key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\nInclusive Guidance and Support: Blockchain is hard, and everyone needs help sometimes. There is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. We learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# Our Ambassador Program\n\nOur SubQuery Ambassador program aims to find community leaders passionate about Polkadot and SubQuery. We’re looking for self-starters that can spread the word about SubQuery in their local areas and provide support to new developers that want to use SubQuery to build amazing apps and services on Polkadot.\n\n\n# Ambassador Benefits\n\nAt SubQuery, we work hard to achieve what we do. Similarly, Ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nFunding and Support: You may be rewarded for good work with early opportunities into private sales and bounties. Additionally, we’ll be providing funding grants for you to run community meetups.\n\nSubQuery Team Access: You’ll have direct access to the core SubQuery team with opportunities for hands-on training, exclusive AMAs with our leaders and developers, and insight into our roadmap.\n\nNetwork Development: Expect to grow your professional network by being an Ambassador for one of the top Polkadot projects. Meet other ambassadors around the world and receive introductions to local Polkadot projects that we need to support locally. You might even get free entry to represent SubQuery in events in your local area.\n\nSwag and other free stuff: Everyone likes free stuff! Receive an annual allocation of SubQuery swag that’ll make you stand out in the crowd. Plus additional allocation that you can share around at community events. You’ll also receive an exclusive NFT for your Ambassador status.\n\n\n# How does it work\n\nOur Ambassador program has multiple tiers, each tier has different benefits and capabilities. You can move up tiers by participating in Ambassador activities and working hard for us.\n\nOnce you have sent through an application, we will select candidates that align with our values. If selected you are placed in our trainee program and will receive an information package, expanding your understanding of SubQuery. After this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a SubQuery Project). We will host workshops throughout this process to support you.\n\nOnce you pass the trainee program, you can call yourself a SubQuery ambassador and will be accepted into our full program. From here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\nApply Now!\n\n\n# Ambassador Activities\n\nSubQuery Ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. You can participate in as many areas as you want, you’re not bound to any single one.\n\nEvent Management: Build local communities by hosting, organising, and managing different events. Building a local community will be a key part of growing the SubQuery community. SubQuery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending Q&As or online events as speakers or in AMA sessions.\n\nContent Creation: We have a long list of content and support material that we need help creating. Remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. Content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the SubQuery Ecosystem. SubQuery will support Content Creators by providing branding assets and expertise. We’ll also use SubQuery’s marketing channels to increase awareness of your content (and yourself).\n\nTranslation: Our customers don’t just speak English! We need your help making SubQuery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\nCommunity Moderation: Moderators will help grow the SubQuery community by ensuring that official community channels are active and engaging. SubQuery will support Moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\nApply Now!",normalizedContent:"# ambassador program\n\n\n\nwe understand that one of our biggest strengths is our community, and with your help, we want to grow and establish local ambassadors for communities around the world.\n\napply now!\n\n\n# what we believe in\n\nour team came together with the shared vision to build the foundations of a flexible and inclusive data service for the polkadot ecosystem.\n\nbuilt by developers, for developers: subquery is a growing community that focuses on providing the best products and services for our developers, and builders in our ecosystem. subquery is only successful if the polkadot ecosystem is successful, and so everything we do is with our customers in mind.\n\nintegrity and accountability: we have team members in auckland, shanghai, and sydney so remote work is important to us. we expect that our team is empowered and works autonomously together to achieve our goals. a key requirement for this is for our team to be accountable for their actions and maintain their integrity.\n\ninclusive guidance and support: blockchain is hard, and everyone needs help sometimes. there is no such thing as a stupid question in our community and everyone in our team is expected to help support our users. we learn some of the most valuable insights about our service (and how we can improve it) directly from our community.\n\n\n# our ambassador program\n\nour subquery ambassador program aims to find community leaders passionate about polkadot and subquery. we’re looking for self-starters that can spread the word about subquery in their local areas and provide support to new developers that want to use subquery to build amazing apps and services on polkadot.\n\n\n# ambassador benefits\n\nat subquery, we work hard to achieve what we do. similarly, ambassadors are expected to commit some time when joining our team but will be rewarded with benefits.\n\nfunding and support: you may be rewarded for good work with early opportunities into private sales and bounties. additionally, we’ll be providing funding grants for you to run community meetups.\n\nsubquery team access: you’ll have direct access to the core subquery team with opportunities for hands-on training, exclusive amas with our leaders and developers, and insight into our roadmap.\n\nnetwork development: expect to grow your professional network by being an ambassador for one of the top polkadot projects. meet other ambassadors around the world and receive introductions to local polkadot projects that we need to support locally. you might even get free entry to represent subquery in events in your local area.\n\nswag and other free stuff: everyone likes free stuff! receive an annual allocation of subquery swag that’ll make you stand out in the crowd. plus additional allocation that you can share around at community events. you’ll also receive an exclusive nft for your ambassador status.\n\n\n# how does it work\n\nour ambassador program has multiple tiers, each tier has different benefits and capabilities. you can move up tiers by participating in ambassador activities and working hard for us.\n\nonce you have sent through an application, we will select candidates that align with our values. if selected you are placed in our trainee program and will receive an information package, expanding your understanding of subquery. after this, you can start to work through the trainee program by completing certain onboarding tasks (e.g. creating a subquery project). we will host workshops throughout this process to support you.\n\nonce you pass the trainee program, you can call yourself a subquery ambassador and will be accepted into our full program. from here on you can continue to work through the program and progress up the tiers, earning more rewards and benefits as you climb the ranks.\n\napply now!\n\n\n# ambassador activities\n\nsubquery ambassadors are able to contribute through four main areas, including event management, content creation, translation, and community moderation. you can participate in as many areas as you want, you’re not bound to any single one.\n\nevent management: build local communities by hosting, organising, and managing different events. building a local community will be a key part of growing the subquery community. subquery will support you by providing funding for events, sending swag/merchandise to be given away, as well as attending q&as or online events as speakers or in ama sessions.\n\ncontent creation: we have a long list of content and support material that we need help creating. remember, our success relies on the ability of our customers to build amazing things on our service, so we need your help to make that easier. content includes videos, infographics, tutorials, animations, or any other related material, to inform, educate, or inspire community members within the subquery ecosystem. subquery will support content creators by providing branding assets and expertise. we’ll also use subquery’s marketing channels to increase awareness of your content (and yourself).\n\ntranslation: our customers don’t just speak english! we need your help making subquery more accessible by translating our content into your own language, as well as helping sharing the word to our international community.\n\ncommunity moderation: moderators will help grow the subquery community by ensuring that official community channels are active and engaging. subquery will support moderators by promoting the channels that they monitor, as well as provide guidelines for our expectations.\n\napply now!",charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Contributing To SubQuery",frontmatter:{summary:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu',meta:[{property:"og:url",content:"/zh/miscellaneous/contributing.html"},{property:"og:title",content:"Contributing To SubQuery"},{property:"og:description",content:'Contributing To SubQuery Welcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future. " This docu'},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/miscellaneous/contributing.html",relativePath:"zh/miscellaneous/contributing.md",key:"v-0501aa26",path:"/zh/miscellaneous/contributing/",headers:[{level:2,title:"Code of Conduct",slug:"code-of-conduct",normalizedTitle:"code of conduct",charIndex:873},{level:2,title:"Getting started",slug:"getting-started",normalizedTitle:"getting started",charIndex:1136},{level:2,title:"How to Contribute",slug:"how-to-contribute",normalizedTitle:"how to contribute",charIndex:1619},{level:3,title:"Reporting Bugs",slug:"reporting-bugs",normalizedTitle:"reporting bugs",charIndex:1641},{level:3,title:"Submitting Pull Requests",slug:"submitting-pull-requests",normalizedTitle:"submitting pull requests",charIndex:2108},{level:2,title:"Coding Conventions",slug:"coding-conventions",normalizedTitle:"coding conventions",charIndex:2510},{level:3,title:"Git Commit Messages",slug:"git-commit-messages",normalizedTitle:"git commit messages",charIndex:2533},{level:3,title:"JavaScript Styleguide",slug:"javascript-styleguide",normalizedTitle:"javascript styleguide",charIndex:2742}],readingTime:{minutes:1.47,words:440},headersStr:"Code of Conduct Getting started How to Contribute Reporting Bugs Submitting Pull Requests Coding Conventions Git Commit Messages JavaScript Styleguide",content:'# Contributing To SubQuery\n\nWelcome and a big thank you for considering contributing to this SubQuery project! Together we can pave the way to a more decentralised future.\n\n> This documentation is actively maintained by the SubQuery team. We welcome your contributions, you can do so by forking our GitHub project and making changes to all the documentation markdown files under the docs directory.\n\nWhat follows is a set of guidelines (not rules) for contributing to SubQuery. Following these guidelines will help us make the contribution process easy and effective for everyone involved. It also communicates that you agree to respect the time of the developers managing and developing this project. In return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# Code of Conduct\n\nWe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. By participating and contributing to this project, you agree to uphold our Code of Conduct.\n\n\n# Getting started\n\nContributions to our repositories are made through Issues and Pull Requests (PRs). A few general guidelines that cover both:\n\n * Search for existing Issues and PRs before creating your own.\n * We work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. A friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# How to Contribute\n\n\n# Reporting Bugs\n\nBugs are tracked as GitHub issues. When logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * Use a clear and descriptive title for the issue to identify the problem.\n * Describe the exact steps to reproduce the problem.\n * Describe the behavior you observed after following the steps.\n * Explain which behavior you expected to see instead and why.\n * Include screenshots if possible.\n\n\n# Submitting Pull Requests\n\nIn general, we follow the "fork-and-pull" Git workflow\n\n * Fork the repository to your own Github account\n * Clone the project to your machine\n * Create a branch locally with a succinct but descriptive name\n * Commit changes to the branch\n * Following any formatting and testing guidelines specific to this repo\n * Push changes to your fork\n * Open a PR in our repository\n\n\n# Coding Conventions\n\n\n# Git Commit Messages\n\n * Use the present tense ("Add feature" not "Added feature")\n * Use the imperative mood ("Move cursor to..." not "Moves cursor to...")\n * Limit the first line to 72 characters or less\n\n\n# JavaScript Styleguide\n\n * All JavaScript code is linted with Prettier and ESLint',normalizedContent:'# contributing to subquery\n\nwelcome and a big thank you for considering contributing to this subquery project! together we can pave the way to a more decentralised future.\n\n> this documentation is actively maintained by the subquery team. we welcome your contributions, you can do so by forking our github project and making changes to all the documentation markdown files under the docs directory.\n\nwhat follows is a set of guidelines (not rules) for contributing to subquery. following these guidelines will help us make the contribution process easy and effective for everyone involved. it also communicates that you agree to respect the time of the developers managing and developing this project. in return, we will reciprocate that respect by addressing your issue, considering changes, collaborating on improvements, and helping you finalise your pull requests.\n\n\n# code of conduct\n\nwe take our open source community projects and responsibility seriously and hold ourselves and other contributors to high standards of communication. by participating and contributing to this project, you agree to uphold our code of conduct.\n\n\n# getting started\n\ncontributions to our repositories are made through issues and pull requests (prs). a few general guidelines that cover both:\n\n * search for existing issues and prs before creating your own.\n * we work hard to makes sure issues are handled in promptly but, depending on the impact, it could take a while to investigate the root cause. a friendly @ mention in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.\n\n\n# how to contribute\n\n\n# reporting bugs\n\nbugs are tracked as github issues. when logging an issue, explain the problem and include additional details to help maintainers reproduce the problem:\n\n * use a clear and descriptive title for the issue to identify the problem.\n * describe the exact steps to reproduce the problem.\n * describe the behavior you observed after following the steps.\n * explain which behavior you expected to see instead and why.\n * include screenshots if possible.\n\n\n# submitting pull requests\n\nin general, we follow the "fork-and-pull" git workflow\n\n * fork the repository to your own github account\n * clone the project to your machine\n * create a branch locally with a succinct but descriptive name\n * commit changes to the branch\n * following any formatting and testing guidelines specific to this repo\n * push changes to your fork\n * open a pr in our repository\n\n\n# coding conventions\n\n\n# git commit messages\n\n * use the present tense ("add feature" not "added feature")\n * use the imperative mood ("move cursor to..." not "moves cursor to...")\n * limit the first line to 72 characters or less\n\n\n# javascript styleguide\n\n * all javascript code is linted with prettier and eslint',charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Branding Materials",frontmatter:{summary:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat",meta:[{property:"og:url",content:"/zh/miscellaneous/branding.html"},{property:"og:title",content:"Branding Materials"},{property:"og:description",content:"Branding Materials All of SubQuery’s brand features are proprietary and we take our brand extremely seriously. If you opt to use any trademarks, logos, designs, or other brand feat"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/miscellaneous/branding.html",relativePath:"zh/miscellaneous/branding.md",key:"v-723b4366",path:"/zh/miscellaneous/branding/",headers:[{level:2,title:"Exportable Figma File",slug:"exportable-figma-file",normalizedTitle:"exportable figma file",charIndex:319},{level:2,title:"Brand Assets Package",slug:"brand-assets-package",normalizedTitle:"brand assets package",charIndex:486}],readingTime:{minutes:.36,words:107},headersStr:"Exportable Figma File Brand Assets Package",content:"# Branding Materials\n\nAll of SubQuery’s brand features are proprietary and we take our brand extremely seriously.\n\nIf you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nIf in doubt, please ask!\n\n\n# Exportable Figma File\n\nOur Figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nFigma - SubQuery Brand Resources\n\n\n# Brand Assets Package\n\nA smaller ZIP package of brand assets\n\npublic_branding.zip",normalizedContent:"# branding materials\n\nall of subquery’s brand features are proprietary and we take our brand extremely seriously.\n\nif you opt to use any trademarks, logos, designs, or other brand features, please carefully follow the guidelines here or reach out to us via social media for clarification.\n\nif in doubt, please ask!\n\n\n# exportable figma file\n\nour figma file has a full collection of all brand assets (logos, fonts, colours, imagery etc) for export.\n\nfigma - subquery brand resources\n\n\n# brand assets package\n\na smaller zip package of brand assets\n\npublic_branding.zip",charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Social Media Links",frontmatter:{summary:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi",meta:[{property:"og:url",content:"/zh/miscellaneous/social_media.html"},{property:"og:title",content:"Social Media Links"},{property:"og:description",content:"Social Media Links SubQuery is an active project that maintains and communicates with our followers through many social media channels. It is our aim to always listen and engage wi"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/miscellaneous/social_media.html",relativePath:"zh/miscellaneous/social_media.md",key:"v-d8f0d426",path:"/zh/miscellaneous/social_media/",headers:[{level:2,title:"Official SubQuery Communities",slug:"official-subquery-communities",normalizedTitle:"official subquery communities",charIndex:280},{level:2,title:"Unofficial SubQuery Communities",slug:"unofficial-subquery-communities",normalizedTitle:"unofficial subquery communities",charIndex:529}],readingTime:{minutes:.48,words:144},headersStr:"Official SubQuery Communities Unofficial SubQuery Communities",content:"# Social Media Links\n\nSubQuery is an active project that maintains and communicates with our followers through many social media channels.\n\nIt is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# Official SubQuery Communities\n\n * Discord (Primary Community with dedicated technical support channels)\n * Medium (Primary announcements channel)\n * Twitter\n * WeChat\n * Telegram (Announcements channel only)\n * GitHub\n * Matrix/Riot\n * LinkedIn\n\n\n# Unofficial SubQuery Communities\n\nThese communities are not moderated by the SubQuery team, but our ambassadors may be there to provide support. 请小心诈骗，因为 SubQuery不对其中发生的事情负责。",normalizedContent:"# social media links\n\nsubquery is an active project that maintains and communicates with our followers through many social media channels.\n\nit is our aim to always listen and engage with our loyal community so please join the conversation and send us your ideas or questions!\n\n\n# official subquery communities\n\n * discord (primary community with dedicated technical support channels)\n * medium (primary announcements channel)\n * twitter\n * wechat\n * telegram (announcements channel only)\n * github\n * matrix/riot\n * linkedin\n\n\n# unofficial subquery communities\n\nthese communities are not moderated by the subquery team, but our ambassadors may be there to provide support. 请小心诈骗，因为 subquery不对其中发生的事情负责。",charsets:{cjk:!0},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Connect to your New Project",frontmatter:{summary:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di",meta:[{property:"og:url",content:"/zh/publish/connect.html"},{property:"og:title",content:"Connect to your New Project"},{property:"og:description",content:"Connect to your New Project Once your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the di"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/publish/connect.html",relativePath:"zh/publish/connect.md",key:"v-44575ff2",path:"/zh/publish/connect/",readingTime:{minutes:.61,words:182},headersStr:null,content:"# Connect to your New Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started.\n\n\n\n\n# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# connect to your new project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started.\n\n\n\n\n# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Publish your SubQuery Project",frontmatter:{summary:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T",meta:[{property:"og:url",content:"/zh/publish/publish.html"},{property:"og:title",content:"Publish your SubQuery Project"},{property:"og:description",content:"Publish your SubQuery Project Benefits of hosting your project with SubQuery We'll run your SubQuery projects for you in a high performance, scalable, and managed public service; T"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/publish/publish.html",relativePath:"zh/publish/publish.md",key:"v-67b53086",path:"/zh/publish/publish/",headers:[{level:2,title:"Benefits of hosting your project with SubQuery",slug:"benefits-of-hosting-your-project-with-subquery",normalizedTitle:"benefits of hosting your project with subquery",charIndex:36},{level:2,title:"Create your First Project",slug:"create-your-first-project",normalizedTitle:"create your first project",charIndex:505},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:3806},{level:2,title:"Add GitHub Organization Account to SubQuery Projects",slug:"add-github-organization-account-to-subquery-projects",normalizedTitle:"add github organization account to subquery projects",charIndex:4261}],readingTime:{minutes:3.78,words:1134},headersStr:"Benefits of hosting your project with SubQuery Create your First Project Next Steps - Connect to your Project Add GitHub Organization Account to SubQuery Projects",content:"# Publish your SubQuery Project\n\n\n# Benefits of hosting your project with SubQuery\n\n * We'll run your SubQuery projects for you in a high performance, scalable, and managed public service\n * This service is being provided to the community for free!\n * You can make your projects public so that they'll be listed in the SubQuery Explorer and anyone around the world can view them\n * We're integrated with GitHub, so anyone in your GitHub organisations will be able to view shared organisation projects\n\n\n# Create your First Project\n\n# Login to SubQuery Projects\n\nBefore starting, please make sure that your SubQuery project is online in a public GitHub repository. The schema.graphql file must be in the root of your directory.\n\nTo create your first project, head to project.subquery.network. You'll need to authenticate with your GitHub account to login.\n\nOn first login, you will be asked to authorize SubQuery. We only need your email address to identify your account, and we don't use any other data from your GitHub account for any other reasons. In this step, you can also request or grant access to your GitHub Organization account so you can post SubQuery projects under your GitHub Organization instead of your personal account.\n\n\n\nSubQuery Projects is where you manage all your hosted projects uploaded to the SubQuery platform. You can create, delete, and even upgrade projects all from this application.\n\n\n\nIf you have a GitHub Organization accounts connected, you can use the switcher on the header to change between your personal account and your GitHub Organization account. Projects created in a GitHub Organization account are shared between members in that GitHub Organization. To connect your GitHub Organization account, you can follow the steps here.\n\n\n\n# Create your First Project\n\nLet's start by clicking on \"Create Project\". You'll be taken to the New Project form. Please enter the following (you can change this in the future):\n\n * GitHub account: If you have more than one GitHub account, select which account this project will be created under. Projects created in a GitHub organisation account are shared between members in that organisation.\n * Name\n * Subtitle\n * Description\n * GitHub Repository URL: This must be a valid GitHub URL to a public repository that has your SubQuery project. The schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * Hide project: If selected, this will hide the project from the public SubQuery explorer. Keep this unselected if you want to share your SubQuery with the community!\n\nCreate your project and you'll see it on your SubQuery Project's list. _We're almost there! We just need to deploy a new version of it. _\n\n# Deploy your first Version\n\nWhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. Deploying a version triggers a new SubQuery indexing operation to start, and sets up the required query service to start accepting GraphQL requests. You can also deploy new versions to existing projects here.\n\nWith your new project, you'll see a Deploy New Version button. Click this, and fill in the required information about the deployment:\n\n * Commit Hash of new Version: From GitHub, copy the full commit hash of the version of your SubQuery project codebase that you want deployed\n * Indexer Version: This is the version of SubQuery's node service that you want to run this SubQuery on. See @subql/node\n * Query Version: This is the version of SubQuery's query service that you want to run this SubQuery on. See @subql/query\n\n\n\nIf deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. This process may take time until it reaches 100%.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in-browser playground to get started - read more about how to user our Explorer here.\n\n\n\n\n# Add GitHub Organization Account to SubQuery Projects\n\nIt is common to publish your SubQuery project under the name of your GitHub Organization account rather than your personal GitHub account. At any point your can change your currently selected account on SubQuery Projects using the account switcher.\n\n\n\nIf you can't see your GitHub Organization account listed in the switcher, the you may need to grant access to SubQuery for your GitHub Organization (or request it from an administrator). To do this, you first need to revoke permissions from your GitHub account to the SubQuery Application. To do this, login to your account settings in GitHub, go to Applications, and under the Authorized OAuth Apps tab, revoke SubQuery - you can follow the exact steps here. Don't worry, this will not delete your SubQuery project and you will not lose any data.\n\n\n\nOnce you have revoked access, log out of SubQuery Projects and log back in again. You should be redirected to a page titled Authorize SubQuery where you can request or grant SubQuery access to your GitHub Organization account. If you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nOnce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct GitHub Organization account in the account switcher.",normalizedContent:"# publish your subquery project\n\n\n# benefits of hosting your project with subquery\n\n * we'll run your subquery projects for you in a high performance, scalable, and managed public service\n * this service is being provided to the community for free!\n * you can make your projects public so that they'll be listed in the subquery explorer and anyone around the world can view them\n * we're integrated with github, so anyone in your github organisations will be able to view shared organisation projects\n\n\n# create your first project\n\n# login to subquery projects\n\nbefore starting, please make sure that your subquery project is online in a public github repository. the schema.graphql file must be in the root of your directory.\n\nto create your first project, head to project.subquery.network. you'll need to authenticate with your github account to login.\n\non first login, you will be asked to authorize subquery. we only need your email address to identify your account, and we don't use any other data from your github account for any other reasons. in this step, you can also request or grant access to your github organization account so you can post subquery projects under your github organization instead of your personal account.\n\n\n\nsubquery projects is where you manage all your hosted projects uploaded to the subquery platform. you can create, delete, and even upgrade projects all from this application.\n\n\n\nif you have a github organization accounts connected, you can use the switcher on the header to change between your personal account and your github organization account. projects created in a github organization account are shared between members in that github organization. to connect your github organization account, you can follow the steps here.\n\n\n\n# create your first project\n\nlet's start by clicking on \"create project\". you'll be taken to the new project form. please enter the following (you can change this in the future):\n\n * github account: if you have more than one github account, select which account this project will be created under. projects created in a github organisation account are shared between members in that organisation.\n * name\n * subtitle\n * description\n * github repository url: this must be a valid github url to a public repository that has your subquery project. the schema.graphql file must be in the root of your directory (learn more about the directory structure).\n * hide project: if selected, this will hide the project from the public subquery explorer. keep this unselected if you want to share your subquery with the community!\n\ncreate your project and you'll see it on your subquery project's list. _we're almost there! we just need to deploy a new version of it. _\n\n# deploy your first version\n\nwhile creating a project will setup the display behaviour of the project, you must deploy a version of it before it becomes operational. deploying a version triggers a new subquery indexing operation to start, and sets up the required query service to start accepting graphql requests. you can also deploy new versions to existing projects here.\n\nwith your new project, you'll see a deploy new version button. click this, and fill in the required information about the deployment:\n\n * commit hash of new version: from github, copy the full commit hash of the version of your subquery project codebase that you want deployed\n * indexer version: this is the version of subquery's node service that you want to run this subquery on. see @subql/node\n * query version: this is the version of subquery's query service that you want to run this subquery on. see @subql/query\n\n\n\nif deployed successfully, you'll see the indexer start working and report back progress on indexing the current chain. this process may take time until it reaches 100%.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in-browser playground to get started - read more about how to user our explorer here.\n\n\n\n\n# add github organization account to subquery projects\n\nit is common to publish your subquery project under the name of your github organization account rather than your personal github account. at any point your can change your currently selected account on subquery projects using the account switcher.\n\n\n\nif you can't see your github organization account listed in the switcher, the you may need to grant access to subquery for your github organization (or request it from an administrator). to do this, you first need to revoke permissions from your github account to the subquery application. to do this, login to your account settings in github, go to applications, and under the authorized oauth apps tab, revoke subquery - you can follow the exact steps here. don't worry, this will not delete your subquery project and you will not lose any data.\n\n\n\nonce you have revoked access, log out of subquery projects and log back in again. you should be redirected to a page titled authorize subquery where you can request or grant subquery access to your github organization account. if you don't have admin permissions, you must make a request for an adminstrator to enable this for you.\n\n\n\nonce this request has been approved by your administrator (or if are able to grant it youself), you will see the correct github organization account in the account switcher.",charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"部署您的 SubQuery 项目的新版本",frontmatter:{summary:"部署您的 SubQuery 项目的新版本 创作指南 尽管您可以随时升级和部署您的 SubQuery 项目的新版本， 如果您的 SubQuery 项目是为世界公开的，请在此过程中考虑。 需要注意的一些关键要点： 如果您的升级是一个突破性的变化，或者创建一个新的项目(例如) 我的 SubQuery 项目 V2或通过社交媒体渠道向您的社区发出大量警告。; 部署一个",meta:[{property:"og:url",content:"/zh/publish/upgrade.html"},{property:"og:title",content:"部署您的 SubQuery 项目的新版本"},{property:"og:description",content:"部署您的 SubQuery 项目的新版本 创作指南 尽管您可以随时升级和部署您的 SubQuery 项目的新版本， 如果您的 SubQuery 项目是为世界公开的，请在此过程中考虑。 需要注意的一些关键要点： 如果您的升级是一个突破性的变化，或者创建一个新的项目(例如) 我的 SubQuery 项目 V2或通过社交媒体渠道向您的社区发出大量警告。; 部署一个"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/publish/upgrade.html",relativePath:"zh/publish/upgrade.md",key:"v-ea5c64ba",path:"/zh/publish/upgrade/",headers:[{level:2,title:"创作指南",slug:"创作指南",normalizedTitle:"创作指南",charIndex:27},{level:2,title:"部署变更",slug:"部署变更",normalizedTitle:"部署变更",charIndex:241},{level:2,title:"Next Steps - Connect to your Project",slug:"next-steps-connect-to-your-project",normalizedTitle:"next steps - connect to your project",charIndex:2462}],readingTime:{minutes:2.33,words:698},headersStr:"创作指南 部署变更 Next Steps - Connect to your Project",content:"# 部署您的 SubQuery 项目的新版本\n\n\n# 创作指南\n\n尽管您可以随时升级和部署您的 SubQuery 项目的新版本， 如果您的 SubQuery 项目是为世界公开的，请在此过程中考虑。 需要注意的一些关键要点：\n\n * 如果您的升级是一个突破性的变化，或者创建一个新的项目(例如) 我的 SubQuery 项目 V2或通过社交媒体渠道向您的社区发出大量警告。\n * 部署一个新的 SubQuery 项目版本会导致一些关闭时间，因为新版本会从起源区块索引整个链。\n\n\n# 部署变更\n\nLogin to SubQuery Projects, and find the project that you want to deploy a new version of. Under Deployment Details you'll see three dots in the top right, click on the Deploy New Version button. You can choose to either deploy to the production or staging slot. These two slots are isolated environments and each has their own databases and synchronise independently.\n\nWe recommend deploying to your staging slot only for final staging testing or when you need to resync your project data. You can then promote it to production with zero downtime. You will find testing is faster when running a project locally as you can more easily debug issues.\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n * Final validation of changes to your SubQuery Project in a separate environment. The staging slot has a different URL to production that you can use in your dApps.\n * Fill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n * Preparing a new release for your SubQuery Project without exposing it publicly. The staging slot is not shown to the public in the Explorer and has a unique URL that is visible only to you.\n\n\n\n# Upgrade to the Latest Indexer and Query Service\n\nIf you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. This will cause only a few minutes of downtime.\n\n# Deploy New Version of your SubQuery Project\n\nFill in the Commit Hash from GitHub (copy the full commit hash) of the version of your SubQuery project codebase that you want deployed. This will cause a longer downtime depending on the time it takes to index the current chain. You can always report back here for progress.\n\n\n# Next Steps - Connect to your Project\n\nOnce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed GraphQL Query endpoint.\n\n\n\nAlternatively, you can click on the three dots next to the title of your project, and view it on SubQuery Explorer. There you can use the in browser playground to get started - read more about how to user our Explorer here. There you can use the in browser playground to get started - read more about how to user our Explorer here.",normalizedContent:"# 部署您的 subquery 项目的新版本\n\n\n# 创作指南\n\n尽管您可以随时升级和部署您的 subquery 项目的新版本， 如果您的 subquery 项目是为世界公开的，请在此过程中考虑。 需要注意的一些关键要点：\n\n * 如果您的升级是一个突破性的变化，或者创建一个新的项目(例如) 我的 subquery 项目 v2或通过社交媒体渠道向您的社区发出大量警告。\n * 部署一个新的 subquery 项目版本会导致一些关闭时间，因为新版本会从起源区块索引整个链。\n\n\n# 部署变更\n\nlogin to subquery projects, and find the project that you want to deploy a new version of. under deployment details you'll see three dots in the top right, click on the deploy new version button. you can choose to either deploy to the production or staging slot. these two slots are isolated environments and each has their own databases and synchronise independently.\n\nwe recommend deploying to your staging slot only for final staging testing or when you need to resync your project data. you can then promote it to production with zero downtime. you will find testing is faster when running a project locally as you can more easily debug issues.\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n * final validation of changes to your subquery project in a separate environment. the staging slot has a different url to production that you can use in your dapps.\n * fill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n * preparing a new release for your subquery project without exposing it publicly. the staging slot is not shown to the public in the explorer and has a unique url that is visible only to you.\n\n\n\n# upgrade to the latest indexer and query service\n\nif you just want to upgrade to the latest indexer (@subql/node) or query service (@subql/query) to take advantage of our regular performance and stability improvements, just select a newer versions of our packages and save. this will cause only a few minutes of downtime.\n\n# deploy new version of your subquery project\n\nfill in the commit hash from github (copy the full commit hash) of the version of your subquery project codebase that you want deployed. this will cause a longer downtime depending on the time it takes to index the current chain. you can always report back here for progress.\n\n\n# next steps - connect to your project\n\nonce your deployment has succesfully completed and our nodes have indexed your data from the chain, you'll be able to connect to your project via the displayed graphql query endpoint.\n\n\n\nalternatively, you can click on the three dots next to the title of your project, and view it on subquery explorer. there you can use the in browser playground to get started - read more about how to user our explorer here. there you can use the in browser playground to get started - read more about how to user our explorer here.",charsets:{cjk:!0},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Learn more about GraphQL",frontmatter:{summary:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap",meta:[{property:"og:url",content:"/zh/query/graphql.html"},{property:"og:title",content:"Learn more about GraphQL"},{property:"og:description",content:"Learn more about GraphQL You can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it: There are libraries to help you implement Grap"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/query/graphql.html",relativePath:"zh/query/graphql.md",key:"v-29ed5952",path:"/zh/query/graphql/",readingTime:{minutes:.29,words:87},headersStr:null,content:"# Learn more about GraphQL\n\nYou can follow the official GraphQL guide here to learn more about GraphQL, how it works, and how to use it:\n\n * There are libraries to help you implement GraphQL in many different languages\n * For an in-depth learning experience with practical tutorials, see How to GraphQL.\n * Check out the free online course, Exploring GraphQL: A Query Language for APIs.",normalizedContent:"# learn more about graphql\n\nyou can follow the official graphql guide here to learn more about graphql, how it works, and how to use it:\n\n * there are libraries to help you implement graphql in many different languages\n * for an in-depth learning experience with practical tutorials, see how to graphql.\n * check out the free online course, exploring graphql: a query language for apis.",charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Query your Project in SubQuery Explorer",frontmatter:{summary:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con",meta:[{property:"og:url",content:"/zh/query/query.html"},{property:"og:title",content:"Query your Project in SubQuery Explorer"},{property:"og:description",content:"Query your Project in SubQuery Explorer SubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by con"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/query/query.html",relativePath:"zh/query/query.md",key:"v-37f14c59",path:"/zh/query/query/",readingTime:{minutes:.96,words:288},headersStr:null,content:"# Query your Project in SubQuery Explorer\n\nSubQuery Explorer is an online hosted service (at explorer.subquery.network) that provides access to published SubQuery projects made by contributors in our community and managed by the SubQuery team. You can publish your own SubQuery projects to our explorer by following our guide to Publish your SubQuery Project.\n\n\n\nThe SubQuery explorer makes getting started easy. We’re hosting these SubQuery projects online and allow anyone to query each for free. These managed nodes will be monitored and run by the SubQuery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nYou’ll also note that the SubQuery Explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. Additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s Polkadot data.\n\nOn the top right of the playground, you'll find a Docs button that will open a documentation draw. This documentation is automatically generated and helps you find what entities and methods you can query. In the example below we're using the Sum Rewards SubQuery to get the top 5 most rewarded accounts (in terms of staking revenue) on Polkadot that have never been slashed.\n\n\n\nLearn more about the GraphQL Query language.",normalizedContent:"# query your project in subquery explorer\n\nsubquery explorer is an online hosted service (at explorer.subquery.network) that provides access to published subquery projects made by contributors in our community and managed by the subquery team. you can publish your own subquery projects to our explorer by following our guide to publish your subquery project.\n\n\n\nthe subquery explorer makes getting started easy. we’re hosting these subquery projects online and allow anyone to query each for free. these managed nodes will be monitored and run by the subquery team at a performance level that will allow production apps to use and rely on them.\n\n\n\nyou’ll also note that the subquery explorer provides a playground for discovering available data with example queries - you can test queries directly in your browser without implementing code. additionally, we’ve made some small improvements to our documentation to better support developers on their journey to better query and analyse the world’s polkadot data.\n\non the top right of the playground, you'll find a docs button that will open a documentation draw. this documentation is automatically generated and helps you find what entities and methods you can query. in the example below we're using the sum rewards subquery to get the top 5 most rewarded accounts (in terms of staking revenue) on polkadot that have never been slashed.\n\n\n\nlearn more about the graphql query language.",charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (由 SubQuery 托管)",frontmatter:{summary:"Hello World (由 SubQuery 托管) 本快速入门的目的是展示如何通过几个简单的步骤让默认启动项目在 SubQuery Projects（我们的管理服务）中运行。 我们将采用简单的入门项目（以及我们学到的所有内容）。但我们不会在 Docker 中本地运行它，而是利用 SubQuery 的托管基础架构。 换言之，我们会让 SubQuery 完成",meta:[{property:"og:url",content:"/zh/quickstart/helloworld-hosted.html"},{property:"og:title",content:"Hello World (由 SubQuery 托管)"},{property:"og:description",content:"Hello World (由 SubQuery 托管) 本快速入门的目的是展示如何通过几个简单的步骤让默认启动项目在 SubQuery Projects（我们的管理服务）中运行。 我们将采用简单的入门项目（以及我们学到的所有内容）。但我们不会在 Docker 中本地运行它，而是利用 SubQuery 的托管基础架构。 换言之，我们会让 SubQuery 完成"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/quickstart/helloworld-hosted.html",relativePath:"zh/quickstart/helloworld-hosted.md",key:"v-50bff266",path:"/zh/quickstart/helloworld-hosted/",headers:[{level:2,title:"学习目标",slug:"学习目标",normalizedTitle:"学习目标",charIndex:209},{level:2,title:"目标听众",slug:"目标听众",normalizedTitle:"目标听众",charIndex:370},{level:2,title:"视频指南",slug:"视频指南",normalizedTitle:"视频指南",charIndex:421},{level:2,title:"先决条件",slug:"先决条件",normalizedTitle:"先决条件",charIndex:239},{level:2,title:"第 1 步：创建您的项目",slug:"第-1-步-创建您的项目",normalizedTitle:"第 1 步：创建您的项目",charIndex:464},{level:2,title:"第 2 步：创建 GitHub 存储库",slug:"第-2-步-创建-github-存储库",normalizedTitle:"第 2 步：创建 github 存储库",charIndex:650},{level:2,title:"第 3 步：推送到 GitHub",slug:"第-3-步-推送到-github",normalizedTitle:"第 3 步：推送到 github",charIndex:781},{level:2,title:"第 4 步：创建您的项目",slug:"第-4-步-创建您的项目",normalizedTitle:"第 4 步：创建您的项目",charIndex:2177},{level:2,title:"第 5 步：部署您的项目",slug:"第-5-步-部署您的项目",normalizedTitle:"第 5 步：部署您的项目",charIndex:2701},{level:2,title:"第 6 步：测试您的项目",slug:"第-6-步-测试您的项目",normalizedTitle:"第 6 步：测试您的项目",charIndex:3308},{level:2,title:"第 7 步：奖励步骤",slug:"第-7-步-奖励步骤",normalizedTitle:"第 7 步：奖励步骤",charIndex:3412},{level:2,title:"概括",slug:"概括",normalizedTitle:"概括",charIndex:4515}],readingTime:{minutes:6.61,words:1982},headersStr:"学习目标 目标听众 视频指南 先决条件 第 1 步：创建您的项目 第 2 步：创建 GitHub 存储库 第 3 步：推送到 GitHub 第 4 步：创建您的项目 第 5 步：部署您的项目 第 6 步：测试您的项目 第 7 步：奖励步骤 概括",content:'# Hello World (由 SubQuery 托管)\n\n本快速入门的目的是展示如何通过几个简单的步骤让默认启动项目在 SubQuery Projects（我们的管理服务）中运行。\n\n我们将采用简单的入门项目（以及我们学到的所有内容）。但我们不会在 Docker 中本地运行它，而是利用 SubQuery 的托管基础架构。 换言之，我们会让 SubQuery 完成所有繁重的工作，运行和管理生产基础设施。\n\n\n# 学习目标\n\n在本快速入门结束时，您应该：\n\n * 了解所需的先决条件\n * 能够在SubQuery Projects中托管项目\n * 运行一个简单的查询以使用 Playground 来获取 Polkadot 主网的块高度\n * 运行一个简单的 GET 查询以使用 cURL 来获取 Polkadot 主网的块高度\n\n\n# 目标听众\n\n本指南面向具有一些开发经验并有兴趣了解更多关于 SubQuery 的新开发人员。\n\n\n# 视频指南\n\n\n# 先决条件\n\n你将会需要：\n\n * 一个 GitHub 帐户\n\n\n# 第 1 步：创建您的项目\n\n让我们创建一个叫做 subql_hellowworld 的项目，并使用您最喜欢的软件包管理器运行必需的安装、代码生成和构建。\n\n> subql init --starter subqlHelloWorld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\n不要运行 docker 命令。\n\n\n# 第 2 步：创建 GitHub 存储库\n\n在 GitHub 中，创建一个新的公共资源库。 提供一个名称并将您的可见性设置为公开。 在这里，一切都会被保留为默认值。\n\n\n\n记下您的 GitHub URL，它必须是公开的，SubQuery 才能访问它。\n\n\n\n\n# 第 3 步：推送到 GitHub\n\n回到您的项目目录，将其初始化为 git 目录。 否则，您可能会收到"fatal: not a git repository (or any of the parent directories): .git”\n\ngit init\n\n\n1\n\n\n然后使用以下命令添加远程存储库：\n\ngit remote add origin https://github.com/seandotau/subqlHelloWorld.git\n\n\n1\n\n\n这会将您的远程存储库设置为“https://github.com/seandotau/subqlHelloWorld.git”，并将其命名为“origin” — 这是 GitHub 中远程存储库的标准命名法。\n\n下一步，我们通过以下命令将代码添加到我们的存储库中：\n\n> git add .\n> git commit -m "First commit"\n[master (root-commit) a999d88] First commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 README.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappingHandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nEnumerating objects: 14, done.\nCounting objects: 100% (14/14), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (13/13), done.\nWriting objects: 100% (14/14), 59.35 KiB | 8.48 MiB/s, done.\nTotal 14 (delta 0), reused 0 (delta 0)\nTo https://github.com/seandotau/subqlHelloWorld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\npush 命令的意思是“请将我的代码从我的主本地存储库推送到原始存储库”。 刷新 GitHub 会显示 GitHub 中的所有代码。\n\n\n\n现在你已经将你的代码存入 GitHub, 让我们来看看如何能够在 SubQuery Projects 中托管它。\n\n\n# 第 4 步：创建您的项目\n\n浏览此网址 https://project.subquery.network 并使用您的 GitHub 帐户登录。\n\n\n\n然后创建一个新项目。\n\n\n\n并用适当的详细信息填写各个字段。\n\n * GitHub 帐户： 如果您有多个 GitHub 帐户，请选择该项目将在哪个帐户下创建。 在 GitHub 组织账户中创建的项目由该组织的成员共享。\n * 项目名称： 在此处为您的项目命名。\n * 副标题： 为您的项目提供副标题。\n * 描述： 解释您的 SubQuery 项目的用途。\n * GitHub 存储库 URL： 这必须是包含您的 SubQuery 项目的公共存储库的有效 GitHub URL。 schemagraphql 文件必须在您的目录的根目录中。\n * 隐藏项目： 如果选中，如果选中，这将在公共 SubQuery 浏览器中隐藏项目。 如果您想与社区共享您的 SubQuery 项目，请不要选择此项！\n\n\n\n当您单击创建时，您将被带到控制面板。\n\n\n\n控制面板包含许多有用的信息，例如它使用的网络、它运行的源代码的 GitHub 存储库 URL、它的创建时间和上次更新时间，尤其是部署的详细信息。\n\n\n# 第 5 步：部署您的项目\n\n现在您已经在 SubQuery Projects 项目中创建了您的项目，设置显示行为后，下一步是部署您的项目，使其能够运行。 部署一个版本会触发一个新的 SubQuery 索引操作来启动，并设置所需的查询服务来开始接受 GraphQL 请求。 您也可以在这里部署新版本到现有的项目。\n\n您可以选择部署到不同的环境，例如生产槽或暂存槽。 在这里，我们将部署到生产槽。 单击“部署”按钮会显示一个包含以下字段的屏幕：\n\n\n\n * 新版本的 Commit Hash： 从 GitHub 中选择您要部署的 SubQuery 项目代码库的正确交付\n * 索引器版本： 这是您要在其上运行此 SubQuery 项目的 SubQuery 节点服务的版本。 请登录此网址参考 @subql/node\n * 查询版本： 这是您要在其上运行此 SubQuery 项目的 SubQuery 查询服务的版本。 请登录此网址参考 @subql/quiry\n\n因为我们只有一个交付，所以下拉菜单中只有一个选项。 我们还将使用最新版本的索引器和查询版本，因此我们将接受默认值，然后单击“部署更新”。\n\n然后，您将看到您的部署处于“正在处理”状态。 在这里，您的代码正在部署到 SubQuery 的托管基础架构上。 服务器正在按需启动并准备为您提供服务。 这将需要几分钟的时间。\n\n\n\n目前正在进行部署。\n\n\n\n\n# 第 6 步：测试您的项目\n\n要测试您的项目，请单击省略号并选择“在 SubQuery 浏览器上查看”。\n\n\n\n这将带您进入熟悉的“Playground”，您可以在其中单击播放按钮并查看查询结果。\n\n\n\n\n# 第 7 步：奖励步骤\n\n对于我们中的敏锐者，您会记得在学习目标中，最后一点是运行一个简单的 GET 查询。 为此，我们需要获取部署详细信息中显示的“查询端点”。\n\n\n\n然后您可以使用您最喜欢的客户端，例如 Postman 或 Mockoon 或通过您终端中的 cURL 将 GET 请求发送到这个端点。 为了简单起见，cURL 将在下面显示。\n\n要运行的 curl 命令是：\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterEntities (first: 5, orderBy: CREATED_AT_DESC) { totalCount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\n给出以下结果：\n\n{"data":{"starterEntities":{"totalCount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\n可读性在这里不是问题，因为您可能会有一些前端代码来使用和解析这个 JSON 响应。\n\n\n# 概括\n\n在这个 SubQuery 托管的快速入门中，我们展示了获取 Subql 项目并将其部署到 SubQuery Projects 是多么快速和简单，这里为您提供所以的基础设施。 并且有一个用于运行各种查询的内置 playground，以及一个供您的代码集成的 API 端点。',normalizedContent:'# hello world (由 subquery 托管)\n\n本快速入门的目的是展示如何通过几个简单的步骤让默认启动项目在 subquery projects（我们的管理服务）中运行。\n\n我们将采用简单的入门项目（以及我们学到的所有内容）。但我们不会在 docker 中本地运行它，而是利用 subquery 的托管基础架构。 换言之，我们会让 subquery 完成所有繁重的工作，运行和管理生产基础设施。\n\n\n# 学习目标\n\n在本快速入门结束时，您应该：\n\n * 了解所需的先决条件\n * 能够在subquery projects中托管项目\n * 运行一个简单的查询以使用 playground 来获取 polkadot 主网的块高度\n * 运行一个简单的 get 查询以使用 curl 来获取 polkadot 主网的块高度\n\n\n# 目标听众\n\n本指南面向具有一些开发经验并有兴趣了解更多关于 subquery 的新开发人员。\n\n\n# 视频指南\n\n\n# 先决条件\n\n你将会需要：\n\n * 一个 github 帐户\n\n\n# 第 1 步：创建您的项目\n\n让我们创建一个叫做 subql_hellowworld 的项目，并使用您最喜欢的软件包管理器运行必需的安装、代码生成和构建。\n\n> subql init --starter subqlhelloworld\nyarn install\nyarn codegen\nyarn build\n\n\n1\n2\n3\n4\n\n\n不要运行 docker 命令。\n\n\n# 第 2 步：创建 github 存储库\n\n在 github 中，创建一个新的公共资源库。 提供一个名称并将您的可见性设置为公开。 在这里，一切都会被保留为默认值。\n\n\n\n记下您的 github url，它必须是公开的，subquery 才能访问它。\n\n\n\n\n# 第 3 步：推送到 github\n\n回到您的项目目录，将其初始化为 git 目录。 否则，您可能会收到"fatal: not a git repository (or any of the parent directories): .git”\n\ngit init\n\n\n1\n\n\n然后使用以下命令添加远程存储库：\n\ngit remote add origin https://github.com/seandotau/subqlhelloworld.git\n\n\n1\n\n\n这会将您的远程存储库设置为“https://github.com/seandotau/subqlhelloworld.git”，并将其命名为“origin” — 这是 github 中远程存储库的标准命名法。\n\n下一步，我们通过以下命令将代码添加到我们的存储库中：\n\n> git add .\n> git commit -m "first commit"\n[master (root-commit) a999d88] first commit\n10 files changed, 3512 insertions(+)\ncreate mode 100644 .gitignore\ncreate mode 100644 readme.md\ncreate mode 100644 docker-compose.yml\ncreate mode 100644 package.json\ncreate mode 100644 project.yaml\ncreate mode 100644 schema.graphql\ncreate mode 100644 src/index.ts\ncreate mode 100644 src/mappings/mappinghandlers.ts\ncreate mode 100644 tsconfig.json\ncreate mode 100644 yarn.lock\n> git push origin master\nenumerating objects: 14, done.\ncounting objects: 100% (14/14), done.\ndelta compression using up to 12 threads\ncompressing objects: 100% (13/13), done.\nwriting objects: 100% (14/14), 59.35 kib | 8.48 mib/s, done.\ntotal 14 (delta 0), reused 0 (delta 0)\nto https://github.com/seandotau/subqlhelloworld.git\n * [new branch]      master -> master\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\npush 命令的意思是“请将我的代码从我的主本地存储库推送到原始存储库”。 刷新 github 会显示 github 中的所有代码。\n\n\n\n现在你已经将你的代码存入 github, 让我们来看看如何能够在 subquery projects 中托管它。\n\n\n# 第 4 步：创建您的项目\n\n浏览此网址 https://project.subquery.network 并使用您的 github 帐户登录。\n\n\n\n然后创建一个新项目。\n\n\n\n并用适当的详细信息填写各个字段。\n\n * github 帐户： 如果您有多个 github 帐户，请选择该项目将在哪个帐户下创建。 在 github 组织账户中创建的项目由该组织的成员共享。\n * 项目名称： 在此处为您的项目命名。\n * 副标题： 为您的项目提供副标题。\n * 描述： 解释您的 subquery 项目的用途。\n * github 存储库 url： 这必须是包含您的 subquery 项目的公共存储库的有效 github url。 schemagraphql 文件必须在您的目录的根目录中。\n * 隐藏项目： 如果选中，如果选中，这将在公共 subquery 浏览器中隐藏项目。 如果您想与社区共享您的 subquery 项目，请不要选择此项！\n\n\n\n当您单击创建时，您将被带到控制面板。\n\n\n\n控制面板包含许多有用的信息，例如它使用的网络、它运行的源代码的 github 存储库 url、它的创建时间和上次更新时间，尤其是部署的详细信息。\n\n\n# 第 5 步：部署您的项目\n\n现在您已经在 subquery projects 项目中创建了您的项目，设置显示行为后，下一步是部署您的项目，使其能够运行。 部署一个版本会触发一个新的 subquery 索引操作来启动，并设置所需的查询服务来开始接受 graphql 请求。 您也可以在这里部署新版本到现有的项目。\n\n您可以选择部署到不同的环境，例如生产槽或暂存槽。 在这里，我们将部署到生产槽。 单击“部署”按钮会显示一个包含以下字段的屏幕：\n\n\n\n * 新版本的 commit hash： 从 github 中选择您要部署的 subquery 项目代码库的正确交付\n * 索引器版本： 这是您要在其上运行此 subquery 项目的 subquery 节点服务的版本。 请登录此网址参考 @subql/node\n * 查询版本： 这是您要在其上运行此 subquery 项目的 subquery 查询服务的版本。 请登录此网址参考 @subql/quiry\n\n因为我们只有一个交付，所以下拉菜单中只有一个选项。 我们还将使用最新版本的索引器和查询版本，因此我们将接受默认值，然后单击“部署更新”。\n\n然后，您将看到您的部署处于“正在处理”状态。 在这里，您的代码正在部署到 subquery 的托管基础架构上。 服务器正在按需启动并准备为您提供服务。 这将需要几分钟的时间。\n\n\n\n目前正在进行部署。\n\n\n\n\n# 第 6 步：测试您的项目\n\n要测试您的项目，请单击省略号并选择“在 subquery 浏览器上查看”。\n\n\n\n这将带您进入熟悉的“playground”，您可以在其中单击播放按钮并查看查询结果。\n\n\n\n\n# 第 7 步：奖励步骤\n\n对于我们中的敏锐者，您会记得在学习目标中，最后一点是运行一个简单的 get 查询。 为此，我们需要获取部署详细信息中显示的“查询端点”。\n\n\n\n然后您可以使用您最喜欢的客户端，例如 postman 或 mockoon 或通过您终端中的 curl 将 get 请求发送到这个端点。 为了简单起见，curl 将在下面显示。\n\n要运行的 curl 命令是：\n\ncurl https://api.subquery.network/sq/seandotau/subqueryhelloworld -d "query=query { starterentities (first: 5, orderby: created_at_desc) { totalcount nodes { id field1 field2 field3 } } }"\n\n\n1\n\n\n给出以下结果：\n\n{"data":{"starterentities":{"totalcount":23098,"nodes":[{"id":"0x29dfe9c8e5a1d51178565c2c23f65d249b548fe75a9b6d74cebab777b961b1a6","field1":23098,"field2":null,"field3":null},{"id":"0xab7d3e0316a01cdaf9eda420cf4021dd53bb604c29c5136fef17088c8d9233fb","field1":23097,"field2":null,"field3":null},{"id":"0x534e89bbae0857f2f07b0dea8dc42a933f9eb2d95f7464bf361d766a644d17e3","field1":23096,"field2":null,"field3":null},{"id":"0xd0af03ab2000a58b40abfb96a61d312a494069de3670b509454bd06157357db6","field1":23095,"field2":null,"field3":null},{"id":"0xc9f5a92f4684eb039e11dffa4b8b22c428272b2aa09aff291169f71c1ba0b0f7","field1":23094,"field2":null,"field3":null}]}}}\n\n\n\n1\n2\n\n\n可读性在这里不是问题，因为您可能会有一些前端代码来使用和解析这个 json 响应。\n\n\n# 概括\n\n在这个 subquery 托管的快速入门中，我们展示了获取 subql 项目并将其部署到 subquery projects 是多么快速和简单，这里为您提供所以的基础设施。 并且有一个用于运行各种查询的内置 playground，以及一个供您的代码集成的 api 端点。',charsets:{cjk:!0},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World (localhost + Docker)",frontmatter:{summary:"Hello World (localhost + Docker) 欢迎使用 SubQuery Hello World 快速入门。 快速入门旨在通过几个简单的步骤向您展示如何在 Docker 中运行默认的启动项目。 学习目标 在本快速入门结束时，您应该： 了解所需的先决条件; 了解基本的常用命令; 能够导航到 localhost:3000 并查看 playgr",meta:[{property:"og:url",content:"/zh/quickstart/helloworld-localhost.html"},{property:"og:title",content:"Hello World (localhost + Docker)"},{property:"og:description",content:"Hello World (localhost + Docker) 欢迎使用 SubQuery Hello World 快速入门。 快速入门旨在通过几个简单的步骤向您展示如何在 Docker 中运行默认的启动项目。 学习目标 在本快速入门结束时，您应该： 了解所需的先决条件; 了解基本的常用命令; 能够导航到 localhost:3000 并查看 playgr"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/quickstart/helloworld-localhost.html",relativePath:"zh/quickstart/helloworld-localhost.md",key:"v-9101a14a",path:"/zh/quickstart/helloworld-localhost/",headers:[{level:2,title:"学习目标",slug:"学习目标",normalizedTitle:"学习目标",charIndex:114},{level:2,title:"目标受众",slug:"目标受众",normalizedTitle:"目标受众",charIndex:238},{level:2,title:"视频指南",slug:"视频指南",normalizedTitle:"视频指南",charIndex:289},{level:2,title:"先决条件",slug:"先决条件",normalizedTitle:"先决条件",charIndex:144},{level:2,title:"第 1 步：初始化项目",slug:"第-1-步-初始化项目",normalizedTitle:"第 1 步：初始化项目",charIndex:875},{level:2,title:"第 2 步：安装依赖包",slug:"第-2-步-安装依赖包",normalizedTitle:"第 2 步：安装依赖包",charIndex:1292},{level:2,title:"第 3 步：生成代码",slug:"第-3-步-生成代码",normalizedTitle:"第 3 步：生成代码",charIndex:1673},{level:2,title:"第 4 步: 构建代码",slug:"第-4-步-构建代码",normalizedTitle:"第 4 步: 构建代码",charIndex:2255},{level:2,title:"第 5 步：运行 Docker",slug:"第-5-步-运行-docker",normalizedTitle:"第 5 步：运行 docker",charIndex:2445},{level:2,title:"第 6 步：浏览 playground",slug:"第-6-步-浏览-playground",normalizedTitle:"第 6 步：浏览 playground",charIndex:3559},{level:2,title:"概括",slug:"概括",normalizedTitle:"概括",charIndex:3849}],readingTime:{minutes:3.51,words:1054},headersStr:"学习目标 目标受众 视频指南 先决条件 第 1 步：初始化项目 第 2 步：安装依赖包 第 3 步：生成代码 第 4 步: 构建代码 第 5 步：运行 Docker 第 6 步：浏览 playground 概括",content:'# Hello World (localhost + Docker)\n\n欢迎使用 SubQuery Hello World 快速入门。 快速入门旨在通过几个简单的步骤向您展示如何在 Docker 中运行默认的启动项目。\n\n\n# 学习目标\n\n在本快速入门结束时，您应该：\n\n * 了解所需的先决条件\n * 了解基本的常用命令\n * 能够导航到 localhost:3000 并查看 playground\n * 运行一个简单的查询来获取 Polkadot 主网的区块高度\n\n\n# 目标受众\n\n本指南面向具有一些开发经验并有兴趣了解更多关于 SubQuery 的新开发人员。\n\n\n# 视频指南\n\n\n# 先决条件\n\n您会需要：\n\n * yarn 或 npm 软件包管理器\n * SubQuery CLI (@subql/cli)\n * Docker\n\n您可以在终端中运行以下命令来查看您是否已经拥有这些先决条件。\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\n对于更高级的用户，复制并粘贴以下内容：\n\necho -e "My yarn version is:" `yarn -v` "\\nMy subql version is:" `subql -v`  "\\nMy docker version is:" `docker -v`\n\n\n1\n\n\n这应该返回：(对于 npm 用户，用 npm 替换 yarn）\n\nMy yarn version is: 1.22.10\nMy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nMy docker version is: Docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\n如果你得到了上面的内容，那么你就可以开始了。 如果没有，请按照以下链接安装它们：\n\n * yarn or npm\n * SubQuery CLI\n * Docker\n\n\n# 第 1 步：初始化项目\n\n开始使用 SubQuery 的第一步是运行 subql init 命令。 让我们初始化一个名为 subqlHelloWorld 的启动项目。 请注意，只有作者是强制性的。 其他所有内容都在下面都是空着的。\n\n> subql init --starter subqlHelloWorld\nGit repository:\nRPC endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nAuthors: sa\nDescription:\nVersion: [1.0.0]:\nLicense: [Apache-2.0]:\nInit the starter package... subqlHelloWorld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n请不要忘记切换到这个新目录。\n\ncd subqlHelloWorld\n\n\n1\n\n\n\n# 第 2 步：安装依赖包\n\n现在执行 yarn 或 node install 以安装各种依赖包。\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nyarn install示例\n\n> yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 第 3 步：生成代码\n\n现在运行 yarn codegen 生成来自 GraphQL schema 的 Typescript。\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nAn example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------Subql Codegen---------\n===============================\n* Schema StarterEntity generated !\n* Models index generated !\n* Types index generated !\n✨  Done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nWarning When changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# 第 4 步: 构建代码\n\n下一步是使用 yarn building 来构建代码。\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nyarn build 示例\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  Done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# 第 5 步：运行 Docker\n\n使用 Docker 可以让您非常快速地运行此示例，因为 Docker 中提供所有必需的基础设施。 运行 docker-compose praw && docker-compose up.\n\n这将把一切都变成现实，最终，您将获得正在被获取的区块。\n\n> #SNIPPET\nsubquery-node_1   | 2021-06-05T22:20:31.450Z <subql-node> INFO node started\nsubquery-node_1   | 2021-06-05T22:20:35.134Z <fetch> INFO fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05T22:20:38.412Z <fetch> INFO fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05T22:20:39.353Z <nestjs> INFO Starting Nest application...\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO AppModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.382Z <nestjs> INFO ConfigureModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.383Z <nestjs> INFO GraphqlModule dependencies initialized\ngraphql-engine_1  | 2021-06-05T22:20:39.809Z <nestjs> INFO Nest application successfully started\nsubquery-node_1   | 2021-06-05T22:20:41.122Z <fetch> INFO fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05T22:20:43.244Z <express> INFO request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 第 6 步：浏览 playground\n\n导航到 http://localhost:3000/， 并将下面的查询粘贴到屏幕左侧，然后点击播放按钮。\n\n{\n query{\n   starterEntities(last:10, orderBy:FIELD1_ASC ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n在 localhost 上的 SubQuery playground\n\n\n\nPlayground 中的区块计数也应与终端中的区块计数（严格来说是区块高度）相匹配。\n\n\n# 概括\n\n在这个快速入门中，我们演示了在 Docker 环境中启动和运行一个初始项目的基本步骤，然后导航到 localhost:3000，并运行查询以返回主网 Polkadot network 的区块号。',normalizedContent:'# hello world (localhost + docker)\n\n欢迎使用 subquery hello world 快速入门。 快速入门旨在通过几个简单的步骤向您展示如何在 docker 中运行默认的启动项目。\n\n\n# 学习目标\n\n在本快速入门结束时，您应该：\n\n * 了解所需的先决条件\n * 了解基本的常用命令\n * 能够导航到 localhost:3000 并查看 playground\n * 运行一个简单的查询来获取 polkadot 主网的区块高度\n\n\n# 目标受众\n\n本指南面向具有一些开发经验并有兴趣了解更多关于 subquery 的新开发人员。\n\n\n# 视频指南\n\n\n# 先决条件\n\n您会需要：\n\n * yarn 或 npm 软件包管理器\n * subquery cli (@subql/cli)\n * docker\n\n您可以在终端中运行以下命令来查看您是否已经拥有这些先决条件。\n\nyarn -v (or npm -v)\nsubql -v\ndocker -v\n\n\n1\n2\n3\n\n\n对于更高级的用户，复制并粘贴以下内容：\n\necho -e "my yarn version is:" `yarn -v` "\\nmy subql version is:" `subql -v`  "\\nmy docker version is:" `docker -v`\n\n\n1\n\n\n这应该返回：(对于 npm 用户，用 npm 替换 yarn）\n\nmy yarn version is: 1.22.10\nmy subql version is: @subql/cli/0.9.3 darwin-x64 node-v16.3.0\nmy docker version is: docker version 20.10.5, build 55c4c88\n\n\n1\n2\n3\n\n\n如果你得到了上面的内容，那么你就可以开始了。 如果没有，请按照以下链接安装它们：\n\n * yarn or npm\n * subquery cli\n * docker\n\n\n# 第 1 步：初始化项目\n\n开始使用 subquery 的第一步是运行 subql init 命令。 让我们初始化一个名为 subqlhelloworld 的启动项目。 请注意，只有作者是强制性的。 其他所有内容都在下面都是空着的。\n\n> subql init --starter subqlhelloworld\ngit repository:\nrpc endpoint [wss://polkadot.api.onfinality.io/public-ws]:\nauthors: sa\ndescription:\nversion: [1.0.0]:\nlicense: [apache-2.0]:\ninit the starter package... subqlhelloworld is ready\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n请不要忘记切换到这个新目录。\n\ncd subqlhelloworld\n\n\n1\n\n\n\n# 第 2 步：安装依赖包\n\n现在执行 yarn 或 node install 以安装各种依赖包。\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n\n\nyarn install示例\n\n> yarn install\nyarn install v1.22.10\ninfo no lockfile found.\n[1/4] 🔍  resolving packages...\n[2/4] 🚚  fetching packages...\n[3/4] 🔗  linking dependencies...\n[4/4] 🔨  building fresh packages...\nsuccess saved lockfile.\n✨  done in 31.84s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 第 3 步：生成代码\n\n现在运行 yarn codegen 生成来自 graphql schema 的 typescript。\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\nan example of yarn codegen\n\n> yarn codegen\nyarn run v1.22.10\n$ ./node_modules/.bin/subql codegen\n===============================\n---------subql codegen---------\n===============================\n* schema starterentity generated !\n* models index generated !\n* types index generated !\n✨  done in 1.02s.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\nwarning when changes are made to the schema file, please remember to re-run yarn codegen to regenerate your types directory.\n\n\n# 第 4 步: 构建代码\n\n下一步是使用 yarn building 来构建代码。\n\n# yarn\nyarn build\n\n# npm\nnpm run-script build\n\n\n1\n2\n3\n4\n5\n\n\nyarn build 示例\n\n> yarn build\nyarn run v1.22.10\n$ tsc -b\n✨  done in 5.68s.\n\n\n1\n2\n3\n4\n\n\n\n# 第 5 步：运行 docker\n\n使用 docker 可以让您非常快速地运行此示例，因为 docker 中提供所有必需的基础设施。 运行 docker-compose praw && docker-compose up.\n\n这将把一切都变成现实，最终，您将获得正在被获取的区块。\n\n> #snippet\nsubquery-node_1   | 2021-06-05t22:20:31.450z <subql-node> info node started\nsubquery-node_1   | 2021-06-05t22:20:35.134z <fetch> info fetch block [1, 100]\nsubqlhelloworld_graphql-engine_1 exited with code 0\nsubquery-node_1   | 2021-06-05t22:20:38.412z <fetch> info fetch block [101, 200]\ngraphql-engine_1  | 2021-06-05t22:20:39.353z <nestjs> info starting nest application...\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info appmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.382z <nestjs> info configuremodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.383z <nestjs> info graphqlmodule dependencies initialized\ngraphql-engine_1  | 2021-06-05t22:20:39.809z <nestjs> info nest application successfully started\nsubquery-node_1   | 2021-06-05t22:20:41.122z <fetch> info fetch block [201, 300]\ngraphql-engine_1  | 2021-06-05t22:20:43.244z <express> info request completed\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 第 6 步：浏览 playground\n\n导航到 http://localhost:3000/， 并将下面的查询粘贴到屏幕左侧，然后点击播放按钮。\n\n{\n query{\n   starterentities(last:10, orderby:field1_asc ){\n     nodes{\n       field1\n     }\n   }\n }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n在 localhost 上的 subquery playground\n\n\n\nplayground 中的区块计数也应与终端中的区块计数（严格来说是区块高度）相匹配。\n\n\n# 概括\n\n在这个快速入门中，我们演示了在 docker 环境中启动和运行一个初始项目的基本步骤，然后导航到 localhost:3000，并运行查询以返回主网 polkadot network 的区块号。',charsets:{cjk:!0},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"快速入门指南",frontmatter:{summary:"快速入门指南 在本快速入门指南中，我们将创建一个简单的入门项目，您可以将其用作开发您自己的 SubQuery 项目的框架。 在本指南的最后，您将拥有一个在 SubQuery 节点上运行的可工作 的 SubQuery 项目，该节点具有一个可以从中查询数据的 GraphQL 端点。 如果您还没有准备好，我们建议您熟悉 SubQuery 中所使用的 术语。 准备工",meta:[{property:"og:url",content:"/zh/quickstart/quickstart.html"},{property:"og:title",content:"快速入门指南"},{property:"og:description",content:"快速入门指南 在本快速入门指南中，我们将创建一个简单的入门项目，您可以将其用作开发您自己的 SubQuery 项目的框架。 在本指南的最后，您将拥有一个在 SubQuery 节点上运行的可工作 的 SubQuery 项目，该节点具有一个可以从中查询数据的 GraphQL 端点。 如果您还没有准备好，我们建议您熟悉 SubQuery 中所使用的 术语。 准备工"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/quickstart/quickstart.html",relativePath:"zh/quickstart/quickstart.md",key:"v-2c2604bd",path:"/zh/quickstart/quickstart/",headers:[{level:2,title:"准备工作",slug:"准备工作",normalizedTitle:"准备工作",charIndex:186},{level:3,title:"本地开发环境",slug:"本地开发环境",normalizedTitle:"本地开发环境",charIndex:195},{level:3,title:"安装 SubQuery CLI",slug:"安装-subquery-cli",normalizedTitle:"安装 subquery cli",charIndex:306},{level:2,title:"初始化 Starter SubQuery 项目",slug:"初始化-starter-subquery-项目",normalizedTitle:"初始化 starter subquery 项目",charIndex:492},{level:2,title:"配置和构建入门项目",slug:"配置和构建入门项目",normalizedTitle:"配置和构建入门项目",charIndex:1209},{level:3,title:"GraphQL 模型生成",slug:"graphql-模型生成",normalizedTitle:"graphql 模型生成",charIndex:1396},{level:2,title:"构建项目",slug:"构建项目",normalizedTitle:"构建项目",charIndex:1609},{level:2,title:"运行并查询您的启动项目",slug:"运行并查询您的启动项目",normalizedTitle:"运行并查询您的启动项目",charIndex:1747},{level:3,title:"运行您的 SubQuery 项目",slug:"运行您的-subquery-项目",normalizedTitle:"运行您的 subquery 项目",charIndex:1636},{level:3,title:"查询您的项目",slug:"查询您的项目",normalizedTitle:"查询您的项目",charIndex:2207},{level:2,title:"下一步",slug:"下一步",normalizedTitle:"下一步",charIndex:2583}],readingTime:{minutes:4.6,words:1381},headersStr:"准备工作 本地开发环境 安装 SubQuery CLI 初始化 Starter SubQuery 项目 配置和构建入门项目 GraphQL 模型生成 构建项目 运行并查询您的启动项目 运行您的 SubQuery 项目 查询您的项目 下一步",content:"# 快速入门指南\n\n在本快速入门指南中，我们将创建一个简单的入门项目，您可以将其用作开发您自己的 SubQuery 项目的框架。\n\n在本指南的最后，您将拥有一个在 SubQuery 节点上运行的可工作 的 SubQuery 项目，该节点具有一个可以从中查询数据的 GraphQL 端点。\n\n如果您还没有准备好，我们建议您熟悉 SubQuery 中所使用的 术语。\n\n\n# 准备工作\n\n\n# 本地开发环境\n\n * 编译项目和定义类型需要用到Typescript 。\n * SubQuery CLI 和生成的项目都有依赖关系，并且需要一个现代版本 Node。\n * SubQuery 节点需要 Docker\n\n\n# 安装 SubQuery CLI\n\n使用 NPM 在终端上全局安装 SubQuery CLI：\n\n# NPM\nnpm install -g @subql/cli\n\n\n1\n2\n\n\n请注意我们不鼓励使用 yarn global ，因为它的依赖性管理很差，这可能会导致错误。\n\n然后，您可以运行帮助以查看 CLI 提供的可用命令和用法。\n\nsubql help\n\n\n1\n\n\n\n# 初始化 Starter SubQuery 项目\n\n在您要创建 SubQuery 项目的目录中，只需将PROJECT_NAME 替换为您自己的项目名称并运行命令：\n\nsubql init --starter PROJECT_NAME\n\n\n1\n\n\n在初始化 SubQuery project 时，您会被问到一些问题：\n\n * Git 存储库（可选）：提供指向此 SubQuery 项目的，并将在其中托管的存储库的 Git URL（当托管在 SubQuery Explorer 中时）\n * RPC 端点(必填)：提供一个 wss URL 给一个正在运行的 RPC 端点，该端点将默认用于此项目。 您可以快速访问不同的 Polkadot 网络的公共端点，甚至可以使用 OnFinality 或仅使用默认的 Polkadot 端点创建您自己的专用节点。\n * 作者(必填)：在此处输入此 SubQuery 项目的所有者\n * 描述(可选)：您可以提供一个简短的段落介绍您的项目，描述它包含哪些数据以及用户可以做些什么。\n * 版本 (必填)：输入一个自定义版本号或使用默认版本(1.0.0)\n * 许可证(必填)：提供此项目的软件许可或接受默认设置(Apache-2.0)\n\n在初始化过程完成后，您应该看到目录内创建了一个项目名称的文件夹。 此目录的内容应该与 Directory Structure 中列出的内容完全相同。\n\n最后，在项目目录下，运行以下命令来安装新项目的依赖关系。\n\ncd PROJECT_NAME\n\n# Yarn\nyarn install\n\n# NPM\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 配置和构建入门项目\n\n在您刚刚初始化的启动软件包中，我们为您的新项目提供了标准配置。 您将主要处理以下文件：\n\n * project.yaml 中的清单\n * schema.graphql 的 GraphQL 架构\n * src/mappings/ 目录中的映射函数\n\n关于如何编写您自己的子查询的更多信息，请查阅 Create a Project 下的我们的文档\n\n\n# GraphQL 模型生成\n\n为了 索引 您的 SubQuery 项目，您必须首先生成您在 GraphQL Schema 文件中定义的 GraphQL 模型(Schema)。 rachql。 在项目目录的根目录中运行此命令。\n\n# Yarn\nyarn codegen\n\n# NPM\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\n您将在 /src/types/model 目录中找到生成的模型\n\n\n# 构建项目\n\n为了在本地托管的 SubQuery 节点上运行您的 SubQuery 项目，您需要构建您的工作。\n\n从项目的根目录运行构建命令。\n\n# Yarn\nyarn build\n\n# NPM\nnpm run-script building\n\n\n1\n2\n3\n4\n5\n\n\n\n# 运行并查询您的启动项目\n\n虽然您可以快速发布您的新项目到 SubQuery Projects 并使用我们的 Explorer进行查询， 本地运行 SubQuery 节点的最简单方法是 Docker 容器中， 如果你还没有 Docker，你可以从 docker.com安装它。\n\n跳过它并将您的新项目发布到 SubQuery 项目中\n\n\n# 运行您的 SubQuery 项目\n\n在此 docker-compose.yml 文件中定义了控制子查询节点如何运行的所有配置。 对于刚刚初始化的新项目，您无需在此处更改任何内容，但您可以在我们的 Run a Project section部分阅读有关文件和设置的更多信息。\n\n在项目目录下运行以下命令：\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\n下载所需软件包可能需要一些时间(@subql/node, @subql/quiry, and Postgress) ，但很快你会看到一个运行中的 SubQuery 节点。\n\n\n# 查询您的项目\n\n打开浏览器并前往 http://localhost:3000。\n\n您应该会看到 GraphQL playground 显示在资源管理器中，其模式是准备查询。 在 Playground 的右上角，您会找到一个Docs按钮，该按钮将打开文档绘图。 该文档是自动生成的，可帮助您查找实体和方法。\n\n对于一个新的 SubQuery 入门项目，您可以尝试以下查询以了解其工作原理，或者 了解更多关于 GraphQL 查询语言的信息。\n\n{\n  query {\n    starterEntities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 下一步\n\n恭喜，您现在有一个本地运行的 SubQuery 项目，该项目接受 GraphQL API 对示例数据的请求。 在下一个指南中， 我们会向您展示如何发布您的新项目到\n\nSubQuery Projects/0> 并使用我们的 Explorer 进行查询\n\n\n\n将您的新项目发布到 SubQuery Projects 。",normalizedContent:"# 快速入门指南\n\n在本快速入门指南中，我们将创建一个简单的入门项目，您可以将其用作开发您自己的 subquery 项目的框架。\n\n在本指南的最后，您将拥有一个在 subquery 节点上运行的可工作 的 subquery 项目，该节点具有一个可以从中查询数据的 graphql 端点。\n\n如果您还没有准备好，我们建议您熟悉 subquery 中所使用的 术语。\n\n\n# 准备工作\n\n\n# 本地开发环境\n\n * 编译项目和定义类型需要用到typescript 。\n * subquery cli 和生成的项目都有依赖关系，并且需要一个现代版本 node。\n * subquery 节点需要 docker\n\n\n# 安装 subquery cli\n\n使用 npm 在终端上全局安装 subquery cli：\n\n# npm\nnpm install -g @subql/cli\n\n\n1\n2\n\n\n请注意我们不鼓励使用 yarn global ，因为它的依赖性管理很差，这可能会导致错误。\n\n然后，您可以运行帮助以查看 cli 提供的可用命令和用法。\n\nsubql help\n\n\n1\n\n\n\n# 初始化 starter subquery 项目\n\n在您要创建 subquery 项目的目录中，只需将project_name 替换为您自己的项目名称并运行命令：\n\nsubql init --starter project_name\n\n\n1\n\n\n在初始化 subquery project 时，您会被问到一些问题：\n\n * git 存储库（可选）：提供指向此 subquery 项目的，并将在其中托管的存储库的 git url（当托管在 subquery explorer 中时）\n * rpc 端点(必填)：提供一个 wss url 给一个正在运行的 rpc 端点，该端点将默认用于此项目。 您可以快速访问不同的 polkadot 网络的公共端点，甚至可以使用 onfinality 或仅使用默认的 polkadot 端点创建您自己的专用节点。\n * 作者(必填)：在此处输入此 subquery 项目的所有者\n * 描述(可选)：您可以提供一个简短的段落介绍您的项目，描述它包含哪些数据以及用户可以做些什么。\n * 版本 (必填)：输入一个自定义版本号或使用默认版本(1.0.0)\n * 许可证(必填)：提供此项目的软件许可或接受默认设置(apache-2.0)\n\n在初始化过程完成后，您应该看到目录内创建了一个项目名称的文件夹。 此目录的内容应该与 directory structure 中列出的内容完全相同。\n\n最后，在项目目录下，运行以下命令来安装新项目的依赖关系。\n\ncd project_name\n\n# yarn\nyarn install\n\n# npm\nnpm install\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 配置和构建入门项目\n\n在您刚刚初始化的启动软件包中，我们为您的新项目提供了标准配置。 您将主要处理以下文件：\n\n * project.yaml 中的清单\n * schema.graphql 的 graphql 架构\n * src/mappings/ 目录中的映射函数\n\n关于如何编写您自己的子查询的更多信息，请查阅 create a project 下的我们的文档\n\n\n# graphql 模型生成\n\n为了 索引 您的 subquery 项目，您必须首先生成您在 graphql schema 文件中定义的 graphql 模型(schema)。 rachql。 在项目目录的根目录中运行此命令。\n\n# yarn\nyarn codegen\n\n# npm\nnpm run-script codegen\n\n\n1\n2\n3\n4\n5\n\n\n您将在 /src/types/model 目录中找到生成的模型\n\n\n# 构建项目\n\n为了在本地托管的 subquery 节点上运行您的 subquery 项目，您需要构建您的工作。\n\n从项目的根目录运行构建命令。\n\n# yarn\nyarn build\n\n# npm\nnpm run-script building\n\n\n1\n2\n3\n4\n5\n\n\n\n# 运行并查询您的启动项目\n\n虽然您可以快速发布您的新项目到 subquery projects 并使用我们的 explorer进行查询， 本地运行 subquery 节点的最简单方法是 docker 容器中， 如果你还没有 docker，你可以从 docker.com安装它。\n\n跳过它并将您的新项目发布到 subquery 项目中\n\n\n# 运行您的 subquery 项目\n\n在此 docker-compose.yml 文件中定义了控制子查询节点如何运行的所有配置。 对于刚刚初始化的新项目，您无需在此处更改任何内容，但您可以在我们的 run a project section部分阅读有关文件和设置的更多信息。\n\n在项目目录下运行以下命令：\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\n下载所需软件包可能需要一些时间(@subql/node, @subql/quiry, and postgress) ，但很快你会看到一个运行中的 subquery 节点。\n\n\n# 查询您的项目\n\n打开浏览器并前往 http://localhost:3000。\n\n您应该会看到 graphql playground 显示在资源管理器中，其模式是准备查询。 在 playground 的右上角，您会找到一个docs按钮，该按钮将打开文档绘图。 该文档是自动生成的，可帮助您查找实体和方法。\n\n对于一个新的 subquery 入门项目，您可以尝试以下查询以了解其工作原理，或者 了解更多关于 graphql 查询语言的信息。\n\n{\n  query {\n    starterentities(first: 10) {\n      nodes {\n        field1\n        field2\n        field3\n      }\n    }\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 下一步\n\n恭喜，您现在有一个本地运行的 subquery 项目，该项目接受 graphql api 对示例数据的请求。 在下一个指南中， 我们会向您展示如何发布您的新项目到\n\nsubquery projects/0> 并使用我们的 explorer 进行查询\n\n\n\n将您的新项目发布到 subquery projects 。",charsets:{cjk:!0},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Hello World Explained",frontmatter:{summary:"Hello World Explained 在 Hello World quick start guide中，我们运行了一些简单的命令，并很快就启动并运行了一个示例。 这使您可以确保具备所有先决条件，并且可以使用本地 Playground 进行简单查询以从 SubQuery 获取您的第一个数据。 让我们来仔细看看所有这些命令的含义。 subql init 我",meta:[{property:"og:url",content:"/zh/quickstart/understanding-helloworld.html"},{property:"og:title",content:"Hello World Explained"},{property:"og:description",content:"Hello World Explained 在 Hello World quick start guide中，我们运行了一些简单的命令，并很快就启动并运行了一个示例。 这使您可以确保具备所有先决条件，并且可以使用本地 Playground 进行简单查询以从 SubQuery 获取您的第一个数据。 让我们来仔细看看所有这些命令的含义。 subql init 我"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/quickstart/understanding-helloworld.html",relativePath:"zh/quickstart/understanding-helloworld.md",key:"v-31d49c56",path:"/zh/quickstart/understanding-helloworld/",headers:[{level:2,title:"subql init",slug:"subql-init",normalizedTitle:"subql init",charIndex:175},{level:2,title:"yarn install",slug:"yarn-install",normalizedTitle:"yarn install",charIndex:574},{level:2,title:"yarn codegen",slug:"yarn-codegen",normalizedTitle:"yarn codegen",charIndex:960},{level:2,title:"yarn build",slug:"yarn-build",normalizedTitle:"yarn build",charIndex:1151},{level:2,title:"docker-compose",slug:"docker-compose",normalizedTitle:"docker-compose",charIndex:1260},{level:2,title:"概括",slug:"概括",normalizedTitle:"概括",charIndex:1680}],readingTime:{minutes:3.11,words:932},headersStr:"subql init yarn install yarn codegen yarn build docker-compose 概括",content:"# Hello World Explained\n\n在 Hello World quick start guide中，我们运行了一些简单的命令，并很快就启动并运行了一个示例。 这使您可以确保具备所有先决条件，并且可以使用本地 Playground 进行简单查询以从 SubQuery 获取您的第一个数据。 让我们来仔细看看所有这些命令的含义。\n\n\n# subql init\n\n我们运行的第一个命令是 subql init --starter subqlHelloWorld。\n\n这个指令完成了繁重的工作，并为您创建了一大堆文件。 正如 official documentation中所指出的那样，您将主要处理以下文件：\n\n * project.yaml中的清单\n * schema.graphql中的 GraphQL 架构\n * src/mappings/ 目录中的映射函数\n\n\n\n这些文件是我们所做一切的核心。 因此，我们将在另一篇文章中花更多时间来介绍这些文件。 不过现在，只需要知道这样的模式包含了用户可以从 SubQuery API 请求的数据的描述，project yaml 文件包含了“配置”类型参数，当然还有包含了含有 typescript 的 mappingHandlers — 其 typescript 有转换数据的功能。\n\n\n# yarn install\n\n我们所做的下一个事情是 yarn install。 您也可以使用 npm install 。\n\n> 一段简短的历史。 Node Package Manager 或 npm 最初于 2010 年发布，是 JavaScript 开发人员中非常流行的包管理器。 它是您在系统上安装 Node.js 时自动安装的默认包。 Yarn 最初由 Facebook 于 2016 年发布，旨在解决使用 npm（当时）的一些性能和安全缺陷。\n\n真的 yarn 是查看 package.json 文件并下载其他依赖项。 yarn 所做的是查看 package.json 文件并下载各种其他依赖项。package.json 文件看起来没有很多依赖项，但是当您运行该命令时，您会注意到添加了 18,983 个文件。 这是因为每个依赖项也将有自己的依赖项。\n\n\n\n\n# yarn codegen\n\n然后我们运行 yarn codegen 或 npm run-script codegen。 这样做是为了获取 GraphQL 架构（在schema.graphql中）并生成相关的 typescript 模型文件（因此输出文件将具有 .ts 扩展名）。 您不应该更改这些生成的文件中的任何一个，只能更改源 schema.graphql 文件。\n\n\n\n\n# yarn build\n\n然后执行yarn build or npm run-script build 。 这对于经验丰富的程序员来说应该很熟悉。 它创建一个分发文件夹，执行如准备部署的代码优化之类的事情。\n\n\n\n\n# docker-compose\n\n最后一步是组合 docker 命令 docker-compose pra && docker-compose up (也可以单独运行)。 pull命令从 Docker Hub 获取所有需要的图像， up命令启动容器。\n\n> docker-compose pull\nPulling postgres        ... done\nPulling subquery-node   ... done\nPulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\n当容器启动时，您会看到终端吐出大量文本，显示节点和 GraphQL 引擎的状态。 当你看到：\n\nsubquery-node_1   | 2021-06-06T02:04:25.490Z <fetch> INFO fetch block [1, 100]\n\n\n1\n\n\n您就知道 SubQuery 节点已经开始同步。\n\n\n# 概括\n\n现在您已经了解了幕后发生的事情，问题是接下来该做什么？ 如果您有信心，可以开始学习 create a project并详细了解三个关键文件。 清单文件、GraphQL 架构和映射文件。\n\n或者您可以继续我们的教程部分，我们将学习如何在 SubQuery 的托管基础架构上运行这个 Hello World 示例，我们将学习如何修改 start 块，我们将运行随时可用的开源项目来更深入地了解如何运行 SubQuery 项目。",normalizedContent:"# hello world explained\n\n在 hello world quick start guide中，我们运行了一些简单的命令，并很快就启动并运行了一个示例。 这使您可以确保具备所有先决条件，并且可以使用本地 playground 进行简单查询以从 subquery 获取您的第一个数据。 让我们来仔细看看所有这些命令的含义。\n\n\n# subql init\n\n我们运行的第一个命令是 subql init --starter subqlhelloworld。\n\n这个指令完成了繁重的工作，并为您创建了一大堆文件。 正如 official documentation中所指出的那样，您将主要处理以下文件：\n\n * project.yaml中的清单\n * schema.graphql中的 graphql 架构\n * src/mappings/ 目录中的映射函数\n\n\n\n这些文件是我们所做一切的核心。 因此，我们将在另一篇文章中花更多时间来介绍这些文件。 不过现在，只需要知道这样的模式包含了用户可以从 subquery api 请求的数据的描述，project yaml 文件包含了“配置”类型参数，当然还有包含了含有 typescript 的 mappinghandlers — 其 typescript 有转换数据的功能。\n\n\n# yarn install\n\n我们所做的下一个事情是 yarn install。 您也可以使用 npm install 。\n\n> 一段简短的历史。 node package manager 或 npm 最初于 2010 年发布，是 javascript 开发人员中非常流行的包管理器。 它是您在系统上安装 node.js 时自动安装的默认包。 yarn 最初由 facebook 于 2016 年发布，旨在解决使用 npm（当时）的一些性能和安全缺陷。\n\n真的 yarn 是查看 package.json 文件并下载其他依赖项。 yarn 所做的是查看 package.json 文件并下载各种其他依赖项。package.json 文件看起来没有很多依赖项，但是当您运行该命令时，您会注意到添加了 18,983 个文件。 这是因为每个依赖项也将有自己的依赖项。\n\n\n\n\n# yarn codegen\n\n然后我们运行 yarn codegen 或 npm run-script codegen。 这样做是为了获取 graphql 架构（在schema.graphql中）并生成相关的 typescript 模型文件（因此输出文件将具有 .ts 扩展名）。 您不应该更改这些生成的文件中的任何一个，只能更改源 schema.graphql 文件。\n\n\n\n\n# yarn build\n\n然后执行yarn build or npm run-script build 。 这对于经验丰富的程序员来说应该很熟悉。 它创建一个分发文件夹，执行如准备部署的代码优化之类的事情。\n\n\n\n\n# docker-compose\n\n最后一步是组合 docker 命令 docker-compose pra && docker-compose up (也可以单独运行)。 pull命令从 docker hub 获取所有需要的图像， up命令启动容器。\n\n> docker-compose pull\npulling postgres        ... done\npulling subquery-node   ... done\npulling graphql-engine  ... done\n\n\n1\n2\n3\n4\n\n\n当容器启动时，您会看到终端吐出大量文本，显示节点和 graphql 引擎的状态。 当你看到：\n\nsubquery-node_1   | 2021-06-06t02:04:25.490z <fetch> info fetch block [1, 100]\n\n\n1\n\n\n您就知道 subquery 节点已经开始同步。\n\n\n# 概括\n\n现在您已经了解了幕后发生的事情，问题是接下来该做什么？ 如果您有信心，可以开始学习 create a project并详细了解三个关键文件。 清单文件、graphql 架构和映射文件。\n\n或者您可以继续我们的教程部分，我们将学习如何在 subquery 的托管基础架构上运行这个 hello world 示例，我们将学习如何修改 start 块，我们将运行随时可用的开源项目来更深入地了解如何运行 subquery 项目。",charsets:{cjk:!0},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Running SubQuery Locally",frontmatter:{summary:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab",meta:[{property:"og:url",content:"/zh/run/run.html"},{property:"og:title",content:"Running SubQuery Locally"},{property:"og:description",content:"Running SubQuery Locally This guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry ab"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/run/run.html",relativePath:"zh/run/run.md",key:"v-5f7fb3cd",path:"/zh/run/run/",headers:[{level:2,title:"Using Docker",slug:"using-docker",normalizedTitle:"using docker",charIndex:392},{level:2,title:"Running an Indexer (subql/node)",slug:"running-an-indexer-subql-node",normalizedTitle:"running an indexer (subql/node)",charIndex:859},{level:3,title:"Installation",slug:"installation",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Key Commands",slug:"key-commands",normalizedTitle:"key commands",charIndex:1512},{level:2,title:"Running a Query Service (subql/query)",slug:"running-a-query-service-subql-query",normalizedTitle:"running a query service (subql/query)",charIndex:3939},{level:3,title:"Installation",slug:"installation-2",normalizedTitle:"installation",charIndex:1219},{level:3,title:"Running the Query service",slug:"running-the-query-service",normalizedTitle:"running the query service",charIndex:4182}],readingTime:{minutes:2.57,words:772},headersStr:"Using Docker Running an Indexer (subql/node) Installation Key Commands Running a Query Service (subql/query) Installation Running the Query service",content:"# Running SubQuery Locally\n\nThis guide works through how to run a local SubQuery node on your infrastructure, which includes both the indexer and query service. Don't want to worry about running your own SubQuery infrastructure? SubQuery provides a managed hosted service to the community for free. Follow our publishing guide to see how you can upload your project to SubQuery Projects.\n\n\n# Using Docker\n\nAn alternative solution is to run a Docker Container, defined by the docker-compose.yml file. For a new project that has been just initialised you won't need to change anything here.\n\nUnder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nIt may take some time to download the required packages (@subql/node, @subql/query, and Postgres) for the first time but soon you'll see a running SubQuery node.\n\n\n# Running an Indexer (subql/node)\n\nRequirements:\n\n * Postgres database (version 12 or higher). While the SubQuery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\nA SubQuery node is an implementation that extracts substrate-based blockchain data per the SubQuery project and saves it into a Postgres database.\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/node\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nOnce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# Key Commands\n\nThe following commands will assist you to complete the configuration of a SubQuery node and begin indexing. To find out more, you can always run --help.\n\n# Point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# Using a Dictionary\n\nUsing a full chain dictionary can dramatically speed up the processing of a SubQuery project during testing or during your first index. In some cases, we've seen indexing performance increases of up to 10x.\n\nA full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nYou can add the dictionary endpoint in your project.yaml file (see Manifest File), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# Connect to database\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\nDepending on the configuration of your Postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# Specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nThis will point the query node to a configuration file which can be in YAML or JSON format. Check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryName: extrinsics\nbatchSize:100\nlocalMode:true\n\n\n1\n2\n3\n4\n\n\n# Change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nResult:\n[IndexerManager] fetch block [203, 402]\n[IndexerManager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nWhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. Increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. The current default batch size is 100.\n\n# Local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nFor debugging purposes, users can run the node in local mode. Switching to local model will create Postgres tables in the default schema public.\n\nIf local mode is not used, a new Postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# Running a Query Service (subql/query)\n\n\n# Installation\n\n# NPM\nnpm install -g @subql/query\n\n\n1\n2\n\n\nPlease note that we DO NOT encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# Running the Query service\n\n``` export DB_HOST=localhost subql-query --name <project_name> --playground ````\n\nMake sure the project name is the same as the project name when you initialize the project. Also, check the environment variables are correct.\n\nAfter running the subql-query service successfully, open your browser and head to http://localhost:3000. You should see a GraphQL playground showing in the Explorer and the schema that is ready to query.",normalizedContent:"# running subquery locally\n\nthis guide works through how to run a local subquery node on your infrastructure, which includes both the indexer and query service. don't want to worry about running your own subquery infrastructure? subquery provides a managed hosted service to the community for free. follow our publishing guide to see how you can upload your project to subquery projects.\n\n\n# using docker\n\nan alternative solution is to run a docker container, defined by the docker-compose.yml file. for a new project that has been just initialised you won't need to change anything here.\n\nunder the project directory run the following command:\n\ndocker-compose pull && docker-compose up\n\n\n1\n\n\nit may take some time to download the required packages (@subql/node, @subql/query, and postgres) for the first time but soon you'll see a running subquery node.\n\n\n# running an indexer (subql/node)\n\nrequirements:\n\n * postgres database (version 12 or higher). while the subquery node is indexing the blockchain, the extracted data is stored in an external database instance.\n\na subquery node is an implementation that extracts substrate-based blockchain data per the subquery project and saves it into a postgres database.\n\n\n# installation\n\n# npm\nnpm install -g @subql/node\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\nonce installed, you can start a node with the following command:\n\nsubql-node <command>\n\n\n1\n\n\n\n# key commands\n\nthe following commands will assist you to complete the configuration of a subquery node and begin indexing. to find out more, you can always run --help.\n\n# point to local project path\n\nsubql-node -f your-project-path\n\n\n1\n\n\n# using a dictionary\n\nusing a full chain dictionary can dramatically speed up the processing of a subquery project during testing or during your first index. in some cases, we've seen indexing performance increases of up to 10x.\n\na full chain dictionary pre-indexes the location of all events and extrinsics within the specific chain and allows your node service to skip to relevant locations when indexing rather than inspecting each block.\n\nyou can add the dictionary endpoint in your project.yaml file (see manifest file), or specify it at run time using the following command:\n\nsubql-node --network-dictionary=https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n\n\n# connect to database\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\nsubql-node -f your-project-path\n\n\n1\n2\n3\n4\n5\n6\n\n\ndepending on the configuration of your postgres database (e.g. a different database password), please ensure also that both the indexer (subql/node) and the query service (subql/query) can establish a connection to it.\n\n# specify a configuration file\n\nsubql-node -c your-project-config.yml\n\n\n1\n\n\nthis will point the query node to a configuration file which can be in yaml or json format. check out the example below.\n\nsubquery: ../../../../subql-example/extrinsics\nsubqueryname: extrinsics\nbatchsize:100\nlocalmode:true\n\n\n1\n2\n3\n4\n\n\n# change the block fetching batch size\n\nsubql-node -f your-project-path --batch-size 200\n\nresult:\n[indexermanager] fetch block [203, 402]\n[indexermanager] fetch block [403, 602]\n\n\n1\n2\n3\n4\n5\n\n\nwhen the indexer first indexes the chain, fetching single blocks will significantly decrease the performance. increasing the batch size to adjust the number of blocks fetched will decrease the overall processing time. the current default batch size is 100.\n\n# local mode\n\nsubql-node -f your-project-path --local\n\n\n1\n\n\nfor debugging purposes, users can run the node in local mode. switching to local model will create postgres tables in the default schema public.\n\nif local mode is not used, a new postgres schema with the initial subquery_ and corresponding project tables will be created.\n\n\n# running a query service (subql/query)\n\n\n# installation\n\n# npm\nnpm install -g @subql/query\n\n\n1\n2\n\n\nplease note that we do not encourage the use of yarn global due to its poor dependency management which may lead to an errors down the line.\n\n\n# running the query service\n\n``` export db_host=localhost subql-query --name <project_name> --playground ````\n\nmake sure the project name is the same as the project name when you initialize the project. also, check the environment variables are correct.\n\nafter running the subql-query service successfully, open your browser and head to http://localhost:3000. you should see a graphql playground showing in the explorer and the schema that is ready to query.",charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"The Sandbox",frontmatter:{summary:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti",meta:[{property:"og:url",content:"/zh/run/sandbox.html"},{property:"og:title",content:"The Sandbox"},{property:"og:description",content:"The Sandbox In our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not enti"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/run/sandbox.html",relativePath:"zh/run/sandbox.md",key:"v-63936655",path:"/zh/run/sandbox/",headers:[{level:2,title:"Restriction",slug:"restriction",normalizedTitle:"restriction",charIndex:742}],readingTime:{minutes:.6,words:179},headersStr:"Restriction",content:"# The Sandbox\n\nIn our envisioned usage scenario, the SubQuery node is usually run by a trusted host, and the code of the SubQuery project submitted by the user to the node is not entirely trustworthy.\n\nSome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. Therefore, we use the VM2 sandbox secured mechanism to reduce risks. This:\n\n * Runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * Securely calls methods and exchanges data and callbacks between sandboxes.\n\n * Is immune to many known methods of attack.\n\n\n# Restriction\n\n * To limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * We support 3rd party modules written in CommonJS and hybrid libraries like @polkadot/* that use ESM as default.\n\n * Any modules using HTTP and WebSocket are forbidden.",normalizedContent:"# the sandbox\n\nin our envisioned usage scenario, the subquery node is usually run by a trusted host, and the code of the subquery project submitted by the user to the node is not entirely trustworthy.\n\nsome malicious code is likely to attack the host or even compromise it, and cause damage to the data of other projects in the same host. therefore, we use the vm2 sandbox secured mechanism to reduce risks. this:\n\n * runs untrusted code securely in an isolated context and malicious code will not access the network and file system of the host unless through the exposed interface we injected into the sandbox.\n\n * securely calls methods and exchanges data and callbacks between sandboxes.\n\n * is immune to many known methods of attack.\n\n\n# restriction\n\n * to limit access to certain built-in modules, only assert, buffer, crypto,util and path are whitelisted.\n\n * we support 3rd party modules written in commonjs and hybrid libraries like @polkadot/* that use esm as default.\n\n * any modules using http and websocket are forbidden.",charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to change the blockchain fetching batch size?",frontmatter:{summary:"How to change the blockchain fetching batch size? Video guide Introduction The default batch size is 100, but this can be changed by using the extra command --batch-size=xx. You ne",meta:[{property:"og:url",content:"/zh/tutorials_examples/batch-size.html"},{property:"og:title",content:"How to change the blockchain fetching batch size?"},{property:"og:description",content:"How to change the blockchain fetching batch size? Video guide Introduction The default batch size is 100, but this can be changed by using the extra command --batch-size=xx. You ne"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/tutorials_examples/batch-size.html",relativePath:"zh/tutorials_examples/batch-size.md",key:"v-0810fd7b",path:"/zh/tutorials_examples/batch-size/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:56},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:72},{level:2,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:744}],readingTime:{minutes:.47,words:141},headersStr:"Video guide Introduction Why change the batch size?",content:'# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive.',normalizedContent:'# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive.',charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to start at a different block height?",frontmatter:{summary:"How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from b",meta:[{property:"og:url",content:"/zh/tutorials_examples/block-height.html"},{property:"og:title",content:"How to start at a different block height?"},{property:"og:description",content:"How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from b"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/tutorials_examples/block-height.html",relativePath:"zh/tutorials_examples/block-height.md",key:"v-b6f39256",path:"/zh/tutorials_examples/block-height/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:48},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:64},{level:2,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:952},{level:2,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1259},{level:2,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1439},{level:2,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1633}],readingTime:{minutes:1.02,words:307},headersStr:"Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen?",content:'# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.',normalizedContent:'# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.',charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to debug a SubQuery project?",frontmatter:{summary:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will",meta:[{property:"og:url",content:"/zh/tutorials_examples/debug-projects.html"},{property:"og:title",content:"How to debug a SubQuery project?"},{property:"og:description",content:"How to debug a SubQuery project? Video guide Introduction In order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/tutorials_examples/debug-projects.html",relativePath:"zh/tutorials_examples/debug-projects.md",key:"v-0b15eafb",path:"/zh/tutorials_examples/debug-projects/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:39},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:55},{level:2,title:"Node inspector",slug:"node-inspector",normalizedTitle:"node inspector",charIndex:272},{level:2,title:"Chrome devtools",slug:"chrome-devtools",normalizedTitle:"chrome devtools",charIndex:683}],readingTime:{minutes:.65,words:196},headersStr:"Video guide Introduction Node inspector Chrome devtools",content:"# How to debug a SubQuery project?\n\n\n# Video guide\n\n\n# Introduction\n\nIn order to debug SubQuery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a Node.js inspector in conjunction with Chrome developer tools.\n\n\n# Node inspector\n\nRun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subQuery project>\n\n\n1\n\n\nFor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/Code/subQuery/projects/subql-helloworld/\nDebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# Chrome devtools\n\nOpen up Chrome DevTools and navigate to the Sources tab. Note that clicking on the green icon will open up a new window.\n\n\n\nNavigate to Filesystem and add your project folder to the workspace. Then open the dist > mappings folder and select the code you wish to debug. Then step through the code as with any standard debugging tool.\n\n",normalizedContent:"# how to debug a subquery project?\n\n\n# video guide\n\n\n# introduction\n\nin order to debug subquery projects such as stepping through code, setting breakpoints, and inspecting variables, you will have to use a node.js inspector in conjunction with chrome developer tools.\n\n\n# node inspector\n\nrun the following command in a terminal screen.\n\nnode --inspect-brk <path to subql-node> -f <path to subquery project>\n\n\n1\n\n\nfor example:\n\nnode --inspect-brk /usr/local/bin/subql-node -f ~/code/subquery/projects/subql-helloworld/\ndebugger listening on ws://127.0.0.1:9229/56156753-c07d-4bbe-af2d-2c7ff4bcc5ad\nfor help, see: https://nodejs.org/en/docs/inspector\ndebugger attached.\n\n\n1\n2\n3\n4\n\n\n\n# chrome devtools\n\nopen up chrome devtools and navigate to the sources tab. note that clicking on the green icon will open up a new window.\n\n\n\nnavigate to filesystem and add your project folder to the workspace. then open the dist > mappings folder and select the code you wish to debug. then step through the code as with any standard debugging tool.\n\n",charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How does a SubQuery dictionary work?",frontmatter:{summary:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod",meta:[{property:"og:url",content:"/zh/tutorials_examples/dictionary.html"},{property:"og:title",content:"How does a SubQuery dictionary work?"},{property:"og:description",content:"How does a SubQuery dictionary work? The whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (mod"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/tutorials_examples/dictionary.html",relativePath:"zh/tutorials_examples/dictionary.md",key:"v-38ed8592",path:"/zh/tutorials_examples/dictionary/",headers:[{level:2,title:"How to incorporate a dictionary into your project?",slug:"how-to-incorporate-a-dictionary-into-your-project",normalizedTitle:"how to incorporate a dictionary into your project?",charIndex:1024},{level:2,title:"What happens when a dictionary IS NOT used?",slug:"what-happens-when-a-dictionary-is-not-used",normalizedTitle:"what happens when a dictionary is not used?",charIndex:1350},{level:2,title:"What happens when a dictionary IS used?",slug:"what-happens-when-a-dictionary-is-used",normalizedTitle:"what happens when a dictionary is used?",charIndex:1772},{level:2,title:"When is a dictionary NOT useful?",slug:"when-is-a-dictionary-not-useful",normalizedTitle:"when is a dictionary not useful?",charIndex:2849}],readingTime:{minutes:2,words:601},headersStr:"How to incorporate a dictionary into your project? What happens when a dictionary IS NOT used? What happens when a dictionary IS used? When is a dictionary NOT useful?",content:"# How does a SubQuery dictionary work?\n\nThe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. Another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nThe network.dictionary endpoint is an optional parameter that if present, the SDK will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\nTaking the SubQuery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specVersion. These 3 entities contain 6, 4, and 2 fields respectively. When this project is run, these fields are reflected in the database tables.\n\n\n\nData from the blockchain is then stored in these tables and indexed for performance. The project is then hosted in SubQuery Projects and the API endpoint is available to be added to the manifest file.\n\n\n# How to incorporate a dictionary into your project?\n\nAdd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. Eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# What happens when a dictionary IS NOT used?\n\nWhen a dictionary is NOT used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. Later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# What happens when a dictionary IS used?\n\nWhen a dictionary IS used, the indexer will first take the call and event filters as parameters and merge this into a GraphQL query. It then uses the dictionary's API to obtain a list of relevant block heights only that contains the specific events and extrinsics. Often this is substantially less than 100 if the default is used.\n\nFor example, imagine a situation where you're indexing transfer events. Not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nThe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. This is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nThis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. But compared to the traditional method, it adds an additional step to get data from the dictionary’s API.\n\n\n# When is a dictionary NOT useful?\n\nWhen block handlers are used to grab data from a chain, every block needs to be processed. Therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nAlso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",normalizedContent:"# how does a subquery dictionary work?\n\nthe whole idea of a generic dictionary project is to index all the data from a blockchain and record the events, extrinsics, and its types (module and method) in a database in order of block height. another project can then query this network.dictionary endpoint instead of the default network.endpoint defined in the manifest file.\n\nthe network.dictionary endpoint is an optional parameter that if present, the sdk will automatically detect and use. network.endpoint is mandatory and will not compile if not present.\n\ntaking the subquery dictionary project as an example, the schema file defines 3 entities; extrinsic, events, specversion. these 3 entities contain 6, 4, and 2 fields respectively. when this project is run, these fields are reflected in the database tables.\n\n\n\ndata from the blockchain is then stored in these tables and indexed for performance. the project is then hosted in subquery projects and the api endpoint is available to be added to the manifest file.\n\n\n# how to incorporate a dictionary into your project?\n\nadd dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot to the network section of the manifest. eg:\n\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\n\n\n1\n2\n3\n\n\n\n# what happens when a dictionary is not used?\n\nwhen a dictionary is not used, an indexer will fetch every block data via the polkadot api according to the batch-size flag which is 100 by default, and place this in a buffer for processing. later, the indexer takes all these blocks from the buffer and while processing the block data, checks whether the event and extrinsic in these blocks match the user-defined filter.\n\n\n# what happens when a dictionary is used?\n\nwhen a dictionary is used, the indexer will first take the call and event filters as parameters and merge this into a graphql query. it then uses the dictionary's api to obtain a list of relevant block heights only that contains the specific events and extrinsics. often this is substantially less than 100 if the default is used.\n\nfor example, imagine a situation where you're indexing transfer events. not all blocks have this event (in the image below there are no transfer events in blocks 3 and 4).\n\n\n\nthe dictionary allows your project to skip this so rather than looking in each block for a transfer event, it skips to just blocks 1, 2, and 5. this is because the dictionary is a pre-computed reference to all calls and events in each block.\n\nthis means that using a dictionary can reduce the amount of data that the indexer obtains from the chain and reduce the number of “unwanted” blocks stored in the local buffer. but compared to the traditional method, it adds an additional step to get data from the dictionary’s api.\n\n\n# when is a dictionary not useful?\n\nwhen block handlers are used to grab data from a chain, every block needs to be processed. therefore, using a dictionary in this case does not provide any advantage and the indexer will automatically switch to the default non-dictionary approach.\n\nalso, when dealing with events or extrinsic that occur or exist in every block such as timestamp.set, using a dictionary will not offer any additional advantage.",charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Tutorials",frontmatter:{summary:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor",meta:[{property:"og:url",content:"/zh/tutorials_examples/howto.html"},{property:"og:title",content:"Tutorials"},{property:"og:description",content:"Tutorials How to start at a different block height? Video guide Introduction By default, all starter projects start synchronising the blockchain from the genesis block. In otherwor"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/tutorials_examples/howto.html",relativePath:"zh/tutorials_examples/howto.md",key:"v-58f735ed",path:"/zh/tutorials_examples/howto/",headers:[{level:2,title:"How to start at a different block height?",slug:"how-to-start-at-a-different-block-height",normalizedTitle:"how to start at a different block height?",charIndex:16},{level:3,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why not start from zero?",slug:"why-not-start-from-zero",normalizedTitle:"why not start from zero?",charIndex:966},{level:3,title:"What are the drawbacks of not starting from zero?",slug:"what-are-the-drawbacks-of-not-starting-from-zero",normalizedTitle:"what are the drawbacks of not starting from zero?",charIndex:1273},{level:3,title:"How to figure out the current blockchain height?",slug:"how-to-figure-out-the-current-blockchain-height",normalizedTitle:"how to figure out the current blockchain height?",charIndex:1453},{level:3,title:"Do I have to do a rebuild or a codegen?",slug:"do-i-have-to-do-a-rebuild-or-a-codegen",normalizedTitle:"do i have to do a rebuild or a codegen?",charIndex:1647},{level:2,title:"How to change the blockchain fetching batch size?",slug:"how-to-change-the-blockchain-fetching-batch-size",normalizedTitle:"how to change the blockchain fetching batch size?",charIndex:1852},{level:3,title:"Video guide",slug:"video-guide-2",normalizedTitle:"video guide",charIndex:62},{level:3,title:"Introduction",slug:"introduction-2",normalizedTitle:"introduction",charIndex:78},{level:3,title:"Why change the batch size?",slug:"why-change-the-batch-size",normalizedTitle:"why change the batch size?",charIndex:2594}],readingTime:{minutes:1.61,words:483},headersStr:"How to start at a different block height? Video guide Introduction Why not start from zero? What are the drawbacks of not starting from zero? How to figure out the current blockchain height? Do I have to do a rebuild or a codegen? How to change the blockchain fetching batch size? Video guide Introduction Why change the batch size?",content:'# Tutorials\n\n\n# How to start at a different block height?\n\n\n# Video guide\n\n\n# Introduction\n\nBy default, all starter projects start synchronising the blockchain from the genesis block. In otherwords, from block 1. For large blockchains, this can typically take days or even weeks to fully synchronise.\n\nTo start a SubQuery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startBlock key.\n\nBelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecVersion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1000000\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Why not start from zero?\n\nThe main reason is that it can reduce the time to synchronise the blockchain. This means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# What are the drawbacks of not starting from zero?\n\nThe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# How to figure out the current blockchain height?\n\nIf you are using the Polkadot network, you can visit https://polkascan.io/, select the network, and then view the "Finalised Block" figure.\n\n\n# Do I have to do a rebuild or a codegen?\n\nNo. Because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# How to change the blockchain fetching batch size?\n\n\n# Video guide\n\n\n# Introduction\n\nThe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nYou need to this to the command line as an extra flag or if you are using Docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      DB_USER: postgres\n      DB_PASS: postgres\n      DB_DATABASE: postgres\n      DB_HOST: postgres\n      DB_PORT: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nThis example sets the batch size to 50.\n\n\n# Why change the batch size?\n\nUsing a smaller batch size can reduce memory usage and not leave users hanging for large queries. In otherwords, your application can be more responsive. However, more API calls are being made so if you are being charged on an I/O basis or if you have API limits somewhere in your chain, this could work to your disadvantage.',normalizedContent:'# tutorials\n\n\n# how to start at a different block height?\n\n\n# video guide\n\n\n# introduction\n\nby default, all starter projects start synchronising the blockchain from the genesis block. in otherwords, from block 1. for large blockchains, this can typically take days or even weeks to fully synchronise.\n\nto start a subquery node synchronising from a non-zero height, all you have to do is to modify your project.yaml file and change the startblock key.\n\nbelow is a project.yaml file where the start block has been set to 1,000,000\n\nspecversion: 0.0.1\ndescription: ""\nrepository: ""\nschema: ./schema.graphql\nnetwork:\n  endpoint: wss://polkadot.api.onfinality.io/public-ws\n  dictionary: https://api.subquery.network/sq/subquery/dictionary-polkadot\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1000000\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# why not start from zero?\n\nthe main reason is that it can reduce the time to synchronise the blockchain. this means that if you are only interested in transactions in the last 3 months, you can only synchronise the last 3 months worth meaning less waiting time and you can start your development faster.\n\n\n# what are the drawbacks of not starting from zero?\n\nthe most obvious drawback will be that you won’t be able to query for data on the blockchain for blocks that you don’t have.\n\n\n# how to figure out the current blockchain height?\n\nif you are using the polkadot network, you can visit https://polkascan.io/, select the network, and then view the "finalised block" figure.\n\n\n# do i have to do a rebuild or a codegen?\n\nno. because you are modifying the project.yaml file, which is essentially a configuration file, you will not have to rebuild or regenerate the typescript code.\n\n\n# how to change the blockchain fetching batch size?\n\n\n# video guide\n\n\n# introduction\n\nthe default batch size is 100, but this can be changed by using the extra command --batch-size=xx.\n\nyou need to this to the command line as an extra flag or if you are using docker, modify the docker-compose.yml with:\n\nsubquery-node:\n    image: onfinality/subql-node:latest\n    depends_on:\n      - "postgres"\n    restart: always\n    environment:\n      db_user: postgres\n      db_pass: postgres\n      db_database: postgres\n      db_host: postgres\n      db_port: 5432\n    volumes:\n      - ./:/app\n    command:\n      - -f=/app\n      - --local\n      - --batch-size=50\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\nthis example sets the batch size to 50.\n\n\n# why change the batch size?\n\nusing a smaller batch size can reduce memory usage and not leave users hanging for large queries. in otherwords, your application can be more responsive. however, more api calls are being made so if you are being charged on an i/o basis or if you have api limits somewhere in your chain, this could work to your disadvantage.',charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"教程 &",frontmatter:{summary:"教程 & 这里我们将列出我们的教程，并探索各种示例来帮助你以最简单和最快的方式站起来和运行。 SubQuery 示例 示例 描述 主题 ---------------------------------------------------------------------------------------------- -----------------",meta:[{property:"og:url",content:"/zh/tutorials_examples/introduction.html"},{property:"og:title",content:"教程 &"},{property:"og:description",content:"教程 & 这里我们将列出我们的教程，并探索各种示例来帮助你以最简单和最快的方式站起来和运行。 SubQuery 示例 示例 描述 主题 ---------------------------------------------------------------------------------------------- -----------------"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/tutorials_examples/introduction.html",relativePath:"zh/tutorials_examples/introduction.md",key:"v-aff4ed22",path:"/zh/tutorials_examples/introduction/",headers:[{level:2,title:"SubQuery 示例",slug:"subquery-示例",normalizedTitle:"subquery 示例",charIndex:54}],readingTime:{minutes:1.19,words:357},headersStr:"SubQuery 示例",content:"# 教程 &\n\n这里我们将列出我们的教程，并探索各种示例来帮助你以最简单和最快的方式站起来和运行。\n\n\n# SubQuery 示例\n\n示例       描述                                    主题\n外部已完成块   索引外观可以通过其散列进行查询                       带有 块处理器 函数的最简单示例\n区块时间戳    索引每个最后一个块的时间戳                         另一个简单的 调用处理器 函数\n验证器阈值    索引选择验证器所需的最低存档金额。                     更复杂的 块处理器 函数让 外部调用 到 @polkadot/api 获取更多链上的数据\n合计奖励     索引封存保证金、 奖励和从终结块事件中的斜线                更复杂的 事件处理器 带有 一对多的 关系\n实体关系     索引帐户间的平衡转移，同时索引实用工具批处理。所有以查找外在通话的内容   一对多 和 多对多 关系和复杂 外在处理\n小工具      索引工具包的出生信息。                           复杂的 通话处理程序 和 事件处理程序, 数据索引来自 自定义链",normalizedContent:"# 教程 &\n\n这里我们将列出我们的教程，并探索各种示例来帮助你以最简单和最快的方式站起来和运行。\n\n\n# subquery 示例\n\n示例       描述                                    主题\n外部已完成块   索引外观可以通过其散列进行查询                       带有 块处理器 函数的最简单示例\n区块时间戳    索引每个最后一个块的时间戳                         另一个简单的 调用处理器 函数\n验证器阈值    索引选择验证器所需的最低存档金额。                     更复杂的 块处理器 函数让 外部调用 到 @polkadot/api 获取更多链上的数据\n合计奖励     索引封存保证金、 奖励和从终结块事件中的斜线                更复杂的 事件处理器 带有 一对多的 关系\n实体关系     索引帐户间的平衡转移，同时索引实用工具批处理。所有以查找外在通话的内容   一对多 和 多对多 关系和复杂 外在处理\n小工具      索引工具包的出生信息。                           复杂的 通话处理程序 和 事件处理程序, 数据索引来自 自定义链",charsets:{cjk:!0},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"How to run an indexer node?",frontmatter:{summary:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r",meta:[{property:"og:url",content:"/zh/tutorials_examples/run-indexer.html"},{property:"og:title",content:"How to run an indexer node?"},{property:"og:description",content:"How to run an indexer node? Video guide Introduction Running an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It r"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/tutorials_examples/run-indexer.html",relativePath:"zh/tutorials_examples/run-indexer.md",key:"v-7d8a77a6",path:"/zh/tutorials_examples/run-indexer/",headers:[{level:2,title:"Video guide",slug:"video-guide",normalizedTitle:"video guide",charIndex:34},{level:2,title:"Introduction",slug:"introduction",normalizedTitle:"introduction",charIndex:50},{level:2,title:"Postgres",slug:"postgres",normalizedTitle:"postgres",charIndex:300},{level:2,title:"Install subql/node",slug:"install-subql-node",normalizedTitle:"install subql/node",charIndex:484},{level:2,title:"Setting DB configs",slug:"setting-db-configs",normalizedTitle:"setting db configs",charIndex:802},{level:2,title:"Indexing a project",slug:"indexing-a-project",normalizedTitle:"indexing a project",charIndex:1380},{level:2,title:"Inspecting Postgres",slug:"inspecting-postgres",normalizedTitle:"inspecting postgres",charIndex:1687}],readingTime:{minutes:1.18,words:353},headersStr:"Video guide Introduction Postgres Install subql/node Setting DB configs Indexing a project Inspecting Postgres",content:"# How to run an indexer node?\n\n\n# Video guide\n\n\n# Introduction\n\nRunning an indexer node is another option outside of using Docker or having a project hosted for you at SubQuery Projects. It requires more time and effort but will enhance your understanding of how SubQuery works under the covers.\n\n\n# Postgres\n\nRunning an indexer node on your infrastructure will require the setup of a Postgres database. You can install Postgres from here and ensure the version is 12 or greater.\n\n\n# Install subql/node\n\nThen to run a SubQuery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nThe -g flag means to install it globally which means on OSX, the location will be /usr/local/lib/node_modules.\n\nOnce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# Setting DB configs\n\nNext, you need to set the following environmental variables:\n\nexport DB_USER=postgres\nexport DB_PASS=postgres\nexport DB_DATABASE=postgres\nexport DB_HOST=localhost\nexport DB_PORT=5432\n\n\n1\n2\n3\n4\n5\n\n\nOf course, if you have different values for the above keys, please adjust accordingly. Note that the env command will display the current environment variables and that this process only sets these values temporarily. That is, they are only valid for the duration of the terminal session. To set them permanently, store them in your ~/bash_profile instead.\n\n\n# Indexing a project\n\nTo start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nIf you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. You should see the indexer node kick into life and start indexing blocks.\n\n\n# Inspecting Postgres\n\nIf you navigate to Postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. The starter_entities table contains the indexes. To view the data, run select (*) from subquery_1.starter_entities.",normalizedContent:"# how to run an indexer node?\n\n\n# video guide\n\n\n# introduction\n\nrunning an indexer node is another option outside of using docker or having a project hosted for you at subquery projects. it requires more time and effort but will enhance your understanding of how subquery works under the covers.\n\n\n# postgres\n\nrunning an indexer node on your infrastructure will require the setup of a postgres database. you can install postgres from here and ensure the version is 12 or greater.\n\n\n# install subql/node\n\nthen to run a subquery node, run the following command:\n\nnpm install -g @subql/node\n\n\n1\n\n\nthe -g flag means to install it globally which means on osx, the location will be /usr/local/lib/node_modules.\n\nonce installed, you can check the version by running:\n\n> subql-node --version\n0.19.1\n\n\n1\n2\n\n\n\n# setting db configs\n\nnext, you need to set the following environmental variables:\n\nexport db_user=postgres\nexport db_pass=postgres\nexport db_database=postgres\nexport db_host=localhost\nexport db_port=5432\n\n\n1\n2\n3\n4\n5\n\n\nof course, if you have different values for the above keys, please adjust accordingly. note that the env command will display the current environment variables and that this process only sets these values temporarily. that is, they are only valid for the duration of the terminal session. to set them permanently, store them in your ~/bash_profile instead.\n\n\n# indexing a project\n\nto start indexing a project, navigate into your project folder and run the following command:\n\nsubql-node -f .\n\n\n1\n\n\nif you do not have a project handy, git clone https://github.com/subquery/subql-helloworld. you should see the indexer node kick into life and start indexing blocks.\n\n\n# inspecting postgres\n\nif you navigate to postgres, you should see two tables created. public.subqueries and subquery_1.starter_entities.\n\npublic.subqueries only contains 1 row which the indexer checks upon start up to “understand the current state” so it knows where to continue from. the starter_entities table contains the indexes. to view the data, run select (*) from subquery_1.starter_entities.",charsets:{},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"术语",frontmatter:{summary:"术语 SubQuery 项目 (魔法会在哪里发生): 一个 SubQuery 节点定义(@subql/cli); SubQuery 节点 (工作完成了): 一个包(@subql/node) 将接受一个 SubQuery 项目定义， 然后运行一个不断索引连接网络到数据库的节点; SubQuery 查询服务(我们从其中获取数据): 包(@subql/quy) 与",meta:[{property:"og:url",content:"/zh/tutorials_examples/terminology.html"},{property:"og:title",content:"术语"},{property:"og:description",content:"术语 SubQuery 项目 (魔法会在哪里发生): 一个 SubQuery 节点定义(@subql/cli); SubQuery 节点 (工作完成了): 一个包(@subql/node) 将接受一个 SubQuery 项目定义， 然后运行一个不断索引连接网络到数据库的节点; SubQuery 查询服务(我们从其中获取数据): 包(@subql/quy) 与"},{property:"og:type",content:"article"},{property:"og:locale",content:"zh-CN"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/zh/tutorials_examples/terminology.html",relativePath:"zh/tutorials_examples/terminology.md",key:"v-cc84cb26",path:"/zh/tutorials_examples/terminology/",headers:[{level:2,title:"术语",slug:"术语",normalizedTitle:"术语",charIndex:2}],readingTime:{minutes:.58,words:174},headersStr:"术语",content:"# 术语\n\n * SubQuery 项目 (魔法会在哪里发生): 一个 SubQuery 节点定义(@subql/cli)\n * SubQuery 节点 (工作完成了): 一个包(@subql/node) 将接受一个 SubQuery 项目定义， 然后运行一个不断索引连接网络到数据库的节点\n * SubQuery 查询服务(我们从其中获取数据): 包(@subql/quy) 与已部署的 SubQuery 节点的 GraphQL API 交互以查询和查看索引数据\n * GraphQL (我们如何查询数据)：一个 API 的查询 langage ，它特别适合于基于灵活图形的数据 - 查看 graphql。 rg",normalizedContent:"# 术语\n\n * subquery 项目 (魔法会在哪里发生): 一个 subquery 节点定义(@subql/cli)\n * subquery 节点 (工作完成了): 一个包(@subql/node) 将接受一个 subquery 项目定义， 然后运行一个不断索引连接网络到数据库的节点\n * subquery 查询服务(我们从其中获取数据): 包(@subql/quy) 与已部署的 subquery 节点的 graphql api 交互以查询和查看索引数据\n * graphql (我们如何查询数据)：一个 api 的查询 langage ，它特别适合于基于灵活图形的数据 - 查看 graphql。 rg",charsets:{cjk:!0},updateTime:"2021年10月6日 02:24",updateTimeStamp:163348706e4,createTime:"2021年10月6日 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Manifest File",frontmatter:{summary:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat",meta:[{property:"og:url",content:"/th/create/manifest.html"},{property:"og:title",content:"Manifest File"},{property:"og:description",content:"Manifest File The Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain dat"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/create/manifest.html",relativePath:"th/create/manifest.md",key:"v-79043d8b",path:"/th/create/manifest/",headers:[{level:2,title:"Network Filters",slug:"network-filters",normalizedTitle:"network filters",charIndex:2013},{level:2,title:"Mapping Filters",slug:"mapping-filters",normalizedTitle:"mapping filters",charIndex:3238},{level:2,title:"Custom Chains",slug:"custom-chains",normalizedTitle:"custom chains",charIndex:4555}],readingTime:{minutes:2.5,words:751},headersStr:"Network Filters Mapping Filters Custom Chains",content:'# Manifest File\n\nThe Manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how SubQuery will index and transform the chain data.\n\nThe Manifest can be in either YAML or JSON format. In this document, we will use YAML in all the examples. Below is a standard example of a basic project.yaml.\n\nspecVersion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # Optionally provide the HTTP endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndataSources:\n  - name: main\n    kind: substrate/Runtime\n    startBlock: 1\n    mapping:\n      handlers:\n        - handler: handleBlock\n          kind: substrate/BlockHandler\n        - handler: handleEvent\n          kind: substrate/EventHandler\n          filter: #Filter is optional but suggested to speed up event processing\n            module: balances\n            method: Deposit\n        - handler: handleCall\n          kind: substrate/CallHandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - This must be a full archive node.\n * network.dictionary optionally provides the HTTP endpoint of a full chain dictionary to speed up processing - read how a SubQuery Dictionary works.\n * dataSources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/Runtime for now.\n   * startBlock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# Network Filters\n\nUsually the user will create a SubQuery and expect to reuse it for both their testnet and mainnet environments (e.g Polkadot and Kusama). Between networks, various options are likely to be different (e.g. index start block). Therefore, we allow users to define different details for each data source which means that one SubQuery project can still be used across multiple networks.\n\nUsers can add a filter on dataSources to decide which data source to run on each network.\n\nBelow is an example that shows different data sources for both the Polkadot and Kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#Create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleBlock\n        kind: substrate/BlockHandler\n\ndataSources:\n  - name: polkadotRuntime\n    kind: substrate/Runtime\n    filter:  #Optional\n        specName: polkadot\n    startBlock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaRuntime\n    kind: substrate/Runtime\n    filter: \n        specName: kusama\n    startBlock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# Mapping Filters\n\nMapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nOnly incoming data that satisfy the filter conditions will be processed by the mapping functions. Mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your SubQuery project and will improve indexing performance.\n\n#Example filter from callHandler\nfilter: \n   module: balances\n   method: Deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nThe following table explains filters supported by different handlers.\n\nHANDLER        SUPPORTED FILTER\nBlockHandler   specVersion\nEventHandler   module,method\nCallHandler    module,method ,success\n\n * Module and method filters are supported on any substrate-based chain.\n * The success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * The specVersion filter specifies the spec version range for a substrate block. The following examples describe how to set version ranges.\n\nfilter:\n  specVersion: [23, 24]   #Index block with specVersion in between 23 and 24 (inclusive).\n  specVersion: [100]      #Index block with specVersion greater than or equal 100.\n  specVersion: [null, 23] #Index block with specVersion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# Custom Chains\n\nYou can index data from custom chains by also including chain types in the project.yaml. Declare the specific types supported by this blockchain in network.types. We support the additional types used by substrate runtime modules.\n\ntypesAlias, typesBundle, typesChain, and typesSpec are also supported.\n\nspecVersion: "0.0.1"\ndescription: "This subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]"\n  }\n# typesChain: { chain: { Type5: \'example\' } }\n# typesSpec: { spec: { Type6: \'example\' } }\ndataSources:\n  - name: runtime\n    kind: substrate/Runtime\n    startBlock: 1\n    filter:  #Optional\n      specName: kitty-chain \n    mapping:\n      handlers:\n        - handler: handleKittyBred\n          kind: substrate/CallHandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',normalizedContent:'# manifest file\n\nthe manifest project.yaml file can be seen as an entry point of your project and it defines most of the details on how subquery will index and transform the chain data.\n\nthe manifest can be in either yaml or json format. in this document, we will use yaml in all the examples. below is a standard example of a basic project.yaml.\n\nspecversion: "0.0.1"\ndescription: ""\nrepository: "https://github.com/subquery/subql-starter"\n\nschema: "./schema.graphql"\n\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n  # optionally provide the http endpoint of a full chain dictionary to speed up processing\n  dictionary: "https://api.subquery.network/sq/subquery/dictionary-polkadot"\n\ndatasources:\n  - name: main\n    kind: substrate/runtime\n    startblock: 1\n    mapping:\n      handlers:\n        - handler: handleblock\n          kind: substrate/blockhandler\n        - handler: handleevent\n          kind: substrate/eventhandler\n          filter: #filter is optional but suggested to speed up event processing\n            module: balances\n            method: deposit\n        - handler: handlecall\n          kind: substrate/callhandler\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n * network.endpoint defines the wss or ws endpoint of the blockchain to be indexed - this must be a full archive node.\n * network.dictionary optionally provides the http endpoint of a full chain dictionary to speed up processing - read how a subquery dictionary works.\n * datasources defines the data that will be filtered and extracted and the location of the mapping function handler for the data transformation to be applied.\n   * kind only supports substrate/runtime for now.\n   * startblock specifies the block height to start indexing from.\n   * filter will filter the data source to execute by the network endpoint spec name, see network filters\n   * mapping.handlers will list all the mapping functions and their corresponding handler types, with additional mapping filters.\n\n\n# network filters\n\nusually the user will create a subquery and expect to reuse it for both their testnet and mainnet environments (e.g polkadot and kusama). between networks, various options are likely to be different (e.g. index start block). therefore, we allow users to define different details for each data source which means that one subquery project can still be used across multiple networks.\n\nusers can add a filter on datasources to decide which data source to run on each network.\n\nbelow is an example that shows different data sources for both the polkadot and kusama networks.\n\n...\nnetwork:\n  endpoint: "wss://polkadot.api.onfinality.io/public-ws"\n\n#create a template to avoid redundancy\ndefinitions:\n  mapping: &mymapping\n    handlers:\n      - handler: handleblock\n        kind: substrate/blockhandler\n\ndatasources:\n  - name: polkadotruntime\n    kind: substrate/runtime\n    filter:  #optional\n        specname: polkadot\n    startblock: 1000\n    mapping: *mymapping #use template here\n  - name: kusamaruntime\n    kind: substrate/runtime\n    filter: \n        specname: kusama\n    startblock: 12000 \n    mapping: *mymapping # can reuse or change\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# mapping filters\n\nmapping filters are an extremely useful feature to decide what block, event, or extrinsic will trigger a mapping handler.\n\nonly incoming data that satisfy the filter conditions will be processed by the mapping functions. mapping filters are optional but are recommended as they significantly reduce the amount of data processed by your subquery project and will improve indexing performance.\n\n#example filter from callhandler\nfilter: \n   module: balances\n   method: deposit\n   success: true\n\n\n1\n2\n3\n4\n5\n\n\nthe following table explains filters supported by different handlers.\n\nhandler        supported filter\nblockhandler   specversion\neventhandler   module,method\ncallhandler    module,method ,success\n\n * module and method filters are supported on any substrate-based chain.\n * the success filter takes a boolean value and can be used to filter the extrinsic by its success status.\n * the specversion filter specifies the spec version range for a substrate block. the following examples describe how to set version ranges.\n\nfilter:\n  specversion: [23, 24]   #index block with specversion in between 23 and 24 (inclusive).\n  specversion: [100]      #index block with specversion greater than or equal 100.\n  specversion: [null, 23] #index block with specversion less than or equal 23.\n\n\n1\n2\n3\n4\n\n\n\n# custom chains\n\nyou can index data from custom chains by also including chain types in the project.yaml. declare the specific types supported by this blockchain in network.types. we support the additional types used by substrate runtime modules.\n\ntypesalias, typesbundle, typeschain, and typesspec are also supported.\n\nspecversion: "0.0.1"\ndescription: "this subquery indexes kitty\'s birth info"\nrepository: "https://github.com/onfinality-io/subql-examples"\nschema: "./schema.graphql"\nnetwork:\n  endpoint: "ws://host.kittychain.io/public-ws"\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]"\n  }\n# typeschain: { chain: { type5: \'example\' } }\n# typesspec: { spec: { type6: \'example\' } }\ndatasources:\n  - name: runtime\n    kind: substrate/runtime\n    startblock: 1\n    filter:  #optional\n      specname: kitty-chain \n    mapping:\n      handlers:\n        - handler: handlekittybred\n          kind: substrate/callhandler\n          filter:\n            module: kitties\n            method: breed\n            success: true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n',charsets:{},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{title:"Mapping",frontmatter:{summary:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written ",meta:[{property:"og:url",content:"/th/create/mapping.html"},{property:"og:title",content:"Mapping"},{property:"og:description",content:"Mapping Mapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file. Mappings are written "},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/th/create/mapping.html",relativePath:"th/create/mapping.md",key:"v-7bbe2fad",path:"/th/create/mapping/",headers:[{level:2,title:"Block Handler",slug:"block-handler",normalizedTitle:"block handler",charIndex:598},{level:2,title:"Event Handler",slug:"event-handler",normalizedTitle:"event handler",charIndex:559},{level:2,title:"Call Handler",slug:"call-handler",normalizedTitle:"call handler",charIndex:579},{level:2,title:"Query States",slug:"query-states",normalizedTitle:"query states",charIndex:3141},{level:2,title:"RPC calls",slug:"rpc-calls",normalizedTitle:"rpc calls",charIndex:4151},{level:2,title:"Modules and Libraries",slug:"modules-and-libraries",normalizedTitle:"modules and libraries",charIndex:5111},{level:3,title:"Built-in modules",slug:"built-in-modules",normalizedTitle:"built-in modules",charIndex:5541},{level:3,title:"Third-party libraries",slug:"third-party-libraries",normalizedTitle:"third-party libraries",charIndex:6209},{level:2,title:"Custom Substrate Chains",slug:"custom-substrate-chains",normalizedTitle:"custom substrate chains",charIndex:5061},{level:3,title:"Preparation",slug:"preparation",normalizedTitle:"preparation",charIndex:6926},{level:3,title:"Type generation",slug:"type-generation",normalizedTitle:"type generation",charIndex:10271},{level:3,title:"Usage",slug:"usage",normalizedTitle:"usage",charIndex:11506},{level:3,title:"Custom chain rpc calls",slug:"custom-chain-rpc-calls",normalizedTitle:"custom chain rpc calls",charIndex:11728}],readingTime:{minutes:6.91,words:2073},headersStr:"Block Handler Event Handler Call Handler Query States RPC calls Modules and Libraries Built-in modules Third-party libraries Custom Substrate Chains Preparation Type generation Usage Custom chain rpc calls",content:'# Mapping\n\nMapping functions define how chain data is transformed into the optimised GraphQL entities that we have previously defined in the schema.graphql file.\n\nMappings are written in a subset of TypeScript called AssemblyScript which can be compiled to WASM (WebAssembly).\n\n * Mappings are defined in the src/mappings directory and are exported as a function\n * These mappings are also exported in src/index.ts\n * The mappings files are reference in project.yaml under the mapping handlers.\n\nThere are three classes of mappings functions; Block handlers, Event Handlers, and Call Handlers.\n\n\n# Block Handler\n\nYou can use block handlers to capture information each time a new block is attached to the Substrate chain, e.g. block number. To achieve this, a defined BlockHandler will be called once for every block.\n\nimport {SubstrateBlock} from "@subql/types";\n\nexport async function handleBlock(block: SubstrateBlock): Promise<void> {\n    // Create a new StarterEntity with the block hash as it\'s ID\n    const record = new starterEntity(block.block.header.hash.toString());\n    record.field1 = block.block.header.number.toNumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nA SubstrateBlock is an extended interface type of signedBlock, but also includes the specVersion and timestamp.\n\n\n# Event Handler\n\nYou can use event handlers to capture information when certain events are included on a new block. The events that are part of the default Substrate runtime and a block may contain multiple events.\n\nDuring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. Any type of event will trigger the mapping, allowing activity with the data source to be captured. You should use Mapping Filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {SubstrateEvent} from "@subql/types";\n\nexport async function handleEvent(event: SubstrateEvent): Promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // Retrieve the record by its ID\n    const record = new starterEntity(event.extrinsic.block.block.header.hash.toString());\n    record.field2 = account.toString();\n    record.field3 = (balance as Balance).toBigInt();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nA SubstrateEvent is an extended interface type of the EventRecord. Besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# Call Handler\n\nCall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nThe SubstrateExtrinsic extends GenericExtrinsic. It is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. Additionally, it records the success status of this extrinsic.\n\n\n# Query States\n\nOur goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). Therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nThese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.queryMulti() will make multiple queries of different types at the current block.\n\nThese are the interfaces we do NOT support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesAt\n * api.query.<module>.<method>.entriesPaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysAt\n * api.query.<module>.<method>.keysPaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeAt\n\nSee an example of using this API in our validator-threshold example use case.\n\n\n# RPC calls\n\nWe also support some API RPC methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. A core premise of SubQuery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical RPC calls.\n\nDocuments in JSON-RPC provide some methods that take BlockHash as an input parameter (e.g. at?: BlockHash), which are now permitted. We have also modified these methods to take the current indexing block hash by default.\n\n// Let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// Original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getBlock(blockhash);\n\n// It will use the current block has by default like so\nconst b2 = await api.rpc.chain.getBlock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * For Custom Substrate Chains RPC calls, see usage.\n\n\n# Modules and Libraries\n\nTo improve SubQuery\'s data processing capabilities, we have allowed some of the NodeJS\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nPlease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. Please report any bugs you find by creating an issue in GitHub.\n\n\n# Built-in modules\n\nCurrently, we allow the following NodeJS modules: assert, buffer, crypto, util, and path.\n\nRather than importing the whole module, we recommend only importing the required method(s) that you need. Some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashMessage} from "ethers/lib/utils"; //Good way\nimport {utils} from "ethers" //Bad way\n\nexport async function handleCall(extrinsic: SubstrateExtrinsic): Promise<void> {\n    const record = new starterEntity(extrinsic.block.block.header.hash.toString());\n    record.field1 = hashMessage(\'Hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# Third-party libraries\n\nDue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by CommonJS.\n\nWe also support a hybrid library like @polkadot/* that uses ESM as default. However, if any other libraries depend on any modules in ESM format, the virtual machine will NOT compile and return an error.\n\n\n# Custom Substrate Chains\n\nSubQuery can be used on any Substrate-based chain, not just Polkadot or Kusama.\n\nYou can use a custom Substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nIn the following sections, we use our kitty example to explain the integration process.\n\n\n# Preparation\n\nCreate a new directory api-interfaces under the project src folder to store all required and generated files. We also create an api-interfaces/kitties directory as we want to add decoration in the API from the kitties module.\n\n# Metadata\n\nWe need metadata to generate the actual API endpoints. In the kitty example, we use an endpoint from a local testnet, and it provides additional types. Follow the steps in PolkadotJS metadata setup to retrieve a node\'s metadata from its HTTP endpoint.\n\ncurl -H "Content-Type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getMetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//Install the websocat\nbrew install websocat\n\n//Get metadata\necho state_getMetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nNext, copy and paste the output to a JSON file. In our kitty example, we have created api-interface/kitty.json.\n\n# Type definitions\n\nWe assume that the user knows the specific types and RPC support from the chain, and it is defined in the Manifest.\n\nFollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        Address: "AccountId",\n        LookupSource: "AccountId",\n        KittyIndex: "u32",\n        Kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getKittyPrice\n    rpc: {\n        getKittyPrice:{\n            description: \'Get Kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                },\n                {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                }\n            ],\n            type: \'Balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# Packages\n\n * In the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). We also need ts-node as a development dependency to help us run the scripts.\n * We add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nHere is a simplified version of package.json. Make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devDependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# Type generation\n\nNow that preparation is completed, we are ready to generate types and metadata. Run the commands below:\n\n# Yarn to install new dependencies\nyarn\n\n# Generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nIn each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# Generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nThis command will generate the metadata and a new api-augment for the APIs. As we don\'t want to use the built-in API, we will need to replace them by adding an explicit override in our tsconfig.json. After the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compilerOptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# Usage\n\nNow in the mapping function, we can show how the metadata and types actually decorate the API. The RPC endpoint will support the modules and methods we declared above. And to use custom rpc call, please see section Custom chain rpc calls\n\nexport async function kittyApiHandler(): Promise<void> {\n    //return the KittyIndex type\n    const nextKittyId = await api.query.kitties.nextKittyId();\n    // return the Kitty type, input parameters types are AccountId and KittyIndex\n    const allKitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`Next kitty id ${nextKittyId}`)\n    //Custom rpc, set undefined to blockhash\n    const kittyPrice = await api.rpc.kitties.getKittyPrice(undefined,nextKittyId);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nIf you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# Custom chain rpc calls\n\nTo support customised chain RPC calls, we must manually inject RPC definitions for typesBundle, allowing per-spec configuration. You can define the typesBundle in the project.yml. And please remember only isHistoric type of calls are supported.\n\n...\n  types: {\n    "KittyIndex": "u32",\n    "Kitty": "[u8; 16]",\n  }\n  typesBundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getKittyPrice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'BlockHash\',\n                    isHistoric: true,\n                    isOptional: false\n                  },\n                  {\n                    name: \'kittyIndex\',\n                    type: \'KittyIndex\',\n                    isOptional: false\n                  }\n                ],\n                type: "Balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',normalizedContent:'# mapping\n\nmapping functions define how chain data is transformed into the optimised graphql entities that we have previously defined in the schema.graphql file.\n\nmappings are written in a subset of typescript called assemblyscript which can be compiled to wasm (webassembly).\n\n * mappings are defined in the src/mappings directory and are exported as a function\n * these mappings are also exported in src/index.ts\n * the mappings files are reference in project.yaml under the mapping handlers.\n\nthere are three classes of mappings functions; block handlers, event handlers, and call handlers.\n\n\n# block handler\n\nyou can use block handlers to capture information each time a new block is attached to the substrate chain, e.g. block number. to achieve this, a defined blockhandler will be called once for every block.\n\nimport {substrateblock} from "@subql/types";\n\nexport async function handleblock(block: substrateblock): promise<void> {\n    // create a new starterentity with the block hash as it\'s id\n    const record = new starterentity(block.block.header.hash.tostring());\n    record.field1 = block.block.header.number.tonumber();\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\na substrateblock is an extended interface type of signedblock, but also includes the specversion and timestamp.\n\n\n# event handler\n\nyou can use event handlers to capture information when certain events are included on a new block. the events that are part of the default substrate runtime and a block may contain multiple events.\n\nduring the processing, the event handler will receive a substrate event as an argument with the event\'s typed inputs and outputs. any type of event will trigger the mapping, allowing activity with the data source to be captured. you should use mapping filters in your manifest to filter events to reduce the time it takes to index data and improve mapping performance.\n\nimport {substrateevent} from "@subql/types";\n\nexport async function handleevent(event: substrateevent): promise<void> {\n    const {event: {data: [account, balance]}} = event;\n    // retrieve the record by its id\n    const record = new starterentity(event.extrinsic.block.block.header.hash.tostring());\n    record.field2 = account.tostring();\n    record.field3 = (balance as balance).tobigint();\n    await record.save();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\na substrateevent is an extended interface type of the eventrecord. besides the event data, it also includes an id (the block to which this event belongs) and the extrinsic inside of this block.\n\n\n# call handler\n\ncall handlers are used when you want to capture information on certain substrate extrinsics.\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field4 = extrinsic.block.timestamp;\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n\n\nthe substrateextrinsic extends genericextrinsic. it is assigned an id (the block to which this extrinsic belongs) and provides an extrinsic property that extends the events among this block. additionally, it records the success status of this extrinsic.\n\n\n# query states\n\nour goal is to cover all data sources for users for mapping handlers (more than just the three interface event types above). therefore, we have exposed some of the @polkadot/api interfaces to increase capabilities.\n\nthese are the interfaces we currently support:\n\n * api.query.<module>.<method>() will query the current block.\n * api.query.<module>.<method>.multi() will make multiple queries of the same type at the current block.\n * api.querymulti() will make multiple queries of different types at the current block.\n\nthese are the interfaces we do not support currently:\n\n * api.tx.*\n * api.derive.*\n * api.query.<module>.<method>.at\n * api.query.<module>.<method>.entriesat\n * api.query.<module>.<method>.entriespaged\n * api.query.<module>.<method>.hash\n * api.query.<module>.<method>.keysat\n * api.query.<module>.<method>.keyspaged\n * api.query.<module>.<method>.range\n * api.query.<module>.<method>.sizeat\n\nsee an example of using this api in our validator-threshold example use case.\n\n\n# rpc calls\n\nwe also support some api rpc methods that are remote calls that allow the mapping function to interact with the actual node, query, and submission. a core premise of subquery is that it\'s deterministic, and therefore, to keep the results consistent we only allow historical rpc calls.\n\ndocuments in json-rpc provide some methods that take blockhash as an input parameter (e.g. at?: blockhash), which are now permitted. we have also modified these methods to take the current indexing block hash by default.\n\n// let\'s say we are currently indexing a block with this hash number\nconst blockhash = `0x844047c4cf1719ba6d54891e92c071a41e3dfe789d064871148e9d41ef086f6a`;\n\n// original method has an optional input is block hash\nconst b1 = await api.rpc.chain.getblock(blockhash);\n\n// it will use the current block has by default like so\nconst b2 = await api.rpc.chain.getblock();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * for custom substrate chains rpc calls, see usage.\n\n\n# modules and libraries\n\nto improve subquery\'s data processing capabilities, we have allowed some of the nodejs\'s built-in modules for running mapping functions in the sandbox, and have allowed users to call third-party libraries.\n\nplease note this is an experimental feature and you may encounter bugs or issues that may negatively impact your mapping functions. please report any bugs you find by creating an issue in github.\n\n\n# built-in modules\n\ncurrently, we allow the following nodejs modules: assert, buffer, crypto, util, and path.\n\nrather than importing the whole module, we recommend only importing the required method(s) that you need. some methods in these modules may have dependencies that are unsupported and will fail on import.\n\nimport {hashmessage} from "ethers/lib/utils"; //good way\nimport {utils} from "ethers" //bad way\n\nexport async function handlecall(extrinsic: substrateextrinsic): promise<void> {\n    const record = new starterentity(extrinsic.block.block.header.hash.tostring());\n    record.field1 = hashmessage(\'hello\');\n    await record.save();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# third-party libraries\n\ndue to the limitations of the virtual machine in our sandbox, currently, we only support third-party libraries written by commonjs.\n\nwe also support a hybrid library like @polkadot/* that uses esm as default. however, if any other libraries depend on any modules in esm format, the virtual machine will not compile and return an error.\n\n\n# custom substrate chains\n\nsubquery can be used on any substrate-based chain, not just polkadot or kusama.\n\nyou can use a custom substrate-based chain and we provide tools to import types, interfaces, and additional methods automatically using @polkadot/typegen.\n\nin the following sections, we use our kitty example to explain the integration process.\n\n\n# preparation\n\ncreate a new directory api-interfaces under the project src folder to store all required and generated files. we also create an api-interfaces/kitties directory as we want to add decoration in the api from the kitties module.\n\n# metadata\n\nwe need metadata to generate the actual api endpoints. in the kitty example, we use an endpoint from a local testnet, and it provides additional types. follow the steps in polkadotjs metadata setup to retrieve a node\'s metadata from its http endpoint.\n\ncurl -h "content-type: application/json" -d \'{"id":"1", "jsonrpc":"2.0", "method": "state_getmetadata", "params":[]}\' http://localhost:9933\n\n\n1\n\n\nor from its websocket endpoint with help from websocat:\n\n//install the websocat\nbrew install websocat\n\n//get metadata\necho state_getmetadata | websocat \'ws://127.0.0.1:9944\' --jsonrpc\n\n\n1\n2\n3\n4\n5\n\n\nnext, copy and paste the output to a json file. in our kitty example, we have created api-interface/kitty.json.\n\n# type definitions\n\nwe assume that the user knows the specific types and rpc support from the chain, and it is defined in the manifest.\n\nfollowing types setup, we create :\n\n * src/api-interfaces/definitions.ts - this exports all the sub-folder definitions\n\nexport { default as kitties } from \'./kitties/definitions\';\n\n\n1\n\n * src/api-interfaces/kitties/definitions.ts - type definitions for the kitties module\n\nexport default {\n    // custom types\n    types: {\n        address: "accountid",\n        lookupsource: "accountid",\n        kittyindex: "u32",\n        kitty: "[u8; 16]"\n    },\n    // custom rpc : api.rpc.kitties.getkittyprice\n    rpc: {\n        getkittyprice:{\n            description: \'get kitty price\',\n            params: [\n                {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                },\n                {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                }\n            ],\n            type: \'balance\'\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n# packages\n\n * in the package.json file, make sure to add @polkadot/typegen as a development dependency and @polkadot/api as a regular dependency (ideally the same version). we also need ts-node as a development dependency to help us run the scripts.\n * we add scripts to run both types; generate:defs and metadata generate:meta generators (in that order, so metadata can use the types).\n\nhere is a simplified version of package.json. make sure in the scripts section the package name is correct and the directories are valid.\n\n{\n  "name": "kitty-birthinfo",\n  "scripts": {\n    "generate:defs": "ts-node --skip-project node_modules/.bin/polkadot-types-from-defs --package kitty-birthinfo/api-interfaces --input ./src/api-interfaces",\n    "generate:meta": "ts-node --skip-project node_modules/.bin/polkadot-types-from-chain --package kitty-birthinfo/api-interfaces --endpoint ./src/api-interfaces/kitty.json --output ./src/api-interfaces --strict"\n  },\n  "dependencies": {\n    "@polkadot/api": "^4.9.2"\n  },\n  "devdependencies": {\n    "typescript": "^4.1.3",\n    "@polkadot/typegen": "^4.9.2",\n    "ts-node": "^8.6.2"\n  }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# type generation\n\nnow that preparation is completed, we are ready to generate types and metadata. run the commands below:\n\n# yarn to install new dependencies\nyarn\n\n# generate types\nyarn generate:defs\n\n\n1\n2\n3\n4\n5\n\n\nin each modules folder (eg /kitties), there should now be a generated types.ts that defines all interfaces from this modules\' definitions, also a file index.ts that exports them all.\n\n# generate metadata\nyarn generate:meta\n\n\n1\n2\n\n\nthis command will generate the metadata and a new api-augment for the apis. as we don\'t want to use the built-in api, we will need to replace them by adding an explicit override in our tsconfig.json. after the updates, the paths in the config will look like this (without the comments):\n\n{\n  "compileroptions": {\n      // this is the package name we use (in the interface imports, --package for generators) */\n      "kitty-birthinfo/*": ["src/*"],\n      // here we replace the @polkadot/api augmentation with our own, generated from chain\n      "@polkadot/api/augment": ["src/interfaces/augment-api.ts"],\n      // replace the augmented types with our own, as generated from definitions\n      "@polkadot/types/augment": ["src/interfaces/augment-types.ts"]\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# usage\n\nnow in the mapping function, we can show how the metadata and types actually decorate the api. the rpc endpoint will support the modules and methods we declared above. and to use custom rpc call, please see section custom chain rpc calls\n\nexport async function kittyapihandler(): promise<void> {\n    //return the kittyindex type\n    const nextkittyid = await api.query.kitties.nextkittyid();\n    // return the kitty type, input parameters types are accountid and kittyindex\n    const allkitties  = await api.query.kitties.kitties(\'xxxxxxxxx\',123)\n    logger.info(`next kitty id ${nextkittyid}`)\n    //custom rpc, set undefined to blockhash\n    const kittyprice = await api.rpc.kitties.getkittyprice(undefined,nextkittyid);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nif you wish to publish this project to our explorer, please include the generated files in src/api-interfaces.\n\n\n# custom chain rpc calls\n\nto support customised chain rpc calls, we must manually inject rpc definitions for typesbundle, allowing per-spec configuration. you can define the typesbundle in the project.yml. and please remember only ishistoric type of calls are supported.\n\n...\n  types: {\n    "kittyindex": "u32",\n    "kitty": "[u8; 16]",\n  }\n  typesbundle: {\n    spec: {\n      chainname: {\n        rpc: {\n          kitties: {\n            getkittyprice:{\n                description: string,\n                params: [\n                  {\n                    name: \'at\',\n                    type: \'blockhash\',\n                    ishistoric: true,\n                    isoptional: false\n                  },\n                  {\n                    name: \'kittyindex\',\n                    type: \'kittyindex\',\n                    isoptional: false\n                  }\n                ],\n                type: "balance",\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n',charsets:{cjk:!0},updateTime:"October 6, 2021 02:24",updateTimeStamp:163348706e4,createTime:"October 6, 2021 02:24",createTimeStamp:163348706e4,contributors:[]},{frontmatter:{layout:"Blog",summary:"",meta:[{property:"og:url",content:"/article/"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/article/",key:"v-6453f364",path:"/article/",readingTime:{minutes:0,words:0},headersStr:null,content:"",normalizedContent:"",charsets:{}},{frontmatter:{layout:"Blog",summary:"",meta:[{property:"og:url",content:"/star/"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/star/",key:"v-4340f7e8",path:"/star/",readingTime:{minutes:0,words:0},headersStr:null,content:"",normalizedContent:"",charsets:{}},{frontmatter:{layout:"Blog",summary:"",meta:[{property:"og:url",content:"/encrypt/"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/encrypt/",key:"v-7d484ebf",path:"/encrypt/",readingTime:{minutes:0,words:0},headersStr:null,content:"",normalizedContent:"",charsets:{}},{frontmatter:{layout:"Blog",summary:"",meta:[{property:"og:url",content:"/slide/"},{property:"og:type",content:"article"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/slide/",key:"v-2470be33",path:"/slide/",readingTime:{minutes:0,words:0},headersStr:null,content:"",normalizedContent:"",charsets:{}},{frontmatter:{layout:"Blog",summary:"",meta:[{property:"og:url",content:"/timeline/"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/timeline/",key:"v-6319eb4e",path:"/timeline/",readingTime:{minutes:0,words:0},headersStr:null,content:"",normalizedContent:"",charsets:{}},{frontmatter:{layout:"Blog",title:"Tag",summary:"",meta:[{property:"og:url",content:"/tag/"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/tag/",key:"v-b1564aac",path:"/tag/",readingTime:{minutes:0,words:0},headersStr:null,content:"",normalizedContent:"",charsets:{}},{frontmatter:{layout:"Blog",title:"Category",summary:"",meta:[{property:"og:url",content:"/category/"},{property:"og:type",content:"website"},{property:"og:locale",content:"en-UK"},{property:"og:locale:alternate",content:"en-US"},{name:"twitter:card",content:"summary_large_image"}]},regularPath:"/category/",key:"v-28e6393c",path:"/category/",readingTime:{minutes:0,words:0},headersStr:null,content:"",normalizedContent:"",charsets:{}}],themeConfig:{logo:"/assets/img/logo.png",logoLink:"https://subquery.network",lastUpdated:!0,nav:[{text:"Explorer",link:"https://explorer.subquery.network/",target:"_blank",rel:""},{text:"Projects",link:"https://project.subquery.network/",target:"_blank",rel:""},{text:"Documentation",link:"/"},{text:"GitHub",link:"https://github.com/subquery/subql",target:"_blank",rel:""}],sidebarDepth:2,themeColor:!1,sidebar:[{title:"Welcome to SubQuery",path:"/",collapsable:!0},{title:"Quick Start Guide",path:"/quickstart/quickstart",collapsable:!0,children:["/quickstart/quickstart.md","/quickstart/helloworld-localhost.md","/quickstart/understanding-helloworld.md","/quickstart/helloworld-hosted.md"]},{title:"Installation",path:"/install/install",collapsable:!0,children:["/install/install.md"]},{title:"Create a Project",path:"/create/introduction",collapsable:!0,children:["/create/introduction.md","/create/manifest.md","/create/graphql.md","/create/mapping.md"]},{title:"Run a Project",path:"/run/run",collapsable:!0,children:["/run/run.md","/run/sandbox.md"]},{title:"Publish a Project",path:"/publish/publish",collapsable:!0,children:["/publish/publish.md","/publish/upgrade.md","/publish/connect.md"]},{title:"Query your Data",path:"/query/query",collapsable:!0,children:["/query/query.md","/query/graphql.md"]},{title:"Tutorials & Examples",path:"/tutorials_examples/introduction",collapsable:!0,children:["/tutorials_examples/introduction","/tutorials_examples/block-height.md","/tutorials_examples/batch-size.md","/tutorials_examples/run-indexer.md","/tutorials_examples/dictionary.md","/tutorials_examples/debug-projects.md","/tutorials_examples/terminology.md"]},{title:"FAQs",path:"/faqs/faqs.md",collapsable:!0,children:[]},{title:"Miscellaneous",path:"/miscellaneous/contributing",collapsable:!0,children:["/miscellaneous/contributing.md","/miscellaneous/social_media.md","/miscellaneous/branding.md","/miscellaneous/ambassadors.md"]},{title:"References",path:"/references/references",collapsable:!0,children:["/references/references.md"]}],locales:{"/":{lang:"en-US",selectText:"Language",label:"English",ariaLabel:"Select language",meta:{contributor:"Contributors",editLink:"Edit this page",updateTime:"Last update"},themeColor:{themeColor:"Theme Color",themeMode:"Theme Mode"},encrypt:{title:"Please enter password",errorHint:"Please enter the corrent password!"},error404:{hint:["There’s nothing here.","How did we get here?","That’s a Four-Oh-Four.","Looks like we've got some broken links."],back:"Go back",home:"Take me home"},blog:{article:"Articles",articleList:"Article List",category:"Category",tag:"Tags",timeline:"Timeline",timelineText:"Yesterday Once More!",allText:"All",intro:"Personal Intro",star:"Star",slides:"Slides",encrypt:"Encrypted"}}}},locales:{"/":{lang:"en-UK",title:"SubQuery Blog Posts",description:"Explore and transform your chain data to build intuitive dApps faster!",path:"/"},"/de/":{lang:"de",title:"SubQuery Blog Posts",description:"Explore and transform your chain data to build intuitive dApps faster!.",path:"/de/"},"/vi/":{lang:"vi",title:"SubQuery Blog Posts",description:"Explore and transform your chain data to build intuitive dApps faster!.",path:"/vi/"},"/zh/":{lang:"zh-CN",title:"SubQuery Blog Posts",description:"Explore and transform your chain data to build intuitive dApps faster!.",path:"/zh/"}}};t(161);const Gn={"/zh/":{backToTop:"返回顶部",pagination:{prev:"上一页",next:"下一页",navigate:"跳转到",button:"前往",errorText:"请输入 1 到 $page 之前的页码！"}},"/en/":{backToTop:"Back to top",pagination:{prev:"Prev",next:"Next",navigate:"Jump to",button:"Go",errorText:"Please enter a number between 1 and $page !"}},"/de/":{backToTop:"Zurück nach oben.",pagination:{prev:"Vorheriges",next:"Nächstes",navigate:"Springe zu",button:"Los",errorText:"Bitte gib eine Nummer zwischen 1 und $page ein!"}},"/vi/":{backToTop:"Trở lại đầu trang",pagination:{prev:"Bài kế",next:"Bài trước",navigate:"Đi đến",button:"Đi",errorText:"Xin hãy nhập 1 số từ 1 đến $page !"}},"/":{backToTop:"Back to top",pagination:{prev:"Prev",next:"Next",navigate:"Jump to",button:"Go",errorText:"Please enter a number between 1 and $page !"}}};let Nn;var Mn=a.a.extend({name:"BackToTop",props:{threshold:{type:Number,default:300}},data:()=>({scrollTop:0}),computed:{thresholdDistance(){return"number"==typeof this.$themeConfig.backToTop?this.$themeConfig.backToTop:this.threshold},isDisplay(){const e=!1!==this.$themeConfig.backToTop,n=this.$page.frontmatter.backToTop;return(n||e&&!1!==n)&&this.scrollTop>this.thresholdDistance},hint(){return Gn[this.$localePath||"/"].backToTop}},mounted(){this.scrollTop=this.getScrollTop(),Nn=Tn()(()=>{this.scrollTop=this.getScrollTop()},100),window.addEventListener("scroll",Nn)},beforeDestroy(){window.removeEventListener("scroll",Nn)},methods:{getScrollTop:()=>window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,scrollToTop(){window.scrollTo({top:0,behavior:"smooth"}),this.scrollTop=0}}}),Rn=(t(162),Object(Ln.a)(Mn,(function(){var e=this.$createElement,n=this._self._c||e;return n("transition",{attrs:{name:"fade"}},[this.isDisplay?n("button",{staticClass:"back-to-top",attrs:{"aria-label":this.hint,"data-balloon-pos":"left"},on:{click:this.scrollToTop}},[n("svg",{attrs:{viewBox:"0 0 1024 1024",xmlns:"http://www.w3.org/2000/svg"}},[n("path",{attrs:{d:"M512 0C229.517 0 0 229.517 0 512s227.752 512 512 512c282.483 0 512-227.752 512-512C1024 229.517 794.483\n      0 512 0zM351.338 271.89h305.434c14.125 0 26.483 12.358 26.483 26.482s-12.358 26.483-26.483\n      26.483H351.338c-14.124 0-26.483-12.358-26.483-26.483 0-15.89 12.359-26.482 26.483-26.482z\n      m331.917 303.669c-12.358 12.358-33.545 12.358-45.903 0L531.42 471.393v270.124c0 14.124-12.359\n      26.483-26.483 26.483s-26.483-12.359-26.483-26.483v-271.89l-105.93 104.166c-12.36 12.359-33.546 12.359-45.904\n      0-12.359-12.359-12.359-31.78 0-45.903l155.365-151.835c7.062-7.062 14.124-8.827 22.952-8.827s15.89 3.53 22.952\n      8.827L683.255 527.89c12.359 15.89 12.359 35.31 0 47.669z",fill:"currentColor"}})])]):this._e()])}),[],!1,null,null,null).exports),Wn=a.a.extend({name:"Badge",functional:!0,props:{type:{type:String,default:"tip"},text:{type:String,default:""},vertical:{type:String,default:"top"},color:{type:String,default:""}},render(e,{props:n,slots:t}){const a={class:["badge",n.type],style:{verticalAlign:n.vertical}};return n.color&&(a.class.push("diy"),a.style.backgroundColor=n.color,a["data-color"]=n.color),e("span",a,n.text||t().default)}}),Un=(t(163),Object(Ln.a)(Wn,void 0,void 0,!1,null,"7b453e57",null).exports),Fn=a.a.extend({name:"BreadCrumb",computed:{enable(){const e=!1!==this.$themeConfig.breadcrumb,n=this.$page.frontmatter.breadcrumb;return(e&&!1!==n||!0===n)&&this.config.length>1},iconEnable(){const e=!1!==this.$themeConfig.breadcrumbIcon,n=this.$page.frontmatter.breadcrumbIcon;return this.enable&&(e&&!1!==n||!0===n)},iconPrefix(){const{iconPrefix:e}=this.$themeConfig;return""===e?"":e||"icon-"},config(){const e=[],{pages:n}=this.$site,t=this.getLinks(this.$route);for(let a=1;a<t.length;a++)for(let o=0;o<n.length;o++){const r=n[o];if(r.path===t[a]){e.push({title:r.title,icon:r.frontmatter.icon,url:r.path});break}}return e}},methods:{getLinks(e){const n=e.path.split("/"),t=[];let a="";return n.forEach((e,o)=>{o!==n.length-1?(a+=e+"/",t.push(a)):""!==e&&(a+=e,t.push(a))}),t}}}),Kn=(t(164),Object(Ln.a)(Fn,(function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("nav",{staticClass:"breadcrumb",class:{disable:!e.enable}},[e.enable?t("ol",{attrs:{vocab:"https://schema.org/",typeof:"BreadcrumbList"}},e._l(e.config,(function(n,a){return t("li",{key:n.url,class:{"is-active":e.config.length-1===a},attrs:{property:"itemListElement",typeof:"ListItem"}},[t("RouterLink",{attrs:{to:n.url,property:"item",typeof:"WebPage"}},[n.icon&&e.iconEnable?t("i",{class:"iconfont "+e.iconPrefix+n.icon}):e._e(),e._v(" "),t("span",{attrs:{property:"name"}},[e._v(e._s(n.title))])]),e._v(" "),t("meta",{attrs:{property:"position",content:a+1}})],1)})),0):e._e()])}),[],!1,null,null,null).exports),Vn=a.a.extend({name:"CodeGroup",data:()=>({codeTabs:[],activeTabIndex:-1}),watch:{activeTabIndex(e){this.activateCodeTab(e)}},mounted(){this.loadTabs()},methods:{loadTabs(){this.codeTabs=(this.$slots.default||[]).filter(e=>Boolean(e.componentOptions)).map((e,n)=>{const t=e.componentOptions.propsData;return t.active&&(this.activeTabIndex=n),{title:t.title,element:e.elm}}),-1===this.activeTabIndex&&this.codeTabs.length>0&&(this.activeTabIndex=0),this.activateCodeTab(0)},changeCodeTab(e){this.activeTabIndex=e},keyDownHandler(e,n){" "===e.key||"Enter"===e.key?(e.preventDefault(),this.activeTabIndex=n):"ArrowRight"===e.key?(e.preventDefault(),n+1<this.codeTabs.length&&(this.activeTabIndex=n+1,this.$refs.tab[n+1].focus())):"ArrowLeft"===e.key&&(e.preventDefault(),n-1>=0&&(this.activeTabIndex=n-1,this.$refs.tab[n-1].focus()))},activateCodeTab(e){this.codeTabs.forEach((n,t)=>{const{element:a}=n;a&&(e===t?a.classList.add("active"):a.classList.remove("active"))})}}}),Yn=(t(165),Object(Ln.a)(Vn,(function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("ClientOnly",[t("div",{staticClass:"code-group"},[t("div",{staticClass:"code-group-nav",attrs:{"v:if":"codeTabs.length"}},e._l(e.codeTabs,(function(n,a){return t("button",{key:n.title,ref:"tab",refInFor:!0,staticClass:"code-group-nav-tab",class:{active:a===e.activeTabIndex},attrs:{"aria-pressed":a===e.activeTabIndex,"aria-expanded":a===e.activeTabIndex},domProps:{textContent:e._s(n.title)},on:{click:function(n){return e.changeCodeTab(a)},keydown:function(n){return e.keyDownHandler(n,a)}}})})),0),e._v(" "),e._t("default"),e._v(" "),e.codeTabs.length?e._e():t("pre",{staticClass:"hints",domProps:{textContent:e._s("// Make sure to add code blocks to your code group")}})],2)])}),[],!1,null,null,null).exports),Jn=a.a.extend({name:"CodeGroupItem",props:{title:{type:String,required:!0},active:{type:Boolean,required:!1,default:!1}},mounted(){this.$parent&&this.$parent.loadTabs&&this.$parent.loadTabs()}}),$n=(t(166),Object(Ln.a)(Jn,(function(){var e=this.$createElement;return(this._self._c||e)("div",{staticClass:"code-group-item",class:{active:this.active},attrs:{"aria-selected":this.active}},[this._t("default")],2)}),[],!1,null,null,null).exports),Zn=a.a.extend({name:"Pagination",model:{prop:"currentPage",event:"change"},props:{total:{type:Number,default:10},perPage:{type:Number,default:10},currentPage:{type:Number,default:1}},data:()=>({input:""}),computed:{totalPages(){return Math.ceil(this.total/this.perPage)},enable(){return Boolean(this.totalPages)&&1!==this.totalPages},displayLeftEllipsis(){return!(this.totalPages<7)&&this.currentPage>4},displayRightEllipsis(){return!(this.totalPages<7)&&this.currentPage<this.totalPages-3},indexs(){const{currentPage:e,totalPages:n}=this;let t=1,a=n;const o=[];n>=7&&(e<=4&&e<n-3?(t=1,a=5):e>4&&e>=n-3?(a=n,t=n-4):n>7&&(t=e-2,a=e+2));for(let e=t;e<=a;e++)o.push(e);return o},i18n(){return Gn[this.$localePath||"/"].pagination}},mounted(){const{index:e}=this.$route.query;this.navigate(e?Number(e):1)},methods:{navigate(e){const n=Object.assign({},this.$route.query);n.page===e.toString()||1===e&&!n.page||(this.$emit("change",e),1===e?delete n.page:n.page=e.toString(),this.$router.push({path:this.$route.path,query:n}))},jumpPage(e){const n=parseInt(e);n<=this.totalPages&&n>0?this.navigate(n):alert(this.i18n.errorText.replace(/\$page/g,this.totalPages.toString()))}}}),Xn=(t(167),Object(Ln.a)(Zn,(function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("div",{staticClass:"pagination-wrapper"},[e.enable?t("div",{staticClass:"pagination-list"},[t("div",{staticClass:"btn-group"},[e.currentPage>1?t("div",{staticClass:"prev",attrs:{role:"navigation",unselectable:"on"},on:{click:function(n){return e.navigate(e.currentPage-1)}}},[e._v("\n        "+e._s(e.i18n.prev)+"\n      ")]):e._e(),e._v(" "),e.displayLeftEllipsis?t("div",{attrs:{role:"navigation"},on:{click:function(n){return e.navigate(1)}}},[e._v("\n        1\n      ")]):e._e(),e._v(" "),e.displayLeftEllipsis?t("div",{staticClass:"ellipsis"},[e._v("...")]):e._e(),e._v(" "),e._l(e.indexs,(function(n){return t("div",{key:n,class:{active:e.currentPage===n},attrs:{role:"navigation"},on:{click:function(t){return e.navigate(n)}}},[e._v("\n        "+e._s(n)+"\n      ")])})),e._v(" "),e.displayRightEllipsis?t("div",{staticClass:"ellipsis"},[e._v("...")]):e._e(),e._v(" "),e.displayRightEllipsis?t("div",{attrs:{role:"navigation"},on:{click:function(n){return e.navigate(e.totalPages)}}},[e._v("\n        "+e._s(e.totalPages)+"\n      ")]):e._e(),e._v(" "),e.currentPage<e.totalPages?t("div",{staticClass:"next",attrs:{role:"navigation"},on:{click:function(n){return e.navigate(e.currentPage+1)}}},[e._v("\n        "+e._s(e.i18n.next)+"\n      ")]):e._e()],2),e._v(" "),t("div",{staticClass:"navigate-wrapper"},[t("label",{attrs:{for:"navigation-text"}},[e._v(e._s(e.i18n.navigate)+": ")]),e._v(" "),t("input",{directives:[{name:"model",rawName:"v-model",value:e.input,expression:"input"}],attrs:{id:"navigation-text",type:"text"},domProps:{value:e.input},on:{keypress:function(n){return!n.type.indexOf("key")&&e._k(n.keyCode,"enter",13,n.key,"Enter")?null:e.jumpPage(e.input)},input:function(n){n.target.composing||(e.input=n.target.value)}}}),e._v(" "),t("button",{staticClass:"navigate",attrs:{role:"navigation",title:e.i18n.button},on:{click:function(n){return e.jumpPage(e.input)}}},[e._v("\n        "+e._s(e.i18n.button)+"\n      ")])])]):e._e()])}),[],!1,null,null,null).exports),et=t(8),nt=a.a.extend({name:"ScreenFull",data:()=>({canFullscreen:!1,isFullscreen:!1}),mounted(){this.canFullscreen=et.isEnabled&&!1!==this.$themeConfig.fullscreen},methods:{click(){et.isEnabled&&et.toggle().then(()=>{this.isFullscreen=et.isFullscreen})}}}),tt=(t(168),Object(Ln.a)(nt,(function(){var e=this.$createElement,n=this._self._c||e;return this.canFullscreen?n("button",{class:this.isFullscreen?"cancel-full-screen":"full-screen",attrs:{"aria-pressed":this.isFullscreen},on:{click:this.click}},[n("svg",{attrs:{viewBox:"0 0 1024 1024",xmlns:"http://www.w3.org/2000/svg"}},[this.isFullscreen?n("path",{attrs:{d:"M778.46755555 78.62044445H247.92177778c-102.51377778 0-186.02666667 83.51288889-186.02666667 186.02666666v530.432c0 102.51377778 83.51288889 186.02666667 186.02666667 186.02666667h530.432c102.51377778 0 186.70933333-83.51288889 186.02666667-186.02666667V264.64711111c0.11377778-102.62755555-83.39911111-186.02666667-185.9128889-186.02666666zM250.88 574.35022222h171.12177778c23.32444445 0 43.12177778 19.11466667 43.80444444 43.80444445v171.12177778c0 24.00711111-19.11466667 43.12177778-43.12177777 43.12177777-12.06044445 0-22.64177778-5.00622222-30.37866667-12.74311111s-12.74311111-19.11466667-12.74311111-30.37866666v-66.44622223L224.59733333 877.90933333c-16.95288889 16.95288889-44.60088889 16.95288889-61.55377778 0-16.95288889-16.95288889-16.95288889-44.60088889 0-61.55377778l154.96533334-154.96533333h-66.44622222c-24.00711111 0-43.12177778-19.11466667-43.12177778-43.12177777 0-24.12088889 18.432-43.91822222 42.43911111-43.91822223z m521.89866667-98.87288889H601.65688889c-23.32444445 0-43.12177778-19.11466667-43.80444444-43.80444444V260.55111111c0-24.00711111 19.11466667-43.12177778 43.12177777-43.12177778 12.06044445 0 22.64177778 5.00622222 30.37866667 12.74311112s12.74311111 19.11466667 12.74311111 30.37866666v66.44622222l154.96533333-154.96533333c16.95288889-16.95288889 44.60088889-16.95288889 61.55377778 0 16.95288889 16.95288889 16.95288889 44.60088889 0 61.55377778L705.536 388.55111111h66.44622222c24.00711111 0 43.12177778 19.11466667 43.12177778 43.12177778 0.11377778 24.00711111-18.31822222 43.80444445-42.32533333 43.80444444z"}}):n("path",{attrs:{d:"M762.77333333 90.24H265.49333333c-96.10666667 0-174.4 78.29333333-174.4 174.4v497.28c0 96.10666667 78.29333333 174.4 174.4 174.4h497.28c96.10666667 0 175.04-78.29333333 174.4-174.4V264.64c0-96.21333333-78.18666667-174.4-174.4-174.4z m-387.2 761.17333333H215.04c-21.86666667 0-40.42666667-17.92-41.06666667-41.06666666V649.92c0-22.50666667 17.92-40.42666667 40.42666667-40.42666667 11.30666667 0 21.22666667 4.69333333 28.48 11.94666667 7.25333333 7.25333333 11.94666667 17.92 11.94666667 28.48v62.29333333l145.28-145.28c15.89333333-15.89333333 41.81333333-15.89333333 57.70666666 0 15.89333333 15.89333333 15.89333333 41.81333333 0 57.70666667L312.53333333 769.92h62.29333334c22.50666667 0 40.42666667 17.92 40.42666666 40.42666667s-17.17333333 41.06666667-39.68 41.06666666z m274.66666667-685.65333333H810.66666667c21.86666667 0 40.42666667 17.92 41.06666666 41.06666667v160.42666666c0 22.50666667-17.92 40.42666667-40.42666666 40.42666667-11.30666667 0-21.22666667-4.69333333-28.48-11.94666667-7.25333333-7.25333333-11.94666667-17.92-11.94666667-28.48V305.06666667L625.6 450.34666667c-15.89333333 15.89333333-41.81333333 15.89333333-57.70666667 0-15.89333333-15.89333333-15.89333333-41.81333333 0-57.70666667l145.28-145.28h-62.29333333c-22.50666667 0-40.42666667-17.92-40.42666667-40.42666667s17.17333333-41.17333333 39.78666667-41.17333333z"}})])]):this._e()}),[],!1,null,null,null).exports);var at=({Vue:e})=>{e.component("BackToTop",Rn),e.component("Badge",Un),e.component("BreadCrumb",Kn),e.component("CodeGroup",Yn),e.component("CodeGroupItem",$n),e.component("Pagination",Xn),e.component("ScreenFull",tt)};class ot{constructor(e){this.registration=e}update(){return this.registration.update()}skipWaiting(){const e=this.registration.waiting;return e?(console.log("[PWA]: Execute worker.skipWaiting()."),new Promise((n,t)=>{const a=new MessageChannel;a.port1.onmessage=e=>{console.log("[PWA]: Finish worker.skipWaiting()."),e.data.error?t(e.data.error):n(e.data)},e.postMessage({type:"skip-waiting"},[a.port2])})):Promise.resolve()}}var rt=Object(Ln.a)({},(function(){var e=this.$createElement,n=this._self._c||e;return n("svg",{staticClass:"icon icon-arrow-left",attrs:{xmlns:"http://www.w3.org/2000/svg",viewBox:"0 0 512 512"}},[n("path",{attrs:{d:"M401.4 224h-214l83-79.4c11.9-12.5 11.9-32.7 0-45.2s-31.2-12.5-43.2 0L89 233.4c-6 5.8-9 13.7-9 22.4v.4c0 8.7 3 16.6 9 22.4l138.1 134c12 12.5 31.3 12.5 43.2 0 11.9-12.5 11.9-32.7 0-45.2l-83-79.4h214c16.9 0 30.6-14.3 30.6-32 .1-18-13.6-32-30.5-32z"}})])}),[],!1,null,null,null).exports,it=Object(Ln.a)({},(function(){var e=this.$createElement,n=this._self._c||e;return n("svg",{staticClass:"icon icon-arrow-right",attrs:{xmlns:"http://www.w3.org/2000/svg",viewBox:"0 0 512 512"}},[n("path",{attrs:{d:"M284.9 412.6l138.1-134c6-5.8 9-13.7 9-22.4v-.4c0-8.7-3-16.6-9-22.4l-138.1-134c-12-12.5-31.3-12.5-43.2 0-11.9 12.5-11.9 32.7 0 45.2l83 79.4h-214c-17 0-30.7 14.3-30.7 32 0 18 13.7 32 30.6 32h214l-83 79.4c-11.9 12.5-11.9 32.7 0 45.2 12 12.5 31.3 12.5 43.3 0z"}})])}),[],!1,null,null,null).exports,st=Object(Ln.a)({},(function(){var e=this.$createElement,n=this._self._c||e;return n("svg",{staticClass:"icon close-icon",attrs:{width:"23",height:"22",xmlns:"http://www.w3.org/2000/svg"}},[n("path",{attrs:{"fill-rule":"evenodd","clip-rule":"evenodd",d:"M1.12.358a1.224 1.224 0 011.729 0l8.92 8.914L20.686.358a1.224 1.224 0 011.73 1.728L13.497 11l8.92 8.913a1.222 1.222 0 11-1.73 1.729l-8.919-8.913-8.92 8.913a1.224 1.224 0 01-1.729-1.729L10.04 11l-8.92-8.914a1.222 1.222 0 010-1.728z",fill:"currentColor"}})])}),[],!1,null,null,null).exports;const lt={"/zh/":{install:"安装",iOSInstall:"点击分享按钮然后点击“添加到主屏幕”",cancel:"取消",close:"关闭",prevImage:"上一张图片",nextImage:"下一张图片",desc:"详情",feature:"主要特色",explain:"该应用可以安装在您的 PC 或移动设备上。这将使该 Web 应用程序外观和行为与其他应用程序相同。它将在出现在应用程序列表中，并可以固定到主屏幕，开始菜单或任务栏。此 Web 应用程序还将能够与其他应用程序和您的操作系统安全地进行交互。",update:"发现新内容可用"},"/en/":{install:"Install",iOSInstall:"Tap the share button and then 'Add to Homescreen'",cancel:"Cancel",close:"Close",prevImage:"Previous Image",nextImage:"Next Image",desc:"Description",feature:"Key Features",explain:"This app can be installed on your PC or mobile device.  This will allow this web app to look and behave like any other installed app.  You will find it in your app lists and be able to pin it to your home screen, start menus or task bars.  This installed web app will also be able to safely interact with other apps and your operating system. ",update:"New content is available."},"/de/":{install:"Installieren",iOSInstall:"Drucke den Share-Button und dan 'zu Homescreen hinzufügen'",cancel:"Abbrechen",close:"Schließen",prevImage:"Vorheriges Bild",nextImage:"Nächstes Bild",desc:"Berschreibung",feature:"Features",explain:"Diese App kann auf Ihrem PC oder Mobilgerät installiert werden.  Dadurch sieht diese Web-App aus und verhält sich wie jede andere installierte App.  Sie finden sie in Ihren App-Listen und können sie an den Startbildschirm, die Startmenüs oder die Taskleisten anheften.  Diese installierte Web-App kann auch sicher mit anderen Apps und Ihrem Betriebssystem interagieren.",update:"Neue Inhalte sind verfügbar."},"/vi/":{install:"Tải về",iOSInstall:"Nhấn vào nút chia sẻ và sau đó 'Thêm vào Màn hình chính'",cancel:"Huỷ bỏ",close:"Đóng",prevImage:"Hình ảnh trước đó",nextImage:"Hình ảnh tiếp theo",desc:"Sự miêu tả",feature:"Các tính năng chính",explain:"Ứng dụng này có thể được cài đặt trên PC hoặc thiết bị di động của bạn. Điều này sẽ cho phép ứng dụng web này trông và hoạt động giống như bất kỳ ứng dụng đã cài đặt nào khác. Bạn sẽ tìm thấy nó trong danh sách ứng dụng của mình và có thể ghim nó vào màn hình chính, menu bắt đầu hoặc thanh tác vụ. Ứng dụng web đã cài đặt này cũng sẽ có thể tương tác an toàn với các ứng dụng khác và hệ điều hành của bạn.",update:"Đã có nội dung mới"},"/":{install:"Install",iOSInstall:"Tap the share button and then 'Add to Homescreen'",cancel:"Cancel",close:"Close",prevImage:"Previous Image",nextImage:"Next Image",desc:"Description",feature:"Key Features",explain:"This app can be installed on your PC or mobile device.  This will allow this web app to look and behave like any other installed app.  You will find it in your app lists and be able to pin it to your home screen, start menus or task bars.  This installed web app will also be able to safely interact with other apps and your operating system. ",update:"New content is available."}};let ut,ct;var dt=a.a.extend({name:"PWAInstallModal",components:{ArrowLeftIcon:rt,ArrowRightIcon:it,CloseIcon:st},props:{useHint:{type:Boolean,default:!1}},data:()=>({manifest:{},isIOS:!1,deferredprompt:null}),computed:{i18n(){return lt[this.$localePath||"/"]}},mounted(){window.hasOwnProperty("BeforeInstallPromptEvent")&&(ct=e=>{this.deferredprompt=e,this.$emit("can-install",!0),e.preventDefault()},window.addEventListener("beforeinstallprompt",ct),this.getManifest(),ut=e=>{"Escape"===e.key&&this.$emit("toogle",!1)},document.addEventListener("keyup",ut))},beforeDestroy(){window.hasOwnProperty("BeforeInstallPromptEvent")&&document.removeEventListener("beforeinstallprompt",ct),document.removeEventListener("keyup",ut)},methods:{async getManifest(){const e=localStorage.getItem("manifest");if(e)this.manifest=JSON.parse(e);else try{const e=await fetch("/manifest.webmanifest"),n=await e.json();this.manifest=n,localStorage.setItem("manifest",JSON.stringify(n))}catch(e){console.error("Error getting manifest, check that you have a valid web manifest or network connection")}},scrollToLeft(){const e=document.querySelector(".screenshot");e&&e.scrollBy({left:-e.clientWidth,top:0,behavior:"smooth"})},scrollToRight(){const e=document.querySelector(".screenshot");e&&e.scrollBy({left:e.clientWidth,top:0,behavior:"smooth"})},async install(){if(this.deferredprompt){this.deferredprompt.prompt(),document.dispatchEvent(new CustomEvent("show"));if("accepted"===(await this.deferredprompt.userChoice).outcome)return console.info("PWA has been installed"),this.$emit("toogle",!1),this.$emit("can-install",!1),!0;console.info("You choose to not install PWA"),this.$emit("toogle",!1),this.$emit("can-install",!1)}return!1},hint(){console.info("You accepted the install hint"),this.$emit("hint")}}}),ht=(t(169),Object(Ln.a)(dt,(function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("div",{attrs:{id:"install-modal-wrapper"}},[t("div",{staticClass:"background",on:{click:function(n){return e.$emit("toogle",!1)}}}),e._v(" "),t("div",{staticClass:"install-modal"},[t("div",{staticClass:"header"},[t("button",{staticClass:"close-button",attrs:{"aria-label":e.i18n.close},on:{click:function(n){return e.$emit("toogle",!1)}}},[t("CloseIcon")],1),e._v(" "),t("div",{staticClass:"logo"},[e.manifest.icons?t("img",{attrs:{src:e.manifest.icons[0].src,alt:"App Logo"}}):e._e(),e._v(" "),t("div",{staticClass:"title"},[t("h1",[e._v(e._s(e.manifest.short_name||e.manifest.name))]),e._v(" "),t("p",{staticClass:"desc"},[e._v(e._s(e.i18n.explain))])])])]),e._v(" "),t("div",{staticClass:"content"},[t("div",{staticClass:"highlight"},[e.manifest.features?t("div",{staticClass:"feature-wrapper"},[t("h3",[e._v(e._s(e.i18n.feature))]),e._v(" "),e.manifest.features?t("ul",e._l(e.manifest.features,(function(n){return t("li",{key:n,domProps:{textContent:e._s(n)}})})),0):e._e()]):e._e(),e._v(" "),e.manifest.screenshots?t("div",{staticClass:"screenshot-wrapper"},[t("button",{attrs:{"aria-label":e.i18n.prevImage},on:{click:e.scrollToLeft}},[t("ArrowLeftIcon")],1),e._v(" "),t("section",{staticClass:"screenshot"},e._l(e.manifest.screenshots,(function(e){return t("div",{key:e.src},[t("img",{attrs:{alt:"App Screenshot",src:e.src}})])})),0),e._v(" "),t("button",{attrs:{"aria-label":e.i18n.nextImage},on:{click:e.scrollToRight}},[t("ArrowRightIcon")],1)]):e._e()]),e._v(" "),t("div",{staticClass:"description"},[t("h3",{domProps:{textContent:e._s(e.i18n.desc)}}),e._v(" "),t("p",{domProps:{textContent:e._s(e.manifest.description)}})])]),e._v(" "),e.useHint?t("div",{staticClass:"ios-text",on:{click:e.hint}},[t("p",[e._v(e._s(e.i18n.iOSInstall))]),e._v(" "),t("button",{staticClass:"success"},[e._v("Got it!")])]):t("div",{staticClass:"button-wrapper"},[t("button",{staticClass:"install-button",on:{click:e.install}},[e._v("\n        "+e._s(e.i18n.install)+" "),t("span",[e._v(e._s(e.manifest.short_name))])]),e._v(" "),t("button",{staticClass:"cancel-button",on:{click:function(n){return e.$emit("toogle",!1)}}},[e._v("\n        "+e._s(e.i18n.cancel)+"\n      ")])])])])}),[],!1,null,null,null).exports),pt=a.a.extend({name:"PWAInstall",components:{PWAInstallModal:ht},data:()=>({canInstall:!1,hasRelatedApps:!1,isOpen:!1,isIOS:!1,isSafari:!1,hinted:!1}),computed:{install(){return lt[this.$localePath||"/"].install},useHint(){return this.isIOS&&this.isSafari&&!1===this.hinted},showInstall(){return this.hasRelatedApps&&this.canInstall||this.useHint}},mounted(){if(this.getInstalledStatus()){const{userAgent:e}=navigator;this.isIOS=e.includes("iPhone")||e.includes("iPad")||Boolean(e.includes("Macintosh")&&navigator.maxTouchPoints&&navigator.maxTouchPoints>2),this.isSafari=navigator.userAgent.includes("Safari")&&!e.includes("Chrome"),this.hinted=Boolean(localStorage.getItem("iOS-pwa-hint"))}"getInstalledRelatedApps"in navigator&&navigator.getInstalledRelatedApps().then(e=>{this.hasRelatedApps=e.length>0})},methods:{getInstalledStatus:()=>navigator.standalone?navigator.standalone:matchMedia("(display-mode: standalone)").matches,hint(){this.isOpen=!1,this.hinted=!0,localStorage.setItem("iOS-pwa-hint","hinted")}}}),mt=(t(170),Object(Ln.a)(pt,(function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("div",{attrs:{id:"pwa-install"}},[e.showInstall?t("button",{staticClass:"modal-button",attrs:{"use-hint":e.useHint},domProps:{textContent:e._s(e.install)},on:{click:function(n){e.isOpen=!0}}}):e._e(),e._v(" "),t("PWAInstallModal",{directives:[{name:"show",rawName:"v-show",value:e.isOpen,expression:"isOpen"}],on:{"can-install":function(n){e.canInstall=n},hint:e.hint,toogle:function(n){e.isOpen=n}}})],1)}),[],!1,null,null,null).exports);const yt=new a.a;var gt=a.a.extend({name:"SWUpdatePopup",data:()=>({updateEvent:null}),computed:{enabled(){return Boolean(this.updateEvent)},message(){return lt[this.$localePath||"/"].update}},created(){yt.$on("sw-updated",this.onSWUpdated.bind(this))},methods:{onSWUpdated(e){this.updateEvent=e},reload(){this.updateEvent&&this.updateEvent.skipWaiting().then(()=>{location.reload(!0),this.updateEvent=null})}}}),bt=(t(171),Object(Ln.a)(gt,(function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("transition",{attrs:{name:"sw-update-popup"}},[e._t("default",(function(){return[e.enabled?t("div",{staticClass:"sw-update-popup",attrs:{role:"button",tabindex:"0"},on:{click:e.reload}},[e._v("\n      "+e._s(e.message)+"\n      "),t("span",{staticClass:"refresh"},[t("svg",{attrs:{viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg",width:"84",height:"84"}},[t("path",{attrs:{d:"M949.948959 146.249899l0 255.82655c0 21.980617-13.988596 35.969213-35.969213 35.969213l-255.82655\n            0c-13.988596 0-25.982768-7.992021-33.972742-21.980617-5.997598-13.988596-4.001127-27.977191\n            7.990998-39.97034l79.941704-77.945233c-55.954383-51.973722-121.917724-77.955466-199.862957-77.955466-37.974893 0-75.949786 8.002254-113.924679 21.99085-37.974893 15.984043-67.947532 37.974893-91.933829\n            63.956637-25.981744 23.986297-47.972595 53.958936-63.956637 91.933829-29.982872 73.954339-29.982872\n            153.895019 0 227.849358 15.984043 37.975916 37.974893 67.947532 63.956637 91.933829 23.986297 25.982768\n            53.958936 47.973618 91.933829 63.956637 37.974893 13.988596 75.949786 21.99085 113.924679 21.99085\n            45.966914 0 87.941911-9.997702 127.913275-29.981848 41.97602-17.989723 75.950809-45.966914\n            101.930507-83.942831 7.993045-4.001127 11.994172-5.995551 13.988596-5.995551 5.997598 0 9.998725\n            1.994424 13.988596 5.995551l77.957513 77.945233c3.988848 4.001127 5.986341 7.993045 5.986341\n            11.994172 0 1.994424-1.99647 5.995551-3.990894 11.994172-43.972491 51.962465-93.940532\n            91.933829-151.898549 117.91455-53.958936 25.982768-115.921149 39.971363-185.874361\n            39.971363-61.96119 0-119.921253-11.983939-169.889295-33.972742C284.40084 889.74325 236.438479\n            857.764931 202.464713\n            821.785485c-35.979446-33.972742-67.957765-81.936127-93.939509-139.897214-45.966914-101.930507-45.966914-237.846036 0-339.777567 25.981744-57.960063 57.960063-105.922425 93.939509-139.89619\n            33.973766-35.979446 81.936127-67.957765 139.89619-93.939509 49.968042-21.99085\n            107.928105-33.973766 169.889295-33.973766 55.963593 0 109.923552 9.987468 161.886017\n            29.972639 53.969169 21.99085 101.932554 51.963489 139.907447 89.938382l73.954339-73.944106c9.987468-9.997702 23.987321-13.988596 39.971363-8.002254C941.956937 120.268154 949.948959 132.261303\n            949.948959 146.249899z"}})])])]):e._e()]}),{reload:e.reload,enabled:e.enabled,message:e.message})],2)}),[],!1,null,null,null).exports);var kt=async({Vue:e,router:n,isServer:a})=>{if(e.component("PWAInstall",mt),e.component("SWUpdatePopup",bt),!a){const{register:e}=await t.e(188).then(t.bind(null,476));n.onReady(()=>{e("/service-worker.js",{registrationOptions:{},ready(){console.log("[PWA]: Service worker is active"),yt.$emit("sw-ready")},cached(e){console.log("[PWA]: Content has been cached for offline usage"),yt.$emit("sw-cached",new ot(e))},updated(e){console.log("[PWA]: Content has been updated");const n="service-worker-version",t=Number(localStorage.getItem(n)||0);localStorage.setItem(n,(t+1).toString()),localStorage.removeItem("manifest"),yt.$emit("sw-updated",new ot(e))},offline(){console.log("[PWA]: No internet connection，APP runs in offline mode"),yt.$emit("sw-offline")},error(e){console.error("[PWA]: Register Service Worker error:",e),yt.$emit("sw-error",e)}})})}};t(172);const ft=e=>{const n=document.documentElement.getBoundingClientRect(),t=e.getBoundingClientRect();return{x:t.left-n.left,y:t.top-n.top}};var wt=({Vue:e,router:n})=>{n.options.scrollBehavior=(n,t,a)=>{a?window.scrollTo({top:a.y,behavior:"smooth"}):n.hash?e.$vuepress.$get("disableScrollBehavior")||setTimeout(()=>{const e=decodeURI(n.hash.slice(1)),t=document.getElementById(e)||document.querySelector(`[name='${e}']`);t&&window.scrollTo({top:ft(t).y,behavior:"smooth"})},500):window.scrollTo({top:0,behavior:"smooth"})}},vt={tag:{},category:{}};class qt{constructor(e,n){this._metaMap=Object.assign({},e),Object.keys(this._metaMap).forEach(e=>{const{pageKeys:t}=this._metaMap[e];this._metaMap[e].pages=t.map(e=>function(e,n){for(let t=0;t<e.length;t++){const a=e[t];if(a.key===n)return a}return{path:"",frontmatter:{}}}(n,e))})}get length(){return Object.keys(this._metaMap).length}get map(){return this._metaMap}get pages(){return this.list}get list(){return this.toArray()}toArray(){const e=[];return Object.keys(this._metaMap).forEach(n=>{const{pages:t,path:a}=this._metaMap[n];e.push({name:n,pages:t,path:a})}),e}getItemByName(e){return this._metaMap[e]}}var xt=t(61);const jt=t.n(xt)()("plugin-blog:pagination");class St{constructor(e,n,t){jt("pagination",e);const{pages:a,prevText:o,nextText:r}=e,{path:i}=t;this._prevText=o,this._nextText=r;for(let e=0,n=a.length;e<n;e++){if(a[e].path===i){this.paginationIndex=e;break}}this.paginationIndex||(this.paginationIndex=0),this._paginationPages=a,this._currentPage=a[this.paginationIndex],this._matchedPages=n.filter(n=>e.filter(n,e.id,e.pid)).sort(e.sorter)}setIndexPage(e){this._indexPage=e}get length(){return this._paginationPages.length}get pages(){const[e,n]=this._currentPage.interval;return this._matchedPages.slice(e,n+1)}get hasPrev(){return 0!==this.paginationIndex}get prevLink(){return this.hasPrev?this.paginationIndex-1==0&&this._indexPage?this._indexPage:this._paginationPages[this.paginationIndex-1].path:null}get hasNext(){return this.paginationIndex!==this.length-1}get nextLink(){return this.hasNext?this._paginationPages[this.paginationIndex+1].path:null}get prevText(){return this._prevText}get nextText(){return this._nextText}getSpecificPageLink(e){return this._paginationPages[e].path}}const Tt=new class{constructor(e){this.paginations=e}get pages(){return a.a.$vuepress.$get("siteData").pages}getPagination(e,n,t){jt("id",n),jt("pid",e);const a=this.paginations.filter(t=>t.id===n&&t.pid===e)[0];return new St(a,this.pages,t)}}([]);var zt={comment:{enabled:!1,service:""},email:{enabled:!1},feed:{rss:!1,atom:!1,json:!1}};t(175),t(16),t(176);var Qt=({Vue:e})=>{};let It;const Pt={"/zh/":{close:"关闭",fullsreen:"切换全屏",share:"分享",zoom:"缩放",prev:"上一个 (左箭头)",next:"下一个 (右箭头)",buttons:[{id:"qq",label:"分享到 QQ",url:"https://connect.qq.com/widget/shareqq/iframe_index.html?url={{url}}&title={{text}}&pics={{image_url}}"},{id:"qzone",label:"分享到 Qzone",url:"https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url={{url}}&title={{text}}&pics={{image_url}}"},{id:"weibo",label:"分享到 Weibo",url:"http://service.weibo.com/share/share.php?url={{url}}&title={{text}}&content=utf8&pic={{image_url}}"},{id:"download",label:"下载图片",url:"{{raw_image_url}}",download:!0}]},"/en/":{close:"Close",fullsreen:"Vollbild umschalten",share:"Teilen",zoom:"Zoom in/out",prev:"Prev (Arrow Left)",next:"Next (Arrow Right)",buttons:[{id:"facebook",label:"Share on Facebook",url:"https://www.facebook.com/sharer/sharer.php?u={{url}}"},{id:"twitter",label:"Tweet",url:"https://twitter.com/intent/tweet?text={{text}}&url={{url}}"},{id:"pinterest",label:"Pin it",url:"http://www.pinterest.com/pin/create/button/?url={{url}}&media={{image_url}}&description={{text}}"},{id:"download",label:"Download image",url:"{{raw_image_url}}",download:!0}]},"/de/":{close:"Schließen",fullsreen:"Toggle fullscreen",share:"Teilen",zoom:"Rein / rauszoomen",prev:"Zurück (Pfeil links)",next:"Weiter (Pfeil rechts)",buttons:[{id:"facebook",label:"Teilen auf Facebook",url:"https://www.facebook.com/sharer/sharer.php?u={{url}}"},{id:"twitter",label:"Tweet",url:"https://twitter.com/intent/tweet?text={{text}}&url={{url}}"},{id:"pinterest",label:"Pin it",url:"http://www.pinterest.com/pin/create/button/?url={{url}}&media={{image_url}}&description={{text}}"},{id:"download",label:"Bild herunterladen",url:"{{raw_image_url}}",download:!0}]},"/vi/":{close:"Đóng",fullsreen:"Bật chế độ toàn màn hình",share:"Chia sẻ",zoom:"Phóng to / thu nhỏ",prev:"Trước (Mũi tên trái)",next:"Tiếp theo (Mũi tên Phải)",buttons:[{id:"facebook",label:"Share on Facebook",url:"https://www.facebook.com/sharer/sharer.php?u={{url}}"},{id:"twitter",label:"Tweet",url:"https://twitter.com/intent/tweet?text={{text}}&url={{url}}"},{id:"pinterest",label:"Pin it",url:"http://www.pinterest.com/pin/create/button/?url={{url}}&media={{image_url}}&description={{text}}"},{id:"download",label:"Download image",url:"{{raw_image_url}}",download:!0}]},"/":{close:"Close",fullsreen:"Vollbild umschalten",share:"Teilen",zoom:"Zoom in/out",prev:"Prev (Arrow Left)",next:"Next (Arrow Right)",buttons:[{id:"facebook",label:"Share on Facebook",url:"https://www.facebook.com/sharer/sharer.php?u={{url}}"},{id:"twitter",label:"Tweet",url:"https://twitter.com/intent/tweet?text={{text}}&url={{url}}"},{id:"pinterest",label:"Pin it",url:"http://www.pinterest.com/pin/create/button/?url={{url}}&media={{image_url}}&description={{text}}"},{id:"download",label:"Download image",url:"{{raw_image_url}}",download:!0}]}};var _t=a.a.extend({name:"PhotoSwipeUI",data:()=>({i18n:Pt}),watch:{$route(){const e=setInterval(()=>{document.querySelector(".theme-default-content")&&(this.photoswipe(),clearInterval(e))},200)}},mounted(){const e=setInterval(()=>{document.querySelector(".theme-default-content")&&(this.photoswipe(),clearInterval(e))},200)},methods:{photoswipe(){const e=document.querySelector(".pswp");Promise.all([t.e(187).then(t.t.bind(null,477,7)),t.e(187).then(t.t.bind(null,478,7))]).then(([n,t])=>{this.getImages().then(a=>{It.forEach((o,r)=>{o.onclick=()=>{new n.default(e,t.default,a,Object.assign(Object.assign({shareButtons:Pt[this.$localePath||"/"].buttons},{}),{index:r})).init()}})})})},getImageInfo:e=>({src:e.src,w:e.naturalWidth,h:e.naturalHeight,title:e.alt}),getImages(){const e=[];return It=document.querySelectorAll(".theme-default-content :not(a) > img"),It.forEach((n,t)=>{e[t]=new Promise((e,t)=>{n.complete?e(this.getImageInfo(n)):(n.onload=()=>e(this.getImageInfo(n)),n.onerror=e=>t(e))})}),Promise.all(e)}}}),Ct=(t(177),Object(Ln.a)(_t,(function(){var e=this,n=e.$createElement,t=e._self._c||n;return t("div",{staticClass:"pswp",attrs:{tabindex:"-1",role:"dialog","aria-hidden":"true"}},[t("div",{staticClass:"pswp__bg"}),e._v(" "),t("div",{staticClass:"pswp__scroll-wrap"},[e._m(0),e._v(" "),t("div",{staticClass:"pswp__ui pswp__ui--hidden"},[t("div",{staticClass:"pswp__top-bar"},[t("div",{staticClass:"pswp__counter"}),e._v(" "),t("button",{staticClass:"pswp__button pswp__button--close",attrs:{title:e.i18n.close,"aria-label":e.i18n.close}}),e._v(" "),t("button",{staticClass:"pswp__button pswp__button--share",attrs:{title:e.i18n.share,"aria-label":e.i18n.share}}),e._v(" "),t("button",{staticClass:"pswp__button pswp__button--fs",attrs:{title:e.i18n.fullscreen,"aria-label":e.i18n.fullscreen}}),e._v(" "),t("button",{staticClass:"pswp__button pswp__button--zoom",attrs:{title:e.i18n.zoom,"aria-label":e.i18n.zoom}}),e._v(" "),e._m(1)]),e._v(" "),e._m(2),e._v(" "),t("button",{staticClass:"pswp__button pswp__button--arrow--left",attrs:{title:e.i18n.prev,"aria-label":e.i18n.prev}}),e._v(" "),t("button",{staticClass:"pswp__button pswp__button--arrow--right",attrs:{title:e.i18n.next,"aria-label":e.i18n.next}}),e._v(" "),e._m(3)])])])}),[function(){var e=this.$createElement,n=this._self._c||e;return n("div",{staticClass:"pswp__container"},[n("div",{staticClass:"pswp__item"}),this._v(" "),n("div",{staticClass:"pswp__item"}),this._v(" "),n("div",{staticClass:"pswp__item"})])},function(){var e=this.$createElement,n=this._self._c||e;return n("div",{staticClass:"pswp__preloader"},[n("div",{staticClass:"pswp__preloader__icn"},[n("div",{staticClass:"pswp__preloader__cut"},[n("div",{staticClass:"pswp__preloader__donut"})])])])},function(){var e=this.$createElement,n=this._self._c||e;return n("div",{staticClass:"pswp__share-modal pswp__share-modal--hidden pswp__single-tap"},[n("div",{staticClass:"pswp__share-tooltip"})])},function(){var e=this.$createElement,n=this._self._c||e;return n("div",{staticClass:"pswp__caption"},[n("div",{staticClass:"pswp__caption__center"})])}],!1,null,null,null).exports);var At=[{},({Vue:e})=>{e.mixin({computed:{$dataBlock(){return this.$options.__data__block__}}})},{},at,kt,wt,({Vue:e})=>{const n=Object.keys(vt).map(e=>{const n=vt[e],t="$"+e;return{[t](){const{pages:e}=this.$site;return new qt(n,e)},["$current"+(e.charAt(0).toUpperCase()+e.slice(1))](){const e=this.$route.meta.id;return this[t].getItemByName(e)}}}).reduce((e,n)=>(Object.assign(e,n),e),{});n.$frontmatterKey=function(){const e=this["$"+this.$route.meta.id];return e||null},e.mixin({computed:n})},({Vue:e})=>{e.mixin({computed:{$pagination(){return this.$route.meta.pid&&this.$route.meta.id?this.$getPagination(this.$route.meta.pid,this.$route.meta.id):null}},methods:{$getPagination(e,n){return n=n||e,Tt.getPagination(e,n,this.$route)}}})},({Vue:e})=>{const n={$service:()=>zt};e.mixin({computed:n})},{},Qt,({Vue:e})=>{e.component("PhotoSwipeUI",Ct)},({router:e})=>{0}],Ot=["BackToTop","SWUpdatePopup","PWAInstall","PhotoSwipeUI"];class Ht extends class{constructor(){this.store=new a.a({data:{state:{}}})}$get(e){return this.store.state[e]}$set(e,n){a.a.set(this.store.state,e,n)}$emit(...e){this.store.$emit(...e)}$on(...e){this.store.$on(...e)}}{}Object.assign(Ht.prototype,{getPageAsyncComponent:un,getLayoutAsyncComponent:cn,getAsyncComponent:dn,getVueComponent:hn});var Lt={install(e){const n=new Ht;e.$vuepress=n,e.prototype.$vuepress=n}};function Dt(e,n){const t=n.toLowerCase();return e.options.routes.some(e=>e.path.toLowerCase()===t)}var Et={props:{pageKey:String,slotKey:{type:String,default:"default"}},render(e){const n=this.pageKey||this.$parent.$page.key;return mn("pageKey",n),a.a.component(n)||a.a.component(n,un(n)),a.a.component(n)?e(n):e("")}},Bt={functional:!0,props:{slotKey:String,required:!0},render:(e,{props:n,slots:t})=>e("div",{class:["content__"+n.slotKey]},t()[n.slotKey])},Gt={computed:{openInNewWindowTitle(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Nt=(t(178),t(179),Object(Ln.a)(Gt,(function(){var e=this.$createElement,n=this._self._c||e;return n("span",[n("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[n("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),n("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),n("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports),Mt={functional:!0,render(e,{parent:n,children:t}){if(n._isMounted)return t;n.$once("hook:mounted",()=>{n.$forceUpdate()})}};a.a.config.productionTip=!1,a.a.use(Ke),a.a.use(Lt),a.a.mixin(function(e,n,t=a.a){!function(e){e.locales&&Object.keys(e.locales).forEach(n=>{e.locales[n].path=n});Object.freeze(e)}(n),t.$vuepress.$set("siteData",n);const o=new(e(t.$vuepress.$get("siteData"))),r=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(o)),i={};return Object.keys(r).reduce((e,n)=>(n.startsWith("$")&&(e[n]=r[n].get),e),i),{computed:i}}(e=>class{setPage(e){this.__page=e}get $site(){return e}get $themeConfig(){return this.$site.themeConfig}get $frontmatter(){return this.$page.frontmatter}get $localeConfig(){const{locales:e={}}=this.$site;let n,t;for(const a in e)"/"===a?t=e[a]:0===this.$page.path.indexOf(a)&&(n=e[a]);return n||t||{}}get $siteTitle(){return this.$localeConfig.title||this.$site.title||""}get $canonicalUrl(){const{canonicalUrl:e}=this.$page.frontmatter;return"string"==typeof e&&e}get $title(){const e=this.$page,{metaTitle:n}=this.$page.frontmatter;if("string"==typeof n)return n;const t=this.$siteTitle,a=e.frontmatter.home?null:e.frontmatter.title||e.title;return t?a?a+" | "+t:t:a||"VuePress"}get $description(){const e=function(e){if(e){const n=e.filter(e=>"description"===e.name)[0];if(n)return n.content}}(this.$page.frontmatter.meta);return e||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}get $lang(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}get $localePath(){return this.$localeConfig.path||"/"}get $themeLocaleConfig(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}get $page(){return this.__page?this.__page:function(e,n){for(let t=0;t<e.length;t++){const a=e[t];if(a.path.toLowerCase()===n.toLowerCase())return a}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}},Bn)),a.a.component("Content",Et),a.a.component("ContentSlotsDistributor",Bt),a.a.component("OutboundLink",Nt),a.a.component("ClientOnly",Mt),a.a.component("Layout",cn("Layout")),a.a.component("NotFound",cn("NotFound")),a.a.prototype.$withBase=function(e){const n=this.$site.base;return"/"===e.charAt(0)?n+e.slice(1):e},window.__VUEPRESS__={version:"1.8.2",hash:"190e6a1"},async function(e){const n="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:Bn.routerBase||Bn.base,t=new Ke({base:n,mode:"history",fallback:!1,routes:En,scrollBehavior:(e,n,t)=>t||(e.hash?!a.a.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(e.hash)}:{x:0,y:0})});!function(e){e.beforeEach((n,t,a)=>{if(Dt(e,n.path))a();else if(/(\/|\.html)$/.test(n.path))if(/\/$/.test(n.path)){const t=n.path.replace(/\/$/,"")+".html";Dt(e,t)?a(t):a()}else a();else{const t=n.path+"/",o=n.path+".html";Dt(e,o)?a(o):Dt(e,t)?a(t):a()}})}(t);const o={};try{await Promise.all(At.filter(e=>"function"==typeof e).map(n=>n({Vue:a.a,options:o,router:t,siteData:Bn,isServer:e})))}catch(e){console.error(e)}return{app:new a.a(Object.assign(o,{router:t,render:e=>e("div",{attrs:{id:"app"}},[e("RouterView",{ref:"layout"}),e("div",{class:"global-ui"},Ot.map(n=>e(n)))])})),router:t}}(!1).then(({app:e,router:n})=>{n.onReady(()=>{e.$mount("#app")})})}]);